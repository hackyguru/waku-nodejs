import { v as version_0, e as encodingLength, a as encode$1, d as decode$1, M as MessagePush, F as FilterSubscribeRequest, b as FilterSubscribeResponse$1, P as PushRpc$1, c as PushResponse, S as StoreQueryRequest$1, f as StoreQueryResponse$1, g as createEncoder, p as pubsubTopicToSingleShardInfo, s as shardInfoToPubsubTopics, W as WakuMetadataRequest, h as pubsubTopicsToShardInfo, i as WakuMetadataResponse } from './version_0-CdmZMfkQ.js';
export { j as createDecoder } from './version_0-CdmZMfkQ.js';
import { a as allocUnsafe, b as alloc, L as Logger, P as ProtocolError, u as utf8ToBytes, T as Tags, E as EPeersByDiscoveryEvents, c as EConnectionStateEvents, H as HealthStatus, d as Protocols } from './index-BIW3qNYx.js';
import { B as BaseProtocol } from './base_protocol-Dzv-QHPR.js';
export { S as StreamManager } from './base_protocol-Dzv-QHPR.js';

const MB = 1024 ** 2;
const SIZE_CAP_IN_MB = 1;
/**
 * Return whether the size of the message is under the upper limit for the network.
 * This performs a protobuf encoding! If you have access to the fully encoded message,
 * use {@link isSizeUnderCapBuf} instead.
 * @param message
 * @param encoder
 */
async function isMessageSizeUnderCap(encoder, message) {
    const buf = await encoder.toWire(message);
    if (!buf)
        return false;
    return isWireSizeUnderCap(buf);
}
const isWireSizeUnderCap = (buf) => buf.length / MB <= SIZE_CAP_IN_MB;

const DNS_DISCOVERY_TAG = "@waku/bootstrap";

const decodeRelayShard = (bytes) => {
    // explicitly converting to Uint8Array to avoid Buffer
    // https://github.com/libp2p/js-libp2p/issues/2146
    bytes = new Uint8Array(bytes);
    if (bytes.length < 3)
        throw new Error("Insufficient data");
    const view = new DataView(bytes.buffer);
    const clusterId = view.getUint16(0);
    const shards = [];
    if (bytes.length === 130) {
        // rsv format (Bit Vector)
        for (let i = 0; i < 1024; i++) {
            const byteIndex = Math.floor(i / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (i % 8);
            if (view.getUint8(byteIndex) & (1 << bitIndex)) {
                shards.push(i);
            }
        }
    }
    else {
        // rs format (Index List)
        const numIndices = view.getUint8(2);
        for (let i = 0, offset = 3; i < numIndices; i++, offset += 2) {
            if (offset + 1 >= bytes.length)
                throw new Error("Unexpected end of data");
            shards.push(view.getUint16(offset));
        }
    }
    return { clusterId, shards };
};
const encodeRelayShard = (shardInfo) => {
    const { clusterId, shards } = shardInfo;
    const totalLength = shards.length >= 64 ? 130 : 3 + 2 * shards.length;
    const buffer = new ArrayBuffer(totalLength);
    const view = new DataView(buffer);
    view.setUint16(0, clusterId);
    if (shards.length >= 64) {
        // rsv format (Bit Vector)
        for (const index of shards) {
            const byteIndex = Math.floor(index / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (index % 8);
            view.setUint8(byteIndex, view.getUint8(byteIndex) | (1 << bitIndex));
        }
    }
    else {
        // rs format (Index List)
        view.setUint8(2, shards.length);
        for (let i = 0, offset = 3; i < shards.length; i++, offset += 2) {
            view.setUint16(offset, shards[i]);
        }
    }
    return new Uint8Array(buffer);
};

var index$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    version_0: version_0
});

/**
 * @packageDocumentation
 *
 * For when you need a one-liner to collect iterable values.
 *
 * @example
 *
 * ```javascript
 * import all from 'it-all'
 *
 * // This can also be an iterator, etc
 * const values = function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = all(values)
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = await all(values())
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 */
function isAsyncIterable$3(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function all(source) {
    if (isAsyncIterable$3(source)) {
        return (async () => {
            const arr = [];
            for await (const entry of source) {
                arr.push(entry);
            }
            return arr;
        })();
    }
    const arr = [];
    for (const entry of source) {
        arr.push(entry);
    }
    return arr;
}

/**
 * To guarantee Uint8Array semantics, convert nodejs Buffers
 * into vanilla Uint8Arrays
 */
function asUint8Array(buf) {
    return buf;
}

/**
 * Returns a new Uint8Array created by concatenating the passed Uint8Arrays
 */
function concat(arrays, length) {
    if (length == null) {
        length = arrays.reduce((acc, curr) => acc + curr.length, 0);
    }
    const output = allocUnsafe(length);
    let offset = 0;
    for (const arr of arrays) {
        output.set(arr, offset);
        offset += arr.length;
    }
    return asUint8Array(output);
}

/**
 * Returns true if the two passed Uint8Arrays have the same content
 */
function equals(a, b) {
    if (a === b) {
        return true;
    }
    if (a.byteLength !== b.byteLength) {
        return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
}

/**
 * @packageDocumentation
 *
 * A class that lets you do operations over a list of Uint8Arrays without
 * copying them.
 *
 * ```js
 * import { Uint8ArrayList } from 'uint8arraylist'
 *
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray()
 * // -> Uint8Array([0, 1, 2, 3, 4, 5])
 *
 * list.consume(3)
 * list.subarray()
 * // -> Uint8Array([3, 4, 5])
 *
 * // you can also iterate over the list
 * for (const buf of list) {
 *   // ..do something with `buf`
 * }
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ## Converting Uint8ArrayLists to Uint8Arrays
 *
 * There are two ways to turn a `Uint8ArrayList` into a `Uint8Array` - `.slice` and `.subarray` and one way to turn a `Uint8ArrayList` into a `Uint8ArrayList` with different contents - `.sublist`.
 *
 * ### slice
 *
 * Slice follows the same semantics as [Uint8Array.slice](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/slice) in that it creates a new `Uint8Array` and copies bytes into it using an optional offset & length.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.slice(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ### subarray
 *
 * Subarray attempts to follow the same semantics as [Uint8Array.subarray](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/subarray) with one important different - this is a no-copy operation, unless the requested bytes span two internal buffers in which case it is a copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0]) - no-copy
 *
 * list.subarray(2, 5)
 * // -> Uint8Array([2, 3, 4]) - copy
 * ```
 *
 * ### sublist
 *
 * Sublist creates and returns a new `Uint8ArrayList` that shares the underlying buffers with the original so is always a no-copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.sublist(0, 1)
 * // -> Uint8ArrayList([0]) - no-copy
 *
 * list.sublist(2, 5)
 * // -> Uint8ArrayList([2], [3, 4]) - no-copy
 * ```
 *
 * ## Inspiration
 *
 * Borrows liberally from [bl](https://www.npmjs.com/package/bl) but only uses native JS types.
 */
const symbol = Symbol.for('@achingbrain/uint8arraylist');
function findBufAndOffset(bufs, index) {
    if (index == null || index < 0) {
        throw new RangeError('index is out of bounds');
    }
    let offset = 0;
    for (const buf of bufs) {
        const bufEnd = offset + buf.byteLength;
        if (index < bufEnd) {
            return {
                buf,
                index: index - offset
            };
        }
        offset = bufEnd;
    }
    throw new RangeError('index is out of bounds');
}
/**
 * Check if object is a CID instance
 *
 * @example
 *
 * ```js
 * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'
 *
 * isUint8ArrayList(true) // false
 * isUint8ArrayList([]) // false
 * isUint8ArrayList(new Uint8ArrayList()) // true
 * ```
 */
function isUint8ArrayList(value) {
    return Boolean(value?.[symbol]);
}
class Uint8ArrayList {
    bufs;
    length;
    [symbol] = true;
    constructor(...data) {
        this.bufs = [];
        this.length = 0;
        if (data.length > 0) {
            this.appendAll(data);
        }
    }
    *[Symbol.iterator]() {
        yield* this.bufs;
    }
    get byteLength() {
        return this.length;
    }
    /**
     * Add one or more `bufs` to the end of this Uint8ArrayList
     */
    append(...bufs) {
        this.appendAll(bufs);
    }
    /**
     * Add all `bufs` to the end of this Uint8ArrayList
     */
    appendAll(bufs) {
        let length = 0;
        for (const buf of bufs) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.push(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.push(...buf.bufs);
            }
            else {
                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Add one or more `bufs` to the start of this Uint8ArrayList
     */
    prepend(...bufs) {
        this.prependAll(bufs);
    }
    /**
     * Add all `bufs` to the start of this Uint8ArrayList
     */
    prependAll(bufs) {
        let length = 0;
        for (const buf of bufs.reverse()) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.unshift(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.unshift(...buf.bufs);
            }
            else {
                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Read the value at `index`
     */
    get(index) {
        const res = findBufAndOffset(this.bufs, index);
        return res.buf[res.index];
    }
    /**
     * Set the value at `index` to `value`
     */
    set(index, value) {
        const res = findBufAndOffset(this.bufs, index);
        res.buf[res.index] = value;
    }
    /**
     * Copy bytes from `buf` to the index specified by `offset`
     */
    write(buf, offset = 0) {
        if (buf instanceof Uint8Array) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf[i]);
            }
        }
        else if (isUint8ArrayList(buf)) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf.get(i));
            }
        }
        else {
            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');
        }
    }
    /**
     * Remove bytes from the front of the pool
     */
    consume(bytes) {
        // first, normalize the argument, in accordance with how Buffer does it
        bytes = Math.trunc(bytes);
        // do nothing if not a positive number
        if (Number.isNaN(bytes) || bytes <= 0) {
            return;
        }
        // if consuming all bytes, skip iterating
        if (bytes === this.byteLength) {
            this.bufs = [];
            this.length = 0;
            return;
        }
        while (this.bufs.length > 0) {
            if (bytes >= this.bufs[0].byteLength) {
                bytes -= this.bufs[0].byteLength;
                this.length -= this.bufs[0].byteLength;
                this.bufs.shift();
            }
            else {
                this.bufs[0] = this.bufs[0].subarray(bytes);
                this.length -= bytes;
                break;
            }
        }
    }
    /**
     * Extracts a section of an array and returns a new array.
     *
     * This is a copy operation as it is with Uint8Arrays and Arrays
     * - note this is different to the behaviour of Node Buffers.
     */
    slice(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        return concat(bufs, length);
    }
    /**
     * Returns a alloc from the given start and end element index.
     *
     * In the best case where the data extracted comes from a single Uint8Array
     * internally this is a no-copy operation otherwise it is a copy operation.
     */
    subarray(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        if (bufs.length === 1) {
            return bufs[0];
        }
        return concat(bufs, length);
    }
    /**
     * Returns a allocList from the given start and end element index.
     *
     * This is a no-copy operation.
     */
    sublist(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        const list = new Uint8ArrayList();
        list.length = length;
        // don't loop, just set the bufs
        list.bufs = [...bufs];
        return list;
    }
    _subList(beginInclusive, endExclusive) {
        beginInclusive = beginInclusive ?? 0;
        endExclusive = endExclusive ?? this.length;
        if (beginInclusive < 0) {
            beginInclusive = this.length + beginInclusive;
        }
        if (endExclusive < 0) {
            endExclusive = this.length + endExclusive;
        }
        if (beginInclusive < 0 || endExclusive > this.length) {
            throw new RangeError('index is out of bounds');
        }
        if (beginInclusive === endExclusive) {
            return { bufs: [], length: 0 };
        }
        if (beginInclusive === 0 && endExclusive === this.length) {
            return { bufs: this.bufs, length: this.length };
        }
        const bufs = [];
        let offset = 0;
        for (let i = 0; i < this.bufs.length; i++) {
            const buf = this.bufs[i];
            const bufStart = offset;
            const bufEnd = bufStart + buf.byteLength;
            // for next loop
            offset = bufEnd;
            if (beginInclusive >= bufEnd) {
                // start after this buf
                continue;
            }
            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
            if (sliceStartInBuf && sliceEndsInBuf) {
                // slice is wholly contained within this buffer
                if (beginInclusive === bufStart && endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                const start = beginInclusive - bufStart;
                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));
                break;
            }
            if (sliceStartInBuf) {
                // slice starts in this buffer
                if (beginInclusive === 0) {
                    // requested whole buffer
                    bufs.push(buf);
                    continue;
                }
                // requested part of buffer
                bufs.push(buf.subarray(beginInclusive - bufStart));
                continue;
            }
            if (sliceEndsInBuf) {
                if (endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                bufs.push(buf.subarray(0, endExclusive - bufStart));
                break;
            }
            // slice started before this buffer and ends after it
            bufs.push(buf);
        }
        return { bufs, length: endExclusive - beginInclusive };
    }
    indexOf(search, offset = 0) {
        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
            throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
        }
        const needle = search instanceof Uint8Array ? search : search.subarray();
        offset = Number(offset ?? 0);
        if (isNaN(offset)) {
            offset = 0;
        }
        if (offset < 0) {
            offset = this.length + offset;
        }
        if (offset < 0) {
            offset = 0;
        }
        if (search.length === 0) {
            return offset > this.length ? this.length : offset;
        }
        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm
        const M = needle.byteLength;
        if (M === 0) {
            throw new TypeError('search must be at least 1 byte long');
        }
        // radix
        const radix = 256;
        const rightmostPositions = new Int32Array(radix);
        // position of the rightmost occurrence of the byte c in the pattern
        for (let c = 0; c < radix; c++) {
            // -1 for bytes not in pattern
            rightmostPositions[c] = -1;
        }
        for (let j = 0; j < M; j++) {
            // rightmost position for bytes in pattern
            rightmostPositions[needle[j]] = j;
        }
        // Return offset of first match, -1 if no match
        const right = rightmostPositions;
        const lastIndex = this.byteLength - needle.byteLength;
        const lastPatIndex = needle.byteLength - 1;
        let skip;
        for (let i = offset; i <= lastIndex; i += skip) {
            skip = 0;
            for (let j = lastPatIndex; j >= 0; j--) {
                const char = this.get(i + j);
                if (needle[j] !== char) {
                    skip = Math.max(1, j - right[char]);
                    break;
                }
            }
            if (skip === 0) {
                return i;
            }
        }
        return -1;
    }
    getInt8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt8(0);
    }
    setInt8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt8(0, value);
        this.write(buf, byteOffset);
    }
    getInt16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt16(0, littleEndian);
    }
    setInt16(byteOffset, value, littleEndian) {
        const buf = alloc(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getInt32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt32(0, littleEndian);
    }
    setInt32(byteOffset, value, littleEndian) {
        const buf = alloc(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigInt64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigInt64(0, littleEndian);
    }
    setBigInt64(byteOffset, value, littleEndian) {
        const buf = alloc(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigInt64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint8(0);
    }
    setUint8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint8(0, value);
        this.write(buf, byteOffset);
    }
    getUint16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint16(0, littleEndian);
    }
    setUint16(byteOffset, value, littleEndian) {
        const buf = alloc(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint32(0, littleEndian);
    }
    setUint32(byteOffset, value, littleEndian) {
        const buf = alloc(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigUint64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigUint64(0, littleEndian);
    }
    setBigUint64(byteOffset, value, littleEndian) {
        const buf = alloc(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigUint64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat32(0, littleEndian);
    }
    setFloat32(byteOffset, value, littleEndian) {
        const buf = alloc(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat64(0, littleEndian);
    }
    setFloat64(byteOffset, value, littleEndian) {
        const buf = alloc(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (!(other instanceof Uint8ArrayList)) {
            return false;
        }
        if (other.bufs.length !== this.bufs.length) {
            return false;
        }
        for (let i = 0; i < this.bufs.length; i++) {
            if (!equals(this.bufs[i], other.bufs[i])) {
                return false;
            }
        }
        return true;
    }
    /**
     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
     * method if you know the total size of all the Uint8Arrays ahead of time.
     */
    static fromUint8Arrays(bufs, length) {
        const list = new Uint8ArrayList();
        list.bufs = bufs;
        if (length == null) {
            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
        }
        list.length = length;
        return list;
    }
}
/*
function indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {
  for (let i = offset; i < haystack.byteLength; i++) {
    for (let j = 0; j < needle.length; j++) {
      if (haystack[i + j] !== needle[j]) {
        break
      }

      if (j === needle.byteLength -1) {
        return i
      }
    }

    if (haystack.byteLength - i < needle.byteLength) {
      break
    }
  }

  return -1
}
*/

function isAsyncIterable$2(thing) {
    return thing[Symbol.asyncIterator] != null;
}

const defaultEncoder = (length) => {
    const lengthLength = encodingLength(length);
    const lengthBuf = allocUnsafe(lengthLength);
    encode$1(length, lengthBuf);
    defaultEncoder.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder.bytes = 0;
function encode(source, options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    function* maybeYield(chunk) {
        // length + data
        const length = encodeLength(chunk.byteLength);
        // yield only Uint8Arrays
        if (length instanceof Uint8Array) {
            yield length;
        }
        else {
            yield* length;
        }
        // yield only Uint8Arrays
        if (chunk instanceof Uint8Array) {
            yield chunk;
        }
        else {
            yield* chunk;
        }
    }
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            for await (const chunk of source) {
                yield* maybeYield(chunk);
            }
        })();
    }
    return (function* () {
        for (const chunk of source) {
            yield* maybeYield(chunk);
        }
    })();
}
encode.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

/**
 * The reported length of the next data message was not a positive integer
 */
class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
}
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
}
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
}
/**
 * The incoming stream ended before the expected number of bytes were read
 */
class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
}

/* eslint max-depth: ["error", 6] */
// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH = 1024 * 1024 * 4;
var ReadMode;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode || (ReadMode = {}));
const defaultDecoder = (buf) => {
    const length = decode$1(buf);
    defaultDecoder.bytes = encodingLength(length);
    return length;
};
defaultDecoder.bytes = 0;
function decode(source, options) {
    const buffer = new Uint8ArrayList();
    let mode = ReadMode.LENGTH;
    let dataLength = -1;
    const lengthDecoder = options?.lengthDecoder ?? defaultDecoder;
    const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
    function* maybeYield() {
        while (buffer.byteLength > 0) {
            if (mode === ReadMode.LENGTH) {
                // read length, ignore errors for short reads
                try {
                    dataLength = lengthDecoder(buffer);
                    if (dataLength < 0) {
                        throw new InvalidMessageLengthError('Invalid message length');
                    }
                    if (dataLength > maxDataLength) {
                        throw new InvalidDataLengthError('Message length too long');
                    }
                    const dataLengthLength = lengthDecoder.bytes;
                    buffer.consume(dataLengthLength);
                    if (options?.onLength != null) {
                        options.onLength(dataLength);
                    }
                    mode = ReadMode.DATA;
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        if (buffer.byteLength > maxLengthLength) {
                            throw new InvalidDataLengthLengthError('Message length length too long');
                        }
                        break;
                    }
                    throw err;
                }
            }
            if (mode === ReadMode.DATA) {
                if (buffer.byteLength < dataLength) {
                    // not enough data, wait for more
                    break;
                }
                const data = buffer.sublist(0, dataLength);
                buffer.consume(dataLength);
                if (options?.onData != null) {
                    options.onData(data);
                }
                yield data;
                mode = ReadMode.LENGTH;
            }
        }
    }
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            for await (const buf of source) {
                buffer.append(buf);
                yield* maybeYield();
            }
            if (buffer.byteLength > 0) {
                throw new UnexpectedEOFError('Unexpected end of input');
            }
        })();
    }
    return (function* () {
        for (const buf of source) {
            buffer.append(buf);
            yield* maybeYield();
        }
        if (buffer.byteLength > 0) {
            throw new UnexpectedEOFError('Unexpected end of input');
        }
    })();
}
decode.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode(varByteSource, {
        ...(options ?? {}),
        onLength
    });
};

function pDefer() {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
}

// ported from https://www.npmjs.com/package/fast-fifo
class FixedFIFO {
    buffer;
    mask;
    top;
    btm;
    next;
    constructor(hwm) {
        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {
            throw new Error('Max size for a FixedFIFO should be a power of two');
        }
        this.buffer = new Array(hwm);
        this.mask = hwm - 1;
        this.top = 0;
        this.btm = 0;
        this.next = null;
    }
    push(data) {
        if (this.buffer[this.top] !== undefined) {
            return false;
        }
        this.buffer[this.top] = data;
        this.top = (this.top + 1) & this.mask;
        return true;
    }
    shift() {
        const last = this.buffer[this.btm];
        if (last === undefined) {
            return undefined;
        }
        this.buffer[this.btm] = undefined;
        this.btm = (this.btm + 1) & this.mask;
        return last;
    }
    isEmpty() {
        return this.buffer[this.btm] === undefined;
    }
}
class FIFO {
    size;
    hwm;
    head;
    tail;
    constructor(options = {}) {
        this.hwm = options.splitLimit ?? 16;
        this.head = new FixedFIFO(this.hwm);
        this.tail = this.head;
        this.size = 0;
    }
    calculateSize(obj) {
        if (obj?.byteLength != null) {
            return obj.byteLength;
        }
        return 1;
    }
    push(val) {
        if (val?.value != null) {
            this.size += this.calculateSize(val.value);
        }
        if (!this.head.push(val)) {
            const prev = this.head;
            this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);
            this.head.push(val);
        }
    }
    shift() {
        let val = this.tail.shift();
        if (val === undefined && (this.tail.next != null)) {
            const next = this.tail.next;
            this.tail.next = null;
            this.tail = next;
            val = this.tail.shift();
        }
        if (val?.value != null) {
            this.size -= this.calculateSize(val.value);
        }
        return val;
    }
    isEmpty() {
        return this.head.isEmpty();
    }
}

/**
 * @packageDocumentation
 *
 * An iterable that you can push values into.
 *
 * @example
 *
 * ```js
 * import { pushable } from 'it-pushable'
 *
 * const source = pushable()
 *
 * setTimeout(() => source.push('hello'), 100)
 * setTimeout(() => source.push('world'), 200)
 * setTimeout(() => source.end(), 300)
 *
 * const start = Date.now()
 *
 * for await (const value of source) {
 *   console.log(`got "${value}" after ${Date.now() - start}ms`)
 * }
 * console.log(`done after ${Date.now() - start}ms`)
 *
 * // Output:
 * // got "hello" after 105ms
 * // got "world" after 207ms
 * // done after 309ms
 * ```
 *
 * @example
 *
 * ```js
 * import { pushableV } from 'it-pushable'
 * import all from 'it-all'
 *
 * const source = pushableV()
 *
 * source.push(1)
 * source.push(2)
 * source.push(3)
 * source.end()
 *
 * console.info(await all(source))
 *
 * // Output:
 * // [ [1, 2, 3] ]
 * ```
 */
class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
}
function pushable(options = {}) {
    const getNext = (buffer) => {
        const next = buffer.shift();
        if (next == null) {
            return { done: true };
        }
        if (next.error != null) {
            throw next.error;
        }
        return {
            done: next.done === true,
            // @ts-expect-error if done is false, value will be present
            value: next.value
        };
    };
    return _pushable(getNext, options);
}
function _pushable(getNext, options) {
    options = options ?? {};
    let onEnd = options.onEnd;
    let buffer = new FIFO();
    let pushable;
    let onNext;
    let ended;
    let drain = pDefer();
    const waitNext = async () => {
        try {
            if (!buffer.isEmpty()) {
                return getNext(buffer);
            }
            if (ended) {
                return { done: true };
            }
            return await new Promise((resolve, reject) => {
                onNext = (next) => {
                    onNext = null;
                    buffer.push(next);
                    try {
                        resolve(getNext(buffer));
                    }
                    catch (err) {
                        reject(err);
                    }
                    return pushable;
                };
            });
        }
        finally {
            if (buffer.isEmpty()) {
                // settle promise in the microtask queue to give consumers a chance to
                // await after calling .push
                queueMicrotask(() => {
                    drain.resolve();
                    drain = pDefer();
                });
            }
        }
    };
    const bufferNext = (next) => {
        if (onNext != null) {
            return onNext(next);
        }
        buffer.push(next);
        return pushable;
    };
    const bufferError = (err) => {
        buffer = new FIFO();
        if (onNext != null) {
            return onNext({ error: err });
        }
        buffer.push({ error: err });
        return pushable;
    };
    const push = (value) => {
        if (ended) {
            return pushable;
        }
        // @ts-expect-error `byteLength` is not declared on PushType
        if (options?.objectMode !== true && value?.byteLength == null) {
            throw new Error('objectMode was not true but tried to push non-Uint8Array value');
        }
        return bufferNext({ done: false, value });
    };
    const end = (err) => {
        if (ended)
            return pushable;
        ended = true;
        return (err != null) ? bufferError(err) : bufferNext({ done: true });
    };
    const _return = () => {
        buffer = new FIFO();
        end();
        return { done: true };
    };
    const _throw = (err) => {
        end(err);
        return { done: true };
    };
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next: waitNext,
        return: _return,
        throw: _throw,
        push,
        end,
        get readableLength() {
            return buffer.size;
        },
        onEmpty: async (options) => {
            const signal = options?.signal;
            signal?.throwIfAborted();
            if (buffer.isEmpty()) {
                return;
            }
            let cancel;
            let listener;
            if (signal != null) {
                cancel = new Promise((resolve, reject) => {
                    listener = () => {
                        reject(new AbortError());
                    };
                    signal.addEventListener('abort', listener);
                });
            }
            try {
                await Promise.race([
                    drain.promise,
                    cancel
                ]);
            }
            finally {
                if (listener != null && signal != null) {
                    signal?.removeEventListener('abort', listener);
                }
            }
        }
    };
    if (onEnd == null) {
        return pushable;
    }
    const _pushable = pushable;
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next() {
            return _pushable.next();
        },
        throw(err) {
            _pushable.throw(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return { done: true };
        },
        return() {
            _pushable.return();
            if (onEnd != null) {
                onEnd();
                onEnd = undefined;
            }
            return { done: true };
        },
        push,
        end(err) {
            _pushable.end(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return pushable;
        },
        get readableLength() {
            return _pushable.readableLength;
        },
        onEmpty: (opts) => {
            return _pushable.onEmpty(opts);
        }
    };
    return pushable;
}

/**
 * @packageDocumentation
 *
 * Merge several (async)iterables into one, yield values as they arrive.
 *
 * Nb. sources are iterated over in parallel so the order of emitted items is not guaranteed.
 *
 * @example
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, generator, etc
 * const values1 = [0, 1, 2, 3, 4]
 * const values2 = [5, 6, 7, 8, 9]
 *
 * const arr = all(merge(values1, values2))
 *
 * console.info(arr) // 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, async iterator, generator, etc
 * const values1 = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 * const values2 = async function * () {
 *   yield * [5, 6, 7, 8, 9]
 * }
 *
 * const arr = await all(merge(values1(), values2()))
 *
 * console.info(arr) // 0, 1, 5, 6, 2, 3, 4, 7, 8, 9  <- nb. order is not guaranteed
 * ```
 */
function isAsyncIterable$1(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function merge(...sources) {
    const syncSources = [];
    for (const source of sources) {
        if (!isAsyncIterable$1(source)) {
            syncSources.push(source);
        }
    }
    if (syncSources.length === sources.length) {
        // all sources are synchronous
        return (function* () {
            for (const source of syncSources) {
                yield* source;
            }
        })();
    }
    return (async function* () {
        const output = pushable({
            objectMode: true
        });
        void Promise.resolve().then(async () => {
            try {
                await Promise.all(sources.map(async (source) => {
                    for await (const item of source) {
                        output.push(item);
                    }
                }));
                output.end();
            }
            catch (err) {
                output.end(err);
            }
        });
        yield* output;
    })();
}

function pipe(first, ...rest) {
    if (first == null) {
        throw new Error('Empty pipeline');
    }
    // Duplex at start: wrap in function and return duplex source
    if (isDuplex(first)) {
        const duplex = first;
        first = () => duplex.source;
        // Iterable at start: wrap in function
    }
    else if (isIterable(first) || isAsyncIterable(first)) {
        const source = first;
        first = () => source;
    }
    const fns = [first, ...rest];
    if (fns.length > 1) {
        // Duplex at end: use duplex sink
        if (isDuplex(fns[fns.length - 1])) {
            fns[fns.length - 1] = fns[fns.length - 1].sink;
        }
    }
    if (fns.length > 2) {
        // Duplex in the middle, consume source with duplex sink and return duplex source
        for (let i = 1; i < fns.length - 1; i++) {
            if (isDuplex(fns[i])) {
                fns[i] = duplexPipelineFn(fns[i]);
            }
        }
    }
    return rawPipe(...fns);
}
const rawPipe = (...fns) => {
    let res;
    while (fns.length > 0) {
        res = fns.shift()(res);
    }
    return res;
};
const isAsyncIterable = (obj) => {
    return obj?.[Symbol.asyncIterator] != null;
};
const isIterable = (obj) => {
    return obj?.[Symbol.iterator] != null;
};
const isDuplex = (obj) => {
    if (obj == null) {
        return false;
    }
    return obj.sink != null && obj.source != null;
};
const duplexPipelineFn = (duplex) => {
    return (source) => {
        const p = duplex.sink(source);
        if (p?.then != null) {
            const stream = pushable({
                objectMode: true
            });
            p.then(() => {
                stream.end();
            }, (err) => {
                stream.end(err);
            });
            let sourceWrap;
            const source = duplex.source;
            if (isAsyncIterable(source)) {
                sourceWrap = async function* () {
                    yield* source;
                    stream.end();
                };
            }
            else if (isIterable(source)) {
                sourceWrap = function* () {
                    yield* source;
                    stream.end();
                };
            }
            else {
                throw new Error('Unknown duplex source type - must be Iterable or AsyncIterable');
            }
            return merge(stream, sourceWrap());
        }
        return duplex.source;
    };
};

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];
}

const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native = {
  randomUUID
};

function v4(options, buf, offset) {
  if (native.randomUUID && !buf && !options) {
    return native.randomUUID();
  }

  options = options || {};
  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  return unsafeStringify(rnds);
}

/**
 * FilterPushRPC represents a message conforming to the Waku FilterPush protocol.
 * Protocol documentation: https://rfc.vac.dev/spec/12/
 */
class FilterPushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = MessagePush.decode(bytes);
        return new FilterPushRpc(res);
    }
    encode() {
        return MessagePush.encode(this.proto);
    }
    get wakuMessage() {
        return this.proto.wakuMessage;
    }
    /**
     * Get the pubsub topic from the FilterPushRpc object.
     * @returns string
     */
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
}
class FilterSubscribeRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createSubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeAllRequest(pubsubTopic) {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE_ALL,
            pubsubTopic,
            contentTopics: []
        });
    }
    static createSubscriberPingRequest() {
        return new FilterSubscribeRpc({
            requestId: v4(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBER_PING,
            pubsubTopic: "",
            contentTopics: []
        });
    }
    static decode(bytes) {
        const res = FilterSubscribeRequest.decode(bytes);
        return new FilterSubscribeRpc(res);
    }
    encode() {
        return FilterSubscribeRequest.encode(this.proto);
    }
    get filterSubscribeType() {
        return this.proto.filterSubscribeType;
    }
    get requestId() {
        return this.proto.requestId;
    }
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
    get contentTopics() {
        return this.proto.contentTopics;
    }
}
class FilterSubscribeResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = FilterSubscribeResponse$1.decode(bytes);
        return new FilterSubscribeResponse(res);
    }
    encode() {
        return FilterSubscribeResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get requestId() {
        return this.proto.requestId;
    }
}

const log$5 = new Logger("filter:v2");
const FilterCodecs = {
    SUBSCRIBE: "/vac/waku/filter-subscribe/2.0.0-beta1",
    PUSH: "/vac/waku/filter-push/2.0.0-beta1"
};
class FilterCore extends BaseProtocol {
    handleIncomingMessage;
    pubsubTopics;
    constructor(handleIncomingMessage, pubsubTopics, libp2p) {
        super(FilterCodecs.SUBSCRIBE, libp2p.components, log$5, pubsubTopics);
        this.handleIncomingMessage = handleIncomingMessage;
        this.pubsubTopics = pubsubTopics;
        libp2p
            .handle(FilterCodecs.PUSH, this.onRequest.bind(this), {
            maxInboundStreams: 100
        })
            .catch((e) => {
            log$5.error("Failed to register ", FilterCodecs.PUSH, e);
        });
    }
    async subscribe(pubsubTopic, peer, contentTopics) {
        const stream = await this.getStream(peer);
        const request = FilterSubscribeRpc.createSubscribeRequest(pubsubTopic, contentTopics);
        let res;
        try {
            res = await pipe([request.encode()], encode, stream, decode, async (source) => await all(source));
        }
        catch (error) {
            log$5.error("Failed to send subscribe request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$5.error(`Filter subscribe request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peer.id
        };
    }
    async unsubscribe(pubsubTopic, peer, contentTopics) {
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$5.error(`Failed to get a stream for remote peer${peer.id.toString()}`, error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_STREAM_AVAILABLE,
                    peerId: peer.id
                }
            };
        }
        const unsubscribeRequest = FilterSubscribeRpc.createUnsubscribeRequest(pubsubTopic, contentTopics);
        try {
            await pipe([unsubscribeRequest.encode()], encode, stream.sink);
        }
        catch (error) {
            log$5.error("Failed to send unsubscribe request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        return {
            success: peer.id,
            failure: null
        };
    }
    async unsubscribeAll(pubsubTopic, peer) {
        const stream = await this.getStream(peer);
        const request = FilterSubscribeRpc.createUnsubscribeAllRequest(pubsubTopic);
        const res = await pipe([request.encode()], encode, stream, decode, async (source) => await all(source));
        if (!res || !res.length) {
            return {
                failure: {
                    error: ProtocolError.NO_RESPONSE,
                    peerId: peer.id
                },
                success: null
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$5.error(`Filter unsubscribe all request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peer.id
        };
    }
    async ping(peer) {
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$5.error(`Failed to get a stream for remote peer${peer.id.toString()}`, error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_STREAM_AVAILABLE,
                    peerId: peer.id
                }
            };
        }
        const request = FilterSubscribeRpc.createSubscriberPingRequest();
        let res;
        try {
            res = await pipe([request.encode()], encode, stream, decode, async (source) => await all(source));
        }
        catch (error) {
            log$5.error("Failed to send ping request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        if (!res || !res.length) {
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_RESPONSE,
                    peerId: peer.id
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$5.error(`Filter ping request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                success: null,
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                }
            };
        }
        return {
            success: peer.id,
            failure: null
        };
    }
    onRequest(streamData) {
        const { connection, stream } = streamData;
        const { remotePeer } = connection;
        log$5.info(`Received message from ${remotePeer.toString()}`);
        try {
            pipe(stream, decode, async (source) => {
                for await (const bytes of source) {
                    const response = FilterPushRpc.decode(bytes.slice());
                    const { pubsubTopic, wakuMessage } = response;
                    if (!wakuMessage) {
                        log$5.error("Received empty message");
                        return;
                    }
                    if (!pubsubTopic) {
                        log$5.error("Pubsub topic missing from push message");
                        return;
                    }
                    await this.handleIncomingMessage(pubsubTopic, wakuMessage, connection.remotePeer.toString());
                }
            }).then(() => {
                log$5.info("Receiving pipe closed.");
            }, async (e) => {
                log$5.error(`Error with receiving pipe on peer:${connection.remotePeer.toString()} -- stream:${stream.id} -- protocol:${stream.protocol}: `, e);
            });
        }
        catch (e) {
            log$5.error("Error decoding message", e);
        }
    }
}

var index$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    FilterCodecs: FilterCodecs,
    FilterCore: FilterCore
});

class PushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(message, pubsubTopic) {
        return new PushRpc({
            requestId: v4(),
            request: {
                message: message,
                pubsubTopic: pubsubTopic
            },
            response: undefined
        });
    }
    static decode(bytes) {
        const res = PushRpc$1.decode(bytes);
        return new PushRpc(res);
    }
    encode() {
        return PushRpc$1.encode(this.proto);
    }
    get query() {
        return this.proto.request;
    }
    get response() {
        return this.proto.response;
    }
}

// should match nwaku
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/rln_relay.nim#L309
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/tests/waku_rln_relay/rln/waku_rln_relay_utils.nim#L20
const RLN_GENERATION_PREFIX_ERROR = "could not generate rln-v2 proof";
const isRLNResponseError = (info) => {
    if (!info) {
        return false;
    }
    return info.includes(RLN_GENERATION_PREFIX_ERROR);
};
const matchRLNErrorMessage = (info) => {
    const rlnErrorMap = {
        [ProtocolError.RLN_IDENTITY_MISSING]: ProtocolError.RLN_IDENTITY_MISSING,
        [ProtocolError.RLN_MEMBERSHIP_INDEX]: ProtocolError.RLN_MEMBERSHIP_INDEX,
        [ProtocolError.RLN_LIMIT_MISSING]: ProtocolError.RLN_LIMIT_MISSING
    };
    const infoLowerCase = info.toLowerCase();
    for (const errorKey in rlnErrorMap) {
        if (infoLowerCase.includes(errorKey.toLowerCase())) {
            return rlnErrorMap[errorKey];
        }
    }
    return ProtocolError.RLN_PROOF_GENERATION;
};

const log$4 = new Logger("light-push");
const LightPushCodec = "/vac/waku/lightpush/2.0.0-beta1";
/**
 * Implements the [Waku v2 Light Push protocol](https://rfc.vac.dev/spec/19/).
 */
class LightPushCore extends BaseProtocol {
    pubsubTopics;
    constructor(pubsubTopics, libp2p) {
        super(LightPushCodec, libp2p.components, log$4, pubsubTopics);
        this.pubsubTopics = pubsubTopics;
    }
    async preparePushMessage(encoder, message) {
        try {
            if (!message.payload || message.payload.length === 0) {
                log$4.error("Failed to send waku light push: payload is empty");
                return { query: null, error: ProtocolError.EMPTY_PAYLOAD };
            }
            if (!(await isMessageSizeUnderCap(encoder, message))) {
                log$4.error("Failed to send waku light push: message is bigger than 1MB");
                return { query: null, error: ProtocolError.SIZE_TOO_BIG };
            }
            const protoMessage = await encoder.toProtoObj(message);
            if (!protoMessage) {
                log$4.error("Failed to encode to protoMessage, aborting push");
                return {
                    query: null,
                    error: ProtocolError.ENCODE_FAILED
                };
            }
            const query = PushRpc.createRequest(protoMessage, encoder.pubsubTopic);
            return { query, error: null };
        }
        catch (error) {
            log$4.error("Failed to prepare push message", error);
            return {
                query: null,
                error: ProtocolError.GENERIC_FAIL
            };
        }
    }
    async send(encoder, message, peer) {
        const { query, error: preparationError } = await this.preparePushMessage(encoder, message);
        if (preparationError || !query) {
            return {
                success: null,
                failure: {
                    error: preparationError,
                    peerId: peer.id
                }
            };
        }
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$4.error("Failed to get stream", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_STREAM_AVAILABLE,
                    peerId: peer.id
                }
            };
        }
        let res;
        try {
            res = await pipe([query.encode()], encode, stream, decode, async (source) => await all(source));
        }
        catch (err) {
            log$4.error("Failed to send waku light push request", err);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => {
            bytes.append(chunk);
        });
        let response;
        try {
            response = PushRpc.decode(bytes).response;
        }
        catch (err) {
            log$4.error("Failed to decode push reply", err);
            return {
                success: null,
                failure: {
                    error: ProtocolError.DECODE_FAILED,
                    peerId: peer.id
                }
            };
        }
        if (!response) {
            log$4.error("Remote peer fault: No response in PushRPC");
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_RESPONSE,
                    peerId: peer.id
                }
            };
        }
        if (isRLNResponseError(response.info)) {
            const rlnErrorCase = matchRLNErrorMessage(response.info);
            log$4.error("Remote peer rejected the message: ", rlnErrorCase);
            return {
                success: null,
                failure: {
                    error: rlnErrorCase,
                    peerId: peer.id
                }
            };
        }
        if (!response.isSuccess) {
            log$4.error("Remote peer rejected the message: ", response.info);
            return {
                success: null,
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                }
            };
        }
        return { success: peer.id, failure: null };
    }
}

var index$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    LightPushCodec: LightPushCodec,
    LightPushCore: LightPushCore,
    get PushResponse () { return PushResponse; }
});

const EmptyMessage = {
    payload: new Uint8Array(),
    contentTopic: "",
    version: undefined,
    timestamp: undefined,
    meta: undefined,
    rateLimitProof: undefined,
    ephemeral: undefined
};
function toProtoMessage(wire) {
    return { ...EmptyMessage, ...wire };
}

// https://github.com/waku-org/nwaku/blob/7205f95cff9f49ca0bb762e8fd0bf56a6a7f3b3b/waku/waku_store/common.nim#L12
const DEFAULT_PAGE_SIZE = 20;
const MAX_PAGE_SIZE = 100;
const ONE_MILLION = 1_000000;
class StoreQueryRequest {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static create(params) {
        const request = new StoreQueryRequest({
            ...params,
            requestId: v4(),
            timeStart: params.timeStart
                ? BigInt(params.timeStart.getTime() * ONE_MILLION)
                : undefined,
            timeEnd: params.timeEnd
                ? BigInt(params.timeEnd.getTime() * ONE_MILLION)
                : undefined,
            messageHashes: params.messageHashes || [],
            paginationLimit: params.paginationLimit
                ? BigInt(params.paginationLimit)
                : undefined
        });
        // Validate request parameters based on RFC
        if ((params.pubsubTopic && !params.contentTopics) ||
            (!params.pubsubTopic && params.contentTopics)) {
            throw new Error("Both pubsubTopic and contentTopics must be set or unset");
        }
        if (params.messageHashes &&
            (params.pubsubTopic ||
                params.contentTopics ||
                params.timeStart ||
                params.timeEnd)) {
            throw new Error("Message hash lookup queries cannot include content filter criteria");
        }
        return request;
    }
    static decode(bytes) {
        const res = StoreQueryRequest$1.decode(bytes);
        return new StoreQueryRequest(res);
    }
    encode() {
        return StoreQueryRequest$1.encode(this.proto);
    }
}
class StoreQueryResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = StoreQueryResponse$1.decode(bytes);
        return new StoreQueryResponse(res);
    }
    encode() {
        return StoreQueryResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get messages() {
        return this.proto.messages;
    }
    get paginationCursor() {
        return this.proto.paginationCursor;
    }
}

const log$3 = new Logger("store");
const StoreCodec = "/vac/waku/store-query/3.0.0";
class StoreCore extends BaseProtocol {
    pubsubTopics;
    constructor(pubsubTopics, libp2p) {
        super(StoreCodec, libp2p.components, log$3, pubsubTopics);
        this.pubsubTopics = pubsubTopics;
    }
    async *queryPerPage(queryOpts, decoders, peer) {
        if (queryOpts.contentTopics.toString() !==
            Array.from(decoders.keys()).toString()) {
            throw new Error("Internal error, the decoders should match the query's content topics");
        }
        let currentCursor = queryOpts.paginationCursor;
        while (true) {
            const storeQueryRequest = StoreQueryRequest.create({
                ...queryOpts,
                paginationCursor: currentCursor
            });
            let stream;
            try {
                stream = await this.getStream(peer);
            }
            catch (e) {
                log$3.error("Failed to get stream", e);
                break;
            }
            const res = await pipe([storeQueryRequest.encode()], encode, stream, decode, async (source) => await all(source));
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const storeQueryResponse = StoreQueryResponse.decode(bytes);
            if (!storeQueryResponse.statusCode ||
                storeQueryResponse.statusCode >= 300) {
                const errorMessage = `Store query failed with status code: ${storeQueryResponse.statusCode}, description: ${storeQueryResponse.statusDesc}`;
                log$3.error(errorMessage);
                throw new Error(errorMessage);
            }
            if (!storeQueryResponse.messages || !storeQueryResponse.messages.length) {
                log$3.warn("Stopping pagination due to empty messages in response");
                break;
            }
            log$3.info(`${storeQueryResponse.messages.length} messages retrieved from store`);
            const decodedMessages = storeQueryResponse.messages.map((protoMsg) => {
                if (!protoMsg.message) {
                    return Promise.resolve(undefined);
                }
                const contentTopic = protoMsg.message.contentTopic;
                if (contentTopic) {
                    const decoder = decoders.get(contentTopic);
                    if (decoder) {
                        return decoder.fromProtoObj(protoMsg.pubsubTopic || "", toProtoMessage(protoMsg.message));
                    }
                }
                return Promise.resolve(undefined);
            });
            yield decodedMessages;
            if (queryOpts.paginationForward) {
                currentCursor =
                    storeQueryResponse.messages[storeQueryResponse.messages.length - 1]
                        .messageHash;
            }
            else {
                currentCursor = storeQueryResponse.messages[0].messageHash;
            }
            if (storeQueryResponse.messages.length > MAX_PAGE_SIZE &&
                storeQueryResponse.messages.length <
                    (queryOpts.paginationLimit || DEFAULT_PAGE_SIZE)) {
                break;
            }
        }
    }
}

var index = /*#__PURE__*/Object.freeze({
    __proto__: null,
    StoreCodec: StoreCodec,
    StoreCore: StoreCore
});

/** Noop for browser compatibility */
function setMaxListeners$1() { }

// create a setMaxListeners that doesn't break browser usage
const setMaxListeners = (n, ...eventTargets) => {
    try {
        setMaxListeners$1(n, ...eventTargets);
    }
    catch {
        // swallow error, gulp
    }
};

/**
 * An implementation of a typed event target
 * etc
 */
class TypedEventEmitter extends EventTarget {
    #listeners = new Map();
    constructor() {
        super();
        // silence MaxListenersExceededWarning warning on Node.js, this is a red
        // herring almost all of the time
        setMaxListeners(Infinity, this);
    }
    listenerCount(type) {
        const listeners = this.#listeners.get(type);
        if (listeners == null) {
            return 0;
        }
        return listeners.length;
    }
    addEventListener(type, listener, options) {
        super.addEventListener(type, listener, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            list = [];
            this.#listeners.set(type, list);
        }
        list.push({
            callback: listener,
            once: (options !== true && options !== false && options?.once) ?? false
        });
    }
    removeEventListener(type, listener, options) {
        super.removeEventListener(type.toString(), listener ?? null, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            return;
        }
        list = list.filter(({ callback }) => callback !== listener);
        this.#listeners.set(type, list);
    }
    dispatchEvent(event) {
        const result = super.dispatchEvent(event);
        let list = this.#listeners.get(event.type);
        if (list == null) {
            return result;
        }
        list = list.filter(({ once }) => !once);
        this.#listeners.set(event.type, list);
        return result;
    }
    safeDispatchEvent(type, detail = {}) {
        return this.dispatchEvent(new CustomEvent(type, detail));
    }
}
const CustomEvent = globalThis.CustomEvent;

const RelayPingContentTopic = "/relay-ping/1/ping/null";
const log$2 = new Logger("keep-alive");
class KeepAliveManager {
    relay;
    libp2p;
    options;
    pingKeepAliveTimers = new Map();
    relayKeepAliveTimers = new Map();
    constructor({ options, relay, libp2p }) {
        this.options = options;
        this.relay = relay;
        this.libp2p = libp2p;
    }
    start(peerId) {
        // Just in case a timer already exists for this peer
        this.stop(peerId);
        const { pingKeepAlive: pingPeriodSecs, relayKeepAlive: relayPeriodSecs } = this.options;
        const peerIdStr = peerId.toString();
        // Ping the peer every pingPeriodSecs seconds
        // if pingPeriodSecs is 0, don't ping the peer
        if (pingPeriodSecs !== 0) {
            const interval = setInterval(() => {
                void (async () => {
                    let ping;
                    try {
                        // ping the peer for keep alive
                        // also update the peer store with the latency
                        try {
                            ping = await this.libp2p.services.ping.ping(peerId);
                            log$2.info(`Ping succeeded (${peerIdStr})`, ping);
                        }
                        catch (error) {
                            log$2.error(`Ping failed for peer (${peerIdStr}).
                Next ping will be attempted in ${pingPeriodSecs} seconds.
              `);
                            return;
                        }
                        try {
                            await this.libp2p.peerStore.merge(peerId, {
                                metadata: {
                                    ping: utf8ToBytes(ping.toString())
                                }
                            });
                        }
                        catch (e) {
                            log$2.error("Failed to update ping", e);
                        }
                    }
                    catch (e) {
                        log$2.error(`Ping failed (${peerIdStr})`, e);
                    }
                })();
            }, pingPeriodSecs * 1000);
            this.pingKeepAliveTimers.set(peerIdStr, interval);
        }
        const relay = this.relay;
        if (relay && relayPeriodSecs !== 0) {
            const intervals = this.scheduleRelayPings(relay, relayPeriodSecs, peerId.toString());
            this.relayKeepAliveTimers.set(peerId, intervals);
        }
    }
    stop(peerId) {
        const peerIdStr = peerId.toString();
        if (this.pingKeepAliveTimers.has(peerIdStr)) {
            clearInterval(this.pingKeepAliveTimers.get(peerIdStr));
            this.pingKeepAliveTimers.delete(peerIdStr);
        }
        if (this.relayKeepAliveTimers.has(peerId)) {
            this.relayKeepAliveTimers.get(peerId)?.map(clearInterval);
            this.relayKeepAliveTimers.delete(peerId);
        }
    }
    stopAll() {
        for (const timer of [
            ...Object.values(this.pingKeepAliveTimers),
            ...Object.values(this.relayKeepAliveTimers)
        ]) {
            clearInterval(timer);
        }
        this.pingKeepAliveTimers.clear();
        this.relayKeepAliveTimers.clear();
    }
    connectionsExist() {
        return (this.pingKeepAliveTimers.size > 0 || this.relayKeepAliveTimers.size > 0);
    }
    scheduleRelayPings(relay, relayPeriodSecs, peerIdStr) {
        // send a ping message to each PubsubTopic the peer is part of
        const intervals = [];
        for (const topic of relay.pubsubTopics) {
            const meshPeers = relay.getMeshPeers(topic);
            if (!meshPeers.includes(peerIdStr))
                continue;
            const encoder = createEncoder({
                pubsubTopicShardInfo: pubsubTopicToSingleShardInfo(topic),
                contentTopic: RelayPingContentTopic,
                ephemeral: true
            });
            const interval = setInterval(() => {
                log$2.info("Sending Waku Relay ping message");
                relay
                    .send(encoder, { payload: new Uint8Array([1]) })
                    .catch((e) => log$2.error("Failed to send relay ping", e));
            }, relayPeriodSecs * 1000);
            intervals.push(interval);
        }
        return intervals;
    }
}

const log$1 = new Logger("connection-manager");
const DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED = 1;
const DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER = 3;
const DEFAULT_MAX_PARALLEL_DIALS = 3;
class ConnectionManager extends TypedEventEmitter {
    configuredPubsubTopics;
    static instances = new Map();
    keepAliveManager;
    options;
    libp2p;
    dialAttemptsForPeer = new Map();
    dialErrorsForPeer = new Map();
    currentActiveParallelDialCount = 0;
    pendingPeerDialQueue = [];
    isP2PNetworkConnected = false;
    isConnected() {
        if (globalThis?.navigator && !globalThis?.navigator?.onLine) {
            return false;
        }
        return this.isP2PNetworkConnected;
    }
    static create(peerId, libp2p, keepAliveOptions, pubsubTopics, relay, options) {
        let instance = ConnectionManager.instances.get(peerId);
        if (!instance) {
            instance = new ConnectionManager(libp2p, keepAliveOptions, pubsubTopics, relay, options);
            ConnectionManager.instances.set(peerId, instance);
        }
        return instance;
    }
    stop() {
        this.keepAliveManager.stopAll();
        this.libp2p.removeEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
        this.libp2p.removeEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
        this.libp2p.removeEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
        this.stopNetworkStatusListener();
    }
    async dropConnection(peerId) {
        try {
            this.keepAliveManager.stop(peerId);
            await this.libp2p.hangUp(peerId);
            log$1.info(`Dropped connection with peer ${peerId.toString()}`);
        }
        catch (error) {
            log$1.error(`Error dropping connection with peer ${peerId.toString()} - ${error}`);
        }
    }
    async getPeersByDiscovery() {
        const peersDiscovered = await this.libp2p.peerStore.all();
        const peersConnected = this.libp2p
            .getConnections()
            .map((conn) => conn.remotePeer);
        const peersDiscoveredByBootstrap = [];
        const peersDiscoveredByPeerExchange = [];
        const peersDiscoveredByLocal = [];
        const peersConnectedByBootstrap = [];
        const peersConnectedByPeerExchange = [];
        const peersConnectedByLocal = [];
        for (const peer of peersDiscovered) {
            const tags = await this.getTagNamesForPeer(peer.id);
            if (tags.includes(Tags.BOOTSTRAP)) {
                peersDiscoveredByBootstrap.push(peer);
            }
            else if (tags.includes(Tags.PEER_EXCHANGE)) {
                peersDiscoveredByPeerExchange.push(peer);
            }
            else if (tags.includes(Tags.LOCAL)) {
                peersDiscoveredByLocal.push(peer);
            }
        }
        for (const peerId of peersConnected) {
            const peer = await this.libp2p.peerStore.get(peerId);
            const tags = await this.getTagNamesForPeer(peerId);
            if (tags.includes(Tags.BOOTSTRAP)) {
                peersConnectedByBootstrap.push(peer);
            }
            else if (tags.includes(Tags.PEER_EXCHANGE)) {
                peersConnectedByPeerExchange.push(peer);
            }
            else if (tags.includes(Tags.LOCAL)) {
                peersConnectedByLocal.push(peer);
            }
        }
        return {
            DISCOVERED: {
                [Tags.BOOTSTRAP]: peersDiscoveredByBootstrap,
                [Tags.PEER_EXCHANGE]: peersDiscoveredByPeerExchange,
                [Tags.LOCAL]: peersDiscoveredByLocal
            },
            CONNECTED: {
                [Tags.BOOTSTRAP]: peersConnectedByBootstrap,
                [Tags.PEER_EXCHANGE]: peersConnectedByPeerExchange,
                [Tags.LOCAL]: peersConnectedByLocal
            }
        };
    }
    constructor(libp2p, keepAliveOptions, configuredPubsubTopics, relay, options) {
        super();
        this.configuredPubsubTopics = configuredPubsubTopics;
        this.libp2p = libp2p;
        this.configuredPubsubTopics = configuredPubsubTopics;
        this.options = {
            maxDialAttemptsForPeer: DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER,
            maxBootstrapPeersAllowed: DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED,
            maxParallelDials: DEFAULT_MAX_PARALLEL_DIALS,
            ...options
        };
        this.keepAliveManager = new KeepAliveManager({
            relay,
            libp2p,
            options: keepAliveOptions
        });
        this.startEventListeners()
            .then(() => log$1.info(`Connection Manager is now running`))
            .catch((error) => log$1.error(`Unexpected error while running service`, error));
        // libp2p emits `peer:discovery` events during its initialization
        // which means that before the ConnectionManager is initialized, some peers may have been discovered
        // we will dial the peers in peerStore ONCE before we start to listen to the `peer:discovery` events within the ConnectionManager
        this.dialPeerStorePeers().catch((error) => log$1.error(`Unexpected error while dialing peer store peers`, error));
    }
    async dialPeerStorePeers() {
        const peerInfos = await this.libp2p.peerStore.all();
        const dialPromises = [];
        for (const peerInfo of peerInfos) {
            if (this.libp2p.getConnections().find((c) => c.remotePeer === peerInfo.id))
                continue;
            dialPromises.push(this.attemptDial(peerInfo.id));
        }
        try {
            await Promise.all(dialPromises);
        }
        catch (error) {
            log$1.error(`Unexpected error while dialing peer store peers`, error);
        }
    }
    async startEventListeners() {
        this.startPeerDiscoveryListener();
        this.startPeerConnectionListener();
        this.startPeerDisconnectionListener();
        this.startNetworkStatusListener();
    }
    async dialPeer(peerId) {
        this.currentActiveParallelDialCount += 1;
        let dialAttempt = 0;
        while (dialAttempt < this.options.maxDialAttemptsForPeer) {
            try {
                log$1.info(`Dialing peer ${peerId.toString()} on attempt ${dialAttempt + 1}`);
                await this.libp2p.dial(peerId);
                const tags = await this.getTagNamesForPeer(peerId);
                // add tag to connection describing discovery mechanism
                // don't add duplicate tags
                this.libp2p.getConnections(peerId).forEach((conn) => {
                    conn.tags = Array.from(new Set([...conn.tags, ...tags]));
                });
                // instead of deleting the peer from the peer store, we set the dial attempt to -1
                // this helps us keep track of peers that have been dialed before
                this.dialAttemptsForPeer.set(peerId.toString(), -1);
                // Dialing succeeded, break the loop
                this.keepAliveManager.start(peerId);
                break;
            }
            catch (error) {
                if (error instanceof AggregateError) {
                    // Handle AggregateError
                    log$1.error(`Error dialing peer ${peerId.toString()} - ${error.errors}`);
                }
                else {
                    // Handle generic error
                    log$1.error(`Error dialing peer ${peerId.toString()} - ${error.message}`);
                }
                this.dialErrorsForPeer.set(peerId.toString(), error);
                dialAttempt++;
                this.dialAttemptsForPeer.set(peerId.toString(), dialAttempt);
            }
        }
        // Always decrease the active dial count and process the dial queue
        this.currentActiveParallelDialCount--;
        this.processDialQueue();
        // If max dial attempts reached and dialing failed, delete the peer
        if (dialAttempt === this.options.maxDialAttemptsForPeer) {
            try {
                const error = this.dialErrorsForPeer.get(peerId.toString());
                if (error) {
                    let errorMessage;
                    if (error instanceof AggregateError) {
                        if (!error.errors) {
                            log$1.warn(`No errors array found for AggregateError`);
                        }
                        else if (error.errors.length === 0) {
                            log$1.warn(`Errors array is empty for AggregateError`);
                        }
                        else {
                            errorMessage = JSON.stringify(error.errors[0]);
                        }
                    }
                    else {
                        errorMessage = error.message;
                    }
                    log$1.info(`Deleting undialable peer ${peerId.toString()} from peer store. Reason: ${errorMessage}`);
                }
                this.dialErrorsForPeer.delete(peerId.toString());
                await this.libp2p.peerStore.delete(peerId);
                // if it was last available peer - attempt DNS discovery
                await this.attemptDnsDiscovery();
            }
            catch (error) {
                throw new Error(`Error deleting undialable peer ${peerId.toString()} from peer store - ${error}`);
            }
        }
    }
    async attemptDnsDiscovery() {
        if (this.libp2p.getConnections().length > 0)
            return;
        if ((await this.libp2p.peerStore.all()).length > 0)
            return;
        log$1.info("Attempting to trigger DNS discovery.");
        const dnsDiscovery = Object.values(this.libp2p.components.components).find((v) => {
            if (v && v.toString) {
                return v.toString().includes(DNS_DISCOVERY_TAG);
            }
            return false;
        });
        if (!dnsDiscovery)
            return;
        await dnsDiscovery.findPeers();
    }
    processDialQueue() {
        if (this.pendingPeerDialQueue.length > 0 &&
            this.currentActiveParallelDialCount < this.options.maxParallelDials) {
            const peerId = this.pendingPeerDialQueue.shift();
            if (!peerId)
                return;
            this.attemptDial(peerId).catch((error) => {
                log$1.error(error);
            });
        }
    }
    startPeerDiscoveryListener() {
        this.libp2p.addEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
    }
    startPeerConnectionListener() {
        this.libp2p.addEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
    }
    startPeerDisconnectionListener() {
        // TODO: ensure that these following issues are updated and confirmed
        /**
         * NOTE: Event is not being emitted on closing nor losing a connection.
         * @see https://github.com/libp2p/js-libp2p/issues/939
         * @see https://github.com/status-im/js-waku/issues/252
         *
         * >This event will be triggered anytime we are disconnected from another peer,
         * >regardless of the circumstances of that disconnection.
         * >If we happen to have multiple connections to a peer,
         * >this event will **only** be triggered when the last connection is closed.
         * @see https://github.com/libp2p/js-libp2p/blob/bad9e8c0ff58d60a78314077720c82ae331cc55b/doc/API.md?plain=1#L2100
         */
        this.libp2p.addEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
    }
    async attemptDial(peerId) {
        if (!(await this.shouldDialPeer(peerId)))
            return;
        if (this.currentActiveParallelDialCount >= this.options.maxParallelDials) {
            this.pendingPeerDialQueue.push(peerId);
            return;
        }
        await this.dialPeer(peerId);
    }
    onEventHandlers = {
        "peer:discovery": (evt) => {
            void (async () => {
                const { id: peerId } = evt.detail;
                await this.dispatchDiscoveryEvent(peerId);
                try {
                    await this.attemptDial(peerId);
                }
                catch (error) {
                    log$1.error(`Error dialing peer ${peerId.toString()} : ${error}`);
                }
            })();
        },
        "peer:connect": (evt) => {
            void (async () => {
                log$1.info(`Connected to peer ${evt.detail.toString()}`);
                const peerId = evt.detail;
                this.keepAliveManager.start(peerId);
                const isBootstrap = (await this.getTagNamesForPeer(peerId)).includes(Tags.BOOTSTRAP);
                if (isBootstrap) {
                    const bootstrapConnections = this.libp2p
                        .getConnections()
                        .filter((conn) => conn.tags.includes(Tags.BOOTSTRAP));
                    // If we have too many bootstrap connections, drop one
                    if (bootstrapConnections.length > this.options.maxBootstrapPeersAllowed) {
                        await this.dropConnection(peerId);
                    }
                    else {
                        this.dispatchEvent(new CustomEvent(EPeersByDiscoveryEvents.PEER_CONNECT_BOOTSTRAP, {
                            detail: peerId
                        }));
                    }
                }
                else {
                    this.dispatchEvent(new CustomEvent(EPeersByDiscoveryEvents.PEER_CONNECT_PEER_EXCHANGE, {
                        detail: peerId
                    }));
                }
                this.setP2PNetworkConnected();
            })();
        },
        "peer:disconnect": (evt) => {
            void (async () => {
                this.keepAliveManager.stop(evt.detail);
                this.setP2PNetworkDisconnected();
            })();
        },
        "browser:network": () => {
            this.dispatchWakuConnectionEvent();
        }
    };
    /**
     * Checks if the peer should be dialed based on the following conditions:
     * 1. If the peer is already connected, don't dial
     * 2. If the peer is not part of any of the configured pubsub topics, don't dial
     * 3. If the peer is not dialable based on bootstrap status, don't dial
     * 4. If the peer is already has an active dial attempt, or has been dialed before, don't dial it
     * @returns true if the peer should be dialed, false otherwise
     */
    async shouldDialPeer(peerId) {
        const isConnected = this.libp2p.getConnections(peerId).length > 0;
        if (isConnected) {
            log$1.warn(`Already connected to peer ${peerId.toString()}. Not dialing.`);
            return false;
        }
        const isSameShard = await this.isPeerTopicConfigured(peerId);
        if (!isSameShard) {
            const shardInfo = await this.getPeerShardInfo(peerId, this.libp2p.peerStore);
            log$1.warn(`Discovered peer ${peerId.toString()} with ShardInfo ${shardInfo} is not part of any of the configured pubsub topics (${this.configuredPubsubTopics}).
            Not dialing.`);
            return false;
        }
        const isPreferredBasedOnBootstrap = await this.isPeerDialableBasedOnBootstrapStatus(peerId);
        if (!isPreferredBasedOnBootstrap) {
            log$1.warn(`Peer ${peerId.toString()} is not dialable based on bootstrap status. Not dialing.`);
            return false;
        }
        const hasBeenDialed = this.dialAttemptsForPeer.has(peerId.toString());
        if (hasBeenDialed) {
            log$1.warn(`Peer ${peerId.toString()} has already been attempted dial before, or already has a dial attempt in progress, skipping dial`);
            return false;
        }
        return true;
    }
    /**
     * Checks if the peer is dialable based on the following conditions:
     * 1. If the peer is a bootstrap peer, it is only dialable if the number of current bootstrap connections is less than the max allowed.
     * 2. If the peer is not a bootstrap peer
     */
    async isPeerDialableBasedOnBootstrapStatus(peerId) {
        const tagNames = await this.getTagNamesForPeer(peerId);
        const isBootstrap = tagNames.some((tagName) => tagName === Tags.BOOTSTRAP);
        if (!isBootstrap) {
            return true;
        }
        const currentBootstrapConnections = this.libp2p
            .getConnections()
            .filter((conn) => {
            return conn.tags.find((name) => name === Tags.BOOTSTRAP);
        }).length;
        return currentBootstrapConnections < this.options.maxBootstrapPeersAllowed;
    }
    async dispatchDiscoveryEvent(peerId) {
        const isBootstrap = (await this.getTagNamesForPeer(peerId)).includes(Tags.BOOTSTRAP);
        this.dispatchEvent(new CustomEvent(isBootstrap
            ? EPeersByDiscoveryEvents.PEER_DISCOVERY_BOOTSTRAP
            : EPeersByDiscoveryEvents.PEER_DISCOVERY_PEER_EXCHANGE, {
            detail: peerId
        }));
    }
    /**
     * Fetches the tag names for a given peer
     */
    async getTagNamesForPeer(peerId) {
        try {
            const peer = await this.libp2p.peerStore.get(peerId);
            return Array.from(peer.tags.keys());
        }
        catch (error) {
            log$1.error(`Failed to get peer ${peerId}, error: ${error}`);
            return [];
        }
    }
    async isPeerTopicConfigured(peerId) {
        const shardInfo = await this.getPeerShardInfo(peerId, this.libp2p.peerStore);
        // If there's no shard information, simply return true
        if (!shardInfo)
            return true;
        const pubsubTopics = shardInfoToPubsubTopics(shardInfo);
        const isTopicConfigured = pubsubTopics.some((topic) => this.configuredPubsubTopics.includes(topic));
        return isTopicConfigured;
    }
    async getPeerShardInfo(peerId, peerStore) {
        const peer = await peerStore.get(peerId);
        const shardInfoBytes = peer.metadata.get("shardInfo");
        if (!shardInfoBytes)
            return undefined;
        return decodeRelayShard(shardInfoBytes);
    }
    startNetworkStatusListener() {
        try {
            globalThis.addEventListener("online", this.onEventHandlers["browser:network"]);
            globalThis.addEventListener("offline", this.onEventHandlers["browser:network"]);
        }
        catch (err) {
            log$1.error(`Failed to start network listener: ${err}`);
        }
    }
    stopNetworkStatusListener() {
        try {
            globalThis.removeEventListener("online", this.onEventHandlers["browser:network"]);
            globalThis.removeEventListener("offline", this.onEventHandlers["browser:network"]);
        }
        catch (err) {
            log$1.error(`Failed to stop network listener: ${err}`);
        }
    }
    setP2PNetworkConnected() {
        if (!this.isP2PNetworkConnected) {
            this.isP2PNetworkConnected = true;
            this.dispatchWakuConnectionEvent();
        }
    }
    setP2PNetworkDisconnected() {
        if (this.isP2PNetworkConnected &&
            this.libp2p.getConnections().length === 0) {
            this.isP2PNetworkConnected = false;
            this.dispatchWakuConnectionEvent();
        }
    }
    dispatchWakuConnectionEvent() {
        this.dispatchEvent(new CustomEvent(EConnectionStateEvents.CONNECTION_STATUS, {
            detail: this.isConnected()
        }));
    }
}

class HealthManager {
    static instance;
    health;
    constructor() {
        this.health = {
            overallStatus: HealthStatus.Unhealthy,
            protocolStatuses: new Map()
        };
    }
    static getInstance() {
        if (!HealthManager.instance) {
            HealthManager.instance = new HealthManager();
        }
        return HealthManager.instance;
    }
    getHealthStatus() {
        return this.health.overallStatus;
    }
    getProtocolStatus(protocol) {
        return this.health.protocolStatuses.get(protocol);
    }
    updateProtocolHealth(multicodec, connectedPeers) {
        const protocol = this.getNameFromMulticodec(multicodec);
        let status = HealthStatus.Unhealthy;
        if (connectedPeers == 1) {
            status = HealthStatus.MinimallyHealthy;
        }
        else if (connectedPeers >= 2) {
            status = HealthStatus.SufficientlyHealthy;
        }
        this.health.protocolStatuses.set(protocol, {
            name: protocol,
            status: status,
            lastUpdate: new Date()
        });
        this.updateOverallHealth();
    }
    getNameFromMulticodec(multicodec) {
        let name;
        if (multicodec.includes("filter")) {
            name = Protocols.Filter;
        }
        else if (multicodec.includes("lightpush")) {
            name = Protocols.LightPush;
        }
        else if (multicodec.includes("store")) {
            name = Protocols.Store;
        }
        else {
            throw new Error(`Unknown protocol: ${multicodec}`);
        }
        return name;
    }
    updateOverallHealth() {
        const relevantProtocols = [Protocols.LightPush, Protocols.Filter];
        const statuses = relevantProtocols.map((p) => this.getProtocolStatus(p)?.status);
        if (statuses.some((status) => status === HealthStatus.Unhealthy)) {
            this.health.overallStatus = HealthStatus.Unhealthy;
        }
        else if (statuses.some((status) => status === HealthStatus.MinimallyHealthy)) {
            this.health.overallStatus = HealthStatus.MinimallyHealthy;
        }
        else {
            this.health.overallStatus = HealthStatus.SufficientlyHealthy;
        }
    }
}
const getHealthManager = () => HealthManager.getInstance();

const log = new Logger("metadata");
const MetadataCodec = "/vac/waku/metadata/1.0.0";
class Metadata extends BaseProtocol {
    pubsubTopics;
    libp2pComponents;
    handshakesConfirmed = new Map();
    constructor(pubsubTopics, libp2p) {
        super(MetadataCodec, libp2p.components, log, pubsubTopics);
        this.pubsubTopics = pubsubTopics;
        this.libp2pComponents = libp2p;
        void libp2p.registrar.handle(MetadataCodec, (streamData) => {
            void this.onRequest(streamData);
        });
    }
    /**
     * Make a metadata query to a peer
     */
    async query(peerId) {
        const request = WakuMetadataRequest.encode(pubsubTopicsToShardInfo(this.pubsubTopics));
        const peer = await this.libp2pComponents.peerStore.get(peerId);
        if (!peer) {
            return {
                shardInfo: null,
                error: ProtocolError.NO_PEER_AVAILABLE
            };
        }
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log.error("Failed to get stream", error);
            return {
                shardInfo: null,
                error: ProtocolError.NO_STREAM_AVAILABLE
            };
        }
        const encodedResponse = await pipe([request], encode, stream, decode, async (source) => await all(source));
        const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
        if (error) {
            return {
                shardInfo: null,
                error
            };
        }
        await this.savePeerShardInfo(peerId, shardInfo);
        return {
            shardInfo,
            error: null
        };
    }
    async confirmOrAttemptHandshake(peerId) {
        const shardInfo = this.handshakesConfirmed.get(peerId.toString());
        if (shardInfo) {
            return {
                shardInfo,
                error: null
            };
        }
        return await this.query(peerId);
    }
    /**
     * Handle an incoming metadata request
     */
    async onRequest(streamData) {
        try {
            const { stream, connection } = streamData;
            const encodedShardInfo = WakuMetadataResponse.encode(pubsubTopicsToShardInfo(this.pubsubTopics));
            const encodedResponse = await pipe([encodedShardInfo], encode, stream, decode, async (source) => await all(source));
            const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
            if (error) {
                return;
            }
            await this.savePeerShardInfo(connection.remotePeer, shardInfo);
        }
        catch (error) {
            log.error("Error handling metadata request", error);
        }
    }
    decodeMetadataResponse(encodedResponse) {
        const bytes = new Uint8ArrayList();
        encodedResponse.forEach((chunk) => {
            bytes.append(chunk);
        });
        const response = WakuMetadataResponse.decode(bytes);
        if (!response) {
            log.error("Error decoding metadata response");
            return {
                shardInfo: null,
                error: ProtocolError.DECODE_FAILED
            };
        }
        return {
            shardInfo: response,
            error: null
        };
    }
    async savePeerShardInfo(peerId, shardInfo) {
        // add or update the shardInfo to peer store
        await this.libp2pComponents.peerStore.merge(peerId, {
            metadata: {
                shardInfo: encodeRelayShard(shardInfo)
            }
        });
        this.handshakesConfirmed.set(peerId.toString(), shardInfo);
    }
}
function wakuMetadata(pubsubTopics) {
    return (components) => new Metadata(pubsubTopics, components);
}

export { ConnectionManager, FilterCodecs, FilterCore, KeepAliveManager, LightPushCodec, LightPushCore, MetadataCodec, StoreCodec, StoreCore, createEncoder, getHealthManager, index$3 as message, wakuMetadata, index$2 as waku_filter, index$1 as waku_light_push, index as waku_store };

/**
 * Returns a `Uint8Array` of the requested size. Referenced memory will
 * be initialized to 0.
 */
function alloc$2(size = 0) {
    return new Uint8Array(size);
}
/**
 * Where possible returns a Uint8Array of the requested size that references
 * uninitialized memory. Only use if you are certain you will immediately
 * overwrite every value in the returned `Uint8Array`.
 */
function allocUnsafe(size = 0) {
    return new Uint8Array(size);
}

/* eslint-disable no-fallthrough */
const N1$1 = Math.pow(2, 7);
const N2$1 = Math.pow(2, 14);
const N3$1 = Math.pow(2, 21);
const N4$1 = Math.pow(2, 28);
const N5$1 = Math.pow(2, 35);
const N6$1 = Math.pow(2, 42);
const N7$1 = Math.pow(2, 49);
/** Most significant bit of a byte */
const MSB$2 = 0x80;
/** Rest of the bits in a byte */
const REST$2 = 0x7f;
function encodingLength$3(value) {
    if (value < N1$1) {
        return 1;
    }
    if (value < N2$1) {
        return 2;
    }
    if (value < N3$1) {
        return 3;
    }
    if (value < N4$1) {
        return 4;
    }
    if (value < N5$1) {
        return 5;
    }
    if (value < N6$1) {
        return 6;
    }
    if (value < N7$1) {
        return 7;
    }
    if (Number.MAX_SAFE_INTEGER != null && value > Number.MAX_SAFE_INTEGER) {
        throw new RangeError('Could not encode varint');
    }
    return 8;
}
function encodeUint8Array(value, buf, offset = 0) {
    switch (encodingLength$3(value)) {
        case 8: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 7: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 6: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 5: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value /= 128;
        }
        case 4: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value >>>= 7;
        }
        case 3: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value >>>= 7;
        }
        case 2: {
            buf[offset++] = (value & 0xFF) | MSB$2;
            value >>>= 7;
        }
        case 1: {
            buf[offset++] = (value & 0xFF);
            value >>>= 7;
            break;
        }
        default: throw new Error('unreachable');
    }
    return buf;
}
function encodeUint8ArrayList(value, buf, offset = 0) {
    switch (encodingLength$3(value)) {
        case 8: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 7: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 6: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 5: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value /= 128;
        }
        case 4: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value >>>= 7;
        }
        case 3: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value >>>= 7;
        }
        case 2: {
            buf.set(offset++, (value & 0xFF) | MSB$2);
            value >>>= 7;
        }
        case 1: {
            buf.set(offset++, (value & 0xFF));
            value >>>= 7;
            break;
        }
        default: throw new Error('unreachable');
    }
    return buf;
}
function decodeUint8Array(buf, offset) {
    let b = buf[offset];
    let res = 0;
    res += b & REST$2;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 1];
    res += (b & REST$2) << 7;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 2];
    res += (b & REST$2) << 14;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 3];
    res += (b & REST$2) << 21;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 4];
    res += (b & REST$2) * N4$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 5];
    res += (b & REST$2) * N5$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 6];
    res += (b & REST$2) * N6$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf[offset + 7];
    res += (b & REST$2) * N7$1;
    if (b < MSB$2) {
        return res;
    }
    throw new RangeError('Could not decode varint');
}
function decodeUint8ArrayList(buf, offset) {
    let b = buf.get(offset);
    let res = 0;
    res += b & REST$2;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 1);
    res += (b & REST$2) << 7;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 2);
    res += (b & REST$2) << 14;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 3);
    res += (b & REST$2) << 21;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 4);
    res += (b & REST$2) * N4$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 5);
    res += (b & REST$2) * N5$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 6);
    res += (b & REST$2) * N6$1;
    if (b < MSB$2) {
        return res;
    }
    b = buf.get(offset + 7);
    res += (b & REST$2) * N7$1;
    if (b < MSB$2) {
        return res;
    }
    throw new RangeError('Could not decode varint');
}
function encode$a(value, buf, offset = 0) {
    if (buf == null) {
        buf = allocUnsafe(encodingLength$3(value));
    }
    if (buf instanceof Uint8Array) {
        return encodeUint8Array(value, buf, offset);
    }
    else {
        return encodeUint8ArrayList(value, buf, offset);
    }
}
function decode$a(buf, offset = 0) {
    if (buf instanceof Uint8Array) {
        return decodeUint8Array(buf, offset);
    }
    else {
        return decodeUint8ArrayList(buf, offset);
    }
}

const f32 = new Float32Array([-0]);
const f8b = new Uint8Array(f32.buffer);
/**
 * Writes a 32 bit float to a buffer using little endian byte order
 */
function writeFloatLE(val, buf, pos) {
    f32[0] = val;
    buf[pos] = f8b[0];
    buf[pos + 1] = f8b[1];
    buf[pos + 2] = f8b[2];
    buf[pos + 3] = f8b[3];
}
/**
 * Reads a 32 bit float from a buffer using little endian byte order
 */
function readFloatLE(buf, pos) {
    f8b[0] = buf[pos];
    f8b[1] = buf[pos + 1];
    f8b[2] = buf[pos + 2];
    f8b[3] = buf[pos + 3];
    return f32[0];
}
const f64 = new Float64Array([-0]);
const d8b = new Uint8Array(f64.buffer);
/**
 * Writes a 64 bit double to a buffer using little endian byte order
 */
function writeDoubleLE(val, buf, pos) {
    f64[0] = val;
    buf[pos] = d8b[0];
    buf[pos + 1] = d8b[1];
    buf[pos + 2] = d8b[2];
    buf[pos + 3] = d8b[3];
    buf[pos + 4] = d8b[4];
    buf[pos + 5] = d8b[5];
    buf[pos + 6] = d8b[6];
    buf[pos + 7] = d8b[7];
}
/**
 * Reads a 64 bit double from a buffer using little endian byte order
 */
function readDoubleLE(buf, pos) {
    d8b[0] = buf[pos];
    d8b[1] = buf[pos + 1];
    d8b[2] = buf[pos + 2];
    d8b[3] = buf[pos + 3];
    d8b[4] = buf[pos + 4];
    d8b[5] = buf[pos + 5];
    d8b[6] = buf[pos + 6];
    d8b[7] = buf[pos + 7];
    return f64[0];
}

// the largest BigInt we can safely downcast to a Number
const MAX_SAFE_NUMBER_INTEGER = BigInt(Number.MAX_SAFE_INTEGER);
const MIN_SAFE_NUMBER_INTEGER = BigInt(Number.MIN_SAFE_INTEGER);
/**
 * Constructs new long bits.
 *
 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
 * @memberof util
 * @function Object() { [native code] }
 * @param {number} lo - Low 32 bits, unsigned
 * @param {number} hi - High 32 bits, unsigned
 */
class LongBits {
    lo;
    hi;
    constructor(lo, hi) {
        // note that the casts below are theoretically unnecessary as of today, but older statically
        // generated converter code might still call the ctor with signed 32bits. kept for compat.
        /**
         * Low bits
         */
        this.lo = lo | 0;
        /**
         * High bits
         */
        this.hi = hi | 0;
    }
    /**
     * Converts this long bits to a possibly unsafe JavaScript number
     */
    toNumber(unsigned = false) {
        if (!unsigned && (this.hi >>> 31) > 0) {
            const lo = ~this.lo + 1 >>> 0;
            let hi = ~this.hi >>> 0;
            if (lo === 0) {
                hi = hi + 1 >>> 0;
            }
            return -(lo + hi * 4294967296);
        }
        return this.lo + this.hi * 4294967296;
    }
    /**
     * Converts this long bits to a bigint
     */
    toBigInt(unsigned = false) {
        if (unsigned) {
            return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
        }
        if ((this.hi >>> 31) !== 0) {
            const lo = ~this.lo + 1 >>> 0;
            let hi = ~this.hi >>> 0;
            if (lo === 0) {
                hi = hi + 1 >>> 0;
            }
            return -(BigInt(lo) + (BigInt(hi) << 32n));
        }
        return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
    }
    /**
     * Converts this long bits to a string
     */
    toString(unsigned = false) {
        return this.toBigInt(unsigned).toString();
    }
    /**
     * Zig-zag encodes this long bits
     */
    zzEncode() {
        const mask = this.hi >> 31;
        this.hi = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
        this.lo = (this.lo << 1 ^ mask) >>> 0;
        return this;
    }
    /**
     * Zig-zag decodes this long bits
     */
    zzDecode() {
        const mask = -(this.lo & 1);
        this.lo = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
        this.hi = (this.hi >>> 1 ^ mask) >>> 0;
        return this;
    }
    /**
     * Calculates the length of this longbits when encoded as a varint.
     */
    length() {
        const part0 = this.lo;
        const part1 = (this.lo >>> 28 | this.hi << 4) >>> 0;
        const part2 = this.hi >>> 24;
        return part2 === 0
            ? part1 === 0
                ? part0 < 16384
                    ? part0 < 128 ? 1 : 2
                    : part0 < 2097152 ? 3 : 4
                : part1 < 16384
                    ? part1 < 128 ? 5 : 6
                    : part1 < 2097152 ? 7 : 8
            : part2 < 128 ? 9 : 10;
    }
    /**
     * Constructs new long bits from the specified number
     */
    static fromBigInt(value) {
        if (value === 0n) {
            return zero;
        }
        if (value < MAX_SAFE_NUMBER_INTEGER && value > MIN_SAFE_NUMBER_INTEGER) {
            return this.fromNumber(Number(value));
        }
        const negative = value < 0n;
        if (negative) {
            value = -value;
        }
        let hi = value >> 32n;
        let lo = value - (hi << 32n);
        if (negative) {
            hi = ~hi | 0n;
            lo = ~lo | 0n;
            if (++lo > TWO_32) {
                lo = 0n;
                if (++hi > TWO_32) {
                    hi = 0n;
                }
            }
        }
        return new LongBits(Number(lo), Number(hi));
    }
    /**
     * Constructs new long bits from the specified number
     */
    static fromNumber(value) {
        if (value === 0) {
            return zero;
        }
        const sign = value < 0;
        if (sign) {
            value = -value;
        }
        let lo = value >>> 0;
        let hi = (value - lo) / 4294967296 >>> 0;
        if (sign) {
            hi = ~hi >>> 0;
            lo = ~lo >>> 0;
            if (++lo > 4294967295) {
                lo = 0;
                if (++hi > 4294967295) {
                    hi = 0;
                }
            }
        }
        return new LongBits(lo, hi);
    }
    /**
     * Constructs new long bits from a number, long or string
     */
    static from(value) {
        if (typeof value === 'number') {
            return LongBits.fromNumber(value);
        }
        if (typeof value === 'bigint') {
            return LongBits.fromBigInt(value);
        }
        if (typeof value === 'string') {
            return LongBits.fromBigInt(BigInt(value));
        }
        return value.low != null || value.high != null ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
    }
}
const zero = new LongBits(0, 0);
zero.toBigInt = function () { return 0n; };
zero.zzEncode = zero.zzDecode = function () { return this; };
zero.length = function () { return 1; };
const TWO_32 = 4294967296n;

/**
 * Calculates the UTF8 byte length of a string
 */
function length$1(string) {
    let len = 0;
    let c = 0;
    for (let i = 0; i < string.length; ++i) {
        c = string.charCodeAt(i);
        if (c < 128) {
            len += 1;
        }
        else if (c < 2048) {
            len += 2;
        }
        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {
            ++i;
            len += 4;
        }
        else {
            len += 3;
        }
    }
    return len;
}
/**
 * Reads UTF8 bytes as a string
 */
function read$2(buffer, start, end) {
    const len = end - start;
    if (len < 1) {
        return '';
    }
    let parts;
    const chunk = [];
    let i = 0; // char offset
    let t; // temporary
    while (start < end) {
        t = buffer[start++];
        if (t < 128) {
            chunk[i++] = t;
        }
        else if (t > 191 && t < 224) {
            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;
        }
        else if (t > 239 && t < 365) {
            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;
            chunk[i++] = 0xD800 + (t >> 10);
            chunk[i++] = 0xDC00 + (t & 1023);
        }
        else {
            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;
        }
        if (i > 8191) {
            (parts ?? (parts = [])).push(String.fromCharCode.apply(String, chunk));
            i = 0;
        }
    }
    if (parts != null) {
        if (i > 0) {
            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
        }
        return parts.join('');
    }
    return String.fromCharCode.apply(String, chunk.slice(0, i));
}
/**
 * Writes a string as UTF8 bytes
 */
function write$2(string, buffer, offset) {
    const start = offset;
    let c1; // character 1
    let c2; // character 2
    for (let i = 0; i < string.length; ++i) {
        c1 = string.charCodeAt(i);
        if (c1 < 128) {
            buffer[offset++] = c1;
        }
        else if (c1 < 2048) {
            buffer[offset++] = c1 >> 6 | 192;
            buffer[offset++] = c1 & 63 | 128;
        }
        else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {
            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);
            ++i;
            buffer[offset++] = c1 >> 18 | 240;
            buffer[offset++] = c1 >> 12 & 63 | 128;
            buffer[offset++] = c1 >> 6 & 63 | 128;
            buffer[offset++] = c1 & 63 | 128;
        }
        else {
            buffer[offset++] = c1 >> 12 | 224;
            buffer[offset++] = c1 >> 6 & 63 | 128;
            buffer[offset++] = c1 & 63 | 128;
        }
    }
    return offset - start;
}

/* istanbul ignore next */
function indexOutOfRange(reader, writeLength) {
    return RangeError(`index out of range: ${reader.pos} + ${writeLength ?? 1} > ${reader.len}`);
}
function readFixed32End(buf, end) {
    return (buf[end - 4] |
        buf[end - 3] << 8 |
        buf[end - 2] << 16 |
        buf[end - 1] << 24) >>> 0;
}
/**
 * Constructs a new reader instance using the specified buffer.
 */
class Uint8ArrayReader {
    buf;
    pos;
    len;
    _slice = Uint8Array.prototype.subarray;
    constructor(buffer) {
        /**
         * Read buffer
         */
        this.buf = buffer;
        /**
         * Read buffer position
         */
        this.pos = 0;
        /**
         * Read buffer length
         */
        this.len = buffer.length;
    }
    /**
     * Reads a varint as an unsigned 32 bit value
     */
    uint32() {
        let value = 4294967295;
        value = (this.buf[this.pos] & 127) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 127) << 7) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        value = (value | (this.buf[this.pos] & 15) << 28) >>> 0;
        if (this.buf[this.pos++] < 128)
            return value;
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange(this, 10);
        }
        return value;
    }
    /**
     * Reads a varint as a signed 32 bit value
     */
    int32() {
        return this.uint32() | 0;
    }
    /**
     * Reads a zig-zag encoded varint as a signed 32 bit value
     */
    sint32() {
        const value = this.uint32();
        return value >>> 1 ^ -(value & 1) | 0;
    }
    /**
     * Reads a varint as a boolean
     */
    bool() {
        return this.uint32() !== 0;
    }
    /**
     * Reads fixed 32 bits as an unsigned 32 bit integer
     */
    fixed32() {
        if (this.pos + 4 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const res = readFixed32End(this.buf, this.pos += 4);
        return res;
    }
    /**
     * Reads fixed 32 bits as a signed 32 bit integer
     */
    sfixed32() {
        if (this.pos + 4 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const res = readFixed32End(this.buf, this.pos += 4) | 0;
        return res;
    }
    /**
     * Reads a float (32 bit) as a number
     */
    float() {
        if (this.pos + 4 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const value = readFloatLE(this.buf, this.pos);
        this.pos += 4;
        return value;
    }
    /**
     * Reads a double (64 bit float) as a number
     */
    double() {
        /* istanbul ignore if */
        if (this.pos + 8 > this.len) {
            throw indexOutOfRange(this, 4);
        }
        const value = readDoubleLE(this.buf, this.pos);
        this.pos += 8;
        return value;
    }
    /**
     * Reads a sequence of bytes preceded by its length as a varint
     */
    bytes() {
        const length = this.uint32();
        const start = this.pos;
        const end = this.pos + length;
        /* istanbul ignore if */
        if (end > this.len) {
            throw indexOutOfRange(this, length);
        }
        this.pos += length;
        return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
            ? new Uint8Array(0)
            : this.buf.subarray(start, end);
    }
    /**
     * Reads a string preceded by its byte length as a varint
     */
    string() {
        const bytes = this.bytes();
        return read$2(bytes, 0, bytes.length);
    }
    /**
     * Skips the specified number of bytes if specified, otherwise skips a varint
     */
    skip(length) {
        if (typeof length === 'number') {
            /* istanbul ignore if */
            if (this.pos + length > this.len) {
                throw indexOutOfRange(this, length);
            }
            this.pos += length;
        }
        else {
            do {
                /* istanbul ignore if */
                if (this.pos >= this.len) {
                    throw indexOutOfRange(this);
                }
            } while ((this.buf[this.pos++] & 128) !== 0);
        }
        return this;
    }
    /**
     * Skips the next element of the specified wire type
     */
    skipType(wireType) {
        switch (wireType) {
            case 0:
                this.skip();
                break;
            case 1:
                this.skip(8);
                break;
            case 2:
                this.skip(this.uint32());
                break;
            case 3:
                while ((wireType = this.uint32() & 7) !== 4) {
                    this.skipType(wireType);
                }
                break;
            case 5:
                this.skip(4);
                break;
            /* istanbul ignore next */
            default:
                throw Error(`invalid wire type ${wireType} at offset ${this.pos}`);
        }
        return this;
    }
    readLongVarint() {
        // tends to deopt with local vars for octet etc.
        const bits = new LongBits(0, 0);
        let i = 0;
        if (this.len - this.pos > 4) { // fast route (lo)
            for (; i < 4; ++i) {
                // 1st..4th
                bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
            // 5th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) >> 4) >>> 0;
            if (this.buf[this.pos++] < 128) {
                return bits;
            }
            i = 0;
        }
        else {
            for (; i < 3; ++i) {
                /* istanbul ignore if */
                if (this.pos >= this.len) {
                    throw indexOutOfRange(this);
                }
                // 1st..3th
                bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
            // 4th
            bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
            return bits;
        }
        if (this.len - this.pos > 4) { // fast route (hi)
            for (; i < 5; ++i) {
                // 6th..10th
                bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
        }
        else {
            for (; i < 5; ++i) {
                if (this.pos >= this.len) {
                    throw indexOutOfRange(this);
                }
                // 6th..10th
                bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
                if (this.buf[this.pos++] < 128) {
                    return bits;
                }
            }
        }
        throw Error('invalid varint encoding');
    }
    readFixed64() {
        if (this.pos + 8 > this.len) {
            throw indexOutOfRange(this, 8);
        }
        const lo = readFixed32End(this.buf, this.pos += 4);
        const hi = readFixed32End(this.buf, this.pos += 4);
        return new LongBits(lo, hi);
    }
    /**
     * Reads a varint as a signed 64 bit value
     */
    int64() {
        return this.readLongVarint().toBigInt();
    }
    /**
     * Reads a varint as a signed 64 bit value returned as a possibly unsafe
     * JavaScript number
     */
    int64Number() {
        return this.readLongVarint().toNumber();
    }
    /**
     * Reads a varint as a signed 64 bit value returned as a string
     */
    int64String() {
        return this.readLongVarint().toString();
    }
    /**
     * Reads a varint as an unsigned 64 bit value
     */
    uint64() {
        return this.readLongVarint().toBigInt(true);
    }
    /**
     * Reads a varint as an unsigned 64 bit value returned as a possibly unsafe
     * JavaScript number
     */
    uint64Number() {
        const value = decodeUint8Array(this.buf, this.pos);
        this.pos += encodingLength$3(value);
        return value;
    }
    /**
     * Reads a varint as an unsigned 64 bit value returned as a string
     */
    uint64String() {
        return this.readLongVarint().toString(true);
    }
    /**
     * Reads a zig-zag encoded varint as a signed 64 bit value
     */
    sint64() {
        return this.readLongVarint().zzDecode().toBigInt();
    }
    /**
     * Reads a zig-zag encoded varint as a signed 64 bit value returned as a
     * possibly unsafe JavaScript number
     */
    sint64Number() {
        return this.readLongVarint().zzDecode().toNumber();
    }
    /**
     * Reads a zig-zag encoded varint as a signed 64 bit value returned as a
     * string
     */
    sint64String() {
        return this.readLongVarint().zzDecode().toString();
    }
    /**
     * Reads fixed 64 bits
     */
    fixed64() {
        return this.readFixed64().toBigInt();
    }
    /**
     * Reads fixed 64 bits returned as a possibly unsafe JavaScript number
     */
    fixed64Number() {
        return this.readFixed64().toNumber();
    }
    /**
     * Reads fixed 64 bits returned as a string
     */
    fixed64String() {
        return this.readFixed64().toString();
    }
    /**
     * Reads zig-zag encoded fixed 64 bits
     */
    sfixed64() {
        return this.readFixed64().toBigInt();
    }
    /**
     * Reads zig-zag encoded fixed 64 bits returned as a possibly unsafe
     * JavaScript number
     */
    sfixed64Number() {
        return this.readFixed64().toNumber();
    }
    /**
     * Reads zig-zag encoded fixed 64 bits returned as a string
     */
    sfixed64String() {
        return this.readFixed64().toString();
    }
}
function createReader(buf) {
    return new Uint8ArrayReader(buf instanceof Uint8Array ? buf : buf.subarray());
}

function decodeMessage(buf, codec, opts) {
    const reader = createReader(buf);
    return codec.decode(reader, undefined, opts);
}

function equals$2(aa, bb) {
    if (aa === bb)
        return true;
    if (aa.byteLength !== bb.byteLength) {
        return false;
    }
    for (let ii = 0; ii < aa.byteLength; ii++) {
        if (aa[ii] !== bb[ii]) {
            return false;
        }
    }
    return true;
}
function coerce(o) {
    if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array')
        return o;
    if (o instanceof ArrayBuffer)
        return new Uint8Array(o);
    if (ArrayBuffer.isView(o)) {
        return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
    }
    throw new Error('Unknown type, must be binary type');
}
function fromString$1(str) {
    return new TextEncoder().encode(str);
}
function toString$7(b) {
    return new TextDecoder().decode(b);
}

/* eslint-disable */
// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
/**
 * @param {string} ALPHABET
 * @param {any} name
 */
function base$1(ALPHABET, name) {
    if (ALPHABET.length >= 255) {
        throw new TypeError('Alphabet too long');
    }
    var BASE_MAP = new Uint8Array(256);
    for (var j = 0; j < BASE_MAP.length; j++) {
        BASE_MAP[j] = 255;
    }
    for (var i = 0; i < ALPHABET.length; i++) {
        var x = ALPHABET.charAt(i);
        var xc = x.charCodeAt(0);
        if (BASE_MAP[xc] !== 255) {
            throw new TypeError(x + ' is ambiguous');
        }
        BASE_MAP[xc] = i;
    }
    var BASE = ALPHABET.length;
    var LEADER = ALPHABET.charAt(0);
    var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
    var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
    /**
     * @param {any[] | Iterable<number>} source
     */
    function encode(source) {
        // @ts-ignore
        if (source instanceof Uint8Array)
            ;
        else if (ArrayBuffer.isView(source)) {
            source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
        }
        else if (Array.isArray(source)) {
            source = Uint8Array.from(source);
        }
        if (!(source instanceof Uint8Array)) {
            throw new TypeError('Expected Uint8Array');
        }
        if (source.length === 0) {
            return '';
        }
        // Skip & count leading zeroes.
        var zeroes = 0;
        var length = 0;
        var pbegin = 0;
        var pend = source.length;
        while (pbegin !== pend && source[pbegin] === 0) {
            pbegin++;
            zeroes++;
        }
        // Allocate enough space in big-endian base58 representation.
        var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
        var b58 = new Uint8Array(size);
        // Process the bytes.
        while (pbegin !== pend) {
            var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
            var i = 0;
            for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
                carry += (256 * b58[it1]) >>> 0;
                b58[it1] = (carry % BASE) >>> 0;
                carry = (carry / BASE) >>> 0;
            }
            if (carry !== 0) {
                throw new Error('Non-zero carry');
            }
            length = i;
            pbegin++;
        }
        // Skip leading zeroes in base58 result.
        var it2 = size - length;
        while (it2 !== size && b58[it2] === 0) {
            it2++;
        }
        // Translate the result into a string.
        var str = LEADER.repeat(zeroes);
        for (; it2 < size; ++it2) {
            str += ALPHABET.charAt(b58[it2]);
        }
        return str;
    }
    /**
     * @param {string | string[]} source
     */
    function decodeUnsafe(source) {
        if (typeof source !== 'string') {
            throw new TypeError('Expected String');
        }
        if (source.length === 0) {
            return new Uint8Array();
        }
        var psz = 0;
        // Skip leading spaces.
        if (source[psz] === ' ') {
            return;
        }
        // Skip and count leading '1's.
        var zeroes = 0;
        var length = 0;
        while (source[psz] === LEADER) {
            zeroes++;
            psz++;
        }
        // Allocate enough space in big-endian base256 representation.
        var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
        var b256 = new Uint8Array(size);
        // Process the characters.
        while (source[psz]) {
            // Decode character
            var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
            if (carry === 255) {
                return;
            }
            var i = 0;
            for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
                carry += (BASE * b256[it3]) >>> 0;
                b256[it3] = (carry % 256) >>> 0;
                carry = (carry / 256) >>> 0;
            }
            if (carry !== 0) {
                throw new Error('Non-zero carry');
            }
            length = i;
            psz++;
        }
        // Skip trailing spaces.
        if (source[psz] === ' ') {
            return;
        }
        // Skip leading zeroes in b256.
        var it4 = size - length;
        while (it4 !== size && b256[it4] === 0) {
            it4++;
        }
        var vch = new Uint8Array(zeroes + (size - it4));
        var j = zeroes;
        while (it4 !== size) {
            vch[j++] = b256[it4++];
        }
        return vch;
    }
    /**
     * @param {string | string[]} string
     */
    function decode(string) {
        var buffer = decodeUnsafe(string);
        if (buffer) {
            return buffer;
        }
        throw new Error(`Non-${name} character`);
    }
    return {
        encode: encode,
        decodeUnsafe: decodeUnsafe,
        decode: decode
    };
}
var src = base$1;
var _brrp__multiformats_scope_baseX = src;

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 */
let Encoder$2 = class Encoder {
    name;
    prefix;
    baseEncode;
    constructor(name, prefix, baseEncode) {
        this.name = name;
        this.prefix = prefix;
        this.baseEncode = baseEncode;
    }
    encode(bytes) {
        if (bytes instanceof Uint8Array) {
            return `${this.prefix}${this.baseEncode(bytes)}`;
        }
        else {
            throw Error('Unknown type, must be binary type');
        }
    }
};
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 */
let Decoder$2 = class Decoder {
    name;
    prefix;
    baseDecode;
    prefixCodePoint;
    constructor(name, prefix, baseDecode) {
        this.name = name;
        this.prefix = prefix;
        const prefixCodePoint = prefix.codePointAt(0);
        /* c8 ignore next 3 */
        if (prefixCodePoint === undefined) {
            throw new Error('Invalid prefix character');
        }
        this.prefixCodePoint = prefixCodePoint;
        this.baseDecode = baseDecode;
    }
    decode(text) {
        if (typeof text === 'string') {
            if (text.codePointAt(0) !== this.prefixCodePoint) {
                throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
            }
            return this.baseDecode(text.slice(this.prefix.length));
        }
        else {
            throw Error('Can only multibase decode strings');
        }
    }
    or(decoder) {
        return or$2(this, decoder);
    }
};
class ComposedDecoder {
    decoders;
    constructor(decoders) {
        this.decoders = decoders;
    }
    or(decoder) {
        return or$2(this, decoder);
    }
    decode(input) {
        const prefix = input[0];
        const decoder = this.decoders[prefix];
        if (decoder != null) {
            return decoder.decode(input);
        }
        else {
            throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
        }
    }
}
function or$2(left, right) {
    // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
    return new ComposedDecoder({
        ...(left.decoders ?? { [left.prefix]: left }),
        ...(right.decoders ?? { [right.prefix]: right })
    });
}
class Codec {
    name;
    prefix;
    baseEncode;
    baseDecode;
    encoder;
    decoder;
    constructor(name, prefix, baseEncode, baseDecode) {
        this.name = name;
        this.prefix = prefix;
        this.baseEncode = baseEncode;
        this.baseDecode = baseDecode;
        this.encoder = new Encoder$2(name, prefix, baseEncode);
        this.decoder = new Decoder$2(name, prefix, baseDecode);
    }
    encode(input) {
        return this.encoder.encode(input);
    }
    decode(input) {
        return this.decoder.decode(input);
    }
}
function from$2({ name, prefix, encode, decode }) {
    return new Codec(name, prefix, encode, decode);
}
function baseX({ name, prefix, alphabet }) {
    const { encode, decode } = _brrp__multiformats_scope_baseX(alphabet, name);
    return from$2({
        prefix,
        name,
        encode,
        decode: (text) => coerce(decode(text))
    });
}
function decode$9(string, alphabet, bitsPerChar, name) {
    // Build the character lookup table:
    const codes = {};
    for (let i = 0; i < alphabet.length; ++i) {
        codes[alphabet[i]] = i;
    }
    // Count the padding bytes:
    let end = string.length;
    while (string[end - 1] === '=') {
        --end;
    }
    // Allocate the output:
    const out = new Uint8Array((end * bitsPerChar / 8) | 0);
    // Parse the data:
    let bits = 0; // Number of bits currently in the buffer
    let buffer = 0; // Bits waiting to be written out, MSB first
    let written = 0; // Next byte to write
    for (let i = 0; i < end; ++i) {
        // Read one character from the string:
        const value = codes[string[i]];
        if (value === undefined) {
            throw new SyntaxError(`Non-${name} character`);
        }
        // Append the bits to the buffer:
        buffer = (buffer << bitsPerChar) | value;
        bits += bitsPerChar;
        // Write out some bits if the buffer has a byte's worth:
        if (bits >= 8) {
            bits -= 8;
            out[written++] = 0xff & (buffer >> bits);
        }
    }
    // Verify that we have received just enough bits:
    if (bits >= bitsPerChar || (0xff & (buffer << (8 - bits))) !== 0) {
        throw new SyntaxError('Unexpected end of data');
    }
    return out;
}
function encode$9(data, alphabet, bitsPerChar) {
    const pad = alphabet[alphabet.length - 1] === '=';
    const mask = (1 << bitsPerChar) - 1;
    let out = '';
    let bits = 0; // Number of bits currently in the buffer
    let buffer = 0; // Bits waiting to be written out, MSB first
    for (let i = 0; i < data.length; ++i) {
        // Slurp data into the buffer:
        buffer = (buffer << 8) | data[i];
        bits += 8;
        // Write out as much as we can:
        while (bits > bitsPerChar) {
            bits -= bitsPerChar;
            out += alphabet[mask & (buffer >> bits)];
        }
    }
    // Partial character:
    if (bits !== 0) {
        out += alphabet[mask & (buffer << (bitsPerChar - bits))];
    }
    // Add padding characters until we hit a byte boundary:
    if (pad) {
        while (((out.length * bitsPerChar) & 7) !== 0) {
            out += '=';
        }
    }
    return out;
}
/**
 * RFC4648 Factory
 */
function rfc4648({ name, prefix, bitsPerChar, alphabet }) {
    return from$2({
        prefix,
        name,
        encode(input) {
            return encode$9(input, alphabet, bitsPerChar);
        },
        decode(input) {
            return decode$9(input, alphabet, bitsPerChar, name);
        }
    });
}

const base10 = baseX({
    prefix: '9',
    name: 'base10',
    alphabet: '0123456789'
});

var base10$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10
});

const base16 = rfc4648({
    prefix: 'f',
    name: 'base16',
    alphabet: '0123456789abcdef',
    bitsPerChar: 4
});
const base16upper = rfc4648({
    prefix: 'F',
    name: 'base16upper',
    alphabet: '0123456789ABCDEF',
    bitsPerChar: 4
});

var base16$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16,
    base16upper: base16upper
});

const base2 = rfc4648({
    prefix: '0',
    name: 'base2',
    alphabet: '01',
    bitsPerChar: 1
});

var base2$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2
});

const alphabet = Array.from('🚀🪐☄🛰🌌🌑🌒🌓🌔🌕🌖🌗🌘🌍🌏🌎🐉☀💻🖥💾💿😂❤😍🤣😊🙏💕😭😘👍😅👏😁🔥🥰💔💖💙😢🤔😆🙄💪😉☺👌🤗💜😔😎😇🌹🤦🎉💞✌✨🤷😱😌🌸🙌😋💗💚😏💛🙂💓🤩😄😀🖤😃💯🙈👇🎶😒🤭❣😜💋👀😪😑💥🙋😞😩😡🤪👊🥳😥🤤👉💃😳✋😚😝😴🌟😬🙃🍀🌷😻😓⭐✅🥺🌈😈🤘💦✔😣🏃💐☹🎊💘😠☝😕🌺🎂🌻😐🖕💝🙊😹🗣💫💀👑🎵🤞😛🔴😤🌼😫⚽🤙☕🏆🤫👈😮🙆🍻🍃🐶💁😲🌿🧡🎁⚡🌞🎈❌✊👋😰🤨😶🤝🚶💰🍓💢🤟🙁🚨💨🤬✈🎀🍺🤓😙💟🌱😖👶🥴▶➡❓💎💸⬇😨🌚🦋😷🕺⚠🙅😟😵👎🤲🤠🤧📌🔵💅🧐🐾🍒😗🤑🌊🤯🐷☎💧😯💆👆🎤🙇🍑❄🌴💣🐸💌📍🥀🤢👅💡💩👐📸👻🤐🤮🎼🥵🚩🍎🍊👼💍📣🥂');
const alphabetBytesToChars = (alphabet.reduce((p, c, i) => { p[i] = c; return p; }, ([])));
const alphabetCharsToBytes = (alphabet.reduce((p, c, i) => {
    const codePoint = c.codePointAt(0);
    if (codePoint == null) {
        throw new Error(`Invalid character: ${c}`);
    }
    p[codePoint] = i;
    return p;
}, ([])));
function encode$8(data) {
    return data.reduce((p, c) => {
        p += alphabetBytesToChars[c];
        return p;
    }, '');
}
function decode$8(str) {
    const byts = [];
    for (const char of str) {
        const codePoint = char.codePointAt(0);
        if (codePoint == null) {
            throw new Error(`Invalid character: ${char}`);
        }
        const byt = alphabetCharsToBytes[codePoint];
        if (byt == null) {
            throw new Error(`Non-base256emoji character: ${char}`);
        }
        byts.push(byt);
    }
    return new Uint8Array(byts);
}
const base256emoji = from$2({
    prefix: '🚀',
    name: 'base256emoji',
    encode: encode$8,
    decode: decode$8
});

var base256emoji$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji
});

const base32$2 = rfc4648({
    prefix: 'b',
    name: 'base32',
    alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
    bitsPerChar: 5
});
const base32upper = rfc4648({
    prefix: 'B',
    name: 'base32upper',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
    bitsPerChar: 5
});
const base32pad = rfc4648({
    prefix: 'c',
    name: 'base32pad',
    alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
    bitsPerChar: 5
});
const base32padupper = rfc4648({
    prefix: 'C',
    name: 'base32padupper',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
    bitsPerChar: 5
});
const base32hex = rfc4648({
    prefix: 'v',
    name: 'base32hex',
    alphabet: '0123456789abcdefghijklmnopqrstuv',
    bitsPerChar: 5
});
const base32hexupper = rfc4648({
    prefix: 'V',
    name: 'base32hexupper',
    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
    bitsPerChar: 5
});
const base32hexpad = rfc4648({
    prefix: 't',
    name: 'base32hexpad',
    alphabet: '0123456789abcdefghijklmnopqrstuv=',
    bitsPerChar: 5
});
const base32hexpadupper = rfc4648({
    prefix: 'T',
    name: 'base32hexpadupper',
    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
    bitsPerChar: 5
});
const base32z = rfc4648({
    prefix: 'h',
    name: 'base32z',
    alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
    bitsPerChar: 5
});

var base32$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$2,
    base32hex: base32hex,
    base32hexpad: base32hexpad,
    base32hexpadupper: base32hexpadupper,
    base32hexupper: base32hexupper,
    base32pad: base32pad,
    base32padupper: base32padupper,
    base32upper: base32upper,
    base32z: base32z
});

const base36 = baseX({
    prefix: 'k',
    name: 'base36',
    alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});
const base36upper = baseX({
    prefix: 'K',
    name: 'base36upper',
    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36,
    base36upper: base36upper
});

const base58btc = baseX({
    name: 'base58btc',
    prefix: 'z',
    alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});
const base58flickr = baseX({
    name: 'base58flickr',
    prefix: 'Z',
    alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc,
    base58flickr: base58flickr
});

const base64 = rfc4648({
    prefix: 'm',
    name: 'base64',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
    bitsPerChar: 6
});
const base64pad = rfc4648({
    prefix: 'M',
    name: 'base64pad',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
    bitsPerChar: 6
});
const base64url = rfc4648({
    prefix: 'u',
    name: 'base64url',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
    bitsPerChar: 6
});
const base64urlpad = rfc4648({
    prefix: 'U',
    name: 'base64urlpad',
    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
    bitsPerChar: 6
});

var base64$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64,
    base64pad: base64pad,
    base64url: base64url,
    base64urlpad: base64urlpad
});

const base8 = rfc4648({
    prefix: '7',
    name: 'base8',
    alphabet: '01234567',
    bitsPerChar: 3
});

var base8$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8
});

const identity$1 = from$2({
    prefix: '\x00',
    name: 'identity',
    encode: (buf) => toString$7(buf),
    decode: (str) => fromString$1(str)
});

var identityBase = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$1
});

new TextEncoder();
new TextDecoder();

/* eslint-disable */
var encode_1 = encode$7;
var MSB$1 = 0x80, REST$1 = 0x7F, MSBALL = ~REST$1, INT = Math.pow(2, 31);
/**
 * @param {number} num
 * @param {number[]} out
 * @param {number} offset
 */
function encode$7(num, out, offset) {
    out = out || [];
    offset = offset || 0;
    var oldOffset = offset;
    while (num >= INT) {
        out[offset++] = (num & 0xFF) | MSB$1;
        num /= 128;
    }
    while (num & MSBALL) {
        out[offset++] = (num & 0xFF) | MSB$1;
        num >>>= 7;
    }
    out[offset] = num | 0;
    // @ts-ignore
    encode$7.bytes = offset - oldOffset + 1;
    return out;
}
var decode$7 = read$1;
var MSB$1$1 = 0x80, REST$1$1 = 0x7F;
/**
 * @param {string | any[]} buf
 * @param {number} offset
 */
function read$1(buf, offset) {
    var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
    do {
        if (counter >= l) {
            // @ts-ignore
            read$1.bytes = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf[counter++];
        res += shift < 28
            ? (b & REST$1$1) << shift
            : (b & REST$1$1) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB$1$1);
    // @ts-ignore
    read$1.bytes = counter - offset;
    return res;
}
var N1 = Math.pow(2, 7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);
var length = function (/** @type {number} */ value) {
    return (value < N1 ? 1
        : value < N2 ? 2
            : value < N3 ? 3
                : value < N4 ? 4
                    : value < N5 ? 5
                        : value < N6 ? 6
                            : value < N7 ? 7
                                : value < N8 ? 8
                                    : value < N9 ? 9
                                        : 10);
};
var varint = {
    encode: encode_1,
    decode: decode$7,
    encodingLength: length
};
var _brrp_varint = varint;

function decode$6(data, offset = 0) {
    const code = _brrp_varint.decode(data, offset);
    return [code, _brrp_varint.decode.bytes];
}
function encodeTo(int, target, offset = 0) {
    _brrp_varint.encode(int, target, offset);
    return target;
}
function encodingLength$2(int) {
    return _brrp_varint.encodingLength(int);
}

/**
 * Creates a multihash digest.
 */
function create$1(code, digest) {
    const size = digest.byteLength;
    const sizeOffset = encodingLength$2(code);
    const digestOffset = sizeOffset + encodingLength$2(size);
    const bytes = new Uint8Array(digestOffset + size);
    encodeTo(code, bytes, 0);
    encodeTo(size, bytes, sizeOffset);
    bytes.set(digest, digestOffset);
    return new Digest(code, size, digest, bytes);
}
/**
 * Turns bytes representation of multihash digest into an instance.
 */
function decode$5(multihash) {
    const bytes = coerce(multihash);
    const [code, sizeOffset] = decode$6(bytes);
    const [size, digestOffset] = decode$6(bytes.subarray(sizeOffset));
    const digest = bytes.subarray(sizeOffset + digestOffset);
    if (digest.byteLength !== size) {
        throw new Error('Incorrect length');
    }
    return new Digest(code, size, digest, bytes);
}
function equals$1(a, b) {
    if (a === b) {
        return true;
    }
    else {
        const data = b;
        return (a.code === data.code &&
            a.size === data.size &&
            data.bytes instanceof Uint8Array &&
            equals$2(a.bytes, data.bytes));
    }
}
/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 */
class Digest {
    code;
    size;
    digest;
    bytes;
    /**
     * Creates a multihash digest.
     */
    constructor(code, size, digest, bytes) {
        this.code = code;
        this.size = size;
        this.digest = digest;
        this.bytes = bytes;
    }
}

const code = 0x0;
const name$2 = 'identity';
const encode$6 = coerce;
function digest(input) {
    return create$1(code, encode$6(input));
}
const identity = { code, name: name$2, encode: encode$6, digest };

function from$1({ name, code, encode }) {
    return new Hasher(name, code, encode);
}
/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 */
class Hasher {
    name;
    code;
    encode;
    constructor(name, code, encode) {
        this.name = name;
        this.code = code;
        this.encode = encode;
    }
    digest(input) {
        if (input instanceof Uint8Array) {
            const result = this.encode(input);
            return result instanceof Uint8Array
                ? create$1(this.code, result)
                /* c8 ignore next 1 */
                : result.then(digest => create$1(this.code, digest));
        }
        else {
            throw Error('Unknown type, must be binary type');
            /* c8 ignore next 1 */
        }
    }
}

/* global crypto */
function sha(name) {
    return async (data) => new Uint8Array(await crypto.subtle.digest(name, data));
}
const sha256$1 = from$1({
    name: 'sha2-256',
    code: 0x12,
    encode: sha('SHA-256')
});

function format(link, base) {
    const { bytes, version } = link;
    switch (version) {
        case 0:
            return toStringV0(bytes, baseCache(link), base ?? base58btc.encoder);
        default:
            return toStringV1(bytes, baseCache(link), (base ?? base32$2.encoder));
    }
}
const cache$1 = new WeakMap();
function baseCache(cid) {
    const baseCache = cache$1.get(cid);
    if (baseCache == null) {
        const baseCache = new Map();
        cache$1.set(cid, baseCache);
        return baseCache;
    }
    return baseCache;
}
class CID {
    code;
    version;
    multihash;
    bytes;
    '/';
    /**
     * @param version - Version of the CID
     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
     * @param multihash - (Multi)hash of the of the content.
     */
    constructor(version, code, multihash, bytes) {
        this.code = code;
        this.version = version;
        this.multihash = multihash;
        this.bytes = bytes;
        // flag to serializers that this is a CID and
        // should be treated specially
        this['/'] = bytes;
    }
    /**
     * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
     * please either use `CID.asCID(cid)` or switch to new signalling mechanism
     *
     * @deprecated
     */
    get asCID() {
        return this;
    }
    // ArrayBufferView
    get byteOffset() {
        return this.bytes.byteOffset;
    }
    // ArrayBufferView
    get byteLength() {
        return this.bytes.byteLength;
    }
    toV0() {
        switch (this.version) {
            case 0: {
                return this;
            }
            case 1: {
                const { code, multihash } = this;
                if (code !== DAG_PB_CODE) {
                    throw new Error('Cannot convert a non dag-pb CID to CIDv0');
                }
                // sha2-256
                if (multihash.code !== SHA_256_CODE) {
                    throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0');
                }
                return (CID.createV0(multihash));
            }
            default: {
                throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
            }
        }
    }
    toV1() {
        switch (this.version) {
            case 0: {
                const { code, digest } = this.multihash;
                const multihash = create$1(code, digest);
                return (CID.createV1(this.code, multihash));
            }
            case 1: {
                return this;
            }
            default: {
                throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
            }
        }
    }
    equals(other) {
        return CID.equals(this, other);
    }
    static equals(self, other) {
        const unknown = other;
        return (unknown != null &&
            self.code === unknown.code &&
            self.version === unknown.version &&
            equals$1(self.multihash, unknown.multihash));
    }
    toString(base) {
        return format(this, base);
    }
    toJSON() {
        return { '/': format(this) };
    }
    link() {
        return this;
    }
    [Symbol.toStringTag] = 'CID';
    // Legacy
    [Symbol.for('nodejs.util.inspect.custom')]() {
        return `CID(${this.toString()})`;
    }
    /**
     * Takes any input `value` and returns a `CID` instance if it was
     * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
     * it will return value back. If `value` is not instance of this CID
     * class, but is compatible CID it will return new instance of this
     * `CID` class. Otherwise returns null.
     *
     * This allows two different incompatible versions of CID library to
     * co-exist and interop as long as binary interface is compatible.
     */
    static asCID(input) {
        if (input == null) {
            return null;
        }
        const value = input;
        if (value instanceof CID) {
            // If value is instance of CID then we're all set.
            return value;
        }
        else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
            // If value isn't instance of this CID class but `this.asCID === this` or
            // `value['/'] === value.bytes` is true it is CID instance coming from a
            // different implementation (diff version or duplicate). In that case we
            // rebase it to this `CID` implementation so caller is guaranteed to get
            // instance with expected API.
            const { version, code, multihash, bytes } = value;
            return new CID(version, code, multihash, bytes ?? encodeCID(version, code, multihash.bytes));
        }
        else if (value[cidSymbol] === true) {
            // If value is a CID from older implementation that used to be tagged via
            // symbol we still rebase it to the this `CID` implementation by
            // delegating that to a constructor.
            const { version, multihash, code } = value;
            const digest = decode$5(multihash);
            return CID.create(version, code, digest);
        }
        else {
            // Otherwise value is not a CID (or an incompatible version of it) in
            // which case we return `null`.
            return null;
        }
    }
    /**
     * @param version - Version of the CID
     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
     * @param digest - (Multi)hash of the of the content.
     */
    static create(version, code, digest) {
        if (typeof code !== 'number') {
            throw new Error('String codecs are no longer supported');
        }
        if (!(digest.bytes instanceof Uint8Array)) {
            throw new Error('Invalid digest');
        }
        switch (version) {
            case 0: {
                if (code !== DAG_PB_CODE) {
                    throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);
                }
                else {
                    return new CID(version, code, digest, digest.bytes);
                }
            }
            case 1: {
                const bytes = encodeCID(version, code, digest.bytes);
                return new CID(version, code, digest, bytes);
            }
            default: {
                throw new Error('Invalid version');
            }
        }
    }
    /**
     * Simplified version of `create` for CIDv0.
     */
    static createV0(digest) {
        return CID.create(0, DAG_PB_CODE, digest);
    }
    /**
     * Simplified version of `create` for CIDv1.
     *
     * @param code - Content encoding format code.
     * @param digest - Multihash of the content.
     */
    static createV1(code, digest) {
        return CID.create(1, code, digest);
    }
    /**
     * Decoded a CID from its binary representation. The byte array must contain
     * only the CID with no additional bytes.
     *
     * An error will be thrown if the bytes provided do not contain a valid
     * binary representation of a CID.
     */
    static decode(bytes) {
        const [cid, remainder] = CID.decodeFirst(bytes);
        if (remainder.length !== 0) {
            throw new Error('Incorrect length');
        }
        return cid;
    }
    /**
     * Decoded a CID from its binary representation at the beginning of a byte
     * array.
     *
     * Returns an array with the first element containing the CID and the second
     * element containing the remainder of the original byte array. The remainder
     * will be a zero-length byte array if the provided bytes only contained a
     * binary CID representation.
     */
    static decodeFirst(bytes) {
        const specs = CID.inspectBytes(bytes);
        const prefixSize = specs.size - specs.multihashSize;
        const multihashBytes = coerce(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
        if (multihashBytes.byteLength !== specs.multihashSize) {
            throw new Error('Incorrect length');
        }
        const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
        const digest = new Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
        const cid = specs.version === 0
            ? CID.createV0(digest)
            : CID.createV1(specs.codec, digest);
        return [cid, bytes.subarray(specs.size)];
    }
    /**
     * Inspect the initial bytes of a CID to determine its properties.
     *
     * Involves decoding up to 4 varints. Typically this will require only 4 to 6
     * bytes but for larger multicodec code values and larger multihash digest
     * lengths these varints can be quite large. It is recommended that at least
     * 10 bytes be made available in the `initialBytes` argument for a complete
     * inspection.
     */
    static inspectBytes(initialBytes) {
        let offset = 0;
        const next = () => {
            const [i, length] = decode$6(initialBytes.subarray(offset));
            offset += length;
            return i;
        };
        let version = next();
        let codec = DAG_PB_CODE;
        if (version === 18) {
            // CIDv0
            version = 0;
            offset = 0;
        }
        else {
            codec = next();
        }
        if (version !== 0 && version !== 1) {
            throw new RangeError(`Invalid CID version ${version}`);
        }
        const prefixSize = offset;
        const multihashCode = next(); // multihash code
        const digestSize = next(); // multihash length
        const size = offset + digestSize;
        const multihashSize = size - prefixSize;
        return { version, codec, multihashCode, digestSize, multihashSize, size };
    }
    /**
     * Takes cid in a string representation and creates an instance. If `base`
     * decoder is not provided will use a default from the configuration. It will
     * throw an error if encoding of the CID is not compatible with supplied (or
     * a default decoder).
     */
    static parse(source, base) {
        const [prefix, bytes] = parseCIDtoBytes(source, base);
        const cid = CID.decode(bytes);
        if (cid.version === 0 && source[0] !== 'Q') {
            throw Error('Version 0 CID string must not include multibase prefix');
        }
        // Cache string representation to avoid computing it on `this.toString()`
        baseCache(cid).set(prefix, source);
        return cid;
    }
}
function parseCIDtoBytes(source, base) {
    switch (source[0]) {
        // CIDv0 is parsed differently
        case 'Q': {
            const decoder = base ?? base58btc;
            return [
                base58btc.prefix,
                decoder.decode(`${base58btc.prefix}${source}`)
            ];
        }
        case base58btc.prefix: {
            const decoder = base ?? base58btc;
            return [base58btc.prefix, decoder.decode(source)];
        }
        case base32$2.prefix: {
            const decoder = base ?? base32$2;
            return [base32$2.prefix, decoder.decode(source)];
        }
        case base36.prefix: {
            const decoder = base ?? base36;
            return [base36.prefix, decoder.decode(source)];
        }
        default: {
            if (base == null) {
                throw Error('To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided');
            }
            return [source[0], base.decode(source)];
        }
    }
}
function toStringV0(bytes, cache, base) {
    const { prefix } = base;
    if (prefix !== base58btc.prefix) {
        throw Error(`Cannot string encode V0 in ${base.name} encoding`);
    }
    const cid = cache.get(prefix);
    if (cid == null) {
        const cid = base.encode(bytes).slice(1);
        cache.set(prefix, cid);
        return cid;
    }
    else {
        return cid;
    }
}
function toStringV1(bytes, cache, base) {
    const { prefix } = base;
    const cid = cache.get(prefix);
    if (cid == null) {
        const cid = base.encode(bytes);
        cache.set(prefix, cid);
        return cid;
    }
    else {
        return cid;
    }
}
const DAG_PB_CODE = 0x70;
const SHA_256_CODE = 0x12;
function encodeCID(version, code, multihash) {
    const codeOffset = encodingLength$2(version);
    const hashOffset = codeOffset + encodingLength$2(code);
    const bytes = new Uint8Array(hashOffset + multihash.byteLength);
    encodeTo(version, bytes, 0);
    encodeTo(code, bytes, codeOffset);
    bytes.set(multihash, hashOffset);
    return bytes;
}
const cidSymbol = Symbol.for('@ipld/js-cid/CID');

const bases = { ...identityBase, ...base2$1, ...base8$1, ...base10$1, ...base16$1, ...base32$3, ...base36$1, ...base58, ...base64$1, ...base256emoji$1 };

function createCodec$1(name, prefix, encode, decode) {
    return {
        name,
        prefix,
        encoder: {
            name,
            prefix,
            encode
        },
        decoder: {
            decode
        }
    };
}
const string$2 = createCodec$1('utf8', 'u', (buf) => {
    const decoder = new TextDecoder('utf8');
    return 'u' + decoder.decode(buf);
}, (str) => {
    const encoder = new TextEncoder();
    return encoder.encode(str.substring(1));
});
const ascii = createCodec$1('ascii', 'a', (buf) => {
    let string = 'a';
    for (let i = 0; i < buf.length; i++) {
        string += String.fromCharCode(buf[i]);
    }
    return string;
}, (str) => {
    str = str.substring(1);
    const buf = allocUnsafe(str.length);
    for (let i = 0; i < str.length; i++) {
        buf[i] = str.charCodeAt(i);
    }
    return buf;
});
const BASES = {
    utf8: string$2,
    'utf-8': string$2,
    hex: bases.base16,
    latin1: ascii,
    ascii,
    binary: ascii,
    ...bases
};

/**
 * Create a `Uint8Array` from the passed string
 *
 * Supports `utf8`, `utf-8`, `hex`, and any encoding supported by the multiformats module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function fromString(string, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    // add multibase prefix
    return base.decoder.decode(`${base.prefix}${string}`); // eslint-disable-line @typescript-eslint/restrict-template-expressions
}

/**
 * A general purpose buffer pool
 */
function pool(size) {
    const SIZE = 8192;
    const MAX = SIZE >>> 1;
    let slab;
    let offset = SIZE;
    return function poolAlloc(size) {
        if (size < 1 || size > MAX) {
            return allocUnsafe(size);
        }
        if (offset + size > SIZE) {
            slab = allocUnsafe(SIZE);
            offset = 0;
        }
        const buf = slab.subarray(offset, offset += size);
        if ((offset & 7) !== 0) {
            // align to 32 bit
            offset = (offset | 7) + 1;
        }
        return buf;
    };
}

/**
 * Constructs a new writer operation instance.
 *
 * @classdesc Scheduled writer operation
 */
class Op {
    /**
     * Function to call
     */
    fn;
    /**
     * Value byte length
     */
    len;
    /**
     * Next operation
     */
    next;
    /**
     * Value to write
     */
    val;
    constructor(fn, len, val) {
        this.fn = fn;
        this.len = len;
        this.next = undefined;
        this.val = val; // type varies
    }
}
/* istanbul ignore next */
function noop$1() { } // eslint-disable-line no-empty-function
/**
 * Constructs a new writer state instance
 */
class State {
    /**
     * Current head
     */
    head;
    /**
     * Current tail
     */
    tail;
    /**
     * Current buffer length
     */
    len;
    /**
     * Next state
     */
    next;
    constructor(writer) {
        this.head = writer.head;
        this.tail = writer.tail;
        this.len = writer.len;
        this.next = writer.states;
    }
}
const bufferPool = pool();
/**
 * Allocates a buffer of the specified size
 */
function alloc$1(size) {
    if (globalThis.Buffer != null) {
        return allocUnsafe(size);
    }
    return bufferPool(size);
}
/**
 * When a value is written, the writer calculates its byte length and puts it into a linked
 * list of operations to perform when finish() is called. This both allows us to allocate
 * buffers of the exact required size and reduces the amount of work we have to do compared
 * to first calculating over objects and then encoding over objects. In our case, the encoding
 * part is just a linked list walk calling operations with already prepared values.
 */
class Uint8ArrayWriter {
    /**
     * Current length
     */
    len;
    /**
     * Operations head
     */
    head;
    /**
     * Operations tail
     */
    tail;
    /**
     * Linked forked states
     */
    states;
    constructor() {
        this.len = 0;
        this.head = new Op(noop$1, 0, 0);
        this.tail = this.head;
        this.states = null;
    }
    /**
     * Pushes a new operation to the queue
     */
    _push(fn, len, val) {
        this.tail = this.tail.next = new Op(fn, len, val);
        this.len += len;
        return this;
    }
    /**
     * Writes an unsigned 32 bit value as a varint
     */
    uint32(value) {
        // here, the call to this.push has been inlined and a varint specific Op subclass is used.
        // uint32 is by far the most frequently used operation and benefits significantly from this.
        this.len += (this.tail = this.tail.next = new VarintOp((value = value >>> 0) <
            128
            ? 1
            : value < 16384
                ? 2
                : value < 2097152
                    ? 3
                    : value < 268435456
                        ? 4
                        : 5, value)).len;
        return this;
    }
    /**
     * Writes a signed 32 bit value as a varint`
     */
    int32(value) {
        return value < 0
            ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec
            : this.uint32(value);
    }
    /**
     * Writes a 32 bit value as a varint, zig-zag encoded
     */
    sint32(value) {
        return this.uint32((value << 1 ^ value >> 31) >>> 0);
    }
    /**
     * Writes an unsigned 64 bit value as a varint
     */
    uint64(value) {
        const bits = LongBits.fromBigInt(value);
        return this._push(writeVarint64, bits.length(), bits);
    }
    /**
     * Writes an unsigned 64 bit value as a varint
     */
    uint64Number(value) {
        return this._push(encodeUint8Array, encodingLength$3(value), value);
    }
    /**
     * Writes an unsigned 64 bit value as a varint
     */
    uint64String(value) {
        return this.uint64(BigInt(value));
    }
    /**
     * Writes a signed 64 bit value as a varint
     */
    int64(value) {
        return this.uint64(value);
    }
    /**
     * Writes a signed 64 bit value as a varint
     */
    int64Number(value) {
        return this.uint64Number(value);
    }
    /**
     * Writes a signed 64 bit value as a varint
     */
    int64String(value) {
        return this.uint64String(value);
    }
    /**
     * Writes a signed 64 bit value as a varint, zig-zag encoded
     */
    sint64(value) {
        const bits = LongBits.fromBigInt(value).zzEncode();
        return this._push(writeVarint64, bits.length(), bits);
    }
    /**
     * Writes a signed 64 bit value as a varint, zig-zag encoded
     */
    sint64Number(value) {
        const bits = LongBits.fromNumber(value).zzEncode();
        return this._push(writeVarint64, bits.length(), bits);
    }
    /**
     * Writes a signed 64 bit value as a varint, zig-zag encoded
     */
    sint64String(value) {
        return this.sint64(BigInt(value));
    }
    /**
     * Writes a boolish value as a varint
     */
    bool(value) {
        return this._push(writeByte, 1, value ? 1 : 0);
    }
    /**
     * Writes an unsigned 32 bit value as fixed 32 bits
     */
    fixed32(value) {
        return this._push(writeFixed32, 4, value >>> 0);
    }
    /**
     * Writes a signed 32 bit value as fixed 32 bits
     */
    sfixed32(value) {
        return this.fixed32(value);
    }
    /**
     * Writes an unsigned 64 bit value as fixed 64 bits
     */
    fixed64(value) {
        const bits = LongBits.fromBigInt(value);
        return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
    }
    /**
     * Writes an unsigned 64 bit value as fixed 64 bits
     */
    fixed64Number(value) {
        const bits = LongBits.fromNumber(value);
        return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
    }
    /**
     * Writes an unsigned 64 bit value as fixed 64 bits
     */
    fixed64String(value) {
        return this.fixed64(BigInt(value));
    }
    /**
     * Writes a signed 64 bit value as fixed 64 bits
     */
    sfixed64(value) {
        return this.fixed64(value);
    }
    /**
     * Writes a signed 64 bit value as fixed 64 bits
     */
    sfixed64Number(value) {
        return this.fixed64Number(value);
    }
    /**
     * Writes a signed 64 bit value as fixed 64 bits
     */
    sfixed64String(value) {
        return this.fixed64String(value);
    }
    /**
     * Writes a float (32 bit)
     */
    float(value) {
        return this._push(writeFloatLE, 4, value);
    }
    /**
     * Writes a double (64 bit float).
     *
     * @function
     * @param {number} value - Value to write
     * @returns {Writer} `this`
     */
    double(value) {
        return this._push(writeDoubleLE, 8, value);
    }
    /**
     * Writes a sequence of bytes
     */
    bytes(value) {
        const len = value.length >>> 0;
        if (len === 0) {
            return this._push(writeByte, 1, 0);
        }
        return this.uint32(len)._push(writeBytes, len, value);
    }
    /**
     * Writes a string
     */
    string(value) {
        const len = length$1(value);
        return len !== 0
            ? this.uint32(len)._push(write$2, len, value)
            : this._push(writeByte, 1, 0);
    }
    /**
     * Forks this writer's state by pushing it to a stack.
     * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
     */
    fork() {
        this.states = new State(this);
        this.head = this.tail = new Op(noop$1, 0, 0);
        this.len = 0;
        return this;
    }
    /**
     * Resets this instance to the last state
     */
    reset() {
        if (this.states != null) {
            this.head = this.states.head;
            this.tail = this.states.tail;
            this.len = this.states.len;
            this.states = this.states.next;
        }
        else {
            this.head = this.tail = new Op(noop$1, 0, 0);
            this.len = 0;
        }
        return this;
    }
    /**
     * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
     */
    ldelim() {
        const head = this.head;
        const tail = this.tail;
        const len = this.len;
        this.reset().uint32(len);
        if (len !== 0) {
            this.tail.next = head.next; // skip noop
            this.tail = tail;
            this.len += len;
        }
        return this;
    }
    /**
     * Finishes the write operation
     */
    finish() {
        let head = this.head.next; // skip noop
        const buf = alloc$1(this.len);
        let pos = 0;
        while (head != null) {
            head.fn(head.val, buf, pos);
            pos += head.len;
            head = head.next;
        }
        // this.head = this.tail = null;
        return buf;
    }
}
function writeByte(val, buf, pos) {
    buf[pos] = val & 255;
}
function writeVarint32(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}
/**
 * Constructs a new varint writer operation instance.
 *
 * @classdesc Scheduled varint writer operation
 */
class VarintOp extends Op {
    next;
    constructor(len, val) {
        super(writeVarint32, len, val);
        this.next = undefined;
    }
}
function writeVarint64(val, buf, pos) {
    while (val.hi !== 0) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}
function writeFixed32(val, buf, pos) {
    buf[pos] = val & 255;
    buf[pos + 1] = val >>> 8 & 255;
    buf[pos + 2] = val >>> 16 & 255;
    buf[pos + 3] = val >>> 24;
}
function writeBytes(val, buf, pos) {
    buf.set(val, pos);
}
if (globalThis.Buffer != null) {
    Uint8ArrayWriter.prototype.bytes = function (value) {
        const len = value.length >>> 0;
        this.uint32(len);
        if (len > 0) {
            this._push(writeBytesBuffer, len, value);
        }
        return this;
    };
    Uint8ArrayWriter.prototype.string = function (value) {
        const len = globalThis.Buffer.byteLength(value);
        this.uint32(len);
        if (len > 0) {
            this._push(writeStringBuffer, len, value);
        }
        return this;
    };
}
function writeBytesBuffer(val, buf, pos) {
    buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
    // also works for plain array values
}
function writeStringBuffer(val, buf, pos) {
    if (val.length < 40) {
        // plain js is faster for short strings (probably due to redundant assertions)
        write$2(val, buf, pos);
        // @ts-expect-error buf isn't a Uint8Array?
    }
    else if (buf.utf8Write != null) {
        // @ts-expect-error buf isn't a Uint8Array?
        buf.utf8Write(val, pos);
    }
    else {
        buf.set(fromString(val), pos);
    }
}
/**
 * Creates a new writer
 */
function createWriter() {
    return new Uint8ArrayWriter();
}

function encodeMessage(message, codec) {
    const w = createWriter();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES || (CODEC_TYPES = {}));
function createCodec(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function enumeration(v) {
    function findValue(val) {
        // Use the reverse mapping to look up the enum key for the stored value
        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings
        if (v[val.toString()] == null) {
            throw new Error('Invalid enum value');
        }
        return v[val];
    }
    const encode = function enumEncode(val, writer) {
        const enumValue = findValue(val);
        writer.int32(enumValue);
    };
    const decode = function enumDecode(reader) {
        const val = reader.int32();
        return findValue(val);
    };
    // @ts-expect-error yeah yeah
    return createCodec('enum', CODEC_TYPES.VARINT, encode, decode);
}

function message$1(encode, decode) {
    return createCodec('message', CODEC_TYPES.LENGTH_DELIMITED, encode, decode);
}

/**
 * @packageDocumentation
 *
 * This module contains serialization/deserialization code used when encoding/decoding protobufs.
 *
 * It should be declared as a dependency of your project:
 *
 * ```console
 * npm i protons-runtime
 * ```
 */
/**
 * Thrown when a repeated field has too many elements
 */
class MaxLengthError extends Error {
    /**
     * This will be removed in a future release
     *
     * @deprecated use the `.name` property instead
     */
    code = 'ERR_MAX_LENGTH';
    name = 'MaxLengthError';
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var RateLimitProof$4;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$2(0),
                    merkleRoot: alloc$2(0),
                    epoch: alloc$2(0),
                    shareX: alloc$2(0),
                    shareY: alloc$2(0),
                    nullifier: alloc$2(0),
                    rlnIdentifier: alloc$2(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$4 || (RateLimitProof$4 = {}));
var WakuMessage$4;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$4.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$2(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$4.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$4 || (WakuMessage$4 = {}));

var message = /*#__PURE__*/Object.freeze({
    __proto__: null,
    get RateLimitProof () { return RateLimitProof$4; },
    get WakuMessage () { return WakuMessage$4; }
});

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var FilterRequest;
(function (FilterRequest) {
    (function (ContentFilter) {
        let _codec;
        ContentFilter.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                        w.uint32(10);
                        w.string(obj.contentTopic);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length, opts = {}) => {
                    const obj = {
                        contentTopic: ''
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1: {
                                obj.contentTopic = reader.string();
                                break;
                            }
                            default: {
                                reader.skipType(tag & 7);
                                break;
                            }
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        ContentFilter.encode = (obj) => {
            return encodeMessage(obj, ContentFilter.codec());
        };
        ContentFilter.decode = (buf, opts) => {
            return decodeMessage(buf, ContentFilter.codec(), opts);
        };
    })(FilterRequest.ContentFilter || (FilterRequest.ContentFilter = {}));
    let _codec;
    FilterRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.subscribe != null && obj.subscribe !== false)) {
                    w.uint32(8);
                    w.bool(obj.subscribe);
                }
                if ((obj.topic != null && obj.topic !== '')) {
                    w.uint32(18);
                    w.string(obj.topic);
                }
                if (obj.contentFilters != null) {
                    for (const value of obj.contentFilters) {
                        w.uint32(26);
                        FilterRequest.ContentFilter.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    subscribe: false,
                    topic: '',
                    contentFilters: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.subscribe = reader.bool();
                            break;
                        }
                        case 2: {
                            obj.topic = reader.string();
                            break;
                        }
                        case 3: {
                            if (opts.limits?.contentFilters != null && obj.contentFilters.length === opts.limits.contentFilters) {
                                throw new MaxLengthError('Decode error - map field "contentFilters" had too many elements');
                            }
                            obj.contentFilters.push(FilterRequest.ContentFilter.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.contentFilters$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRequest.encode = (obj) => {
        return encodeMessage(obj, FilterRequest.codec());
    };
    FilterRequest.decode = (buf, opts) => {
        return decodeMessage(buf, FilterRequest.codec(), opts);
    };
})(FilterRequest || (FilterRequest = {}));
var MessagePush$1;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(10);
                        WakuMessage$3.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    messages: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            if (opts.limits?.messages != null && obj.messages.length === opts.limits.messages) {
                                throw new MaxLengthError('Decode error - map field "messages" had too many elements');
                            }
                            obj.messages.push(WakuMessage$3.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.messages$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf, opts) => {
        return decodeMessage(buf, MessagePush.codec(), opts);
    };
})(MessagePush$1 || (MessagePush$1 = {}));
var FilterRpc;
(function (FilterRpc) {
    let _codec;
    FilterRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    FilterRequest.codec().encode(obj.request, w);
                }
                if (obj.push != null) {
                    w.uint32(26);
                    MessagePush$1.codec().encode(obj.push, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.request = FilterRequest.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.request
                            });
                            break;
                        }
                        case 3: {
                            obj.push = MessagePush$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.push
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRpc.encode = (obj) => {
        return encodeMessage(obj, FilterRpc.codec());
    };
    FilterRpc.decode = (buf, opts) => {
        return decodeMessage(buf, FilterRpc.codec(), opts);
    };
})(FilterRpc || (FilterRpc = {}));
var RateLimitProof$3;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$2(0),
                    merkleRoot: alloc$2(0),
                    epoch: alloc$2(0),
                    shareX: alloc$2(0),
                    shareY: alloc$2(0),
                    nullifier: alloc$2(0),
                    rlnIdentifier: alloc$2(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$3 || (RateLimitProof$3 = {}));
var WakuMessage$3;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$3.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$2(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$3.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$3 || (WakuMessage$3 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var TopicOnlyMessage;
(function (TopicOnlyMessage) {
    let _codec;
    TopicOnlyMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    TopicOnlyMessage.encode = (obj) => {
        return encodeMessage(obj, TopicOnlyMessage.codec());
    };
    TopicOnlyMessage.decode = (buf, opts) => {
        return decodeMessage(buf, TopicOnlyMessage.codec(), opts);
    };
})(TopicOnlyMessage || (TopicOnlyMessage = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var FilterSubscribeRequest;
(function (FilterSubscribeRequest) {
    let FilterSubscribeType;
    (function (FilterSubscribeType) {
        FilterSubscribeType["SUBSCRIBER_PING"] = "SUBSCRIBER_PING";
        FilterSubscribeType["SUBSCRIBE"] = "SUBSCRIBE";
        FilterSubscribeType["UNSUBSCRIBE"] = "UNSUBSCRIBE";
        FilterSubscribeType["UNSUBSCRIBE_ALL"] = "UNSUBSCRIBE_ALL";
    })(FilterSubscribeType = FilterSubscribeRequest.FilterSubscribeType || (FilterSubscribeRequest.FilterSubscribeType = {}));
    let __FilterSubscribeTypeValues;
    (function (__FilterSubscribeTypeValues) {
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["SUBSCRIBER_PING"] = 0] = "SUBSCRIBER_PING";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["SUBSCRIBE"] = 1] = "SUBSCRIBE";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["UNSUBSCRIBE"] = 2] = "UNSUBSCRIBE";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["UNSUBSCRIBE_ALL"] = 3] = "UNSUBSCRIBE_ALL";
    })(__FilterSubscribeTypeValues || (__FilterSubscribeTypeValues = {}));
    (function (FilterSubscribeType) {
        FilterSubscribeType.codec = () => {
            return enumeration(__FilterSubscribeTypeValues);
        };
    })(FilterSubscribeType = FilterSubscribeRequest.FilterSubscribeType || (FilterSubscribeRequest.FilterSubscribeType = {}));
    let _codec;
    FilterSubscribeRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.filterSubscribeType != null && __FilterSubscribeTypeValues[obj.filterSubscribeType] !== 0) {
                    w.uint32(16);
                    FilterSubscribeRequest.FilterSubscribeType.codec().encode(obj.filterSubscribeType, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(82);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentTopics != null) {
                    for (const value of obj.contentTopics) {
                        w.uint32(90);
                        w.string(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    filterSubscribeType: FilterSubscribeType.SUBSCRIBER_PING,
                    contentTopics: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.filterSubscribeType = FilterSubscribeRequest.FilterSubscribeType.codec().decode(reader);
                            break;
                        }
                        case 10: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 11: {
                            if (opts.limits?.contentTopics != null && obj.contentTopics.length === opts.limits.contentTopics) {
                                throw new MaxLengthError('Decode error - map field "contentTopics" had too many elements');
                            }
                            obj.contentTopics.push(reader.string());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterSubscribeRequest.encode = (obj) => {
        return encodeMessage(obj, FilterSubscribeRequest.codec());
    };
    FilterSubscribeRequest.decode = (buf, opts) => {
        return decodeMessage(buf, FilterSubscribeRequest.codec(), opts);
    };
})(FilterSubscribeRequest || (FilterSubscribeRequest = {}));
var FilterSubscribeResponse$1;
(function (FilterSubscribeResponse) {
    let _codec;
    FilterSubscribeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if ((obj.statusCode != null && obj.statusCode !== 0)) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    statusCode: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 10: {
                            obj.statusCode = reader.uint32();
                            break;
                        }
                        case 11: {
                            obj.statusDesc = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterSubscribeResponse.encode = (obj) => {
        return encodeMessage(obj, FilterSubscribeResponse.codec());
    };
    FilterSubscribeResponse.decode = (buf, opts) => {
        return decodeMessage(buf, FilterSubscribeResponse.codec(), opts);
    };
})(FilterSubscribeResponse$1 || (FilterSubscribeResponse$1 = {}));
var MessagePush;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.wakuMessage != null) {
                    w.uint32(10);
                    WakuMessage$2.codec().encode(obj.wakuMessage, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(18);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.wakuMessage = WakuMessage$2.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.wakuMessage
                            });
                            break;
                        }
                        case 2: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf, opts) => {
        return decodeMessage(buf, MessagePush.codec(), opts);
    };
})(MessagePush || (MessagePush = {}));
var RateLimitProof$2;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$2(0),
                    merkleRoot: alloc$2(0),
                    epoch: alloc$2(0),
                    shareX: alloc$2(0),
                    shareY: alloc$2(0),
                    nullifier: alloc$2(0),
                    rlnIdentifier: alloc$2(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$2 || (RateLimitProof$2 = {}));
var WakuMessage$2;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$2.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$2(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$2.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$2 || (WakuMessage$2 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PushRequest;
(function (PushRequest) {
    let _codec;
    PushRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.pubsubTopic != null && obj.pubsubTopic !== '')) {
                    w.uint32(10);
                    w.string(obj.pubsubTopic);
                }
                if (obj.message != null) {
                    w.uint32(18);
                    WakuMessage$1.codec().encode(obj.message, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    pubsubTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 2: {
                            obj.message = WakuMessage$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.message
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRequest.encode = (obj) => {
        return encodeMessage(obj, PushRequest.codec());
    };
    PushRequest.decode = (buf, opts) => {
        return decodeMessage(buf, PushRequest.codec(), opts);
    };
})(PushRequest || (PushRequest = {}));
var PushResponse;
(function (PushResponse) {
    let _codec;
    PushResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.isSuccess != null && obj.isSuccess !== false)) {
                    w.uint32(8);
                    w.bool(obj.isSuccess);
                }
                if (obj.info != null) {
                    w.uint32(18);
                    w.string(obj.info);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    isSuccess: false
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.isSuccess = reader.bool();
                            break;
                        }
                        case 2: {
                            obj.info = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushResponse.encode = (obj) => {
        return encodeMessage(obj, PushResponse.codec());
    };
    PushResponse.decode = (buf, opts) => {
        return decodeMessage(buf, PushResponse.codec(), opts);
    };
})(PushResponse || (PushResponse = {}));
var PushRpc$1;
(function (PushRpc) {
    let _codec;
    PushRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    PushRequest.codec().encode(obj.request, w);
                }
                if (obj.response != null) {
                    w.uint32(26);
                    PushResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.request = PushRequest.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.request
                            });
                            break;
                        }
                        case 3: {
                            obj.response = PushResponse.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.response
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRpc.encode = (obj) => {
        return encodeMessage(obj, PushRpc.codec());
    };
    PushRpc.decode = (buf, opts) => {
        return decodeMessage(buf, PushRpc.codec(), opts);
    };
})(PushRpc$1 || (PushRpc$1 = {}));
var RateLimitProof$1;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$2(0),
                    merkleRoot: alloc$2(0),
                    epoch: alloc$2(0),
                    shareX: alloc$2(0),
                    shareY: alloc$2(0),
                    nullifier: alloc$2(0),
                    rlnIdentifier: alloc$2(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof$1 || (RateLimitProof$1 = {}));
var WakuMessage$1;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$1.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$2(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof$1.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage$1 || (WakuMessage$1 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var WakuMessageKeyValue;
(function (WakuMessageKeyValue) {
    let _codec;
    WakuMessageKeyValue.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messageHash != null) {
                    w.uint32(10);
                    w.bytes(obj.messageHash);
                }
                if (obj.message != null) {
                    w.uint32(18);
                    WakuMessage.codec().encode(obj.message, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(26);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.messageHash = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.message = WakuMessage.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.message
                            });
                            break;
                        }
                        case 3: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessageKeyValue.encode = (obj) => {
        return encodeMessage(obj, WakuMessageKeyValue.codec());
    };
    WakuMessageKeyValue.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessageKeyValue.codec(), opts);
    };
})(WakuMessageKeyValue || (WakuMessageKeyValue = {}));
var StoreQueryRequest$1;
(function (StoreQueryRequest) {
    let _codec;
    StoreQueryRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if ((obj.includeData != null && obj.includeData !== false)) {
                    w.uint32(16);
                    w.bool(obj.includeData);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(82);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentTopics != null) {
                    for (const value of obj.contentTopics) {
                        w.uint32(90);
                        w.string(value);
                    }
                }
                if (obj.timeStart != null) {
                    w.uint32(96);
                    w.sint64(obj.timeStart);
                }
                if (obj.timeEnd != null) {
                    w.uint32(104);
                    w.sint64(obj.timeEnd);
                }
                if (obj.messageHashes != null) {
                    for (const value of obj.messageHashes) {
                        w.uint32(162);
                        w.bytes(value);
                    }
                }
                if (obj.paginationCursor != null) {
                    w.uint32(410);
                    w.bytes(obj.paginationCursor);
                }
                if ((obj.paginationForward != null && obj.paginationForward !== false)) {
                    w.uint32(416);
                    w.bool(obj.paginationForward);
                }
                if (obj.paginationLimit != null) {
                    w.uint32(424);
                    w.uint64(obj.paginationLimit);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    includeData: false,
                    contentTopics: [],
                    messageHashes: [],
                    paginationForward: false
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 2: {
                            obj.includeData = reader.bool();
                            break;
                        }
                        case 10: {
                            obj.pubsubTopic = reader.string();
                            break;
                        }
                        case 11: {
                            if (opts.limits?.contentTopics != null && obj.contentTopics.length === opts.limits.contentTopics) {
                                throw new MaxLengthError('Decode error - map field "contentTopics" had too many elements');
                            }
                            obj.contentTopics.push(reader.string());
                            break;
                        }
                        case 12: {
                            obj.timeStart = reader.sint64();
                            break;
                        }
                        case 13: {
                            obj.timeEnd = reader.sint64();
                            break;
                        }
                        case 20: {
                            if (opts.limits?.messageHashes != null && obj.messageHashes.length === opts.limits.messageHashes) {
                                throw new MaxLengthError('Decode error - map field "messageHashes" had too many elements');
                            }
                            obj.messageHashes.push(reader.bytes());
                            break;
                        }
                        case 51: {
                            obj.paginationCursor = reader.bytes();
                            break;
                        }
                        case 52: {
                            obj.paginationForward = reader.bool();
                            break;
                        }
                        case 53: {
                            obj.paginationLimit = reader.uint64();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    StoreQueryRequest.encode = (obj) => {
        return encodeMessage(obj, StoreQueryRequest.codec());
    };
    StoreQueryRequest.decode = (buf, opts) => {
        return decodeMessage(buf, StoreQueryRequest.codec(), opts);
    };
})(StoreQueryRequest$1 || (StoreQueryRequest$1 = {}));
var StoreQueryResponse$1;
(function (StoreQueryResponse) {
    let _codec;
    StoreQueryResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.statusCode != null) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(162);
                        WakuMessageKeyValue.codec().encode(value, w);
                    }
                }
                if (obj.paginationCursor != null) {
                    w.uint32(410);
                    w.bytes(obj.paginationCursor);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    requestId: '',
                    messages: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.requestId = reader.string();
                            break;
                        }
                        case 10: {
                            obj.statusCode = reader.uint32();
                            break;
                        }
                        case 11: {
                            obj.statusDesc = reader.string();
                            break;
                        }
                        case 20: {
                            if (opts.limits?.messages != null && obj.messages.length === opts.limits.messages) {
                                throw new MaxLengthError('Decode error - map field "messages" had too many elements');
                            }
                            obj.messages.push(WakuMessageKeyValue.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.messages$
                            }));
                            break;
                        }
                        case 51: {
                            obj.paginationCursor = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    StoreQueryResponse.encode = (obj) => {
        return encodeMessage(obj, StoreQueryResponse.codec());
    };
    StoreQueryResponse.decode = (buf, opts) => {
        return decodeMessage(buf, StoreQueryResponse.codec(), opts);
    };
})(StoreQueryResponse$1 || (StoreQueryResponse$1 = {}));
var RateLimitProof;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    proof: alloc$2(0),
                    merkleRoot: alloc$2(0),
                    epoch: alloc$2(0),
                    shareX: alloc$2(0),
                    shareY: alloc$2(0),
                    nullifier: alloc$2(0),
                    rlnIdentifier: alloc$2(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.proof = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.merkleRoot = reader.bytes();
                            break;
                        }
                        case 3: {
                            obj.epoch = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.shareX = reader.bytes();
                            break;
                        }
                        case 5: {
                            obj.shareY = reader.bytes();
                            break;
                        }
                        case 6: {
                            obj.nullifier = reader.bytes();
                            break;
                        }
                        case 7: {
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf, opts) => {
        return decodeMessage(buf, RateLimitProof.codec(), opts);
    };
})(RateLimitProof || (RateLimitProof = {}));
var WakuMessage;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    payload: alloc$2(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.payload = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.contentTopic = reader.string();
                            break;
                        }
                        case 3: {
                            obj.version = reader.uint32();
                            break;
                        }
                        case 10: {
                            obj.timestamp = reader.sint64();
                            break;
                        }
                        case 11: {
                            obj.meta = reader.bytes();
                            break;
                        }
                        case 21: {
                            obj.rateLimitProof = RateLimitProof.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.rateLimitProof
                            });
                            break;
                        }
                        case 31: {
                            obj.ephemeral = reader.bool();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMessage.codec(), opts);
    };
})(WakuMessage || (WakuMessage = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PeerInfo;
(function (PeerInfo) {
    let _codec;
    PeerInfo.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.enr != null) {
                    w.uint32(10);
                    w.bytes(obj.enr);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.enr = reader.bytes();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerInfo.encode = (obj) => {
        return encodeMessage(obj, PeerInfo.codec());
    };
    PeerInfo.decode = (buf, opts) => {
        return decodeMessage(buf, PeerInfo.codec(), opts);
    };
})(PeerInfo || (PeerInfo = {}));
var PeerExchangeQuery;
(function (PeerExchangeQuery) {
    let _codec;
    PeerExchangeQuery.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.numPeers != null) {
                    w.uint32(8);
                    w.uint64(obj.numPeers);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.numPeers = reader.uint64();
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeQuery.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeQuery.codec());
    };
    PeerExchangeQuery.decode = (buf, opts) => {
        return decodeMessage(buf, PeerExchangeQuery.codec(), opts);
    };
})(PeerExchangeQuery || (PeerExchangeQuery = {}));
var PeerExchangeResponse;
(function (PeerExchangeResponse) {
    let _codec;
    PeerExchangeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.peerInfos != null) {
                    for (const value of obj.peerInfos) {
                        w.uint32(10);
                        PeerInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    peerInfos: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            if (opts.limits?.peerInfos != null && obj.peerInfos.length === opts.limits.peerInfos) {
                                throw new MaxLengthError('Decode error - map field "peerInfos" had too many elements');
                            }
                            obj.peerInfos.push(PeerInfo.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.peerInfos$
                            }));
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeResponse.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeResponse.codec());
    };
    PeerExchangeResponse.decode = (buf, opts) => {
        return decodeMessage(buf, PeerExchangeResponse.codec(), opts);
    };
})(PeerExchangeResponse || (PeerExchangeResponse = {}));
var PeerExchangeRPC$1;
(function (PeerExchangeRPC) {
    let _codec;
    PeerExchangeRPC.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.query != null) {
                    w.uint32(10);
                    PeerExchangeQuery.codec().encode(obj.query, w);
                }
                if (obj.response != null) {
                    w.uint32(18);
                    PeerExchangeResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.query = PeerExchangeQuery.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.query
                            });
                            break;
                        }
                        case 2: {
                            obj.response = PeerExchangeResponse.codec().decode(reader, reader.uint32(), {
                                limits: opts.limits?.response
                            });
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeRPC.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeRPC.codec());
    };
    PeerExchangeRPC.decode = (buf, opts) => {
        return decodeMessage(buf, PeerExchangeRPC.codec(), opts);
    };
})(PeerExchangeRPC$1 || (PeerExchangeRPC$1 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var WakuMetadataRequest;
(function (WakuMetadataRequest) {
    let _codec;
    WakuMetadataRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.clusterId != null) {
                    w.uint32(8);
                    w.uint32(obj.clusterId);
                }
                if (obj.shards != null) {
                    for (const value of obj.shards) {
                        w.uint32(16);
                        w.uint32(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    shards: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.clusterId = reader.uint32();
                            break;
                        }
                        case 2: {
                            if (opts.limits?.shards != null && obj.shards.length === opts.limits.shards) {
                                throw new MaxLengthError('Decode error - map field "shards" had too many elements');
                            }
                            obj.shards.push(reader.uint32());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMetadataRequest.encode = (obj) => {
        return encodeMessage(obj, WakuMetadataRequest.codec());
    };
    WakuMetadataRequest.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMetadataRequest.codec(), opts);
    };
})(WakuMetadataRequest || (WakuMetadataRequest = {}));
var WakuMetadataResponse;
(function (WakuMetadataResponse) {
    let _codec;
    WakuMetadataResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.clusterId != null) {
                    w.uint32(8);
                    w.uint32(obj.clusterId);
                }
                if (obj.shards != null) {
                    for (const value of obj.shards) {
                        w.uint32(16);
                        w.uint32(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length, opts = {}) => {
                const obj = {
                    shards: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.clusterId = reader.uint32();
                            break;
                        }
                        case 2: {
                            if (opts.limits?.shards != null && obj.shards.length === opts.limits.shards) {
                                throw new MaxLengthError('Decode error - map field "shards" had too many elements');
                            }
                            obj.shards.push(reader.uint32());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMetadataResponse.encode = (obj) => {
        return encodeMessage(obj, WakuMetadataResponse.codec());
    };
    WakuMetadataResponse.decode = (buf, opts) => {
        return decodeMessage(buf, WakuMetadataResponse.codec(), opts);
    };
})(WakuMetadataResponse || (WakuMetadataResponse = {}));

function isDefined(value) {
    return Boolean(value);
}

/**
 * Return pseudo random subset of the input.
 */
function getPseudoRandomSubset(values, wantedNumber) {
    if (values.length <= wantedNumber || values.length <= 1) {
        return values;
    }
    return shuffle(values).slice(0, wantedNumber);
}
function shuffle(arr) {
    if (arr.length <= 1) {
        return arr;
    }
    const randInt = () => {
        return Math.floor(Math.random() * Math.floor(arr.length));
    };
    for (let i = 0; i < arr.length; i++) {
        const j = randInt();
        const tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
    return arr;
}

function groupByContentTopic(values) {
    const groupedDecoders = new Map();
    values.forEach((value) => {
        let decs = groupedDecoders.get(value.contentTopic);
        if (!decs) {
            groupedDecoders.set(value.contentTopic, []);
            decs = groupedDecoders.get(value.contentTopic);
        }
        decs.push(value);
    });
    return groupedDecoders;
}

const FRAME_RATE = 60;
/**
 * Function that transforms IReceiver subscription to iterable stream of data.
 * @param receiver - object that allows to be subscribed to;
 * @param decoder - parameter to be passed to receiver for subscription;
 * @param options - options for receiver for subscription;
 * @param iteratorOptions - optional configuration for iterator;
 * @returns iterator and stop function to terminate it.
 */
async function toAsyncIterator(receiver, decoder, iteratorOptions) {
    const iteratorDelay = iteratorOptions?.iteratorDelay ?? FRAME_RATE;
    const messages = [];
    let unsubscribe;
    unsubscribe = await receiver.subscribeWithUnsubscribe(decoder, (message) => {
        messages.push(message);
    });
    const isWithTimeout = Number.isInteger(iteratorOptions?.timeoutMs);
    const timeoutMs = iteratorOptions?.timeoutMs ?? 0;
    const startTime = Date.now();
    async function* iterator() {
        while (true) {
            if (isWithTimeout && Date.now() - startTime >= timeoutMs) {
                return;
            }
            await wait(iteratorDelay);
            const message = messages.shift();
            if (!unsubscribe && messages.length === 0) {
                return message;
            }
            if (!message && unsubscribe) {
                continue;
            }
            yield message;
        }
    }
    return {
        iterator: iterator(),
        async stop() {
            if (unsubscribe) {
                await unsubscribe();
                unsubscribe = undefined;
            }
        }
    };
}
function wait(ms) {
    return new Promise((resolve) => {
        setTimeout(resolve, ms);
    });
}

const MB = 1024 ** 2;
const SIZE_CAP_IN_MB = 1;
/**
 * Return whether the size of the message is under the upper limit for the network.
 * This performs a protobuf encoding! If you have access to the fully encoded message,
 * use {@link isSizeUnderCapBuf} instead.
 * @param message
 * @param encoder
 */
async function isMessageSizeUnderCap(encoder, message) {
    const buf = await encoder.toWire(message);
    if (!buf)
        return false;
    return isWireSizeUnderCap(buf);
}
const isWireSizeUnderCap = (buf) => buf.length / MB <= SIZE_CAP_IN_MB;

function number$2(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error(`positive integer expected, not ${n}`);
}
// copied from utils
function isBytes$3(a) {
    return (a instanceof Uint8Array ||
        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));
}
function bytes$1(b, ...lengths) {
    if (!isBytes$3(b))
        throw new Error('Uint8Array expected');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error(`Uint8Array expected of length ${lengths}, not of length=${b.length}`);
}
function hash(h) {
    if (typeof h !== 'function' || typeof h.create !== 'function')
        throw new Error('Hash should be wrapped by utils.wrapConstructor');
    number$2(h.outputLen);
    number$2(h.blockLen);
}
function exists$1(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output$1(out, instance) {
    bytes$1(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}

const crypto$2 = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;

/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.
// node.js versions earlier than v19 don't declare it in global scope.
// For node.js, package.json#exports field mapping rewrites import
// from `crypto` to `cryptoNode`, which imports native module.
// Makes the utils un-importable in browsers without a bundler.
// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.
// Cast array to view
const createView$1 = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// The rotate right (circular right shift) operation for uint32
const rotr = (word, shift) => (word << (32 - shift)) | (word >>> shift);
new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
// There is no setImmediate in browser and setTimeout is slow.
// call of async fn will return Promise, which will be fullfiled only on
// next scheduler queue processing step and this is exactly what we need.
const nextTick = async () => { };
// Returns control to thread each 'tick' ms to avoid blocking
async function asyncLoop(iters, tick, cb) {
    let ts = Date.now();
    for (let i = 0; i < iters; i++) {
        cb(i);
        // Date.now() is not monotonic, so in case if clock goes backwards we return return control too
        const diff = Date.now() - ts;
        if (diff >= 0 && diff < tick)
            continue;
        await nextTick();
        ts += diff;
    }
}
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes$3(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes$2(data) {
    if (typeof data === 'string')
        data = utf8ToBytes$3(data);
    bytes$1(data);
    return data;
}
/**
 * Copies several Uint8Arrays into one.
 */
function concatBytes$2(...arrays) {
    let sum = 0;
    for (let i = 0; i < arrays.length; i++) {
        const a = arrays[i];
        bytes$1(a);
        sum += a.length;
    }
    const res = new Uint8Array(sum);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const a = arrays[i];
        res.set(a, pad);
        pad += a.length;
    }
    return res;
}
// For runtime check if class implements interface
class Hash {
    // Safe version that clones internal state
    clone() {
        return this._cloneInto();
    }
}
const toStr = {}.toString;
function checkOpts$1(defaults, opts) {
    if (opts !== undefined && toStr.call(opts) !== '[object Object]')
        throw new Error('Options should be object or undefined');
    const merged = Object.assign(defaults, opts);
    return merged;
}
function wrapConstructor(hashCons) {
    const hashC = (msg) => hashCons().update(toBytes$2(msg)).digest();
    const tmp = hashCons();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashCons();
    return hashC;
}
/**
 * Secure PRNG. Uses `crypto.getRandomValues`, which defers to OS.
 */
function randomBytes$1(bytesLength = 32) {
    if (crypto$2 && typeof crypto$2.getRandomValues === 'function') {
        return crypto$2.getRandomValues(new Uint8Array(bytesLength));
    }
    // Legacy Node.js compatibility
    if (crypto$2 && typeof crypto$2.randomBytes === 'function') {
        return crypto$2.randomBytes(bytesLength);
    }
    throw new Error('crypto.getRandomValues must be defined');
}

/**
 * Polyfill for Safari 14
 */
function setBigUint64$1(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
/**
 * Choice: a ? b : c
 */
const Chi = (a, b, c) => (a & b) ^ (~a & c);
/**
 * Majority function, true if any two inputs is true
 */
const Maj = (a, b, c) => (a & b) ^ (a & c) ^ (b & c);
/**
 * Merkle-Damgard hash construction base class.
 * Could be used to create MD5, RIPEMD, SHA1, SHA2.
 */
class HashMD extends Hash {
    constructor(blockLen, outputLen, padOffset, isLE) {
        super();
        this.blockLen = blockLen;
        this.outputLen = outputLen;
        this.padOffset = padOffset;
        this.isLE = isLE;
        this.finished = false;
        this.length = 0;
        this.pos = 0;
        this.destroyed = false;
        this.buffer = new Uint8Array(blockLen);
        this.view = createView$1(this.buffer);
    }
    update(data) {
        exists$1(this);
        const { view, buffer, blockLen } = this;
        data = toBytes$2(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input, cast it to view and process
            if (take === blockLen) {
                const dataView = createView$1(data);
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(dataView, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(view, 0);
                this.pos = 0;
            }
        }
        this.length += data.length;
        this.roundClean();
        return this;
    }
    digestInto(out) {
        exists$1(this);
        output$1(out, this);
        this.finished = true;
        // Padding
        // We can avoid allocation of buffer for padding completely if it
        // was previously not allocated here. But it won't change performance.
        const { buffer, view, blockLen, isLE } = this;
        let { pos } = this;
        // append the bit '1' to the message
        buffer[pos++] = 0b10000000;
        this.buffer.subarray(pos).fill(0);
        // we have less than padOffset left in buffer, so we cannot put length in
        // current block, need process it and pad again
        if (this.padOffset > blockLen - pos) {
            this.process(view, 0);
            pos = 0;
        }
        // Pad until full block byte with zeros
        for (let i = pos; i < blockLen; i++)
            buffer[i] = 0;
        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that
        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.
        // So we just write lowest 64 bits of that value.
        setBigUint64$1(view, blockLen - 8, BigInt(this.length * 8), isLE);
        this.process(view, 0);
        const oview = createView$1(out);
        const len = this.outputLen;
        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT
        if (len % 4)
            throw new Error('_sha2: outputLen should be aligned to 32bit');
        const outLen = len / 4;
        const state = this.get();
        if (outLen > state.length)
            throw new Error('_sha2: outputLen bigger than state');
        for (let i = 0; i < outLen; i++)
            oview.setUint32(4 * i, state[i], isLE);
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
    _cloneInto(to) {
        to || (to = new this.constructor());
        to.set(...this.get());
        const { blockLen, buffer, length, finished, destroyed, pos } = this;
        to.length = length;
        to.pos = pos;
        to.finished = finished;
        to.destroyed = destroyed;
        if (length % blockLen)
            to.buffer.set(buffer);
        return to;
    }
}

// SHA2-256 need to try 2^128 hashes to execute birthday attack.
// BTC network is doing 2^67 hashes/sec as per early 2023.
// Round constants:
// first 32 bits of the fractional parts of the cube roots of the first 64 primes 2..311)
// prettier-ignore
const SHA256_K = /* @__PURE__ */ new Uint32Array([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
]);
// Initial state:
// first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19
// prettier-ignore
const SHA256_IV = /* @__PURE__ */ new Uint32Array([
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
]);
// Temporary buffer, not used to store anything between runs
// Named this way because it matches specification.
const SHA256_W = /* @__PURE__ */ new Uint32Array(64);
class SHA256 extends HashMD {
    constructor() {
        super(64, 32, 8, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        this.A = SHA256_IV[0] | 0;
        this.B = SHA256_IV[1] | 0;
        this.C = SHA256_IV[2] | 0;
        this.D = SHA256_IV[3] | 0;
        this.E = SHA256_IV[4] | 0;
        this.F = SHA256_IV[5] | 0;
        this.G = SHA256_IV[6] | 0;
        this.H = SHA256_IV[7] | 0;
    }
    get() {
        const { A, B, C, D, E, F, G, H } = this;
        return [A, B, C, D, E, F, G, H];
    }
    // prettier-ignore
    set(A, B, C, D, E, F, G, H) {
        this.A = A | 0;
        this.B = B | 0;
        this.C = C | 0;
        this.D = D | 0;
        this.E = E | 0;
        this.F = F | 0;
        this.G = G | 0;
        this.H = H | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4)
            SHA256_W[i] = view.getUint32(offset, false);
        for (let i = 16; i < 64; i++) {
            const W15 = SHA256_W[i - 15];
            const W2 = SHA256_W[i - 2];
            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);
            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);
            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;
        }
        // Compression function main loop, 64 rounds
        let { A, B, C, D, E, F, G, H } = this;
        for (let i = 0; i < 64; i++) {
            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);
            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);
            const T2 = (sigma0 + Maj(A, B, C)) | 0;
            H = G;
            G = F;
            F = E;
            E = (D + T1) | 0;
            D = C;
            C = B;
            B = A;
            A = (T1 + T2) | 0;
        }
        // Add the compressed chunk to the current hash value
        A = (A + this.A) | 0;
        B = (B + this.B) | 0;
        C = (C + this.C) | 0;
        D = (D + this.D) | 0;
        E = (E + this.E) | 0;
        F = (F + this.F) | 0;
        G = (G + this.G) | 0;
        H = (H + this.H) | 0;
        this.set(A, B, C, D, E, F, G, H);
    }
    roundClean() {
        SHA256_W.fill(0);
    }
    destroy() {
        this.set(0, 0, 0, 0, 0, 0, 0, 0);
        this.buffer.fill(0);
    }
}
/**
 * SHA2-256 hash function
 * @param message - data that would be hashed
 */
const sha256 = /* @__PURE__ */ wrapConstructor(() => new SHA256());

var Protocols;
(function (Protocols) {
    Protocols["Relay"] = "relay";
    Protocols["Store"] = "store";
    Protocols["LightPush"] = "lightpush";
    Protocols["Filter"] = "filter";
})(Protocols || (Protocols = {}));
var ProtocolError;
(function (ProtocolError) {
    /** Could not determine the origin of the fault. Best to check connectivity and try again */
    ProtocolError["GENERIC_FAIL"] = "Generic error";
    /**
     * Failure to protobuf encode the message. This is not recoverable and needs
     * further investigation.
     */
    ProtocolError["ENCODE_FAILED"] = "Failed to encode";
    /**
     * Failure to protobuf decode the message. May be due to a remote peer issue,
     * ensuring that messages are sent via several peer enable mitigation of this error.
     */
    ProtocolError["DECODE_FAILED"] = "Failed to decode";
    /**
     * The message payload is empty, making the message invalid. Ensure that a non-empty
     * payload is set on the outgoing message.
     */
    ProtocolError["EMPTY_PAYLOAD"] = "Payload is empty";
    /**
     * The message size is above the maximum message size allowed on the Waku Network.
     * Compressing the message or using an alternative strategy for large messages is recommended.
     */
    ProtocolError["SIZE_TOO_BIG"] = "Size is too big";
    /**
     * The PubsubTopic passed to the send function is not configured on the Waku node.
     * Please ensure that the PubsubTopic is used when initializing the Waku node.
     */
    ProtocolError["TOPIC_NOT_CONFIGURED"] = "Topic not configured";
    /**
     * The pubsub topic configured on the decoder does not match the pubsub topic setup on the protocol.
     * Ensure that the pubsub topic used for decoder creation is the same as the one used for protocol.
     */
    ProtocolError["TOPIC_DECODER_MISMATCH"] = "Topic decoder mismatch";
    /**
     * The topics passed in the decoders do not match each other, or don't exist at all.
     * Ensure that all the pubsub topics used in the decoders are valid and match each other.
     */
    ProtocolError["INVALID_DECODER_TOPICS"] = "Invalid decoder topics";
    /**
     * Failure to find a peer with suitable protocols. This may due to a connection issue.
     * Mitigation can be: retrying after a given time period, display connectivity issue
     * to user or listening for `peer:connected:bootstrap` or `peer:connected:peer-exchange`
     * on the connection manager before retrying.
     */
    ProtocolError["NO_PEER_AVAILABLE"] = "No peer available";
    /**
     * Failure to find a stream to the peer. This may be because the connection with the peer is not still alive.
     * Mitigation can be: retrying after a given time period, or mitigation for `NO_PEER_AVAILABLE` can be used.
     */
    ProtocolError["NO_STREAM_AVAILABLE"] = "No stream available";
    /**
     * The remote peer did not behave as expected. Mitigation for `NO_PEER_AVAILABLE`
     * or `DECODE_FAILED` can be used.
     */
    ProtocolError["NO_RESPONSE"] = "No response received";
    /**
     * The remote peer rejected the message. Information provided by the remote peer
     * is logged. Review message validity, or mitigation for `NO_PEER_AVAILABLE`
     * or `DECODE_FAILED` can be used.
     */
    ProtocolError["REMOTE_PEER_REJECTED"] = "Remote peer rejected";
    /**
     * The protocol request timed out without a response. This may be due to a connection issue.
     * Mitigation can be: retrying after a given time period
     */
    ProtocolError["REQUEST_TIMEOUT"] = "Request timeout";
    /**
     * Missing credentials info message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L186
     */
    ProtocolError["RLN_IDENTITY_MISSING"] = "Identity credentials are not set";
    /**
     * Membership index missing info message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L188
     */
    ProtocolError["RLN_MEMBERSHIP_INDEX"] = "Membership index is not set";
    /**
     * Message limit is missing.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L190
     */
    ProtocolError["RLN_LIMIT_MISSING"] = "User message limit is not set";
    /**
     * General proof generation error message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L201C19-L201C42
     */
    ProtocolError["RLN_PROOF_GENERATION"] = "Proof generation failed";
})(ProtocolError || (ProtocolError = {}));

var Tags;
(function (Tags) {
    Tags["BOOTSTRAP"] = "bootstrap";
    Tags["PEER_EXCHANGE"] = "peer-exchange";
    Tags["LOCAL"] = "local-peer-cache";
})(Tags || (Tags = {}));
var EPeersByDiscoveryEvents;
(function (EPeersByDiscoveryEvents) {
    EPeersByDiscoveryEvents["PEER_DISCOVERY_BOOTSTRAP"] = "peer:discovery:bootstrap";
    EPeersByDiscoveryEvents["PEER_DISCOVERY_PEER_EXCHANGE"] = "peer:discovery:peer-exchange";
    EPeersByDiscoveryEvents["PEER_CONNECT_BOOTSTRAP"] = "peer:connected:bootstrap";
    EPeersByDiscoveryEvents["PEER_CONNECT_PEER_EXCHANGE"] = "peer:connected:peer-exchange";
})(EPeersByDiscoveryEvents || (EPeersByDiscoveryEvents = {}));
var EConnectionStateEvents;
(function (EConnectionStateEvents) {
    EConnectionStateEvents["CONNECTION_STATUS"] = "waku:connection";
})(EConnectionStateEvents || (EConnectionStateEvents = {}));

const DNS_DISCOVERY_TAG = "@waku/bootstrap";

/**
 * The default cluster ID for The Waku Network
 */
const DEFAULT_CLUSTER_ID = 1;
/**
 * DefaultShardInfo is default configuration for The Waku Network.
 */
const DefaultShardInfo = {
    clusterId: DEFAULT_CLUSTER_ID,
    shards: [0, 1, 2, 3, 4, 5, 6, 7, 8]
};
const DefaultNetworkConfig = DefaultShardInfo;

var HealthStatus;
(function (HealthStatus) {
    HealthStatus["Unhealthy"] = "Unhealthy";
    HealthStatus["MinimallyHealthy"] = "MinimallyHealthy";
    HealthStatus["SufficientlyHealthy"] = "SufficientlyHealthy";
})(HealthStatus || (HealthStatus = {}));

/**
 * Turns a `Uint8Array` into a string.
 *
 * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function toString$6(array, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    // strip multibase prefix
    return base.encoder.encode(array).substring(1);
}

/**
 * Convert input to a byte array.
 *
 * Handles both `0x` prefixed and non-prefixed strings.
 */
function hexToBytes$2(hex) {
    if (typeof hex === "string") {
        const _hex = hex.replace(/^0x/i, "");
        return fromString(_hex.toLowerCase(), "base16");
    }
    return hex;
}
function numberToBytes(value) {
    const buffer = new ArrayBuffer(8);
    const view = new DataView(buffer);
    if (typeof value === "number") {
        view.setFloat64(0, value, false);
    }
    else {
        view.setBigInt64(0, value, false);
    }
    return new Uint8Array(buffer);
}
/**
 * Convert byte array to hex string (no `0x` prefix).
 */
const bytesToHex$2 = (bytes) => toString$6(bytes, "base16");
/**
 * Decode byte array to utf-8 string.
 */
const bytesToUtf8 = (b) => toString$6(b, "utf8");
/**
 * Encode utf-8 string to byte array.
 */
const utf8ToBytes$2 = (s) => fromString(s, "utf8");
/**
 * Concatenate using Uint8Arrays as `Buffer` has a different behavior with `DataView`
 */
function concat$2(byteArrays, totalLength) {
    const len = byteArrays.reduce((acc, curr) => acc + curr.length, 0);
    const res = new Uint8Array(len);
    let offset = 0;
    for (const bytes of byteArrays) {
        res.set(bytes, offset);
        offset += bytes.length;
    }
    return res;
}

function isStaticSharding(config) {
    return ("clusterId" in config && "shards" in config && !("contentTopics" in config));
}
function isAutoSharding(config) {
    return "contentTopics" in config;
}

function derivePubsubTopicsFromNetworkConfig(networkConfig) {
    if (isStaticSharding(networkConfig)) {
        if (networkConfig.shards.length === 0) {
            throw new Error("Invalid shards configuration: please provide at least one shard");
        }
        return shardInfoToPubsubTopics(networkConfig);
    }
    else if (isAutoSharding(networkConfig)) {
        if (networkConfig.contentTopics.length === 0) {
            throw new Error("Invalid content topics configuration: please provide at least one content topic");
        }
        return networkConfig.contentTopics.map((contentTopic) => contentTopicToPubsubTopic(contentTopic, networkConfig.clusterId));
    }
    else {
        throw new Error("Unknown shard config. Please use ShardInfo or ContentTopicInfo");
    }
}
const singleShardInfoToPubsubTopic = (shardInfo) => {
    if (shardInfo.shard === undefined)
        throw new Error("Invalid shard");
    return `/waku/2/rs/${shardInfo.clusterId ?? DEFAULT_CLUSTER_ID}/${shardInfo.shard}`;
};
const singleShardInfosToShardInfo = (singleShardInfos) => {
    if (singleShardInfos.length === 0)
        throw new Error("Invalid shard");
    const clusterIds = singleShardInfos.map((shardInfo) => shardInfo.clusterId);
    if (new Set(clusterIds).size !== 1) {
        throw new Error("Passed shard infos have different clusterIds");
    }
    const shards = singleShardInfos
        .map((shardInfo) => shardInfo.shard)
        .filter((shard) => shard !== undefined);
    return {
        clusterId: singleShardInfos[0].clusterId,
        shards
    };
};
const shardInfoToPubsubTopics = (shardInfo) => {
    if ("contentTopics" in shardInfo && shardInfo.contentTopics) {
        // Autosharding: explicitly defined content topics
        return Array.from(new Set(shardInfo.contentTopics.map((contentTopic) => contentTopicToPubsubTopic(contentTopic, shardInfo.clusterId))));
    }
    else if ("shards" in shardInfo) {
        // Static sharding
        if (shardInfo.shards === undefined)
            throw new Error("Invalid shard");
        return Array.from(new Set(shardInfo.shards.map((index) => `/waku/2/rs/${shardInfo.clusterId ?? DEFAULT_CLUSTER_ID}/${index}`)));
    }
    else if ("application" in shardInfo && "version" in shardInfo) {
        // Autosharding: single shard from application and version
        return [
            contentTopicToPubsubTopic(`/${shardInfo.application}/${shardInfo.version}/default/default`, shardInfo.clusterId)
        ];
    }
    else {
        throw new Error("Missing required configuration in shard parameters");
    }
};
const pubsubTopicToSingleShardInfo = (pubsubTopics) => {
    const parts = pubsubTopics.split("/");
    if (parts.length != 6 ||
        parts[1] !== "waku" ||
        parts[2] !== "2" ||
        parts[3] !== "rs")
        throw new Error("Invalid pubsub topic");
    const clusterId = parseInt(parts[4]);
    const shard = parseInt(parts[5]);
    if (isNaN(clusterId) || isNaN(shard))
        throw new Error("Invalid clusterId or shard");
    return {
        clusterId,
        shard
    };
};
const pubsubTopicsToShardInfo = (pubsubTopics) => {
    const shardInfoSet = new Set();
    const clusterIds = new Set();
    for (const topic of pubsubTopics) {
        const { clusterId, shard } = pubsubTopicToSingleShardInfo(topic);
        shardInfoSet.add(`${clusterId}:${shard}`);
        clusterIds.add(clusterId);
    }
    if (shardInfoSet.size === 0) {
        throw new Error("No valid pubsub topics provided");
    }
    if (clusterIds.size > 1) {
        throw new Error("Pubsub topics from multiple cluster IDs are not supported");
    }
    const clusterId = clusterIds.values().next().value;
    const shards = Array.from(shardInfoSet).map((info) => parseInt(info.split(":")[1]));
    return {
        clusterId,
        shards
    };
};
//TODO: move part of BaseProtocol instead of utils
// return `ProtocolError.TOPIC_NOT_CONFIGURED` instead of throwing
function ensurePubsubTopicIsConfigured(pubsubTopic, configuredTopics) {
    if (!configuredTopics.includes(pubsubTopic)) {
        throw new Error(`Pubsub topic ${pubsubTopic} has not been configured on this instance. Configured topics are: ${configuredTopics}. Please update your configuration by passing in the topic during Waku node instantiation.`);
    }
}
/**
 * Given a string, will throw an error if it is not formatted as a valid content topic for autosharding based on https://rfc.vac.dev/spec/51/
 * @param contentTopic String to validate
 * @returns Object with each content topic field as an attribute
 */
function ensureValidContentTopic(contentTopic) {
    const parts = contentTopic.split("/");
    if (parts.length < 5 || parts.length > 6) {
        throw Error("Content topic format is invalid");
    }
    // Validate generation field if present
    let generation = 0;
    if (parts.length == 6) {
        generation = parseInt(parts[1]);
        if (isNaN(generation)) {
            throw new Error("Invalid generation field in content topic");
        }
        if (generation > 0) {
            throw new Error("Generation greater than 0 is not supported");
        }
    }
    // Validate remaining fields
    const fields = parts.splice(-4);
    // Validate application field
    if (fields[0].length == 0) {
        throw new Error("Application field cannot be empty");
    }
    // Validate version field
    if (fields[1].length == 0) {
        throw new Error("Version field cannot be empty");
    }
    // Validate topic name field
    if (fields[2].length == 0) {
        throw new Error("Topic name field cannot be empty");
    }
    // Validate encoding field
    if (fields[3].length == 0) {
        throw new Error("Encoding field cannot be empty");
    }
    return {
        generation,
        application: fields[0],
        version: fields[1],
        topicName: fields[2],
        encoding: fields[3]
    };
}
/**
 * Given a string, determines which autoshard index to use for its pubsub topic.
 * Based on the algorithm described in the RFC: https://rfc.vac.dev/spec/51//#algorithm
 */
function contentTopicToShardIndex(contentTopic, networkShards = 8) {
    const { application, version } = ensureValidContentTopic(contentTopic);
    const digest = sha256(concat$2([utf8ToBytes$2(application), utf8ToBytes$2(version)]));
    const dataview = new DataView(digest.buffer.slice(-8));
    return Number(dataview.getBigUint64(0, false) % BigInt(networkShards));
}
function contentTopicToPubsubTopic(contentTopic, clusterId = DEFAULT_CLUSTER_ID, networkShards = 8) {
    if (!contentTopic) {
        throw Error("Content topic must be specified");
    }
    const shardIndex = contentTopicToShardIndex(contentTopic, networkShards);
    return `/waku/2/rs/${clusterId}/${shardIndex}`;
}
/**
 * Given an array of content topics, groups them together by their Pubsub topic as derived using the algorithm for autosharding.
 * If any of the content topics are not properly formatted, the function will throw an error.
 */
function contentTopicsByPubsubTopic(contentTopics, clusterId = DEFAULT_CLUSTER_ID, networkShards = 8) {
    const groupedContentTopics = new Map();
    for (const contentTopic of contentTopics) {
        const pubsubTopic = contentTopicToPubsubTopic(contentTopic, clusterId, networkShards);
        let topics = groupedContentTopics.get(pubsubTopic);
        if (!topics) {
            groupedContentTopics.set(pubsubTopic, []);
            topics = groupedContentTopics.get(pubsubTopic);
        }
        topics.push(contentTopic);
    }
    return groupedContentTopics;
}
/**
 * Used when creating encoders/decoders to determine which pubsub topic to use
 */
function determinePubsubTopic(contentTopic, 
// TODO: make it accept ShardInfo https://github.com/waku-org/js-waku/issues/2086
pubsubTopicShardInfo) {
    if (typeof pubsubTopicShardInfo == "string") {
        return pubsubTopicShardInfo;
    }
    return pubsubTopicShardInfo?.shard !== undefined
        ? singleShardInfoToPubsubTopic(pubsubTopicShardInfo)
        : contentTopicToPubsubTopic(contentTopic, pubsubTopicShardInfo?.clusterId ?? DEFAULT_CLUSTER_ID);
}
/**
 * Validates sharding configuration and sets defaults where possible.
 * @returns Validated sharding parameters, with any missing values set to defaults
 */
const ensureShardingConfigured = (networkConfig) => {
    const clusterId = networkConfig.clusterId ?? DEFAULT_CLUSTER_ID;
    const shards = "shards" in networkConfig ? networkConfig.shards : [];
    const contentTopics = "contentTopics" in networkConfig ? networkConfig.contentTopics : [];
    const isShardsConfigured = shards && shards.length > 0;
    const isContentTopicsConfigured = contentTopics && contentTopics.length > 0;
    if (isShardsConfigured) {
        return {
            shardInfo: { clusterId, shards },
            pubsubTopics: shardInfoToPubsubTopics({ clusterId, shards })
        };
    }
    if (isContentTopicsConfigured) {
        const pubsubTopics = Array.from(new Set(contentTopics.map((topic) => contentTopicToPubsubTopic(topic, clusterId))));
        const shards = Array.from(new Set(contentTopics.map((topic) => contentTopicToShardIndex(topic))));
        return {
            shardInfo: { clusterId, shards },
            pubsubTopics
        };
    }
    throw new Error("Missing minimum required configuration options for static sharding or autosharding.");
};

function pushOrInitMapSet(map, key, newValue) {
    let arr = map.get(key);
    if (typeof arr === "undefined") {
        map.set(key, new Set());
        arr = map.get(key);
    }
    arr.add(newValue);
}

const decodeRelayShard = (bytes) => {
    // explicitly converting to Uint8Array to avoid Buffer
    // https://github.com/libp2p/js-libp2p/issues/2146
    bytes = new Uint8Array(bytes);
    if (bytes.length < 3)
        throw new Error("Insufficient data");
    const view = new DataView(bytes.buffer);
    const clusterId = view.getUint16(0);
    const shards = [];
    if (bytes.length === 130) {
        // rsv format (Bit Vector)
        for (let i = 0; i < 1024; i++) {
            const byteIndex = Math.floor(i / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (i % 8);
            if (view.getUint8(byteIndex) & (1 << bitIndex)) {
                shards.push(i);
            }
        }
    }
    else {
        // rs format (Index List)
        const numIndices = view.getUint8(2);
        for (let i = 0, offset = 3; i < numIndices; i++, offset += 2) {
            if (offset + 1 >= bytes.length)
                throw new Error("Unexpected end of data");
            shards.push(view.getUint16(offset));
        }
    }
    return { clusterId, shards };
};
const encodeRelayShard = (shardInfo) => {
    const { clusterId, shards } = shardInfo;
    const totalLength = shards.length >= 64 ? 130 : 3 + 2 * shards.length;
    const buffer = new ArrayBuffer(totalLength);
    const view = new DataView(buffer);
    view.setUint16(0, clusterId);
    if (shards.length >= 64) {
        // rsv format (Bit Vector)
        for (const index of shards) {
            const byteIndex = Math.floor(index / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (index % 8);
            view.setUint8(byteIndex, view.getUint8(byteIndex) | (1 << bitIndex));
        }
    }
    else {
        // rs format (Index List)
        view.setUint8(2, shards.length);
        for (let i = 0, offset = 3; i < shards.length; i++, offset += 2) {
            view.setUint16(offset, shards[i]);
        }
    }
    return new Uint8Array(buffer);
};

async function delay$1(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
}

function removeItemFromArray(arr, value) {
    const index = arr.indexOf(value);
    if (index > -1) {
        arr.splice(index, 1);
    }
    return arr;
}
function getWsMultiaddrFromMultiaddrs(addresses) {
    const wsMultiaddr = addresses.find((addr) => addr.toString().includes("ws") || addr.toString().includes("wss"));
    if (!wsMultiaddr) {
        throw new Error("No ws multiaddr found in the given addresses");
    }
    return wsMultiaddr;
}

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

var browser = {exports: {}};

/**
 * Helpers.
 */

var ms$1;
var hasRequiredMs;

function requireMs () {
	if (hasRequiredMs) return ms$1;
	hasRequiredMs = 1;
	var s = 1000;
	var m = s * 60;
	var h = m * 60;
	var d = h * 24;
	var w = d * 7;
	var y = d * 365.25;

	/**
	 * Parse or format the given `val`.
	 *
	 * Options:
	 *
	 *  - `long` verbose formatting [false]
	 *
	 * @param {String|Number} val
	 * @param {Object} [options]
	 * @throws {Error} throw an error if val is not a non-empty string or a number
	 * @return {String|Number}
	 * @api public
	 */

	ms$1 = function (val, options) {
	  options = options || {};
	  var type = typeof val;
	  if (type === 'string' && val.length > 0) {
	    return parse(val);
	  } else if (type === 'number' && isFinite(val)) {
	    return options.long ? fmtLong(val) : fmtShort(val);
	  }
	  throw new Error(
	    'val is not a non-empty string or a valid number. val=' +
	      JSON.stringify(val)
	  );
	};

	/**
	 * Parse the given `str` and return milliseconds.
	 *
	 * @param {String} str
	 * @return {Number}
	 * @api private
	 */

	function parse(str) {
	  str = String(str);
	  if (str.length > 100) {
	    return;
	  }
	  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
	    str
	  );
	  if (!match) {
	    return;
	  }
	  var n = parseFloat(match[1]);
	  var type = (match[2] || 'ms').toLowerCase();
	  switch (type) {
	    case 'years':
	    case 'year':
	    case 'yrs':
	    case 'yr':
	    case 'y':
	      return n * y;
	    case 'weeks':
	    case 'week':
	    case 'w':
	      return n * w;
	    case 'days':
	    case 'day':
	    case 'd':
	      return n * d;
	    case 'hours':
	    case 'hour':
	    case 'hrs':
	    case 'hr':
	    case 'h':
	      return n * h;
	    case 'minutes':
	    case 'minute':
	    case 'mins':
	    case 'min':
	    case 'm':
	      return n * m;
	    case 'seconds':
	    case 'second':
	    case 'secs':
	    case 'sec':
	    case 's':
	      return n * s;
	    case 'milliseconds':
	    case 'millisecond':
	    case 'msecs':
	    case 'msec':
	    case 'ms':
	      return n;
	    default:
	      return undefined;
	  }
	}

	/**
	 * Short format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtShort(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return Math.round(ms / d) + 'd';
	  }
	  if (msAbs >= h) {
	    return Math.round(ms / h) + 'h';
	  }
	  if (msAbs >= m) {
	    return Math.round(ms / m) + 'm';
	  }
	  if (msAbs >= s) {
	    return Math.round(ms / s) + 's';
	  }
	  return ms + 'ms';
	}

	/**
	 * Long format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtLong(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return plural(ms, msAbs, d, 'day');
	  }
	  if (msAbs >= h) {
	    return plural(ms, msAbs, h, 'hour');
	  }
	  if (msAbs >= m) {
	    return plural(ms, msAbs, m, 'minute');
	  }
	  if (msAbs >= s) {
	    return plural(ms, msAbs, s, 'second');
	  }
	  return ms + ' ms';
	}

	/**
	 * Pluralization helper.
	 */

	function plural(ms, msAbs, n, name) {
	  var isPlural = msAbs >= n * 1.5;
	  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
	}
	return ms$1;
}

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup$1(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = requireMs();
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;
		let namespacesCache;
		let enabledCache;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => {
				if (enableOverride !== null) {
					return enableOverride;
				}
				if (namespacesCache !== createDebug.namespaces) {
					namespacesCache = createDebug.namespaces;
					enabledCache = createDebug.enabled(namespace);
				}

				return enabledCache;
			},
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);
		createDebug.namespaces = namespaces;

		createDebug.names = [];
		createDebug.skips = [];

		let i;
		const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
		const len = split.length;

		for (i = 0; i < len; i++) {
			if (!split[i]) {
				// ignore empty strings
				continue;
			}

			namespaces = split[i].replace(/\*/g, '.*?');

			if (namespaces[0] === '-') {
				createDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));
			} else {
				createDebug.names.push(new RegExp('^' + namespaces + '$'));
			}
		}
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names.map(toNamespace),
			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		if (name[name.length - 1] === '*') {
			return true;
		}

		let i;
		let len;

		for (i = 0, len = createDebug.skips.length; i < len; i++) {
			if (createDebug.skips[i].test(name)) {
				return false;
			}
		}

		for (i = 0, len = createDebug.names.length; i < len; i++) {
			if (createDebug.names[i].test(name)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Convert regexp to namespace
	*
	* @param {RegExp} regxep
	* @return {String} namespace
	* @api private
	*/
	function toNamespace(regexp) {
		return regexp.toString()
			.substring(2, regexp.toString().length - 2)
			.replace(/\.\*\?$/, '*');
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

var common = setup$1;

/* eslint-env browser */

(function (module, exports) {
	/**
	 * This is the web browser implementation of `debug()`.
	 */

	exports.formatArgs = formatArgs;
	exports.save = save;
	exports.load = load;
	exports.useColors = useColors;
	exports.storage = localstorage();
	exports.destroy = (() => {
		let warned = false;

		return () => {
			if (!warned) {
				warned = true;
				console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
			}
		};
	})();

	/**
	 * Colors.
	 */

	exports.colors = [
		'#0000CC',
		'#0000FF',
		'#0033CC',
		'#0033FF',
		'#0066CC',
		'#0066FF',
		'#0099CC',
		'#0099FF',
		'#00CC00',
		'#00CC33',
		'#00CC66',
		'#00CC99',
		'#00CCCC',
		'#00CCFF',
		'#3300CC',
		'#3300FF',
		'#3333CC',
		'#3333FF',
		'#3366CC',
		'#3366FF',
		'#3399CC',
		'#3399FF',
		'#33CC00',
		'#33CC33',
		'#33CC66',
		'#33CC99',
		'#33CCCC',
		'#33CCFF',
		'#6600CC',
		'#6600FF',
		'#6633CC',
		'#6633FF',
		'#66CC00',
		'#66CC33',
		'#9900CC',
		'#9900FF',
		'#9933CC',
		'#9933FF',
		'#99CC00',
		'#99CC33',
		'#CC0000',
		'#CC0033',
		'#CC0066',
		'#CC0099',
		'#CC00CC',
		'#CC00FF',
		'#CC3300',
		'#CC3333',
		'#CC3366',
		'#CC3399',
		'#CC33CC',
		'#CC33FF',
		'#CC6600',
		'#CC6633',
		'#CC9900',
		'#CC9933',
		'#CCCC00',
		'#CCCC33',
		'#FF0000',
		'#FF0033',
		'#FF0066',
		'#FF0099',
		'#FF00CC',
		'#FF00FF',
		'#FF3300',
		'#FF3333',
		'#FF3366',
		'#FF3399',
		'#FF33CC',
		'#FF33FF',
		'#FF6600',
		'#FF6633',
		'#FF9900',
		'#FF9933',
		'#FFCC00',
		'#FFCC33'
	];

	/**
	 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
	 * and the Firebug extension (any Firefox version) are known
	 * to support "%c" CSS customizations.
	 *
	 * TODO: add a `localStorage` variable to explicitly enable/disable colors
	 */

	// eslint-disable-next-line complexity
	function useColors() {
		// NB: In an Electron preload script, document will be defined but not fully
		// initialized. Since we know we're in Chrome, we'll just detect this case
		// explicitly
		if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
			return true;
		}

		// Internet Explorer and Edge do not support colors.
		if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {
			return false;
		}

		let m;

		// Is webkit? http://stackoverflow.com/a/16459606/376773
		// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
		return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||
			// Is firebug? http://stackoverflow.com/a/398120/376773
			(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
			// Is firefox >= v31?
			// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
			(typeof navigator !== 'undefined' && navigator.userAgent && (m = navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/)) && parseInt(m[1], 10) >= 31) ||
			// Double check webkit in userAgent just in case we are in a worker
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));
	}

	/**
	 * Colorize log arguments if enabled.
	 *
	 * @api public
	 */

	function formatArgs(args) {
		args[0] = (this.useColors ? '%c' : '') +
			this.namespace +
			(this.useColors ? ' %c' : ' ') +
			args[0] +
			(this.useColors ? '%c ' : ' ') +
			'+' + module.exports.humanize(this.diff);

		if (!this.useColors) {
			return;
		}

		const c = 'color: ' + this.color;
		args.splice(1, 0, c, 'color: inherit');

		// The final "%c" is somewhat tricky, because there could be other
		// arguments passed either before or after the %c, so we need to
		// figure out the correct index to insert the CSS into
		let index = 0;
		let lastC = 0;
		args[0].replace(/%[a-zA-Z%]/g, match => {
			if (match === '%%') {
				return;
			}
			index++;
			if (match === '%c') {
				// We only are interested in the *last* %c
				// (the user may have provided their own)
				lastC = index;
			}
		});

		args.splice(lastC, 0, c);
	}

	/**
	 * Invokes `console.debug()` when available.
	 * No-op when `console.debug` is not a "function".
	 * If `console.debug` is not available, falls back
	 * to `console.log`.
	 *
	 * @api public
	 */
	exports.log = console.debug || console.log || (() => {});

	/**
	 * Save `namespaces`.
	 *
	 * @param {String} namespaces
	 * @api private
	 */
	function save(namespaces) {
		try {
			if (namespaces) {
				exports.storage.setItem('debug', namespaces);
			} else {
				exports.storage.removeItem('debug');
			}
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	/**
	 * Load `namespaces`.
	 *
	 * @return {String} returns the previously persisted debug modes
	 * @api private
	 */
	function load() {
		let r;
		try {
			r = exports.storage.getItem('debug');
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}

		// If debug isn't set in LS, and we're in Electron, try to load $DEBUG
		if (!r && typeof process !== 'undefined' && 'env' in process) {
			r = process.env.DEBUG;
		}

		return r;
	}

	/**
	 * Localstorage attempts to return the localstorage.
	 *
	 * This is necessary because safari throws
	 * when a user disables cookies/localstorage
	 * and you attempt to access it.
	 *
	 * @return {LocalStorage}
	 * @api private
	 */

	function localstorage() {
		try {
			// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
			// The Browser also has localStorage in the global context.
			return localStorage;
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	module.exports = common(exports);

	const {formatters} = module.exports;

	/**
	 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
	 */

	formatters.j = function (v) {
		try {
			return JSON.stringify(v);
		} catch (error) {
			return '[UnexpectedJSONParseError]: ' + error.message;
		}
	}; 
} (browser, browser.exports));

var browserExports = browser.exports;
var debug = /*@__PURE__*/getDefaultExportFromCjs(browserExports);

const APP_NAME = "waku";
let Logger$1 = class Logger {
    _info;
    _warn;
    _error;
    static createDebugNamespace(level, prefix) {
        return prefix ? `${APP_NAME}:${level}:${prefix}` : `${APP_NAME}:${level}`;
    }
    constructor(prefix) {
        this._info = debug(Logger.createDebugNamespace("info", prefix));
        this._warn = debug(Logger.createDebugNamespace("warn", prefix));
        this._error = debug(Logger.createDebugNamespace("error", prefix));
    }
    get info() {
        return this._info;
    }
    get warn() {
        return this._warn;
    }
    get error() {
        return this._error;
    }
    log(level, ...args) {
        const logger = this[level];
        logger(...args);
    }
};

var index$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Logger: Logger$1,
    contentTopicToPubsubTopic: contentTopicToPubsubTopic,
    contentTopicToShardIndex: contentTopicToShardIndex,
    contentTopicsByPubsubTopic: contentTopicsByPubsubTopic,
    decodeRelayShard: decodeRelayShard,
    delay: delay$1,
    derivePubsubTopicsFromNetworkConfig: derivePubsubTopicsFromNetworkConfig,
    determinePubsubTopic: determinePubsubTopic,
    encodeRelayShard: encodeRelayShard,
    ensurePubsubTopicIsConfigured: ensurePubsubTopicIsConfigured,
    ensureShardingConfigured: ensureShardingConfigured,
    ensureValidContentTopic: ensureValidContentTopic,
    getPseudoRandomSubset: getPseudoRandomSubset,
    getWsMultiaddrFromMultiaddrs: getWsMultiaddrFromMultiaddrs,
    groupByContentTopic: groupByContentTopic,
    isAutoSharding: isAutoSharding,
    isDefined: isDefined,
    isMessageSizeUnderCap: isMessageSizeUnderCap,
    isStaticSharding: isStaticSharding,
    isWireSizeUnderCap: isWireSizeUnderCap,
    pubsubTopicToSingleShardInfo: pubsubTopicToSingleShardInfo,
    pubsubTopicsToShardInfo: pubsubTopicsToShardInfo,
    pushOrInitMapSet: pushOrInitMapSet,
    removeItemFromArray: removeItemFromArray,
    shardInfoToPubsubTopics: shardInfoToPubsubTopics,
    singleShardInfoToPubsubTopic: singleShardInfoToPubsubTopic,
    singleShardInfosToShardInfo: singleShardInfosToShardInfo,
    toAsyncIterator: toAsyncIterator
});

const log$o = new Logger$1("message:version-0");
const OneMillion = BigInt(1_000_000);
const Version = 0;
class DecodedMessage {
    pubsubTopic;
    proto;
    constructor(pubsubTopic, proto) {
        this.pubsubTopic = pubsubTopic;
        this.proto = proto;
    }
    get ephemeral() {
        return Boolean(this.proto.ephemeral);
    }
    get payload() {
        return this.proto.payload;
    }
    get contentTopic() {
        return this.proto.contentTopic;
    }
    get _rawTimestamp() {
        return this.proto.timestamp;
    }
    get timestamp() {
        // In the case we receive a value that is bigger than JS's max number,
        // we catch the error and return undefined.
        try {
            if (this.proto.timestamp) {
                // nanoseconds 10^-9 to milliseconds 10^-3
                const timestamp = this.proto.timestamp / OneMillion;
                return new Date(Number(timestamp));
            }
            return;
        }
        catch (e) {
            return;
        }
    }
    get meta() {
        return this.proto.meta;
    }
    get version() {
        // https://rfc.vac.dev/spec/14/
        // > If omitted, the value SHOULD be interpreted as version 0.
        return this.proto.version ?? 0;
    }
    get rateLimitProof() {
        return this.proto.rateLimitProof;
    }
}
let Encoder$1 = class Encoder {
    contentTopic;
    ephemeral;
    pubsubTopic;
    metaSetter;
    constructor(contentTopic, ephemeral = false, pubsubTopic, metaSetter) {
        this.contentTopic = contentTopic;
        this.ephemeral = ephemeral;
        this.pubsubTopic = pubsubTopic;
        this.metaSetter = metaSetter;
        if (!contentTopic || contentTopic === "") {
            throw new Error("Content topic must be specified");
        }
    }
    async toWire(message$1) {
        return WakuMessage$4.encode(await this.toProtoObj(message$1));
    }
    async toProtoObj(message) {
        const timestamp = message.timestamp ?? new Date();
        const protoMessage = {
            payload: message.payload,
            version: Version,
            contentTopic: this.contentTopic,
            timestamp: BigInt(timestamp.valueOf()) * OneMillion,
            meta: undefined,
            rateLimitProof: message.rateLimitProof,
            ephemeral: this.ephemeral
        };
        if (this.metaSetter) {
            const meta = this.metaSetter(protoMessage);
            return { ...protoMessage, meta };
        }
        return protoMessage;
    }
};
/**
 * Creates an encoder that encode messages without Waku level encryption or signature.
 *
 * An encoder is used to encode messages in the [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format to be sent over the Waku network. The resulting encoder can then be
 * pass to { @link @waku/interfaces!ISender.send } to automatically encode outgoing
 * messages.
 */
function createEncoder({ pubsubTopic, pubsubTopicShardInfo, contentTopic, ephemeral, metaSetter }) {
    return new Encoder$1(contentTopic, ephemeral, determinePubsubTopic(contentTopic, pubsubTopic ?? pubsubTopicShardInfo), metaSetter);
}
let Decoder$1 = class Decoder {
    pubsubTopic;
    contentTopic;
    constructor(pubsubTopic, contentTopic) {
        this.pubsubTopic = pubsubTopic;
        this.contentTopic = contentTopic;
        if (!contentTopic || contentTopic === "") {
            throw new Error("Content topic must be specified");
        }
    }
    fromWireToProtoObj(bytes) {
        const protoMessage = WakuMessage$4.decode(bytes);
        return Promise.resolve({
            payload: protoMessage.payload,
            contentTopic: protoMessage.contentTopic,
            version: protoMessage.version ?? undefined,
            timestamp: protoMessage.timestamp ?? undefined,
            meta: protoMessage.meta ?? undefined,
            rateLimitProof: protoMessage.rateLimitProof ?? undefined,
            ephemeral: protoMessage.ephemeral ?? false
        });
    }
    async fromProtoObj(pubsubTopic, proto) {
        // https://rfc.vac.dev/spec/14/
        // > If omitted, the value SHOULD be interpreted as version 0.
        if (proto.version ?? 0 !== Version) {
            log$o.error("Failed to decode due to incorrect version, expected:", Version, ", actual:", proto.version);
            return Promise.resolve(undefined);
        }
        return new DecodedMessage(pubsubTopic, proto);
    }
};
/**
 * Creates a decoder that decode messages without Waku level encryption.
 *
 * A decoder is used to decode messages from the [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format when received from the Waku network. The resulting decoder can then be
 * pass to { @link @waku/interfaces!IReceiver.subscribe } to automatically decode incoming
 * messages.
 *
 * @param contentTopic The resulting decoder will only decode messages with this content topic.
 */
function createDecoder(contentTopic, pubsubTopicShardInfo) {
    return new Decoder$1(determinePubsubTopic(contentTopic, pubsubTopicShardInfo), contentTopic);
}

var version_0 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    DecodedMessage: DecodedMessage,
    Decoder: Decoder$1,
    Encoder: Encoder$1,
    Version: Version,
    createDecoder: createDecoder,
    createEncoder: createEncoder,
    proto: message
});

var index$4 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    version_0: version_0
});

/**
 * @packageDocumentation
 *
 * For when you need a one-liner to collect iterable values.
 *
 * @example
 *
 * ```javascript
 * import all from 'it-all'
 *
 * // This can also be an iterator, etc
 * const values = function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = all(values)
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = await all(values())
 *
 * console.info(arr) // 0, 1, 2, 3, 4
 * ```
 */
function isAsyncIterable$8(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function all$1(source) {
    if (isAsyncIterable$8(source)) {
        return (async () => {
            const arr = [];
            for await (const entry of source) {
                arr.push(entry);
            }
            return arr;
        })();
    }
    const arr = [];
    for (const entry of source) {
        arr.push(entry);
    }
    return arr;
}

/**
 * To guarantee Uint8Array semantics, convert nodejs Buffers
 * into vanilla Uint8Arrays
 */
function asUint8Array(buf) {
    return buf;
}

/**
 * Returns a new Uint8Array created by concatenating the passed Uint8Arrays
 */
function concat$1(arrays, length) {
    if (length == null) {
        length = arrays.reduce((acc, curr) => acc + curr.length, 0);
    }
    const output = allocUnsafe(length);
    let offset = 0;
    for (const arr of arrays) {
        output.set(arr, offset);
        offset += arr.length;
    }
    return asUint8Array(output);
}

/**
 * Returns true if the two passed Uint8Arrays have the same content
 */
function equals(a, b) {
    if (a === b) {
        return true;
    }
    if (a.byteLength !== b.byteLength) {
        return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
}

/**
 * @packageDocumentation
 *
 * A class that lets you do operations over a list of Uint8Arrays without
 * copying them.
 *
 * ```js
 * import { Uint8ArrayList } from 'uint8arraylist'
 *
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray()
 * // -> Uint8Array([0, 1, 2, 3, 4, 5])
 *
 * list.consume(3)
 * list.subarray()
 * // -> Uint8Array([3, 4, 5])
 *
 * // you can also iterate over the list
 * for (const buf of list) {
 *   // ..do something with `buf`
 * }
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ## Converting Uint8ArrayLists to Uint8Arrays
 *
 * There are two ways to turn a `Uint8ArrayList` into a `Uint8Array` - `.slice` and `.subarray` and one way to turn a `Uint8ArrayList` into a `Uint8ArrayList` with different contents - `.sublist`.
 *
 * ### slice
 *
 * Slice follows the same semantics as [Uint8Array.slice](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/slice) in that it creates a new `Uint8Array` and copies bytes into it using an optional offset & length.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.slice(0, 1)
 * // -> Uint8Array([0])
 * ```
 *
 * ### subarray
 *
 * Subarray attempts to follow the same semantics as [Uint8Array.subarray](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/subarray) with one important different - this is a no-copy operation, unless the requested bytes span two internal buffers in which case it is a copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.subarray(0, 1)
 * // -> Uint8Array([0]) - no-copy
 *
 * list.subarray(2, 5)
 * // -> Uint8Array([2, 3, 4]) - copy
 * ```
 *
 * ### sublist
 *
 * Sublist creates and returns a new `Uint8ArrayList` that shares the underlying buffers with the original so is always a no-copy operation.
 *
 * ```js
 * const list = new Uint8ArrayList()
 * list.append(Uint8Array.from([0, 1, 2]))
 * list.append(Uint8Array.from([3, 4, 5]))
 *
 * list.sublist(0, 1)
 * // -> Uint8ArrayList([0]) - no-copy
 *
 * list.sublist(2, 5)
 * // -> Uint8ArrayList([2], [3, 4]) - no-copy
 * ```
 *
 * ## Inspiration
 *
 * Borrows liberally from [bl](https://www.npmjs.com/package/bl) but only uses native JS types.
 */
const symbol$1 = Symbol.for('@achingbrain/uint8arraylist');
function findBufAndOffset(bufs, index) {
    if (index == null || index < 0) {
        throw new RangeError('index is out of bounds');
    }
    let offset = 0;
    for (const buf of bufs) {
        const bufEnd = offset + buf.byteLength;
        if (index < bufEnd) {
            return {
                buf,
                index: index - offset
            };
        }
        offset = bufEnd;
    }
    throw new RangeError('index is out of bounds');
}
/**
 * Check if object is a CID instance
 *
 * @example
 *
 * ```js
 * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'
 *
 * isUint8ArrayList(true) // false
 * isUint8ArrayList([]) // false
 * isUint8ArrayList(new Uint8ArrayList()) // true
 * ```
 */
function isUint8ArrayList(value) {
    return Boolean(value?.[symbol$1]);
}
class Uint8ArrayList {
    bufs;
    length;
    [symbol$1] = true;
    constructor(...data) {
        this.bufs = [];
        this.length = 0;
        if (data.length > 0) {
            this.appendAll(data);
        }
    }
    *[Symbol.iterator]() {
        yield* this.bufs;
    }
    get byteLength() {
        return this.length;
    }
    /**
     * Add one or more `bufs` to the end of this Uint8ArrayList
     */
    append(...bufs) {
        this.appendAll(bufs);
    }
    /**
     * Add all `bufs` to the end of this Uint8ArrayList
     */
    appendAll(bufs) {
        let length = 0;
        for (const buf of bufs) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.push(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.push(...buf.bufs);
            }
            else {
                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Add one or more `bufs` to the start of this Uint8ArrayList
     */
    prepend(...bufs) {
        this.prependAll(bufs);
    }
    /**
     * Add all `bufs` to the start of this Uint8ArrayList
     */
    prependAll(bufs) {
        let length = 0;
        for (const buf of bufs.reverse()) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.unshift(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.unshift(...buf.bufs);
            }
            else {
                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Read the value at `index`
     */
    get(index) {
        const res = findBufAndOffset(this.bufs, index);
        return res.buf[res.index];
    }
    /**
     * Set the value at `index` to `value`
     */
    set(index, value) {
        const res = findBufAndOffset(this.bufs, index);
        res.buf[res.index] = value;
    }
    /**
     * Copy bytes from `buf` to the index specified by `offset`
     */
    write(buf, offset = 0) {
        if (buf instanceof Uint8Array) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf[i]);
            }
        }
        else if (isUint8ArrayList(buf)) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf.get(i));
            }
        }
        else {
            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');
        }
    }
    /**
     * Remove bytes from the front of the pool
     */
    consume(bytes) {
        // first, normalize the argument, in accordance with how Buffer does it
        bytes = Math.trunc(bytes);
        // do nothing if not a positive number
        if (Number.isNaN(bytes) || bytes <= 0) {
            return;
        }
        // if consuming all bytes, skip iterating
        if (bytes === this.byteLength) {
            this.bufs = [];
            this.length = 0;
            return;
        }
        while (this.bufs.length > 0) {
            if (bytes >= this.bufs[0].byteLength) {
                bytes -= this.bufs[0].byteLength;
                this.length -= this.bufs[0].byteLength;
                this.bufs.shift();
            }
            else {
                this.bufs[0] = this.bufs[0].subarray(bytes);
                this.length -= bytes;
                break;
            }
        }
    }
    /**
     * Extracts a section of an array and returns a new array.
     *
     * This is a copy operation as it is with Uint8Arrays and Arrays
     * - note this is different to the behaviour of Node Buffers.
     */
    slice(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        return concat$1(bufs, length);
    }
    /**
     * Returns a alloc from the given start and end element index.
     *
     * In the best case where the data extracted comes from a single Uint8Array
     * internally this is a no-copy operation otherwise it is a copy operation.
     */
    subarray(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        if (bufs.length === 1) {
            return bufs[0];
        }
        return concat$1(bufs, length);
    }
    /**
     * Returns a allocList from the given start and end element index.
     *
     * This is a no-copy operation.
     */
    sublist(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        const list = new Uint8ArrayList();
        list.length = length;
        // don't loop, just set the bufs
        list.bufs = [...bufs];
        return list;
    }
    _subList(beginInclusive, endExclusive) {
        beginInclusive = beginInclusive ?? 0;
        endExclusive = endExclusive ?? this.length;
        if (beginInclusive < 0) {
            beginInclusive = this.length + beginInclusive;
        }
        if (endExclusive < 0) {
            endExclusive = this.length + endExclusive;
        }
        if (beginInclusive < 0 || endExclusive > this.length) {
            throw new RangeError('index is out of bounds');
        }
        if (beginInclusive === endExclusive) {
            return { bufs: [], length: 0 };
        }
        if (beginInclusive === 0 && endExclusive === this.length) {
            return { bufs: this.bufs, length: this.length };
        }
        const bufs = [];
        let offset = 0;
        for (let i = 0; i < this.bufs.length; i++) {
            const buf = this.bufs[i];
            const bufStart = offset;
            const bufEnd = bufStart + buf.byteLength;
            // for next loop
            offset = bufEnd;
            if (beginInclusive >= bufEnd) {
                // start after this buf
                continue;
            }
            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
            if (sliceStartInBuf && sliceEndsInBuf) {
                // slice is wholly contained within this buffer
                if (beginInclusive === bufStart && endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                const start = beginInclusive - bufStart;
                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));
                break;
            }
            if (sliceStartInBuf) {
                // slice starts in this buffer
                if (beginInclusive === 0) {
                    // requested whole buffer
                    bufs.push(buf);
                    continue;
                }
                // requested part of buffer
                bufs.push(buf.subarray(beginInclusive - bufStart));
                continue;
            }
            if (sliceEndsInBuf) {
                if (endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                bufs.push(buf.subarray(0, endExclusive - bufStart));
                break;
            }
            // slice started before this buffer and ends after it
            bufs.push(buf);
        }
        return { bufs, length: endExclusive - beginInclusive };
    }
    indexOf(search, offset = 0) {
        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
            throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
        }
        const needle = search instanceof Uint8Array ? search : search.subarray();
        offset = Number(offset ?? 0);
        if (isNaN(offset)) {
            offset = 0;
        }
        if (offset < 0) {
            offset = this.length + offset;
        }
        if (offset < 0) {
            offset = 0;
        }
        if (search.length === 0) {
            return offset > this.length ? this.length : offset;
        }
        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm
        const M = needle.byteLength;
        if (M === 0) {
            throw new TypeError('search must be at least 1 byte long');
        }
        // radix
        const radix = 256;
        const rightmostPositions = new Int32Array(radix);
        // position of the rightmost occurrence of the byte c in the pattern
        for (let c = 0; c < radix; c++) {
            // -1 for bytes not in pattern
            rightmostPositions[c] = -1;
        }
        for (let j = 0; j < M; j++) {
            // rightmost position for bytes in pattern
            rightmostPositions[needle[j]] = j;
        }
        // Return offset of first match, -1 if no match
        const right = rightmostPositions;
        const lastIndex = this.byteLength - needle.byteLength;
        const lastPatIndex = needle.byteLength - 1;
        let skip;
        for (let i = offset; i <= lastIndex; i += skip) {
            skip = 0;
            for (let j = lastPatIndex; j >= 0; j--) {
                const char = this.get(i + j);
                if (needle[j] !== char) {
                    skip = Math.max(1, j - right[char]);
                    break;
                }
            }
            if (skip === 0) {
                return i;
            }
        }
        return -1;
    }
    getInt8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt8(0);
    }
    setInt8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt8(0, value);
        this.write(buf, byteOffset);
    }
    getInt16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt16(0, littleEndian);
    }
    setInt16(byteOffset, value, littleEndian) {
        const buf = alloc$2(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getInt32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt32(0, littleEndian);
    }
    setInt32(byteOffset, value, littleEndian) {
        const buf = alloc$2(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigInt64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigInt64(0, littleEndian);
    }
    setBigInt64(byteOffset, value, littleEndian) {
        const buf = alloc$2(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigInt64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint8(0);
    }
    setUint8(byteOffset, value) {
        const buf = allocUnsafe(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint8(0, value);
        this.write(buf, byteOffset);
    }
    getUint16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint16(0, littleEndian);
    }
    setUint16(byteOffset, value, littleEndian) {
        const buf = alloc$2(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint32(0, littleEndian);
    }
    setUint32(byteOffset, value, littleEndian) {
        const buf = alloc$2(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigUint64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigUint64(0, littleEndian);
    }
    setBigUint64(byteOffset, value, littleEndian) {
        const buf = alloc$2(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigUint64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat32(0, littleEndian);
    }
    setFloat32(byteOffset, value, littleEndian) {
        const buf = alloc$2(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat64(0, littleEndian);
    }
    setFloat64(byteOffset, value, littleEndian) {
        const buf = alloc$2(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (!(other instanceof Uint8ArrayList)) {
            return false;
        }
        if (other.bufs.length !== this.bufs.length) {
            return false;
        }
        for (let i = 0; i < this.bufs.length; i++) {
            if (!equals(this.bufs[i], other.bufs[i])) {
                return false;
            }
        }
        return true;
    }
    /**
     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
     * method if you know the total size of all the Uint8Arrays ahead of time.
     */
    static fromUint8Arrays(bufs, length) {
        const list = new Uint8ArrayList();
        list.bufs = bufs;
        if (length == null) {
            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
        }
        list.length = length;
        return list;
    }
}
/*
function indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {
  for (let i = offset; i < haystack.byteLength; i++) {
    for (let j = 0; j < needle.length; j++) {
      if (haystack[i + j] !== needle[j]) {
        break
      }

      if (j === needle.byteLength -1) {
        return i
      }
    }

    if (haystack.byteLength - i < needle.byteLength) {
      break
    }
  }

  return -1
}
*/

function isAsyncIterable$7(thing) {
    return thing[Symbol.asyncIterator] != null;
}

const defaultEncoder = (length) => {
    const lengthLength = encodingLength$3(length);
    const lengthBuf = allocUnsafe(lengthLength);
    encode$a(length, lengthBuf);
    defaultEncoder.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder.bytes = 0;
function encode$5(source, options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    function* maybeYield(chunk) {
        // length + data
        const length = encodeLength(chunk.byteLength);
        // yield only Uint8Arrays
        if (length instanceof Uint8Array) {
            yield length;
        }
        else {
            yield* length;
        }
        // yield only Uint8Arrays
        if (chunk instanceof Uint8Array) {
            yield chunk;
        }
        else {
            yield* chunk;
        }
    }
    if (isAsyncIterable$7(source)) {
        return (async function* () {
            for await (const chunk of source) {
                yield* maybeYield(chunk);
            }
        })();
    }
    return (function* () {
        for (const chunk of source) {
            yield* maybeYield(chunk);
        }
    })();
}
encode$5.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

/**
 * The reported length of the next data message was not a positive integer
 */
let InvalidMessageLengthError$1 = class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
};
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
let InvalidDataLengthError$1 = class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
};
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
let InvalidDataLengthLengthError$1 = class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
};
/**
 * The incoming stream ended before the expected number of bytes were read
 */
let UnexpectedEOFError$1 = class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
};

/* eslint max-depth: ["error", 6] */
// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH = 1024 * 1024 * 4;
var ReadMode;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode || (ReadMode = {}));
const defaultDecoder = (buf) => {
    const length = decode$a(buf);
    defaultDecoder.bytes = encodingLength$3(length);
    return length;
};
defaultDecoder.bytes = 0;
function decode$4(source, options) {
    const buffer = new Uint8ArrayList();
    let mode = ReadMode.LENGTH;
    let dataLength = -1;
    const lengthDecoder = options?.lengthDecoder ?? defaultDecoder;
    const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
    function* maybeYield() {
        while (buffer.byteLength > 0) {
            if (mode === ReadMode.LENGTH) {
                // read length, ignore errors for short reads
                try {
                    dataLength = lengthDecoder(buffer);
                    if (dataLength < 0) {
                        throw new InvalidMessageLengthError$1('Invalid message length');
                    }
                    if (dataLength > maxDataLength) {
                        throw new InvalidDataLengthError$1('Message length too long');
                    }
                    const dataLengthLength = lengthDecoder.bytes;
                    buffer.consume(dataLengthLength);
                    if (options?.onLength != null) {
                        options.onLength(dataLength);
                    }
                    mode = ReadMode.DATA;
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        if (buffer.byteLength > maxLengthLength) {
                            throw new InvalidDataLengthLengthError$1('Message length length too long');
                        }
                        break;
                    }
                    throw err;
                }
            }
            if (mode === ReadMode.DATA) {
                if (buffer.byteLength < dataLength) {
                    // not enough data, wait for more
                    break;
                }
                const data = buffer.sublist(0, dataLength);
                buffer.consume(dataLength);
                if (options?.onData != null) {
                    options.onData(data);
                }
                yield data;
                mode = ReadMode.LENGTH;
            }
        }
    }
    if (isAsyncIterable$7(source)) {
        return (async function* () {
            for await (const buf of source) {
                buffer.append(buf);
                yield* maybeYield();
            }
            if (buffer.byteLength > 0) {
                throw new UnexpectedEOFError$1('Unexpected end of input');
            }
        })();
    }
    return (function* () {
        for (const buf of source) {
            buffer.append(buf);
            yield* maybeYield();
        }
        if (buffer.byteLength > 0) {
            throw new UnexpectedEOFError$1('Unexpected end of input');
        }
    })();
}
decode$4.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode$4(varByteSource, {
        ...(options ?? {}),
        onLength
    });
};

function pDefer() {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
}

// ported from https://www.npmjs.com/package/fast-fifo
class FixedFIFO {
    buffer;
    mask;
    top;
    btm;
    next;
    constructor(hwm) {
        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {
            throw new Error('Max size for a FixedFIFO should be a power of two');
        }
        this.buffer = new Array(hwm);
        this.mask = hwm - 1;
        this.top = 0;
        this.btm = 0;
        this.next = null;
    }
    push(data) {
        if (this.buffer[this.top] !== undefined) {
            return false;
        }
        this.buffer[this.top] = data;
        this.top = (this.top + 1) & this.mask;
        return true;
    }
    shift() {
        const last = this.buffer[this.btm];
        if (last === undefined) {
            return undefined;
        }
        this.buffer[this.btm] = undefined;
        this.btm = (this.btm + 1) & this.mask;
        return last;
    }
    isEmpty() {
        return this.buffer[this.btm] === undefined;
    }
}
class FIFO {
    size;
    hwm;
    head;
    tail;
    constructor(options = {}) {
        this.hwm = options.splitLimit ?? 16;
        this.head = new FixedFIFO(this.hwm);
        this.tail = this.head;
        this.size = 0;
    }
    calculateSize(obj) {
        if (obj?.byteLength != null) {
            return obj.byteLength;
        }
        return 1;
    }
    push(val) {
        if (val?.value != null) {
            this.size += this.calculateSize(val.value);
        }
        if (!this.head.push(val)) {
            const prev = this.head;
            this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);
            this.head.push(val);
        }
    }
    shift() {
        let val = this.tail.shift();
        if (val === undefined && (this.tail.next != null)) {
            const next = this.tail.next;
            this.tail.next = null;
            this.tail = next;
            val = this.tail.shift();
        }
        if (val?.value != null) {
            this.size -= this.calculateSize(val.value);
        }
        return val;
    }
    isEmpty() {
        return this.head.isEmpty();
    }
}

/**
 * @packageDocumentation
 *
 * An iterable that you can push values into.
 *
 * @example
 *
 * ```js
 * import { pushable } from 'it-pushable'
 *
 * const source = pushable()
 *
 * setTimeout(() => source.push('hello'), 100)
 * setTimeout(() => source.push('world'), 200)
 * setTimeout(() => source.end(), 300)
 *
 * const start = Date.now()
 *
 * for await (const value of source) {
 *   console.log(`got "${value}" after ${Date.now() - start}ms`)
 * }
 * console.log(`done after ${Date.now() - start}ms`)
 *
 * // Output:
 * // got "hello" after 105ms
 * // got "world" after 207ms
 * // done after 309ms
 * ```
 *
 * @example
 *
 * ```js
 * import { pushableV } from 'it-pushable'
 * import all from 'it-all'
 *
 * const source = pushableV()
 *
 * source.push(1)
 * source.push(2)
 * source.push(3)
 * source.end()
 *
 * console.info(await all(source))
 *
 * // Output:
 * // [ [1, 2, 3] ]
 * ```
 */
let AbortError$6 = class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
};
function pushable(options = {}) {
    const getNext = (buffer) => {
        const next = buffer.shift();
        if (next == null) {
            return { done: true };
        }
        if (next.error != null) {
            throw next.error;
        }
        return {
            done: next.done === true,
            // @ts-expect-error if done is false, value will be present
            value: next.value
        };
    };
    return _pushable(getNext, options);
}
function _pushable(getNext, options) {
    options = options ?? {};
    let onEnd = options.onEnd;
    let buffer = new FIFO();
    let pushable;
    let onNext;
    let ended;
    let drain = pDefer();
    const waitNext = async () => {
        try {
            if (!buffer.isEmpty()) {
                return getNext(buffer);
            }
            if (ended) {
                return { done: true };
            }
            return await new Promise((resolve, reject) => {
                onNext = (next) => {
                    onNext = null;
                    buffer.push(next);
                    try {
                        resolve(getNext(buffer));
                    }
                    catch (err) {
                        reject(err);
                    }
                    return pushable;
                };
            });
        }
        finally {
            if (buffer.isEmpty()) {
                // settle promise in the microtask queue to give consumers a chance to
                // await after calling .push
                queueMicrotask(() => {
                    drain.resolve();
                    drain = pDefer();
                });
            }
        }
    };
    const bufferNext = (next) => {
        if (onNext != null) {
            return onNext(next);
        }
        buffer.push(next);
        return pushable;
    };
    const bufferError = (err) => {
        buffer = new FIFO();
        if (onNext != null) {
            return onNext({ error: err });
        }
        buffer.push({ error: err });
        return pushable;
    };
    const push = (value) => {
        if (ended) {
            return pushable;
        }
        // @ts-expect-error `byteLength` is not declared on PushType
        if (options?.objectMode !== true && value?.byteLength == null) {
            throw new Error('objectMode was not true but tried to push non-Uint8Array value');
        }
        return bufferNext({ done: false, value });
    };
    const end = (err) => {
        if (ended)
            return pushable;
        ended = true;
        return (err != null) ? bufferError(err) : bufferNext({ done: true });
    };
    const _return = () => {
        buffer = new FIFO();
        end();
        return { done: true };
    };
    const _throw = (err) => {
        end(err);
        return { done: true };
    };
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next: waitNext,
        return: _return,
        throw: _throw,
        push,
        end,
        get readableLength() {
            return buffer.size;
        },
        onEmpty: async (options) => {
            const signal = options?.signal;
            signal?.throwIfAborted();
            if (buffer.isEmpty()) {
                return;
            }
            let cancel;
            let listener;
            if (signal != null) {
                cancel = new Promise((resolve, reject) => {
                    listener = () => {
                        reject(new AbortError$6());
                    };
                    signal.addEventListener('abort', listener);
                });
            }
            try {
                await Promise.race([
                    drain.promise,
                    cancel
                ]);
            }
            finally {
                if (listener != null && signal != null) {
                    signal?.removeEventListener('abort', listener);
                }
            }
        }
    };
    if (onEnd == null) {
        return pushable;
    }
    const _pushable = pushable;
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next() {
            return _pushable.next();
        },
        throw(err) {
            _pushable.throw(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return { done: true };
        },
        return() {
            _pushable.return();
            if (onEnd != null) {
                onEnd();
                onEnd = undefined;
            }
            return { done: true };
        },
        push,
        end(err) {
            _pushable.end(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return pushable;
        },
        get readableLength() {
            return _pushable.readableLength;
        },
        onEmpty: (opts) => {
            return _pushable.onEmpty(opts);
        }
    };
    return pushable;
}

/**
 * @packageDocumentation
 *
 * Merge several (async)iterables into one, yield values as they arrive.
 *
 * Nb. sources are iterated over in parallel so the order of emitted items is not guaranteed.
 *
 * @example
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, generator, etc
 * const values1 = [0, 1, 2, 3, 4]
 * const values2 = [5, 6, 7, 8, 9]
 *
 * const arr = all(merge(values1, values2))
 *
 * console.info(arr) // 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import merge from 'it-merge'
 * import all from 'it-all'
 *
 * // This can also be an iterator, async iterator, generator, etc
 * const values1 = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 * const values2 = async function * () {
 *   yield * [5, 6, 7, 8, 9]
 * }
 *
 * const arr = await all(merge(values1(), values2()))
 *
 * console.info(arr) // 0, 1, 5, 6, 2, 3, 4, 7, 8, 9  <- nb. order is not guaranteed
 * ```
 */
function isAsyncIterable$6(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function merge$1(...sources) {
    const syncSources = [];
    for (const source of sources) {
        if (!isAsyncIterable$6(source)) {
            syncSources.push(source);
        }
    }
    if (syncSources.length === sources.length) {
        // all sources are synchronous
        return (function* () {
            for (const source of syncSources) {
                yield* source;
            }
        })();
    }
    return (async function* () {
        const output = pushable({
            objectMode: true
        });
        void Promise.resolve().then(async () => {
            try {
                await Promise.all(sources.map(async (source) => {
                    for await (const item of source) {
                        output.push(item);
                    }
                }));
                output.end();
            }
            catch (err) {
                output.end(err);
            }
        });
        yield* output;
    })();
}

function pipe(first, ...rest) {
    if (first == null) {
        throw new Error('Empty pipeline');
    }
    // Duplex at start: wrap in function and return duplex source
    if (isDuplex(first)) {
        const duplex = first;
        first = () => duplex.source;
        // Iterable at start: wrap in function
    }
    else if (isIterable(first) || isAsyncIterable$5(first)) {
        const source = first;
        first = () => source;
    }
    const fns = [first, ...rest];
    if (fns.length > 1) {
        // Duplex at end: use duplex sink
        if (isDuplex(fns[fns.length - 1])) {
            fns[fns.length - 1] = fns[fns.length - 1].sink;
        }
    }
    if (fns.length > 2) {
        // Duplex in the middle, consume source with duplex sink and return duplex source
        for (let i = 1; i < fns.length - 1; i++) {
            if (isDuplex(fns[i])) {
                fns[i] = duplexPipelineFn(fns[i]);
            }
        }
    }
    return rawPipe(...fns);
}
const rawPipe = (...fns) => {
    let res;
    while (fns.length > 0) {
        res = fns.shift()(res);
    }
    return res;
};
const isAsyncIterable$5 = (obj) => {
    return obj?.[Symbol.asyncIterator] != null;
};
const isIterable = (obj) => {
    return obj?.[Symbol.iterator] != null;
};
const isDuplex = (obj) => {
    if (obj == null) {
        return false;
    }
    return obj.sink != null && obj.source != null;
};
const duplexPipelineFn = (duplex) => {
    return (source) => {
        const p = duplex.sink(source);
        if (p?.then != null) {
            const stream = pushable({
                objectMode: true
            });
            p.then(() => {
                stream.end();
            }, (err) => {
                stream.end(err);
            });
            let sourceWrap;
            const source = duplex.source;
            if (isAsyncIterable$5(source)) {
                sourceWrap = async function* () {
                    yield* source;
                    stream.end();
                };
            }
            else if (isIterable(source)) {
                sourceWrap = function* () {
                    yield* source;
                    stream.end();
                };
            }
            else {
                throw new Error('Unknown duplex source type - must be Iterable or AsyncIterable');
            }
            return merge$1(stream, sourceWrap());
        }
        return duplex.source;
    };
};

/**
 * Function to sort peers by latency from lowest to highest
 * @param peerStore - The Libp2p PeerStore
 * @param peers - The list of peers to choose from
 * @returns Sorted array of peers by latency
 */
async function sortPeersByLatency(peerStore, peers) {
    if (peers.length === 0)
        return [];
    const results = await Promise.all(peers.map(async (peer) => {
        try {
            const pingBytes = (await peerStore.get(peer.id)).metadata.get("ping");
            if (!pingBytes)
                return { peer, ping: Infinity };
            const ping = Number(bytesToUtf8(pingBytes));
            return { peer, ping };
        }
        catch (error) {
            return { peer, ping: Infinity };
        }
    }));
    // filter out null values
    const validResults = results.filter((result) => result !== null);
    return validResults
        .sort((a, b) => a.ping - b.ping)
        .map((result) => result.peer);
}
/**
 * Returns the list of peers that supports the given protocol.
 */
async function getPeersForProtocol(peerStore, protocols) {
    const peers = [];
    await peerStore.forEach((peer) => {
        for (let i = 0; i < protocols.length; i++) {
            if (peer.protocols.includes(protocols[i])) {
                peers.push(peer);
                break;
            }
        }
    });
    return peers;
}

/**
 * Retrieves a list of peers based on the specified criteria:
 * 1. If numPeers is 0, return all peers
 * 2. Bootstrap peers are prioritized
 * 3. Non-bootstrap peers are randomly selected to fill up to numPeers
 *
 * @param peers - The list of peers to filter from.
 * @param numPeers - The total number of peers to retrieve. If 0, all peers are returned, irrespective of `maxBootstrapPeers`.
 * @param maxBootstrapPeers - The maximum number of bootstrap peers to retrieve.
 * @returns An array of peers based on the specified criteria.
 */
function filterPeersByDiscovery(peers, numPeers, maxBootstrapPeers) {
    // Collect the bootstrap peers up to the specified maximum
    let bootstrapPeers = peers
        .filter((peer) => peer.tags.has(Tags.BOOTSTRAP))
        .slice(0, maxBootstrapPeers);
    // If numPeers is less than the number of bootstrap peers, adjust the bootstrapPeers array
    if (numPeers > 0 && numPeers < bootstrapPeers.length) {
        bootstrapPeers = bootstrapPeers.slice(0, numPeers);
    }
    // Collect non-bootstrap peers
    const nonBootstrapPeers = peers.filter((peer) => !peer.tags.has(Tags.BOOTSTRAP));
    // If numPeers is 0, return all peers
    if (numPeers === 0) {
        return [...bootstrapPeers, ...nonBootstrapPeers];
    }
    // Initialize the list of selected peers with the bootstrap peers
    const selectedPeers = [...bootstrapPeers];
    // Fill up to numPeers with remaining random peers if needed
    while (selectedPeers.length < numPeers && nonBootstrapPeers.length > 0) {
        const randomIndex = Math.floor(Math.random() * nonBootstrapPeers.length);
        const randomPeer = nonBootstrapPeers.splice(randomIndex, 1)[0];
        selectedPeers.push(randomPeer);
    }
    return selectedPeers;
}

function selectOpenConnection(connections) {
    return connections
        .filter((c) => c.status === "open")
        .sort((left, right) => right.timeline.open - left.timeline.open)
        .at(0);
}

const STREAM_LOCK_KEY = "consumed";
class StreamManager {
    multicodec;
    getConnections;
    addEventListener;
    log;
    ongoingCreation = new Set();
    streamPool = new Map();
    constructor(multicodec, getConnections, addEventListener) {
        this.multicodec = multicodec;
        this.getConnections = getConnections;
        this.addEventListener = addEventListener;
        this.log = new Logger$1(`stream-manager:${multicodec}`);
        this.addEventListener("peer:update", this.handlePeerUpdateStreamPool);
    }
    async getStream(peer) {
        const peerId = peer.id.toString();
        const scheduledStream = this.streamPool.get(peerId);
        if (scheduledStream) {
            this.streamPool.delete(peerId);
            await scheduledStream;
        }
        let stream = this.getOpenStreamForCodec(peer.id);
        if (stream) {
            this.log.info(`Found existing stream peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
            this.lockStream(peer.id.toString(), stream);
            return stream;
        }
        stream = await this.createStream(peer);
        this.lockStream(peer.id.toString(), stream);
        return stream;
    }
    async createStream(peer, retries = 0) {
        const connections = this.getConnections(peer.id);
        const connection = selectOpenConnection(connections);
        if (!connection) {
            throw new Error(`Failed to get a connection to the peer peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
        }
        let lastError;
        let stream;
        for (let i = 0; i < retries + 1; i++) {
            try {
                this.log.info(`Attempting to create a stream for peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
                stream = await connection.newStream(this.multicodec);
                this.log.info(`Created stream for peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
                break;
            }
            catch (error) {
                lastError = error;
            }
        }
        if (!stream) {
            throw new Error(`Failed to create a new stream for ${peer.id.toString()} -- ` +
                lastError);
        }
        return stream;
    }
    async createStreamWithLock(peer) {
        const peerId = peer.id.toString();
        if (this.ongoingCreation.has(peerId)) {
            this.log.info(`Skipping creation of a stream due to lock for peerId=${peerId} multicodec=${this.multicodec}`);
            return;
        }
        try {
            this.ongoingCreation.add(peerId);
            await this.createStream(peer);
        }
        catch (error) {
            this.log.error(`Failed to createStreamWithLock:`, error);
        }
        finally {
            this.ongoingCreation.delete(peerId);
        }
        return;
    }
    handlePeerUpdateStreamPool = (evt) => {
        const { peer } = evt.detail;
        if (!peer.protocols.includes(this.multicodec)) {
            return;
        }
        const stream = this.getOpenStreamForCodec(peer.id);
        if (stream) {
            return;
        }
        this.scheduleNewStream(peer);
    };
    scheduleNewStream(peer) {
        this.log.info(`Scheduling creation of a stream for peerId=${peer.id.toString()} multicodec=${this.multicodec}`);
        // abandon previous attempt
        if (this.streamPool.has(peer.id.toString())) {
            this.streamPool.delete(peer.id.toString());
        }
        this.streamPool.set(peer.id.toString(), this.createStreamWithLock(peer));
    }
    getOpenStreamForCodec(peerId) {
        const connections = this.getConnections(peerId);
        const connection = selectOpenConnection(connections);
        if (!connection) {
            return;
        }
        const stream = connection.streams.find((s) => s.protocol === this.multicodec);
        if (!stream) {
            return;
        }
        const isStreamUnusable = ["done", "closed", "closing"].includes(stream.writeStatus || "");
        if (isStreamUnusable || this.isStreamLocked(stream)) {
            return;
        }
        return stream;
    }
    lockStream(peerId, stream) {
        this.log.info(`Locking stream for peerId:${peerId}\tstreamId:${stream.id}`);
        stream.metadata[STREAM_LOCK_KEY] = true;
    }
    isStreamLocked(stream) {
        return !!stream.metadata[STREAM_LOCK_KEY];
    }
}

/**
 * A class with predefined helpers, to be used as a base to implement Waku
 * Protocols.
 */
class BaseProtocol {
    multicodec;
    components;
    log;
    pubsubTopics;
    addLibp2pEventListener;
    removeLibp2pEventListener;
    streamManager;
    constructor(multicodec, components, log, pubsubTopics) {
        this.multicodec = multicodec;
        this.components = components;
        this.log = log;
        this.pubsubTopics = pubsubTopics;
        this.addLibp2pEventListener = components.events.addEventListener.bind(components.events);
        this.removeLibp2pEventListener = components.events.removeEventListener.bind(components.events);
        this.streamManager = new StreamManager(multicodec, components.connectionManager.getConnections.bind(components.connectionManager), this.addLibp2pEventListener);
    }
    async getStream(peer) {
        return this.streamManager.getStream(peer);
    }
    /**
     * Returns known peers from the address book (`libp2p.peerStore`) that support
     * the class protocol. Waku may or may not be currently connected to these
     * peers.
     */
    async allPeers() {
        return getPeersForProtocol(this.components.peerStore, [this.multicodec]);
    }
    async connectedPeers() {
        const peers = await this.allPeers();
        return peers.filter((peer) => {
            const connections = this.components.connectionManager.getConnections(peer.id);
            return connections.length > 0;
        });
    }
    /**
     * Retrieves a list of connected peers that support the protocol. The list is sorted by latency.
     *
     * @param numPeers - The total number of peers to retrieve. If 0, all peers are returned.
     * @param maxBootstrapPeers - The maximum number of bootstrap peers to retrieve.
     * @returns A list of peers that support the protocol sorted by latency. By default, returns all peers available, including bootstrap.
     */
    async getPeers({ numPeers, maxBootstrapPeers } = {
        maxBootstrapPeers: 0,
        numPeers: 0
    }) {
        // Retrieve all connected peers that support the protocol & shard (if configured)
        const allAvailableConnectedPeers = await this.connectedPeers();
        // Filter the peers based on discovery & number of peers requested
        const filteredPeers = filterPeersByDiscovery(allAvailableConnectedPeers, numPeers, maxBootstrapPeers);
        // Sort the peers by latency
        const sortedFilteredPeers = await sortPeersByLatency(this.components.peerStore, filteredPeers);
        if (sortedFilteredPeers.length === 0) {
            this.log.warn("No peers found. Ensure you have a connection to the network.");
        }
        if (sortedFilteredPeers.length < numPeers) {
            this.log.warn(`Only ${sortedFilteredPeers.length} peers found. Requested ${numPeers}.`);
        }
        return sortedFilteredPeers;
    }
}

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];
}

const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native = {
  randomUUID
};

function v4$1(options, buf, offset) {
  if (native.randomUUID && !buf && !options) {
    return native.randomUUID();
  }

  options = options || {};
  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  return unsafeStringify(rnds);
}

/**
 * FilterPushRPC represents a message conforming to the Waku FilterPush protocol.
 * Protocol documentation: https://rfc.vac.dev/spec/12/
 */
class FilterPushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = MessagePush.decode(bytes);
        return new FilterPushRpc(res);
    }
    encode() {
        return MessagePush.encode(this.proto);
    }
    get wakuMessage() {
        return this.proto.wakuMessage;
    }
    /**
     * Get the pubsub topic from the FilterPushRpc object.
     * @returns string
     */
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
}
class FilterSubscribeRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createSubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4$1(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4$1(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeAllRequest(pubsubTopic) {
        return new FilterSubscribeRpc({
            requestId: v4$1(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE_ALL,
            pubsubTopic,
            contentTopics: []
        });
    }
    static createSubscriberPingRequest() {
        return new FilterSubscribeRpc({
            requestId: v4$1(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBER_PING,
            pubsubTopic: "",
            contentTopics: []
        });
    }
    static decode(bytes) {
        const res = FilterSubscribeRequest.decode(bytes);
        return new FilterSubscribeRpc(res);
    }
    encode() {
        return FilterSubscribeRequest.encode(this.proto);
    }
    get filterSubscribeType() {
        return this.proto.filterSubscribeType;
    }
    get requestId() {
        return this.proto.requestId;
    }
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
    get contentTopics() {
        return this.proto.contentTopics;
    }
}
class FilterSubscribeResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = FilterSubscribeResponse$1.decode(bytes);
        return new FilterSubscribeResponse(res);
    }
    encode() {
        return FilterSubscribeResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get requestId() {
        return this.proto.requestId;
    }
}

const log$n = new Logger$1("filter:v2");
const FilterCodecs = {
    SUBSCRIBE: "/vac/waku/filter-subscribe/2.0.0-beta1",
    PUSH: "/vac/waku/filter-push/2.0.0-beta1"
};
class FilterCore extends BaseProtocol {
    handleIncomingMessage;
    pubsubTopics;
    constructor(handleIncomingMessage, pubsubTopics, libp2p) {
        super(FilterCodecs.SUBSCRIBE, libp2p.components, log$n, pubsubTopics);
        this.handleIncomingMessage = handleIncomingMessage;
        this.pubsubTopics = pubsubTopics;
        libp2p
            .handle(FilterCodecs.PUSH, this.onRequest.bind(this), {
            maxInboundStreams: 100
        })
            .catch((e) => {
            log$n.error("Failed to register ", FilterCodecs.PUSH, e);
        });
    }
    async subscribe(pubsubTopic, peer, contentTopics) {
        const stream = await this.getStream(peer);
        const request = FilterSubscribeRpc.createSubscribeRequest(pubsubTopic, contentTopics);
        let res;
        try {
            res = await pipe([request.encode()], encode$5, stream, decode$4, async (source) => await all$1(source));
        }
        catch (error) {
            log$n.error("Failed to send subscribe request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$n.error(`Filter subscribe request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peer.id
        };
    }
    async unsubscribe(pubsubTopic, peer, contentTopics) {
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$n.error(`Failed to get a stream for remote peer${peer.id.toString()}`, error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_STREAM_AVAILABLE,
                    peerId: peer.id
                }
            };
        }
        const unsubscribeRequest = FilterSubscribeRpc.createUnsubscribeRequest(pubsubTopic, contentTopics);
        try {
            await pipe([unsubscribeRequest.encode()], encode$5, stream.sink);
        }
        catch (error) {
            log$n.error("Failed to send unsubscribe request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        return {
            success: peer.id,
            failure: null
        };
    }
    async unsubscribeAll(pubsubTopic, peer) {
        const stream = await this.getStream(peer);
        const request = FilterSubscribeRpc.createUnsubscribeAllRequest(pubsubTopic);
        const res = await pipe([request.encode()], encode$5, stream, decode$4, async (source) => await all$1(source));
        if (!res || !res.length) {
            return {
                failure: {
                    error: ProtocolError.NO_RESPONSE,
                    peerId: peer.id
                },
                success: null
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$n.error(`Filter unsubscribe all request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                },
                success: null
            };
        }
        return {
            failure: null,
            success: peer.id
        };
    }
    async ping(peer) {
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$n.error(`Failed to get a stream for remote peer${peer.id.toString()}`, error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_STREAM_AVAILABLE,
                    peerId: peer.id
                }
            };
        }
        const request = FilterSubscribeRpc.createSubscriberPingRequest();
        let res;
        try {
            res = await pipe([request.encode()], encode$5, stream, decode$4, async (source) => await all$1(source));
        }
        catch (error) {
            log$n.error("Failed to send ping request", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        if (!res || !res.length) {
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_RESPONSE,
                    peerId: peer.id
                }
            };
        }
        const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
        if (statusCode < 200 || statusCode >= 300) {
            log$n.error(`Filter ping request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            return {
                success: null,
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                }
            };
        }
        return {
            success: peer.id,
            failure: null
        };
    }
    onRequest(streamData) {
        const { connection, stream } = streamData;
        const { remotePeer } = connection;
        log$n.info(`Received message from ${remotePeer.toString()}`);
        try {
            pipe(stream, decode$4, async (source) => {
                for await (const bytes of source) {
                    const response = FilterPushRpc.decode(bytes.slice());
                    const { pubsubTopic, wakuMessage } = response;
                    if (!wakuMessage) {
                        log$n.error("Received empty message");
                        return;
                    }
                    if (!pubsubTopic) {
                        log$n.error("Pubsub topic missing from push message");
                        return;
                    }
                    await this.handleIncomingMessage(pubsubTopic, wakuMessage, connection.remotePeer.toString());
                }
            }).then(() => {
                log$n.info("Receiving pipe closed.");
            }, async (e) => {
                log$n.error(`Error with receiving pipe on peer:${connection.remotePeer.toString()} -- stream:${stream.id} -- protocol:${stream.protocol}: `, e);
            });
        }
        catch (e) {
            log$n.error("Error decoding message", e);
        }
    }
}

var index$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    FilterCodecs: FilterCodecs,
    FilterCore: FilterCore
});

class PushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(message, pubsubTopic) {
        return new PushRpc({
            requestId: v4$1(),
            request: {
                message: message,
                pubsubTopic: pubsubTopic
            },
            response: undefined
        });
    }
    static decode(bytes) {
        const res = PushRpc$1.decode(bytes);
        return new PushRpc(res);
    }
    encode() {
        return PushRpc$1.encode(this.proto);
    }
    get query() {
        return this.proto.request;
    }
    get response() {
        return this.proto.response;
    }
}

// should match nwaku
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/rln_relay.nim#L309
// https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/tests/waku_rln_relay/rln/waku_rln_relay_utils.nim#L20
const RLN_GENERATION_PREFIX_ERROR = "could not generate rln-v2 proof";
const isRLNResponseError = (info) => {
    if (!info) {
        return false;
    }
    return info.includes(RLN_GENERATION_PREFIX_ERROR);
};
const matchRLNErrorMessage = (info) => {
    const rlnErrorMap = {
        [ProtocolError.RLN_IDENTITY_MISSING]: ProtocolError.RLN_IDENTITY_MISSING,
        [ProtocolError.RLN_MEMBERSHIP_INDEX]: ProtocolError.RLN_MEMBERSHIP_INDEX,
        [ProtocolError.RLN_LIMIT_MISSING]: ProtocolError.RLN_LIMIT_MISSING
    };
    const infoLowerCase = info.toLowerCase();
    for (const errorKey in rlnErrorMap) {
        if (infoLowerCase.includes(errorKey.toLowerCase())) {
            return rlnErrorMap[errorKey];
        }
    }
    return ProtocolError.RLN_PROOF_GENERATION;
};

const log$m = new Logger$1("light-push");
const LightPushCodec = "/vac/waku/lightpush/2.0.0-beta1";
/**
 * Implements the [Waku v2 Light Push protocol](https://rfc.vac.dev/spec/19/).
 */
class LightPushCore extends BaseProtocol {
    pubsubTopics;
    constructor(pubsubTopics, libp2p) {
        super(LightPushCodec, libp2p.components, log$m, pubsubTopics);
        this.pubsubTopics = pubsubTopics;
    }
    async preparePushMessage(encoder, message) {
        try {
            if (!message.payload || message.payload.length === 0) {
                log$m.error("Failed to send waku light push: payload is empty");
                return { query: null, error: ProtocolError.EMPTY_PAYLOAD };
            }
            if (!(await isMessageSizeUnderCap(encoder, message))) {
                log$m.error("Failed to send waku light push: message is bigger than 1MB");
                return { query: null, error: ProtocolError.SIZE_TOO_BIG };
            }
            const protoMessage = await encoder.toProtoObj(message);
            if (!protoMessage) {
                log$m.error("Failed to encode to protoMessage, aborting push");
                return {
                    query: null,
                    error: ProtocolError.ENCODE_FAILED
                };
            }
            const query = PushRpc.createRequest(protoMessage, encoder.pubsubTopic);
            return { query, error: null };
        }
        catch (error) {
            log$m.error("Failed to prepare push message", error);
            return {
                query: null,
                error: ProtocolError.GENERIC_FAIL
            };
        }
    }
    async send(encoder, message, peer) {
        const { query, error: preparationError } = await this.preparePushMessage(encoder, message);
        if (preparationError || !query) {
            return {
                success: null,
                failure: {
                    error: preparationError,
                    peerId: peer.id
                }
            };
        }
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$m.error("Failed to get stream", error);
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_STREAM_AVAILABLE,
                    peerId: peer.id
                }
            };
        }
        let res;
        try {
            res = await pipe([query.encode()], encode$5, stream, decode$4, async (source) => await all$1(source));
        }
        catch (err) {
            log$m.error("Failed to send waku light push request", err);
            return {
                success: null,
                failure: {
                    error: ProtocolError.GENERIC_FAIL,
                    peerId: peer.id
                }
            };
        }
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => {
            bytes.append(chunk);
        });
        let response;
        try {
            response = PushRpc.decode(bytes).response;
        }
        catch (err) {
            log$m.error("Failed to decode push reply", err);
            return {
                success: null,
                failure: {
                    error: ProtocolError.DECODE_FAILED,
                    peerId: peer.id
                }
            };
        }
        if (!response) {
            log$m.error("Remote peer fault: No response in PushRPC");
            return {
                success: null,
                failure: {
                    error: ProtocolError.NO_RESPONSE,
                    peerId: peer.id
                }
            };
        }
        if (isRLNResponseError(response.info)) {
            const rlnErrorCase = matchRLNErrorMessage(response.info);
            log$m.error("Remote peer rejected the message: ", rlnErrorCase);
            return {
                success: null,
                failure: {
                    error: rlnErrorCase,
                    peerId: peer.id
                }
            };
        }
        if (!response.isSuccess) {
            log$m.error("Remote peer rejected the message: ", response.info);
            return {
                success: null,
                failure: {
                    error: ProtocolError.REMOTE_PEER_REJECTED,
                    peerId: peer.id
                }
            };
        }
        return { success: peer.id, failure: null };
    }
}

var index$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    LightPushCodec: LightPushCodec,
    LightPushCore: LightPushCore,
    get PushResponse () { return PushResponse; }
});

const EmptyMessage = {
    payload: new Uint8Array(),
    contentTopic: "",
    version: undefined,
    timestamp: undefined,
    meta: undefined,
    rateLimitProof: undefined,
    ephemeral: undefined
};
function toProtoMessage(wire) {
    return { ...EmptyMessage, ...wire };
}

// https://github.com/waku-org/nwaku/blob/7205f95cff9f49ca0bb762e8fd0bf56a6a7f3b3b/waku/waku_store/common.nim#L12
const DEFAULT_PAGE_SIZE = 20;
const MAX_PAGE_SIZE = 100;
const ONE_MILLION = 1_000000;
class StoreQueryRequest {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static create(params) {
        const request = new StoreQueryRequest({
            ...params,
            requestId: v4$1(),
            timeStart: params.timeStart
                ? BigInt(params.timeStart.getTime() * ONE_MILLION)
                : undefined,
            timeEnd: params.timeEnd
                ? BigInt(params.timeEnd.getTime() * ONE_MILLION)
                : undefined,
            messageHashes: params.messageHashes || [],
            paginationLimit: params.paginationLimit
                ? BigInt(params.paginationLimit)
                : undefined
        });
        // Validate request parameters based on RFC
        if ((params.pubsubTopic && !params.contentTopics) ||
            (!params.pubsubTopic && params.contentTopics)) {
            throw new Error("Both pubsubTopic and contentTopics must be set or unset");
        }
        if (params.messageHashes &&
            (params.pubsubTopic ||
                params.contentTopics ||
                params.timeStart ||
                params.timeEnd)) {
            throw new Error("Message hash lookup queries cannot include content filter criteria");
        }
        return request;
    }
    static decode(bytes) {
        const res = StoreQueryRequest$1.decode(bytes);
        return new StoreQueryRequest(res);
    }
    encode() {
        return StoreQueryRequest$1.encode(this.proto);
    }
}
class StoreQueryResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = StoreQueryResponse$1.decode(bytes);
        return new StoreQueryResponse(res);
    }
    encode() {
        return StoreQueryResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get messages() {
        return this.proto.messages;
    }
    get paginationCursor() {
        return this.proto.paginationCursor;
    }
}

const log$l = new Logger$1("store");
const StoreCodec = "/vac/waku/store-query/3.0.0";
class StoreCore extends BaseProtocol {
    pubsubTopics;
    constructor(pubsubTopics, libp2p) {
        super(StoreCodec, libp2p.components, log$l, pubsubTopics);
        this.pubsubTopics = pubsubTopics;
    }
    async *queryPerPage(queryOpts, decoders, peer) {
        if (queryOpts.contentTopics.toString() !==
            Array.from(decoders.keys()).toString()) {
            throw new Error("Internal error, the decoders should match the query's content topics");
        }
        let currentCursor = queryOpts.paginationCursor;
        while (true) {
            const storeQueryRequest = StoreQueryRequest.create({
                ...queryOpts,
                paginationCursor: currentCursor
            });
            let stream;
            try {
                stream = await this.getStream(peer);
            }
            catch (e) {
                log$l.error("Failed to get stream", e);
                break;
            }
            const res = await pipe([storeQueryRequest.encode()], encode$5, stream, decode$4, async (source) => await all$1(source));
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const storeQueryResponse = StoreQueryResponse.decode(bytes);
            if (!storeQueryResponse.statusCode ||
                storeQueryResponse.statusCode >= 300) {
                const errorMessage = `Store query failed with status code: ${storeQueryResponse.statusCode}, description: ${storeQueryResponse.statusDesc}`;
                log$l.error(errorMessage);
                throw new Error(errorMessage);
            }
            if (!storeQueryResponse.messages || !storeQueryResponse.messages.length) {
                log$l.warn("Stopping pagination due to empty messages in response");
                break;
            }
            log$l.info(`${storeQueryResponse.messages.length} messages retrieved from store`);
            const decodedMessages = storeQueryResponse.messages.map((protoMsg) => {
                if (!protoMsg.message) {
                    return Promise.resolve(undefined);
                }
                const contentTopic = protoMsg.message.contentTopic;
                if (contentTopic) {
                    const decoder = decoders.get(contentTopic);
                    if (decoder) {
                        return decoder.fromProtoObj(protoMsg.pubsubTopic || "", toProtoMessage(protoMsg.message));
                    }
                }
                return Promise.resolve(undefined);
            });
            yield decodedMessages;
            if (queryOpts.paginationForward) {
                currentCursor =
                    storeQueryResponse.messages[storeQueryResponse.messages.length - 1]
                        .messageHash;
            }
            else {
                currentCursor = storeQueryResponse.messages[0].messageHash;
            }
            if (storeQueryResponse.messages.length > MAX_PAGE_SIZE &&
                storeQueryResponse.messages.length <
                    (queryOpts.paginationLimit || DEFAULT_PAGE_SIZE)) {
                break;
            }
        }
    }
}

var index$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    StoreCodec: StoreCodec,
    StoreCore: StoreCore
});

const connectionSymbol = Symbol.for('@libp2p/connection');

/**
 * Any object that implements this Symbol as a property should return a
 * ContentRouting instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```TypeScript
 * import { contentRoutingSymbol, ContentRouting } from '@libp2p/content-routing'
 *
 * class MyContentRouter implements ContentRouting {
 *   get [contentRoutingSymbol] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const contentRoutingSymbol = Symbol.for('@libp2p/content-routing');

/**
 * Any object that implements this Symbol as a property should return a
 * PeerDiscovery instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```TypeScript
 * import { peerDiscovery, PeerDiscovery } from '@libp2p/peer-discovery'
 *
 * class MyPeerDiscoverer implements PeerDiscovery {
 *   get [peerDiscovery] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const peerDiscoverySymbol = Symbol.for('@libp2p/peer-discovery');

const peerIdSymbol = Symbol.for('@libp2p/peer-id');
function isPeerId(other) {
    return other != null && Boolean(other[peerIdSymbol]);
}

/**
 * Any object that implements this Symbol as a property should return a
 * PeerRouting instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```TypeScript
 * import { peerRouting, PeerRouting } from '@libp2p/peer-routing'
 *
 * class MyPeerRouter implements PeerRouting {
 *   get [peerRouting] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const peerRoutingSymbol = Symbol.for('@libp2p/peer-routing');

const KEEP_ALIVE = 'keep-alive';

const transportSymbol = Symbol.for('@libp2p/transport');
/**
 * Enum Transport Manager Fault Tolerance values
 */
var FaultTolerance;
(function (FaultTolerance) {
    /**
     * should be used for failing in any listen circumstance
     */
    FaultTolerance[FaultTolerance["FATAL_ALL"] = 0] = "FATAL_ALL";
    /**
     * should be used for not failing when not listening
     */
    FaultTolerance[FaultTolerance["NO_FATAL"] = 1] = "NO_FATAL";
})(FaultTolerance || (FaultTolerance = {}));

/**
 * When this error is thrown it means an operation was aborted,
 * usually in response to the `abort` event being emitted by an
 * AbortSignal.
 */
let AbortError$5 = class AbortError extends Error {
    code;
    type;
    constructor(message = 'The operation was aborted') {
        super(message);
        this.name = 'AbortError';
        this.code = AbortError.code;
        this.type = AbortError.type;
    }
    static code = 'ABORT_ERR';
    static type = 'aborted';
};
let CodeError$1 = class CodeError extends Error {
    code;
    props;
    constructor(message, code, props) {
        super(message);
        this.code = code;
        this.name = props?.name ?? 'CodeError';
        this.props = props ?? {}; // eslint-disable-line @typescript-eslint/consistent-type-assertions
    }
};
class AggregateCodeError extends AggregateError {
    code;
    props;
    constructor(errors, message, code, props) {
        super(errors, message);
        this.code = code;
        this.name = props?.name ?? 'AggregateCodeError';
        this.props = props ?? {}; // eslint-disable-line @typescript-eslint/consistent-type-assertions
    }
}
// Error codes
const ERR_TIMEOUT = 'ERR_TIMEOUT';
const ERR_INVALID_MESSAGE = 'ERR_INVALID_MESSAGE';

/** Noop for browser compatibility */
function setMaxListeners$1() { }

// create a setMaxListeners that doesn't break browser usage
const setMaxListeners = (n, ...eventTargets) => {
    try {
        setMaxListeners$1(n, ...eventTargets);
    }
    catch {
        // swallow error, gulp
    }
};

/**
 * An implementation of a typed event target
 * etc
 */
class TypedEventEmitter extends EventTarget {
    #listeners = new Map();
    constructor() {
        super();
        // silence MaxListenersExceededWarning warning on Node.js, this is a red
        // herring almost all of the time
        setMaxListeners(Infinity, this);
    }
    listenerCount(type) {
        const listeners = this.#listeners.get(type);
        if (listeners == null) {
            return 0;
        }
        return listeners.length;
    }
    addEventListener(type, listener, options) {
        super.addEventListener(type, listener, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            list = [];
            this.#listeners.set(type, list);
        }
        list.push({
            callback: listener,
            once: (options !== true && options !== false && options?.once) ?? false
        });
    }
    removeEventListener(type, listener, options) {
        super.removeEventListener(type.toString(), listener ?? null, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            return;
        }
        list = list.filter(({ callback }) => callback !== listener);
        this.#listeners.set(type, list);
    }
    dispatchEvent(event) {
        const result = super.dispatchEvent(event);
        let list = this.#listeners.get(event.type);
        if (list == null) {
            return result;
        }
        list = list.filter(({ once }) => !once);
        this.#listeners.set(event.type, list);
        return result;
    }
    safeDispatchEvent(type, detail = {}) {
        return this.dispatchEvent(new CustomEvent$1(type, detail));
    }
}
const CustomEvent$1 = globalThis.CustomEvent;

function isStartable(obj) {
    return obj != null && typeof obj.start === 'function' && typeof obj.stop === 'function';
}

/**
 * @packageDocumentation
 *
 * Exports a `Libp2p` type for modules to use as a type argument.
 *
 * @example
 *
 * ```typescript
 * import type { Libp2p } from '@libp2p/interface'
 *
 * function doSomethingWithLibp2p (node: Libp2p) {
 *   // ...
 * }
 * ```
 */
/**
 * This symbol is used by libp2p services to define the capabilities they can
 * provide to other libp2p services.
 *
 * The service should define a property with this symbol as the key and the
 * value should be a string array of provided capabilities.
 */
const serviceCapabilities = Symbol.for('@libp2p/service-capabilities');
/**
 * This symbol is used by libp2p services to define the capabilities they
 * require from other libp2p services.
 *
 * The service should define a property with this symbol as the key and the
 * value should be a string array of required capabilities.
 */
const serviceDependencies = Symbol.for('@libp2p/service-dependencies');

const RelayPingContentTopic = "/relay-ping/1/ping/null";
const log$k = new Logger$1("keep-alive");
class KeepAliveManager {
    relay;
    libp2p;
    options;
    pingKeepAliveTimers = new Map();
    relayKeepAliveTimers = new Map();
    constructor({ options, relay, libp2p }) {
        this.options = options;
        this.relay = relay;
        this.libp2p = libp2p;
    }
    start(peerId) {
        // Just in case a timer already exists for this peer
        this.stop(peerId);
        const { pingKeepAlive: pingPeriodSecs, relayKeepAlive: relayPeriodSecs } = this.options;
        const peerIdStr = peerId.toString();
        // Ping the peer every pingPeriodSecs seconds
        // if pingPeriodSecs is 0, don't ping the peer
        if (pingPeriodSecs !== 0) {
            const interval = setInterval(() => {
                void (async () => {
                    let ping;
                    try {
                        // ping the peer for keep alive
                        // also update the peer store with the latency
                        try {
                            ping = await this.libp2p.services.ping.ping(peerId);
                            log$k.info(`Ping succeeded (${peerIdStr})`, ping);
                        }
                        catch (error) {
                            log$k.error(`Ping failed for peer (${peerIdStr}).
                Next ping will be attempted in ${pingPeriodSecs} seconds.
              `);
                            return;
                        }
                        try {
                            await this.libp2p.peerStore.merge(peerId, {
                                metadata: {
                                    ping: utf8ToBytes$2(ping.toString())
                                }
                            });
                        }
                        catch (e) {
                            log$k.error("Failed to update ping", e);
                        }
                    }
                    catch (e) {
                        log$k.error(`Ping failed (${peerIdStr})`, e);
                    }
                })();
            }, pingPeriodSecs * 1000);
            this.pingKeepAliveTimers.set(peerIdStr, interval);
        }
        const relay = this.relay;
        if (relay && relayPeriodSecs !== 0) {
            const intervals = this.scheduleRelayPings(relay, relayPeriodSecs, peerId.toString());
            this.relayKeepAliveTimers.set(peerId, intervals);
        }
    }
    stop(peerId) {
        const peerIdStr = peerId.toString();
        if (this.pingKeepAliveTimers.has(peerIdStr)) {
            clearInterval(this.pingKeepAliveTimers.get(peerIdStr));
            this.pingKeepAliveTimers.delete(peerIdStr);
        }
        if (this.relayKeepAliveTimers.has(peerId)) {
            this.relayKeepAliveTimers.get(peerId)?.map(clearInterval);
            this.relayKeepAliveTimers.delete(peerId);
        }
    }
    stopAll() {
        for (const timer of [
            ...Object.values(this.pingKeepAliveTimers),
            ...Object.values(this.relayKeepAliveTimers)
        ]) {
            clearInterval(timer);
        }
        this.pingKeepAliveTimers.clear();
        this.relayKeepAliveTimers.clear();
    }
    connectionsExist() {
        return (this.pingKeepAliveTimers.size > 0 || this.relayKeepAliveTimers.size > 0);
    }
    scheduleRelayPings(relay, relayPeriodSecs, peerIdStr) {
        // send a ping message to each PubsubTopic the peer is part of
        const intervals = [];
        for (const topic of relay.pubsubTopics) {
            const meshPeers = relay.getMeshPeers(topic);
            if (!meshPeers.includes(peerIdStr))
                continue;
            const encoder = createEncoder({
                pubsubTopicShardInfo: pubsubTopicToSingleShardInfo(topic),
                contentTopic: RelayPingContentTopic,
                ephemeral: true
            });
            const interval = setInterval(() => {
                log$k.info("Sending Waku Relay ping message");
                relay
                    .send(encoder, { payload: new Uint8Array([1]) })
                    .catch((e) => log$k.error("Failed to send relay ping", e));
            }, relayPeriodSecs * 1000);
            intervals.push(interval);
        }
        return intervals;
    }
}

const log$j = new Logger$1("connection-manager");
const DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED = 1;
const DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER = 3;
const DEFAULT_MAX_PARALLEL_DIALS = 3;
class ConnectionManager extends TypedEventEmitter {
    configuredPubsubTopics;
    static instances = new Map();
    keepAliveManager;
    options;
    libp2p;
    dialAttemptsForPeer = new Map();
    dialErrorsForPeer = new Map();
    currentActiveParallelDialCount = 0;
    pendingPeerDialQueue = [];
    isP2PNetworkConnected = false;
    isConnected() {
        if (globalThis?.navigator && !globalThis?.navigator?.onLine) {
            return false;
        }
        return this.isP2PNetworkConnected;
    }
    static create(peerId, libp2p, keepAliveOptions, pubsubTopics, relay, options) {
        let instance = ConnectionManager.instances.get(peerId);
        if (!instance) {
            instance = new ConnectionManager(libp2p, keepAliveOptions, pubsubTopics, relay, options);
            ConnectionManager.instances.set(peerId, instance);
        }
        return instance;
    }
    stop() {
        this.keepAliveManager.stopAll();
        this.libp2p.removeEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
        this.libp2p.removeEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
        this.libp2p.removeEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
        this.stopNetworkStatusListener();
    }
    async dropConnection(peerId) {
        try {
            this.keepAliveManager.stop(peerId);
            await this.libp2p.hangUp(peerId);
            log$j.info(`Dropped connection with peer ${peerId.toString()}`);
        }
        catch (error) {
            log$j.error(`Error dropping connection with peer ${peerId.toString()} - ${error}`);
        }
    }
    async getPeersByDiscovery() {
        const peersDiscovered = await this.libp2p.peerStore.all();
        const peersConnected = this.libp2p
            .getConnections()
            .map((conn) => conn.remotePeer);
        const peersDiscoveredByBootstrap = [];
        const peersDiscoveredByPeerExchange = [];
        const peersDiscoveredByLocal = [];
        const peersConnectedByBootstrap = [];
        const peersConnectedByPeerExchange = [];
        const peersConnectedByLocal = [];
        for (const peer of peersDiscovered) {
            const tags = await this.getTagNamesForPeer(peer.id);
            if (tags.includes(Tags.BOOTSTRAP)) {
                peersDiscoveredByBootstrap.push(peer);
            }
            else if (tags.includes(Tags.PEER_EXCHANGE)) {
                peersDiscoveredByPeerExchange.push(peer);
            }
            else if (tags.includes(Tags.LOCAL)) {
                peersDiscoveredByLocal.push(peer);
            }
        }
        for (const peerId of peersConnected) {
            const peer = await this.libp2p.peerStore.get(peerId);
            const tags = await this.getTagNamesForPeer(peerId);
            if (tags.includes(Tags.BOOTSTRAP)) {
                peersConnectedByBootstrap.push(peer);
            }
            else if (tags.includes(Tags.PEER_EXCHANGE)) {
                peersConnectedByPeerExchange.push(peer);
            }
            else if (tags.includes(Tags.LOCAL)) {
                peersConnectedByLocal.push(peer);
            }
        }
        return {
            DISCOVERED: {
                [Tags.BOOTSTRAP]: peersDiscoveredByBootstrap,
                [Tags.PEER_EXCHANGE]: peersDiscoveredByPeerExchange,
                [Tags.LOCAL]: peersDiscoveredByLocal
            },
            CONNECTED: {
                [Tags.BOOTSTRAP]: peersConnectedByBootstrap,
                [Tags.PEER_EXCHANGE]: peersConnectedByPeerExchange,
                [Tags.LOCAL]: peersConnectedByLocal
            }
        };
    }
    constructor(libp2p, keepAliveOptions, configuredPubsubTopics, relay, options) {
        super();
        this.configuredPubsubTopics = configuredPubsubTopics;
        this.libp2p = libp2p;
        this.configuredPubsubTopics = configuredPubsubTopics;
        this.options = {
            maxDialAttemptsForPeer: DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER,
            maxBootstrapPeersAllowed: DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED,
            maxParallelDials: DEFAULT_MAX_PARALLEL_DIALS,
            ...options
        };
        this.keepAliveManager = new KeepAliveManager({
            relay,
            libp2p,
            options: keepAliveOptions
        });
        this.startEventListeners()
            .then(() => log$j.info(`Connection Manager is now running`))
            .catch((error) => log$j.error(`Unexpected error while running service`, error));
        // libp2p emits `peer:discovery` events during its initialization
        // which means that before the ConnectionManager is initialized, some peers may have been discovered
        // we will dial the peers in peerStore ONCE before we start to listen to the `peer:discovery` events within the ConnectionManager
        this.dialPeerStorePeers().catch((error) => log$j.error(`Unexpected error while dialing peer store peers`, error));
    }
    async dialPeerStorePeers() {
        const peerInfos = await this.libp2p.peerStore.all();
        const dialPromises = [];
        for (const peerInfo of peerInfos) {
            if (this.libp2p.getConnections().find((c) => c.remotePeer === peerInfo.id))
                continue;
            dialPromises.push(this.attemptDial(peerInfo.id));
        }
        try {
            await Promise.all(dialPromises);
        }
        catch (error) {
            log$j.error(`Unexpected error while dialing peer store peers`, error);
        }
    }
    async startEventListeners() {
        this.startPeerDiscoveryListener();
        this.startPeerConnectionListener();
        this.startPeerDisconnectionListener();
        this.startNetworkStatusListener();
    }
    async dialPeer(peerId) {
        this.currentActiveParallelDialCount += 1;
        let dialAttempt = 0;
        while (dialAttempt < this.options.maxDialAttemptsForPeer) {
            try {
                log$j.info(`Dialing peer ${peerId.toString()} on attempt ${dialAttempt + 1}`);
                await this.libp2p.dial(peerId);
                const tags = await this.getTagNamesForPeer(peerId);
                // add tag to connection describing discovery mechanism
                // don't add duplicate tags
                this.libp2p.getConnections(peerId).forEach((conn) => {
                    conn.tags = Array.from(new Set([...conn.tags, ...tags]));
                });
                // instead of deleting the peer from the peer store, we set the dial attempt to -1
                // this helps us keep track of peers that have been dialed before
                this.dialAttemptsForPeer.set(peerId.toString(), -1);
                // Dialing succeeded, break the loop
                this.keepAliveManager.start(peerId);
                break;
            }
            catch (error) {
                if (error instanceof AggregateError) {
                    // Handle AggregateError
                    log$j.error(`Error dialing peer ${peerId.toString()} - ${error.errors}`);
                }
                else {
                    // Handle generic error
                    log$j.error(`Error dialing peer ${peerId.toString()} - ${error.message}`);
                }
                this.dialErrorsForPeer.set(peerId.toString(), error);
                dialAttempt++;
                this.dialAttemptsForPeer.set(peerId.toString(), dialAttempt);
            }
        }
        // Always decrease the active dial count and process the dial queue
        this.currentActiveParallelDialCount--;
        this.processDialQueue();
        // If max dial attempts reached and dialing failed, delete the peer
        if (dialAttempt === this.options.maxDialAttemptsForPeer) {
            try {
                const error = this.dialErrorsForPeer.get(peerId.toString());
                if (error) {
                    let errorMessage;
                    if (error instanceof AggregateError) {
                        if (!error.errors) {
                            log$j.warn(`No errors array found for AggregateError`);
                        }
                        else if (error.errors.length === 0) {
                            log$j.warn(`Errors array is empty for AggregateError`);
                        }
                        else {
                            errorMessage = JSON.stringify(error.errors[0]);
                        }
                    }
                    else {
                        errorMessage = error.message;
                    }
                    log$j.info(`Deleting undialable peer ${peerId.toString()} from peer store. Reason: ${errorMessage}`);
                }
                this.dialErrorsForPeer.delete(peerId.toString());
                await this.libp2p.peerStore.delete(peerId);
                // if it was last available peer - attempt DNS discovery
                await this.attemptDnsDiscovery();
            }
            catch (error) {
                throw new Error(`Error deleting undialable peer ${peerId.toString()} from peer store - ${error}`);
            }
        }
    }
    async attemptDnsDiscovery() {
        if (this.libp2p.getConnections().length > 0)
            return;
        if ((await this.libp2p.peerStore.all()).length > 0)
            return;
        log$j.info("Attempting to trigger DNS discovery.");
        const dnsDiscovery = Object.values(this.libp2p.components.components).find((v) => {
            if (v && v.toString) {
                return v.toString().includes(DNS_DISCOVERY_TAG);
            }
            return false;
        });
        if (!dnsDiscovery)
            return;
        await dnsDiscovery.findPeers();
    }
    processDialQueue() {
        if (this.pendingPeerDialQueue.length > 0 &&
            this.currentActiveParallelDialCount < this.options.maxParallelDials) {
            const peerId = this.pendingPeerDialQueue.shift();
            if (!peerId)
                return;
            this.attemptDial(peerId).catch((error) => {
                log$j.error(error);
            });
        }
    }
    startPeerDiscoveryListener() {
        this.libp2p.addEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
    }
    startPeerConnectionListener() {
        this.libp2p.addEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
    }
    startPeerDisconnectionListener() {
        // TODO: ensure that these following issues are updated and confirmed
        /**
         * NOTE: Event is not being emitted on closing nor losing a connection.
         * @see https://github.com/libp2p/js-libp2p/issues/939
         * @see https://github.com/status-im/js-waku/issues/252
         *
         * >This event will be triggered anytime we are disconnected from another peer,
         * >regardless of the circumstances of that disconnection.
         * >If we happen to have multiple connections to a peer,
         * >this event will **only** be triggered when the last connection is closed.
         * @see https://github.com/libp2p/js-libp2p/blob/bad9e8c0ff58d60a78314077720c82ae331cc55b/doc/API.md?plain=1#L2100
         */
        this.libp2p.addEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
    }
    async attemptDial(peerId) {
        if (!(await this.shouldDialPeer(peerId)))
            return;
        if (this.currentActiveParallelDialCount >= this.options.maxParallelDials) {
            this.pendingPeerDialQueue.push(peerId);
            return;
        }
        await this.dialPeer(peerId);
    }
    onEventHandlers = {
        "peer:discovery": (evt) => {
            void (async () => {
                const { id: peerId } = evt.detail;
                await this.dispatchDiscoveryEvent(peerId);
                try {
                    await this.attemptDial(peerId);
                }
                catch (error) {
                    log$j.error(`Error dialing peer ${peerId.toString()} : ${error}`);
                }
            })();
        },
        "peer:connect": (evt) => {
            void (async () => {
                log$j.info(`Connected to peer ${evt.detail.toString()}`);
                const peerId = evt.detail;
                this.keepAliveManager.start(peerId);
                const isBootstrap = (await this.getTagNamesForPeer(peerId)).includes(Tags.BOOTSTRAP);
                if (isBootstrap) {
                    const bootstrapConnections = this.libp2p
                        .getConnections()
                        .filter((conn) => conn.tags.includes(Tags.BOOTSTRAP));
                    // If we have too many bootstrap connections, drop one
                    if (bootstrapConnections.length > this.options.maxBootstrapPeersAllowed) {
                        await this.dropConnection(peerId);
                    }
                    else {
                        this.dispatchEvent(new CustomEvent$1(EPeersByDiscoveryEvents.PEER_CONNECT_BOOTSTRAP, {
                            detail: peerId
                        }));
                    }
                }
                else {
                    this.dispatchEvent(new CustomEvent$1(EPeersByDiscoveryEvents.PEER_CONNECT_PEER_EXCHANGE, {
                        detail: peerId
                    }));
                }
                this.setP2PNetworkConnected();
            })();
        },
        "peer:disconnect": (evt) => {
            void (async () => {
                this.keepAliveManager.stop(evt.detail);
                this.setP2PNetworkDisconnected();
            })();
        },
        "browser:network": () => {
            this.dispatchWakuConnectionEvent();
        }
    };
    /**
     * Checks if the peer should be dialed based on the following conditions:
     * 1. If the peer is already connected, don't dial
     * 2. If the peer is not part of any of the configured pubsub topics, don't dial
     * 3. If the peer is not dialable based on bootstrap status, don't dial
     * 4. If the peer is already has an active dial attempt, or has been dialed before, don't dial it
     * @returns true if the peer should be dialed, false otherwise
     */
    async shouldDialPeer(peerId) {
        const isConnected = this.libp2p.getConnections(peerId).length > 0;
        if (isConnected) {
            log$j.warn(`Already connected to peer ${peerId.toString()}. Not dialing.`);
            return false;
        }
        const isSameShard = await this.isPeerTopicConfigured(peerId);
        if (!isSameShard) {
            const shardInfo = await this.getPeerShardInfo(peerId, this.libp2p.peerStore);
            log$j.warn(`Discovered peer ${peerId.toString()} with ShardInfo ${shardInfo} is not part of any of the configured pubsub topics (${this.configuredPubsubTopics}).
            Not dialing.`);
            return false;
        }
        const isPreferredBasedOnBootstrap = await this.isPeerDialableBasedOnBootstrapStatus(peerId);
        if (!isPreferredBasedOnBootstrap) {
            log$j.warn(`Peer ${peerId.toString()} is not dialable based on bootstrap status. Not dialing.`);
            return false;
        }
        const hasBeenDialed = this.dialAttemptsForPeer.has(peerId.toString());
        if (hasBeenDialed) {
            log$j.warn(`Peer ${peerId.toString()} has already been attempted dial before, or already has a dial attempt in progress, skipping dial`);
            return false;
        }
        return true;
    }
    /**
     * Checks if the peer is dialable based on the following conditions:
     * 1. If the peer is a bootstrap peer, it is only dialable if the number of current bootstrap connections is less than the max allowed.
     * 2. If the peer is not a bootstrap peer
     */
    async isPeerDialableBasedOnBootstrapStatus(peerId) {
        const tagNames = await this.getTagNamesForPeer(peerId);
        const isBootstrap = tagNames.some((tagName) => tagName === Tags.BOOTSTRAP);
        if (!isBootstrap) {
            return true;
        }
        const currentBootstrapConnections = this.libp2p
            .getConnections()
            .filter((conn) => {
            return conn.tags.find((name) => name === Tags.BOOTSTRAP);
        }).length;
        return currentBootstrapConnections < this.options.maxBootstrapPeersAllowed;
    }
    async dispatchDiscoveryEvent(peerId) {
        const isBootstrap = (await this.getTagNamesForPeer(peerId)).includes(Tags.BOOTSTRAP);
        this.dispatchEvent(new CustomEvent$1(isBootstrap
            ? EPeersByDiscoveryEvents.PEER_DISCOVERY_BOOTSTRAP
            : EPeersByDiscoveryEvents.PEER_DISCOVERY_PEER_EXCHANGE, {
            detail: peerId
        }));
    }
    /**
     * Fetches the tag names for a given peer
     */
    async getTagNamesForPeer(peerId) {
        try {
            const peer = await this.libp2p.peerStore.get(peerId);
            return Array.from(peer.tags.keys());
        }
        catch (error) {
            log$j.error(`Failed to get peer ${peerId}, error: ${error}`);
            return [];
        }
    }
    async isPeerTopicConfigured(peerId) {
        const shardInfo = await this.getPeerShardInfo(peerId, this.libp2p.peerStore);
        // If there's no shard information, simply return true
        if (!shardInfo)
            return true;
        const pubsubTopics = shardInfoToPubsubTopics(shardInfo);
        const isTopicConfigured = pubsubTopics.some((topic) => this.configuredPubsubTopics.includes(topic));
        return isTopicConfigured;
    }
    async getPeerShardInfo(peerId, peerStore) {
        const peer = await peerStore.get(peerId);
        const shardInfoBytes = peer.metadata.get("shardInfo");
        if (!shardInfoBytes)
            return undefined;
        return decodeRelayShard(shardInfoBytes);
    }
    startNetworkStatusListener() {
        try {
            globalThis.addEventListener("online", this.onEventHandlers["browser:network"]);
            globalThis.addEventListener("offline", this.onEventHandlers["browser:network"]);
        }
        catch (err) {
            log$j.error(`Failed to start network listener: ${err}`);
        }
    }
    stopNetworkStatusListener() {
        try {
            globalThis.removeEventListener("online", this.onEventHandlers["browser:network"]);
            globalThis.removeEventListener("offline", this.onEventHandlers["browser:network"]);
        }
        catch (err) {
            log$j.error(`Failed to stop network listener: ${err}`);
        }
    }
    setP2PNetworkConnected() {
        if (!this.isP2PNetworkConnected) {
            this.isP2PNetworkConnected = true;
            this.dispatchWakuConnectionEvent();
        }
    }
    setP2PNetworkDisconnected() {
        if (this.isP2PNetworkConnected &&
            this.libp2p.getConnections().length === 0) {
            this.isP2PNetworkConnected = false;
            this.dispatchWakuConnectionEvent();
        }
    }
    dispatchWakuConnectionEvent() {
        this.dispatchEvent(new CustomEvent$1(EConnectionStateEvents.CONNECTION_STATUS, {
            detail: this.isConnected()
        }));
    }
}

class HealthManager {
    static instance;
    health;
    constructor() {
        this.health = {
            overallStatus: HealthStatus.Unhealthy,
            protocolStatuses: new Map()
        };
    }
    static getInstance() {
        if (!HealthManager.instance) {
            HealthManager.instance = new HealthManager();
        }
        return HealthManager.instance;
    }
    getHealthStatus() {
        return this.health.overallStatus;
    }
    getProtocolStatus(protocol) {
        return this.health.protocolStatuses.get(protocol);
    }
    updateProtocolHealth(multicodec, connectedPeers) {
        const protocol = this.getNameFromMulticodec(multicodec);
        let status = HealthStatus.Unhealthy;
        if (connectedPeers == 1) {
            status = HealthStatus.MinimallyHealthy;
        }
        else if (connectedPeers >= 2) {
            status = HealthStatus.SufficientlyHealthy;
        }
        this.health.protocolStatuses.set(protocol, {
            name: protocol,
            status: status,
            lastUpdate: new Date()
        });
        this.updateOverallHealth();
    }
    getNameFromMulticodec(multicodec) {
        let name;
        if (multicodec.includes("filter")) {
            name = Protocols.Filter;
        }
        else if (multicodec.includes("lightpush")) {
            name = Protocols.LightPush;
        }
        else if (multicodec.includes("store")) {
            name = Protocols.Store;
        }
        else {
            throw new Error(`Unknown protocol: ${multicodec}`);
        }
        return name;
    }
    updateOverallHealth() {
        const relevantProtocols = [Protocols.LightPush, Protocols.Filter];
        const statuses = relevantProtocols.map((p) => this.getProtocolStatus(p)?.status);
        if (statuses.some((status) => status === HealthStatus.Unhealthy)) {
            this.health.overallStatus = HealthStatus.Unhealthy;
        }
        else if (statuses.some((status) => status === HealthStatus.MinimallyHealthy)) {
            this.health.overallStatus = HealthStatus.MinimallyHealthy;
        }
        else {
            this.health.overallStatus = HealthStatus.SufficientlyHealthy;
        }
    }
}
const getHealthManager = () => HealthManager.getInstance();

const log$i = new Logger$1("metadata");
const MetadataCodec = "/vac/waku/metadata/1.0.0";
class Metadata extends BaseProtocol {
    pubsubTopics;
    libp2pComponents;
    handshakesConfirmed = new Map();
    constructor(pubsubTopics, libp2p) {
        super(MetadataCodec, libp2p.components, log$i, pubsubTopics);
        this.pubsubTopics = pubsubTopics;
        this.libp2pComponents = libp2p;
        void libp2p.registrar.handle(MetadataCodec, (streamData) => {
            void this.onRequest(streamData);
        });
    }
    /**
     * Make a metadata query to a peer
     */
    async query(peerId) {
        const request = WakuMetadataRequest.encode(pubsubTopicsToShardInfo(this.pubsubTopics));
        const peer = await this.libp2pComponents.peerStore.get(peerId);
        if (!peer) {
            return {
                shardInfo: null,
                error: ProtocolError.NO_PEER_AVAILABLE
            };
        }
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (error) {
            log$i.error("Failed to get stream", error);
            return {
                shardInfo: null,
                error: ProtocolError.NO_STREAM_AVAILABLE
            };
        }
        const encodedResponse = await pipe([request], encode$5, stream, decode$4, async (source) => await all$1(source));
        const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
        if (error) {
            return {
                shardInfo: null,
                error
            };
        }
        await this.savePeerShardInfo(peerId, shardInfo);
        return {
            shardInfo,
            error: null
        };
    }
    async confirmOrAttemptHandshake(peerId) {
        const shardInfo = this.handshakesConfirmed.get(peerId.toString());
        if (shardInfo) {
            return {
                shardInfo,
                error: null
            };
        }
        return await this.query(peerId);
    }
    /**
     * Handle an incoming metadata request
     */
    async onRequest(streamData) {
        try {
            const { stream, connection } = streamData;
            const encodedShardInfo = WakuMetadataResponse.encode(pubsubTopicsToShardInfo(this.pubsubTopics));
            const encodedResponse = await pipe([encodedShardInfo], encode$5, stream, decode$4, async (source) => await all$1(source));
            const { error, shardInfo } = this.decodeMetadataResponse(encodedResponse);
            if (error) {
                return;
            }
            await this.savePeerShardInfo(connection.remotePeer, shardInfo);
        }
        catch (error) {
            log$i.error("Error handling metadata request", error);
        }
    }
    decodeMetadataResponse(encodedResponse) {
        const bytes = new Uint8ArrayList();
        encodedResponse.forEach((chunk) => {
            bytes.append(chunk);
        });
        const response = WakuMetadataResponse.decode(bytes);
        if (!response) {
            log$i.error("Error decoding metadata response");
            return {
                shardInfo: null,
                error: ProtocolError.DECODE_FAILED
            };
        }
        return {
            shardInfo: response,
            error: null
        };
    }
    async savePeerShardInfo(peerId, shardInfo) {
        // add or update the shardInfo to peer store
        await this.libp2pComponents.peerStore.merge(peerId, {
            metadata: {
                shardInfo: encodeRelayShard(shardInfo)
            }
        });
        this.handshakesConfirmed.set(peerId.toString(), shardInfo);
    }
}
function wakuMetadata(pubsubTopics) {
    return (components) => new Metadata(pubsubTopics, components);
}

var index = /*#__PURE__*/Object.freeze({
    __proto__: null,
    ConnectionManager: ConnectionManager,
    FilterCodecs: FilterCodecs,
    FilterCore: FilterCore,
    KeepAliveManager: KeepAliveManager,
    LightPushCodec: LightPushCodec,
    LightPushCore: LightPushCore,
    MetadataCodec: MetadataCodec,
    StoreCodec: StoreCodec,
    StoreCore: StoreCore,
    StreamManager: StreamManager,
    createDecoder: createDecoder,
    createEncoder: createEncoder,
    getHealthManager: getHealthManager,
    message: index$4,
    wakuMetadata: wakuMetadata,
    waku_filter: index$3,
    waku_light_push: index$2,
    waku_store: index$1
});

/* eslint-disable @typescript-eslint/no-unsafe-return */
class Parser {
    index = 0;
    input = "";
    new(input) {
        this.index = 0;
        this.input = input;
        return this;
    }
    /** Run a parser, and restore the pre-parse state if it fails. */
    readAtomically(fn) {
        const index = this.index;
        const result = fn();
        if (result === undefined) {
            this.index = index;
        }
        return result;
    }
    /** Run a parser, but fail if the entire input wasn't consumed. Doesn't run atomically. */
    parseWith(fn) {
        const result = fn();
        if (this.index !== this.input.length) {
            return undefined;
        }
        return result;
    }
    /** Peek the next character from the input */
    peekChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index];
    }
    /** Read the next character from the input */
    readChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index++];
    }
    /** Read the next character from the input if it matches the target. */
    readGivenChar(target) {
        return this.readAtomically(() => {
            const char = this.readChar();
            if (char !== target) {
                return undefined;
            }
            return char;
        });
    }
    /**
     * Helper for reading separators in an indexed loop. Reads the separator
     * character iff index > 0, then runs the parser. When used in a loop,
     * the separator character will only be read on index > 0 (see
     * readIPv4Addr for an example)
     */
    readSeparator(sep, index, inner) {
        return this.readAtomically(() => {
            if (index > 0) {
                if (this.readGivenChar(sep) === undefined) {
                    return undefined;
                }
            }
            return inner();
        });
    }
    /**
     * Read a number off the front of the input in the given radix, stopping
     * at the first non-digit character or eof. Fails if the number has more
     * digits than max_digits or if there is no number.
     */
    readNumber(radix, maxDigits, allowZeroPrefix, maxBytes) {
        return this.readAtomically(() => {
            let result = 0;
            let digitCount = 0;
            const leadingChar = this.peekChar();
            if (leadingChar === undefined) {
                return undefined;
            }
            const hasLeadingZero = leadingChar === "0";
            const maxValue = 2 ** (8 * maxBytes) - 1;
            // eslint-disable-next-line no-constant-condition
            while (true) {
                const digit = this.readAtomically(() => {
                    const char = this.readChar();
                    if (char === undefined) {
                        return undefined;
                    }
                    const num = Number.parseInt(char, radix);
                    if (Number.isNaN(num)) {
                        return undefined;
                    }
                    return num;
                });
                if (digit === undefined) {
                    break;
                }
                result *= radix;
                result += digit;
                if (result > maxValue) {
                    return undefined;
                }
                digitCount += 1;
                if (maxDigits !== undefined) {
                    if (digitCount > maxDigits) {
                        return undefined;
                    }
                }
            }
            if (digitCount === 0) {
                return undefined;
            }
            else if (!allowZeroPrefix && hasLeadingZero && digitCount > 1) {
                return undefined;
            }
            else {
                return result;
            }
        });
    }
    /** Read an IPv4 address. */
    readIPv4Addr() {
        return this.readAtomically(() => {
            const out = new Uint8Array(4);
            for (let i = 0; i < out.length; i++) {
                const ix = this.readSeparator(".", i, () => this.readNumber(10, 3, false, 1));
                if (ix === undefined) {
                    return undefined;
                }
                out[i] = ix;
            }
            return out;
        });
    }
    /** Read an IPv6 Address. */
    readIPv6Addr() {
        /**
         * Read a chunk of an IPv6 address into `groups`. Returns the number
         * of groups read, along with a bool indicating if an embedded
         * trailing IPv4 address was read. Specifically, read a series of
         * colon-separated IPv6 groups (0x0000 - 0xFFFF), with an optional
         * trailing embedded IPv4 address.
         */
        const readGroups = (groups) => {
            for (let i = 0; i < groups.length / 2; i++) {
                const ix = i * 2;
                // Try to read a trailing embedded IPv4 address. There must be at least 4 groups left.
                if (i < groups.length - 3) {
                    const ipv4 = this.readSeparator(":", i, () => this.readIPv4Addr());
                    if (ipv4 !== undefined) {
                        groups[ix] = ipv4[0];
                        groups[ix + 1] = ipv4[1];
                        groups[ix + 2] = ipv4[2];
                        groups[ix + 3] = ipv4[3];
                        return [ix + 4, true];
                    }
                }
                const group = this.readSeparator(":", i, () => this.readNumber(16, 4, true, 2));
                if (group === undefined) {
                    return [ix, false];
                }
                groups[ix] = group >> 8;
                groups[ix + 1] = group & 255;
            }
            return [groups.length, false];
        };
        return this.readAtomically(() => {
            // Read the front part of the address; either the whole thing, or up to the first ::
            const head = new Uint8Array(16);
            const [headSize, headIp4] = readGroups(head);
            if (headSize === 16) {
                return head;
            }
            // IPv4 part is not allowed before `::`
            if (headIp4) {
                return undefined;
            }
            // Read `::` if previous code parsed less than 8 groups.
            // `::` indicates one or more groups of 16 bits of zeros.
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            // Read the back part of the address. The :: must contain at least one
            // set of zeroes, so our max length is 7.
            const tail = new Uint8Array(14);
            const limit = 16 - (headSize + 2);
            const [tailSize] = readGroups(tail.subarray(0, limit));
            // Concat the head and tail of the IP address
            head.set(tail.subarray(0, tailSize), 16 - tailSize);
            return head;
        });
    }
    /** Read an IP Address, either IPv4 or IPv6. */
    readIPAddr() {
        return this.readIPv4Addr() ?? this.readIPv6Addr();
    }
}

// See https://stackoverflow.com/questions/166132/maximum-length-of-the-textual-representation-of-an-ipv6-address
const MAX_IPV6_LENGTH = 45;
const MAX_IPV4_LENGTH = 15;
const parser = new Parser();
/** Parse `input` into IPv4 bytes. */
function parseIPv4(input) {
    if (input.length > MAX_IPV4_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv4Addr());
}
/** Parse `input` into IPv6 bytes. */
function parseIPv6(input) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv6Addr());
}
/** Parse `input` into IPv4 or IPv6 bytes. */
function parseIP(input) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPAddr());
}

/** Check if `input` is IPv4. */
function isIPv4(input) {
    return Boolean(parseIPv4(input));
}
/** Check if `input` is IPv6. */
function isIPv6(input) {
    return Boolean(parseIPv6(input));
}
/** Check if `input` is IPv4 or IPv6. */
function isIP(input) {
    return Boolean(parseIP(input));
}

const isV4 = isIPv4;
const isV6 = isIPv6;
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const toBytes$1 = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    if (isV4(ip)) {
        const bytes = new Uint8Array(offset + 4);
        ip.split(/\./g).forEach((byte) => {
            bytes[offset++] = parseInt(byte, 10) & 0xff;
        });
        return bytes;
    }
    if (isV6(ip)) {
        const sections = ip.split(':', 8);
        let i;
        for (i = 0; i < sections.length; i++) {
            const isv4 = isV4(sections[i]);
            let v4Buffer;
            if (isv4) {
                v4Buffer = toBytes$1(sections[i]);
                sections[i] = toString$6(v4Buffer.slice(0, 2), 'base16');
            }
            if (v4Buffer != null && ++i < 8) {
                sections.splice(i, 0, toString$6(v4Buffer.slice(2, 4), 'base16'));
            }
        }
        if (sections[0] === '') {
            while (sections.length < 8)
                sections.unshift('0');
        }
        else if (sections[sections.length - 1] === '') {
            while (sections.length < 8)
                sections.push('0');
        }
        else if (sections.length < 8) {
            for (i = 0; i < sections.length && sections[i] !== ''; i++)
                ;
            const argv = [i, 1];
            for (i = 9 - sections.length; i > 0; i--) {
                argv.push('0');
            }
            sections.splice.apply(sections, argv);
        }
        const bytes = new Uint8Array(offset + 16);
        for (i = 0; i < sections.length; i++) {
            const word = parseInt(sections[i], 16);
            bytes[offset++] = (word >> 8) & 0xff;
            bytes[offset++] = word & 0xff;
        }
        return bytes;
    }
    throw new Error('invalid ip address');
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const toString$5 = function (buf, offset = 0, length) {
    offset = ~~offset;
    length = length ?? (buf.length - offset);
    const view = new DataView(buf.buffer);
    if (length === 4) {
        const result = [];
        // IPv4
        for (let i = 0; i < length; i++) {
            result.push(buf[offset + i]);
        }
        return result.join('.');
    }
    if (length === 16) {
        const result = [];
        // IPv6
        for (let i = 0; i < length; i += 2) {
            result.push(view.getUint16(offset + i).toString(16));
        }
        return result.join(':')
            .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
            .replace(/:{3,4}/, '::');
    }
    return '';
};

const V = -1;
const names = {};
const codes$3 = {};
const table = [
    [4, 32, 'ip4'],
    [6, 16, 'tcp'],
    [33, 16, 'dccp'],
    [41, 128, 'ip6'],
    [42, V, 'ip6zone'],
    [43, 8, 'ipcidr'],
    [53, V, 'dns', true],
    [54, V, 'dns4', true],
    [55, V, 'dns6', true],
    [56, V, 'dnsaddr', true],
    [132, 16, 'sctp'],
    [273, 16, 'udp'],
    [275, 0, 'p2p-webrtc-star'],
    [276, 0, 'p2p-webrtc-direct'],
    [277, 0, 'p2p-stardust'],
    [280, 0, 'webrtc-direct'],
    [281, 0, 'webrtc'],
    [290, 0, 'p2p-circuit'],
    [301, 0, 'udt'],
    [302, 0, 'utp'],
    [400, V, 'unix', false, true],
    // `ipfs` is added before `p2p` for legacy support.
    // All text representations will default to `p2p`, but `ipfs` will
    // still be supported
    [421, V, 'ipfs'],
    // `p2p` is the preferred name for 421, and is now the default
    [421, V, 'p2p'],
    [443, 0, 'https'],
    [444, 96, 'onion'],
    [445, 296, 'onion3'],
    [446, V, 'garlic64'],
    [448, 0, 'tls'],
    [449, V, 'sni'],
    [460, 0, 'quic'],
    [461, 0, 'quic-v1'],
    [465, 0, 'webtransport'],
    [466, V, 'certhash'],
    [477, 0, 'ws'],
    [478, 0, 'wss'],
    [479, 0, 'p2p-websocket-star'],
    [480, 0, 'http'],
    [481, V, 'http-path'],
    [777, V, 'memory']
];
// populate tables
table.forEach(row => {
    const proto = createProtocol(...row);
    codes$3[proto.code] = proto;
    names[proto.name] = proto;
});
function createProtocol(code, size, name, resolvable, path) {
    return {
        code,
        size,
        name,
        resolvable: Boolean(resolvable),
        path: Boolean(path)
    };
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 */
function getProtocol(proto) {
    if (typeof proto === 'number') {
        if (codes$3[proto] != null) {
            return codes$3[proto];
        }
        throw new Error(`no protocol with code: ${proto}`);
    }
    else if (typeof proto === 'string') {
        if (names[proto] != null) {
            return names[proto];
        }
        throw new Error(`no protocol with name: ${proto}`);
    }
    throw new Error(`invalid protocol id type: ${typeof proto}`);
}

/**
 * @packageDocumentation
 *
 * Provides methods for converting
 */
getProtocol('ip4');
getProtocol('ip6');
getProtocol('ipcidr');
/**
 * Convert [code,Uint8Array] to string
 */
function convertToString(proto, buf) {
    const protocol = getProtocol(proto);
    switch (protocol.code) {
        case 4: // ipv4
        case 41: // ipv6
            return bytes2ip(buf);
        case 42: // ipv6zone
            return bytes2str(buf);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return bytes2port(buf).toString();
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return bytes2str(buf);
        case 421: // ipfs
            return bytes2mh(buf);
        case 444: // onion
            return bytes2onion(buf);
        case 445: // onion3
            return bytes2onion(buf);
        case 466: // certhash
            return bytes2mb(buf);
        case 481: // http-path
            return globalThis.encodeURIComponent(bytes2str(buf));
        default:
            return toString$6(buf, 'base16'); // no clue. convert to hex
    }
}
function convertToBytes(proto, str) {
    const protocol = getProtocol(proto);
    switch (protocol.code) {
        case 4: // ipv4
            return ip2bytes(str);
        case 41: // ipv6
            return ip2bytes(str);
        case 42: // ipv6zone
            return str2bytes(str);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return port2bytes(parseInt(str, 10));
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return str2bytes(str);
        case 421: // ipfs
            return mh2bytes(str);
        case 444: // onion
            return onion2bytes(str);
        case 445: // onion3
            return onion32bytes(str);
        case 466: // certhash
            return mb2bytes(str);
        case 481: // http-path
            return str2bytes(globalThis.decodeURIComponent(str));
        default:
            return fromString(str, 'base16'); // no clue. convert from hex
    }
}
const decoders = Object.values(bases).map((c) => c.decoder);
const anybaseDecoder = (function () {
    let acc = decoders[0].or(decoders[1]);
    decoders.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function ip2bytes(ipString) {
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return toBytes$1(ipString);
}
function bytes2ip(ipBuff) {
    const ipString = toString$5(ipBuff, 0, ipBuff.length);
    if (ipString == null) {
        throw new Error('ipBuff is required');
    }
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return ipString;
}
function port2bytes(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, port);
    return new Uint8Array(buf);
}
function bytes2port(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset);
}
function str2bytes(str) {
    const buf = fromString(str);
    const size = Uint8Array.from(encode$a(buf.length));
    return concat$1([size, buf], size.length + buf.length);
}
function bytes2str(buf) {
    const size = decode$a(buf);
    buf = buf.slice(encodingLength$3(size));
    if (buf.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$6(buf);
}
function mh2bytes(hash) {
    let mh;
    if (hash[0] === 'Q' || hash[0] === '1') {
        mh = decode$5(base58btc.decode(`z${hash}`)).bytes;
    }
    else {
        mh = CID.parse(hash).multihash.bytes;
    }
    // the address is a varint prefixed multihash string representation
    const size = Uint8Array.from(encode$a(mh.length));
    return concat$1([size, mh], size.length + mh.length);
}
function mb2bytes(mbstr) {
    const mb = anybaseDecoder.decode(mbstr);
    const size = Uint8Array.from(encode$a(mb.length));
    return concat$1([size, mb], size.length + mb.length);
}
function bytes2mb(buf) {
    const size = decode$a(buf);
    const hash = buf.slice(encodingLength$3(size));
    if (hash.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return 'u' + toString$6(hash, 'base64url');
}
/**
 * Converts bytes to bas58btc string
 */
function bytes2mh(buf) {
    const size = decode$a(buf);
    const address = buf.slice(encodingLength$3(size));
    if (address.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$6(address, 'base58btc');
}
function onion2bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$2.decode('b' + addr[0]);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat$1([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$2.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat$1([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion(buf) {
    const addrBytes = buf.slice(0, buf.length - 2);
    const portBytes = buf.slice(buf.length - 2);
    const addr = toString$6(addrBytes, 'base32');
    const port = bytes2port(portBytes);
    return `${addr}:${port}`;
}

function stringToMultiaddrParts(str) {
    str = cleanPath(str);
    const tuples = [];
    const stringTuples = [];
    let path = null;
    const parts = str.split('/').slice(1);
    if (parts.length === 1 && parts[0] === '') {
        return {
            bytes: new Uint8Array(),
            string: '/',
            tuples: [],
            stringTuples: [],
            path: null
        };
    }
    for (let p = 0; p < parts.length; p++) {
        const part = parts[p];
        const proto = getProtocol(part);
        if (proto.size === 0) {
            tuples.push([proto.code]);
            stringTuples.push([proto.code]);
            // eslint-disable-next-line no-continue
            continue;
        }
        p++; // advance addr part
        if (p >= parts.length) {
            throw ParseError('invalid address: ' + str);
        }
        // if it's a path proto, take the rest
        if (proto.path === true) {
            // should we need to check each path part to see if it's a proto?
            // This would allow for other protocols to be added after a unix path,
            // however it would have issues if the path had a protocol name in the path
            path = cleanPath(parts.slice(p).join('/'));
            tuples.push([proto.code, convertToBytes(proto.code, path)]);
            stringTuples.push([proto.code, path]);
            break;
        }
        const bytes = convertToBytes(proto.code, parts[p]);
        tuples.push([proto.code, bytes]);
        stringTuples.push([proto.code, convertToString(proto.code, bytes)]);
    }
    return {
        string: stringTuplesToString(stringTuples),
        bytes: tuplesToBytes(tuples),
        tuples,
        stringTuples,
        path
    };
}
function bytesToMultiaddrParts(bytes) {
    const tuples = [];
    const stringTuples = [];
    let path = null;
    let i = 0;
    while (i < bytes.length) {
        const code = decode$a(bytes, i);
        const n = encodingLength$3(code);
        const p = getProtocol(code);
        const size = sizeForAddr(p, bytes.slice(i + n));
        if (size === 0) {
            tuples.push([code]);
            stringTuples.push([code]);
            i += n;
            // eslint-disable-next-line no-continue
            continue;
        }
        const addr = bytes.slice(i + n, i + n + size);
        i += (size + n);
        if (i > bytes.length) { // did not end _exactly_ at buffer.length
            throw ParseError('Invalid address Uint8Array: ' + toString$6(bytes, 'base16'));
        }
        // ok, tuple seems good.
        tuples.push([code, addr]);
        const stringAddr = convertToString(code, addr);
        stringTuples.push([code, stringAddr]);
        if (p.path === true) {
            // should we need to check each path part to see if it's a proto?
            // This would allow for other protocols to be added after a unix path,
            // however it would have issues if the path had a protocol name in the path
            path = stringAddr;
            break;
        }
    }
    return {
        bytes: Uint8Array.from(bytes),
        string: stringTuplesToString(stringTuples),
        tuples,
        stringTuples,
        path
    };
}
/**
 * [[str name, str addr]... ] -> string
 */
function stringTuplesToString(tuples) {
    const parts = [];
    tuples.map((tup) => {
        const proto = getProtocol(tup[0]);
        parts.push(proto.name);
        if (tup.length > 1 && tup[1] != null) {
            parts.push(tup[1]);
        }
        return null;
    });
    return cleanPath(parts.join('/'));
}
/**
 * [[int code, Uint8Array ]... ] -> Uint8Array
 */
function tuplesToBytes(tuples) {
    return concat$1(tuples.map((tup) => {
        const proto = getProtocol(tup[0]);
        let buf = Uint8Array.from(encode$a(proto.code));
        if (tup.length > 1 && tup[1] != null) {
            buf = concat$1([buf, tup[1]]); // add address buffer
        }
        return buf;
    }));
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr(p, addr) {
    if (p.size > 0) {
        return p.size / 8;
    }
    else if (p.size === 0) {
        return 0;
    }
    else {
        const size = decode$a(addr instanceof Uint8Array ? addr : Uint8Array.from(addr));
        return size + encodingLength$3(size);
    }
}
function cleanPath(str) {
    return '/' + str.trim().split('/').filter((a) => a).join('/');
}
function ParseError(str) {
    return new Error('Error parsing address: ' + str);
}

/**
 * @packageDocumentation
 *
 * An implementation of a Multiaddr in JavaScript
 *
 * @example
 *
 * ```js
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/ip4/127.0.0.1/tcp/1234')
 * ```
 */
const inspect$1 = Symbol.for('nodejs.util.inspect.custom');
const symbol = Symbol.for('@multiformats/js-multiaddr/multiaddr');
const DNS_CODES = [
    getProtocol('dns').code,
    getProtocol('dns4').code,
    getProtocol('dns6').code,
    getProtocol('dnsaddr').code
];
class NoAvailableResolverError extends Error {
    constructor(message = 'No available resolver') {
        super(message);
        this.name = 'NoAvailableResolverError';
    }
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
class Multiaddr {
    bytes;
    #string;
    #tuples;
    #stringTuples;
    #path;
    [symbol] = true;
    constructor(addr) {
        // default
        if (addr == null) {
            addr = '';
        }
        let parts;
        if (addr instanceof Uint8Array) {
            parts = bytesToMultiaddrParts(addr);
        }
        else if (typeof addr === 'string') {
            if (addr.length > 0 && addr.charAt(0) !== '/') {
                throw new Error(`multiaddr "${addr}" must start with a "/"`);
            }
            parts = stringToMultiaddrParts(addr);
        }
        else if (isMultiaddr(addr)) { // Multiaddr
            parts = bytesToMultiaddrParts(addr.bytes);
        }
        else {
            throw new Error('addr must be a string, Buffer, or another Multiaddr');
        }
        this.bytes = parts.bytes;
        this.#string = parts.string;
        this.#tuples = parts.tuples;
        this.#stringTuples = parts.stringTuples;
        this.#path = parts.path;
    }
    toString() {
        return this.#string;
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        const tcp = getProtocol('tcp');
        const udp = getProtocol('udp');
        const ip4 = getProtocol('ip4');
        const ip6 = getProtocol('ip6');
        const dns6 = getProtocol('dns6');
        const ip6zone = getProtocol('ip6zone');
        for (const [code, value] of this.stringTuples()) {
            if (code === ip6zone.code) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES.includes(code)) {
                transport = tcp.name;
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === dns6.code ? 6 : 4;
            }
            if (code === tcp.code || code === udp.code) {
                transport = getProtocol(code).name;
                port = parseInt(value ?? '');
            }
            if (code === ip4.code || code === ip6.code) {
                transport = getProtocol(code).name;
                host = `${value ?? ''}${zone}`;
                family = code === ip6.code ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    protos() {
        return this.#tuples.map(([code]) => Object.assign({}, getProtocol(code)));
    }
    protoCodes() {
        return this.#tuples.map(([code]) => code);
    }
    protoNames() {
        return this.#tuples.map(([code]) => getProtocol(code).name);
    }
    tuples() {
        return this.#tuples;
    }
    stringTuples() {
        return this.#stringTuples;
    }
    encapsulate(addr) {
        addr = new Multiaddr(addr);
        return new Multiaddr(this.toString() + addr.toString());
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new Error(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new Multiaddr(s.slice(0, i));
    }
    decapsulateCode(code) {
        const tuples = this.tuples();
        for (let i = tuples.length - 1; i >= 0; i--) {
            if (tuples[i][0] === code) {
                return new Multiaddr(tuplesToBytes(tuples.slice(0, i)));
            }
        }
        return this;
    }
    getPeerId() {
        try {
            let tuples = [];
            this.stringTuples().forEach(([code, name]) => {
                if (code === names.p2p.code) {
                    tuples.push([code, name]);
                }
                // if this is a p2p-circuit address, return the target peer id if present
                // not the peer id of the relay
                if (code === names['p2p-circuit'].code) {
                    tuples = [];
                }
            });
            // Get the last ipfs tuple ['p2p', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString$6(base58btc.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString$6(CID.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        return this.#path;
    }
    equals(addr) {
        return equals(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers$1.get(resolvableProto.name);
        if (resolver == null) {
            throw new NoAvailableResolverError(`no available resolver for ${resolvableProto.name}`);
        }
        const result = await resolver(this, options);
        return result.map(str => multiaddr(str));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress(addr) {
        const protos = (addr ?? this).protos();
        if (protos.length !== 2) {
            return false;
        }
        if (protos[0].code !== 4 && protos[0].code !== 41) {
            return false;
        }
        if (protos[1].code !== 6 && protos[1].code !== 273) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [inspect$1]() {
        return `Multiaddr(${this.#string})`;
    }
}

/**
 * @packageDocumentation
 *
 * A standard way to represent addresses that
 *
 * - support any standard network protocol
 * - are self-describing
 * - have a binary packed format
 * - have a nice string representation
 * - encapsulate well
 *
 * @example
 *
 * ```TypeScript
 * import { multiaddr } from '@multiformats/multiaddr'
 * const addr =  multiaddr("/ip4/127.0.0.1/udp/1234")
 * // Multiaddr(/ip4/127.0.0.1/udp/1234)
 *
 * const addr = multiaddr("/ip4/127.0.0.1/udp/1234")
 * // Multiaddr(/ip4/127.0.0.1/udp/1234)
 *
 * addr.bytes
 * // <Uint8Array 04 7f 00 00 01 11 04 d2>
 *
 * addr.toString()
 * // '/ip4/127.0.0.1/udp/1234'
 *
 * addr.protos()
 * // [
 * //   {code: 4, name: 'ip4', size: 32},
 * //   {code: 273, name: 'udp', size: 16}
 * // ]
 *
 * // gives you an object that is friendly with what Node.js core modules expect for addresses
 * addr.nodeAddress()
 * // {
 * //   family: 4,
 * //   port: 1234,
 * //   address: "127.0.0.1"
 * // }
 *
 * addr.encapsulate('/sctp/5678')
 * // Multiaddr(/ip4/127.0.0.1/udp/1234/sctp/5678)
 * ```
 *
 * ## Resolving DNSADDR addresses
 *
 * [DNSADDR](https://github.com/multiformats/multiaddr/blob/master/protocols/DNSADDR.md) is a spec that allows storing a TXT DNS record that contains a Multiaddr.
 *
 * To resolve DNSADDR addresses, call the `.resolve()` function the multiaddr, optionally passing a `DNS` resolver.
 *
 * DNSADDR addresses can resolve to multiple multiaddrs, since there is no limit to the number of TXT records that can be stored.
 *
 * @example Resolving DNSADDR Multiaddrs
 *
 * ```TypeScript
 * import { multiaddr, resolvers } from '@multiformats/multiaddr'
 * import { dnsaddr } from '@multiformats/multiaddr/resolvers'
 *
 * resolvers.set('dnsaddr', dnsaddr)
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 *
 * // resolve with a 5s timeout
 * const resolved = await ma.resolve({
 *   signal: AbortSignal.timeout(5000)
 * })
 *
 * console.info(await ma.resolve(resolved)
 * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]
 * ```
 *
 * @example Using a custom DNS resolver to resolve DNSADDR Multiaddrs
 *
 * See the docs for [@multiformats/dns](https://www.npmjs.com/package/@multiformats/dns) for a full breakdown of how to specify multiple resolvers or resolvers that can be used for specific TLDs.
 *
 * ```TypeScript
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { dns } from '@multiformats/dns'
 * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'
 *
 * const resolver = dns({
 *   '.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query')
 * })
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 * const resolved = await ma.resolve({
 *  dns: resolver
 * })
 *
 * console.info(resolved)
 * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]
 * ```
 */
/**
 * All configured {@link Resolver}s
 */
const resolvers$1 = new Map();
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr(value) {
    return Boolean(value?.[symbol]);
}
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr(addr) {
    return new Multiaddr(addr);
}

const E_CANCELED = new Error('request for lock canceled');

var __awaiter$2 = function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
class Semaphore {
    constructor(_value, _cancelError = E_CANCELED) {
        this._value = _value;
        this._cancelError = _cancelError;
        this._queue = [];
        this._weightedWaiters = [];
    }
    acquire(weight = 1, priority = 0) {
        if (weight <= 0)
            throw new Error(`invalid weight ${weight}: must be positive`);
        return new Promise((resolve, reject) => {
            const task = { resolve, reject, weight, priority };
            const i = findIndexFromEnd(this._queue, (other) => priority <= other.priority);
            if (i === -1 && weight <= this._value) {
                // Needs immediate dispatch, skip the queue
                this._dispatchItem(task);
            }
            else {
                this._queue.splice(i + 1, 0, task);
            }
        });
    }
    runExclusive(callback_1) {
        return __awaiter$2(this, arguments, void 0, function* (callback, weight = 1, priority = 0) {
            const [value, release] = yield this.acquire(weight, priority);
            try {
                return yield callback(value);
            }
            finally {
                release();
            }
        });
    }
    waitForUnlock(weight = 1, priority = 0) {
        if (weight <= 0)
            throw new Error(`invalid weight ${weight}: must be positive`);
        if (this._couldLockImmediately(weight, priority)) {
            return Promise.resolve();
        }
        else {
            return new Promise((resolve) => {
                if (!this._weightedWaiters[weight - 1])
                    this._weightedWaiters[weight - 1] = [];
                insertSorted(this._weightedWaiters[weight - 1], { resolve, priority });
            });
        }
    }
    isLocked() {
        return this._value <= 0;
    }
    getValue() {
        return this._value;
    }
    setValue(value) {
        this._value = value;
        this._dispatchQueue();
    }
    release(weight = 1) {
        if (weight <= 0)
            throw new Error(`invalid weight ${weight}: must be positive`);
        this._value += weight;
        this._dispatchQueue();
    }
    cancel() {
        this._queue.forEach((entry) => entry.reject(this._cancelError));
        this._queue = [];
    }
    _dispatchQueue() {
        this._drainUnlockWaiters();
        while (this._queue.length > 0 && this._queue[0].weight <= this._value) {
            this._dispatchItem(this._queue.shift());
            this._drainUnlockWaiters();
        }
    }
    _dispatchItem(item) {
        const previousValue = this._value;
        this._value -= item.weight;
        item.resolve([previousValue, this._newReleaser(item.weight)]);
    }
    _newReleaser(weight) {
        let called = false;
        return () => {
            if (called)
                return;
            called = true;
            this.release(weight);
        };
    }
    _drainUnlockWaiters() {
        if (this._queue.length === 0) {
            for (let weight = this._value; weight > 0; weight--) {
                const waiters = this._weightedWaiters[weight - 1];
                if (!waiters)
                    continue;
                waiters.forEach((waiter) => waiter.resolve());
                this._weightedWaiters[weight - 1] = [];
            }
        }
        else {
            const queuedPriority = this._queue[0].priority;
            for (let weight = this._value; weight > 0; weight--) {
                const waiters = this._weightedWaiters[weight - 1];
                if (!waiters)
                    continue;
                const i = waiters.findIndex((waiter) => waiter.priority <= queuedPriority);
                (i === -1 ? waiters : waiters.splice(0, i))
                    .forEach((waiter => waiter.resolve()));
            }
        }
    }
    _couldLockImmediately(weight, priority) {
        return (this._queue.length === 0 || this._queue[0].priority < priority) &&
            weight <= this._value;
    }
}
function insertSorted(a, v) {
    const i = findIndexFromEnd(a, (other) => v.priority <= other.priority);
    a.splice(i + 1, 0, v);
}
function findIndexFromEnd(a, predicate) {
    for (let i = a.length - 1; i >= 0; i--) {
        if (predicate(a[i])) {
            return i;
        }
    }
    return -1;
}

var __awaiter$1 = function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
class Mutex {
    constructor(cancelError) {
        this._semaphore = new Semaphore(1, cancelError);
    }
    acquire() {
        return __awaiter$1(this, arguments, void 0, function* (priority = 0) {
            const [, releaser] = yield this._semaphore.acquire(1, priority);
            return releaser;
        });
    }
    runExclusive(callback, priority = 0) {
        return this._semaphore.runExclusive(() => callback(), 1, priority);
    }
    isLocked() {
        return this._semaphore.isLocked();
    }
    waitForUnlock(priority = 0) {
        return this._semaphore.waitForUnlock(1, priority);
    }
    release() {
        if (this._semaphore.isLocked())
            this._semaphore.release();
    }
    cancel() {
        return this._semaphore.cancel();
    }
}

class PeerManager {
    connectionManager;
    core;
    log;
    peers = new Map();
    healthManager;
    readMutex = new Mutex();
    writeMutex = new Mutex();
    writeLockHolder = null;
    constructor(connectionManager, core, log) {
        this.connectionManager = connectionManager;
        this.core = core;
        this.log = log;
        this.healthManager = getHealthManager();
        this.healthManager.updateProtocolHealth(this.core.multicodec, 0);
    }
    getWriteLockHolder() {
        return this.writeLockHolder;
    }
    getPeers() {
        return Array.from(this.peers.values());
    }
    async addPeer(peer) {
        return this.writeMutex.runExclusive(async () => {
            this.writeLockHolder = `addPeer: ${peer.id.toString()}`;
            await this.connectionManager.attemptDial(peer.id);
            this.peers.set(peer.id.toString(), peer);
            this.log.info(`Added and dialed peer: ${peer.id.toString()}`);
            this.healthManager.updateProtocolHealth(this.core.multicodec, this.peers.size);
            this.writeLockHolder = null;
        });
    }
    async removePeer(peerId) {
        return this.writeMutex.runExclusive(() => {
            this.writeLockHolder = `removePeer: ${peerId.toString()}`;
            this.peers.delete(peerId.toString());
            this.log.info(`Removed peer: ${peerId.toString()}`);
            this.healthManager.updateProtocolHealth(this.core.multicodec, this.peers.size);
            this.writeLockHolder = null;
        });
    }
    async getPeerCount() {
        return this.readMutex.runExclusive(() => this.peers.size);
    }
    async hasPeers() {
        return this.readMutex.runExclusive(() => this.peers.size > 0);
    }
    async removeExcessPeers(excessPeers) {
        this.log.info(`Removing ${excessPeers} excess peer(s)`);
        const peersToRemove = Array.from(this.peers.values()).slice(0, excessPeers);
        for (const peer of peersToRemove) {
            await this.removePeer(peer.id);
        }
    }
    /**
     * Finds and adds new peers to the peers list.
     * @param numPeers The number of peers to find and add.
     */
    async findAndAddPeers(numPeers) {
        const additionalPeers = await this.findPeers(numPeers);
        if (additionalPeers.length === 0) {
            this.log.warn("No additional peers found");
            return [];
        }
        return this.addMultiplePeers(additionalPeers);
    }
    /**
     * Finds additional peers.
     * @param numPeers The number of peers to find.
     */
    async findPeers(numPeers) {
        const connectedPeers = await this.core.getPeers();
        return this.readMutex.runExclusive(async () => {
            const newPeers = connectedPeers
                .filter((peer) => !this.peers.has(peer.id.toString()))
                .slice(0, numPeers);
            return newPeers;
        });
    }
    async addMultiplePeers(peers) {
        const addedPeers = [];
        for (const peer of peers) {
            await this.addPeer(peer);
            addedPeers.push(peer);
        }
        return addedPeers;
    }
}

const DEFAULT_NUM_PEERS_TO_USE = 2;
const DEFAULT_MAINTAIN_PEERS_INTERVAL = 30_000;
class BaseProtocolSDK {
    core;
    connectionManager;
    peerManager;
    numPeersToUse;
    maintainPeersIntervalId = null;
    log;
    constructor(core, connectionManager, options) {
        this.core = core;
        this.connectionManager = connectionManager;
        this.log = new Logger$1(`sdk:${core.multicodec}`);
        this.numPeersToUse = options?.numPeersToUse ?? DEFAULT_NUM_PEERS_TO_USE;
        const maintainPeersInterval = options?.maintainPeersInterval ?? DEFAULT_MAINTAIN_PEERS_INTERVAL;
        this.peerManager = new PeerManager(connectionManager, core, this.log);
        this.log.info(`Initializing BaseProtocolSDK with numPeersToUse: ${this.numPeersToUse}, maintainPeersInterval: ${maintainPeersInterval}ms`);
        void this.startMaintainPeersInterval(maintainPeersInterval);
    }
    get connectedPeers() {
        return this.peerManager.getPeers().slice(0, this.numPeersToUse);
    }
    /**
     * Disconnects from a peer and tries to find a new one to replace it.
     * @param peerToDisconnect The peer to disconnect from.
     * @returns The new peer that was found and connected to.
     */
    async renewPeer(peerToDisconnect) {
        this.log.info(`Attempting to renew peer ${peerToDisconnect}`);
        const newPeer = await this.peerManager.findPeers(1);
        if (newPeer.length === 0) {
            this.log.error("Failed to find a new peer to replace the disconnected one");
            return undefined;
        }
        await this.peerManager.removePeer(peerToDisconnect);
        await this.peerManager.addPeer(newPeer[0]);
        this.log.info(`Successfully renewed peer. New peer: ${newPeer[0].id}`);
        return newPeer[0];
    }
    /**
     * Stops the maintain peers interval.
     */
    stopMaintainPeersInterval() {
        if (this.maintainPeersIntervalId) {
            clearInterval(this.maintainPeersIntervalId);
            this.maintainPeersIntervalId = null;
            this.log.info("Maintain peers interval stopped");
        }
        else {
            this.log.info("Maintain peers interval was not running");
        }
    }
    /**
     * Checks if there are sufficient peers to send a message to.
     * If `forceUseAllPeers` is `false` (default), returns `true` if there are any connected peers.
     * If `forceUseAllPeers` is `true`, attempts to connect to `numPeersToUse` peers.
     * @param options Optional options object
     * @param options.forceUseAllPeers Optional flag to force connecting to `numPeersToUse` peers (default: false)
     * @param options.maxAttempts Optional maximum number of attempts to reach the required number of peers (default: 3)
     * @returns `true` if the required number of peers are connected, `false` otherwise
     */
    async hasPeers(options = {}) {
        const { forceUseAllPeers = false, maxAttempts = 3 } = options;
        this.log.info(`Checking for peers. forceUseAllPeers: ${forceUseAllPeers}, maxAttempts: ${maxAttempts}`);
        for (let attempts = 0; attempts < maxAttempts; attempts++) {
            this.log.info(`Attempt ${attempts + 1}/${maxAttempts} to reach required number of peers`);
            await this.maintainPeers();
            if (!forceUseAllPeers && this.connectedPeers.length > 0) {
                this.log.info(`At least one peer connected (${this.connectedPeers.length}), not forcing use of all peers`);
                return true;
            }
            if (this.connectedPeers.length >= this.numPeersToUse) {
                this.log.info(`Required number of peers (${this.numPeersToUse}) reached`);
                return true;
            }
            this.log.warn(`Found only ${this.connectedPeers.length}/${this.numPeersToUse} required peers. Retrying...`);
        }
        this.log.error(`Failed to find required number of peers (${this.numPeersToUse}) after ${maxAttempts} attempts`);
        return false;
    }
    /**
     * Starts an interval to maintain the peers list to `numPeersToUse`.
     * @param interval The interval in milliseconds to maintain the peers.
     */
    async startMaintainPeersInterval(interval) {
        this.log.info(`Starting maintain peers interval with ${interval}ms interval`);
        try {
            this.maintainPeersIntervalId = setInterval(() => {
                this.log.info("Running scheduled peer maintenance");
                this.maintainPeers().catch((error) => {
                    this.log.error("Error during scheduled peer maintenance:", error);
                });
            }, interval);
            this.log.info("Maintain peers interval started successfully");
        }
        catch (error) {
            this.log.error("Error starting maintain peers interval:", error);
            throw error;
        }
    }
    /**
     * Maintains the peers list to `numPeersToUse`.
     */
    async maintainPeers() {
        try {
            const currentPeerCount = await this.peerManager.getPeerCount();
            const numPeersToAdd = this.numPeersToUse - currentPeerCount;
            this.log.info(`Current peer count: ${currentPeerCount}, target: ${this.numPeersToUse}`);
            if (numPeersToAdd === 0) {
                this.log.info("Peer count is at target, no maintenance required");
                return;
            }
            if (numPeersToAdd > 0) {
                this.log.info(`Attempting to add ${numPeersToAdd} peer(s)`);
                await this.peerManager.findAndAddPeers(numPeersToAdd);
            }
            else {
                this.log.info(`Attempting to remove ${Math.abs(numPeersToAdd)} excess peer(s)`);
                await this.peerManager.removeExcessPeers(Math.abs(numPeersToAdd));
            }
            const finalPeerCount = await this.peerManager.getPeerCount();
            this.log.info(`Peer maintenance completed. Initial count: ${currentPeerCount}, Final count: ${finalPeerCount}`);
        }
        catch (error) {
            this.log.error("Error during peer maintenance", { error });
        }
    }
}

const DEFAULT_KEEP_ALIVE = 60_000;
const DEFAULT_LIGHT_PUSH_FILTER_CHECK = false;
const DEFAULT_LIGHT_PUSH_FILTER_CHECK_INTERVAL = 10_000;
const DEFAULT_SUBSCRIBE_OPTIONS = {
    keepAlive: DEFAULT_KEEP_ALIVE,
    enableLightPushFilterCheck: DEFAULT_LIGHT_PUSH_FILTER_CHECK
};

/**
 * Deterministic Message Hashing as defined in
 * [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/#deterministic-message-hashing)
 */
function messageHash(pubsubTopic, message) {
    const pubsubTopicBytes = utf8ToBytes$2(pubsubTopic);
    const contentTopicBytes = utf8ToBytes$2(message.contentTopic);
    const timestampBytes = tryConvertTimestampToBytes(message.timestamp);
    const bytes = concat$2([
        pubsubTopicBytes,
        message.payload,
        contentTopicBytes,
        message.meta,
        timestampBytes
    ].filter(isDefined));
    return sha256(bytes);
}
function tryConvertTimestampToBytes(timestamp) {
    if (!timestamp) {
        return;
    }
    let bigIntTimestamp;
    if (typeof timestamp === "bigint") {
        bigIntTimestamp = timestamp;
    }
    else {
        bigIntTimestamp = BigInt(timestamp.valueOf()) * 1000000n;
    }
    return numberToBytes(bigIntTimestamp);
}
function messageHashStr(pubsubTopic, message) {
    const hash = messageHash(pubsubTopic, message);
    const hashStr = bytesToHex$2(hash);
    return hashStr;
}

const log$h = new Logger$1("sdk:receiver:reliability_monitor");
const DEFAULT_MAX_PINGS = 3;
const MESSAGE_VERIFICATION_DELAY = 5_000;
class ReceiverReliabilityMonitor {
    pubsubTopic;
    getPeers;
    renewPeer;
    getContentTopics;
    protocolSubscribe;
    addLibp2pEventListener;
    sendLightPushMessage;
    receivedMessagesFormPeer = new Set();
    receivedMessages = new Set();
    scheduledVerification = new Map();
    verifiedPeers = new Set();
    peerFailures = new Map();
    maxPingFailures = DEFAULT_MAX_PINGS;
    peerRenewalLocks = new Set();
    constructor(pubsubTopic, getPeers, renewPeer, getContentTopics, protocolSubscribe, addLibp2pEventListener, sendLightPushMessage) {
        this.pubsubTopic = pubsubTopic;
        this.getPeers = getPeers;
        this.renewPeer = renewPeer;
        this.getContentTopics = getContentTopics;
        this.protocolSubscribe = protocolSubscribe;
        this.addLibp2pEventListener = addLibp2pEventListener;
        this.sendLightPushMessage = sendLightPushMessage;
        this.addLibp2pEventListener("peer:disconnect", (evt) => {
            const peerId = evt.detail;
            if (this.getPeers().some((p) => p.id.equals(peerId))) {
                void this.renewAndSubscribePeer(peerId);
            }
        });
    }
    setMaxPingFailures(value) {
        if (value === undefined) {
            return;
        }
        this.maxPingFailures = value;
    }
    async handlePingResult(peerId, result) {
        if (result?.success) {
            this.peerFailures.delete(peerId.toString());
            return;
        }
        const failures = (this.peerFailures.get(peerId.toString()) || 0) + 1;
        this.peerFailures.set(peerId.toString(), failures);
        if (failures >= this.maxPingFailures) {
            try {
                log$h.info(`Attempting to renew ${peerId.toString()} due to ping failures.`);
                await this.renewAndSubscribePeer(peerId);
                this.peerFailures.delete(peerId.toString());
            }
            catch (error) {
                log$h.error(`Failed to renew peer ${peerId.toString()}: ${error}.`);
            }
        }
    }
    notifyMessageReceived(peerIdStr, message) {
        const hash = this.buildMessageHash(message);
        this.verifiedPeers.add(peerIdStr);
        this.receivedMessagesFormPeer.add(`${peerIdStr}-${hash}`);
        log$h.info(`notifyMessage received debug: ephemeral:${message.ephemeral}\t${bytesToUtf8(message.payload)}`);
        log$h.info(`notifyMessage received: peer:${peerIdStr}\tmessage:${hash}`);
        if (this.receivedMessages.has(hash)) {
            return true;
        }
        this.receivedMessages.add(hash);
        return false;
    }
    notifyMessageSent(peerId, message) {
        const peerIdStr = peerId.toString();
        const hash = this.buildMessageHash(message);
        log$h.info(`notifyMessage sent debug: ${bytesToUtf8(message.payload)}`);
        if (this.scheduledVerification.has(peerIdStr)) {
            log$h.warn(`notifyMessage sent: attempting to schedule verification for pending peer:${peerIdStr}\tmessage:${hash}`);
            return;
        }
        const timeout = window.setTimeout((async () => {
            const receivedAnyMessage = this.verifiedPeers.has(peerIdStr);
            const receivedTestMessage = this.receivedMessagesFormPeer.has(`${peerIdStr}-${hash}`);
            if (receivedAnyMessage || receivedTestMessage) {
                log$h.info(`notifyMessage sent setTimeout: verified that peer pushes filter messages, peer:${peerIdStr}\tmessage:${hash}`);
                return;
            }
            log$h.warn(`notifyMessage sent setTimeout: peer didn't return probe message, attempting renewAndSubscribe, peer:${peerIdStr}\tmessage:${hash}`);
            this.scheduledVerification.delete(peerIdStr);
            await this.renewAndSubscribePeer(peerId);
        }), MESSAGE_VERIFICATION_DELAY);
        this.scheduledVerification.set(peerIdStr, timeout);
    }
    shouldVerifyPeer(peerId) {
        const peerIdStr = peerId.toString();
        const isPeerVerified = this.verifiedPeers.has(peerIdStr);
        const isVerificationPending = this.scheduledVerification.has(peerIdStr);
        return !(isPeerVerified || isVerificationPending);
    }
    buildMessageHash(message) {
        return messageHashStr(this.pubsubTopic, message);
    }
    async renewAndSubscribePeer(peerId) {
        const peerIdStr = peerId.toString();
        try {
            if (this.peerRenewalLocks.has(peerIdStr)) {
                log$h.info(`Peer ${peerIdStr} is already being renewed.`);
                return;
            }
            this.peerRenewalLocks.add(peerIdStr);
            const newPeer = await this.renewPeer(peerId);
            if (!newPeer) {
                log$h.warn(`Failed to renew peer ${peerIdStr}: No new peer found.`);
                return;
            }
            await this.protocolSubscribe(this.pubsubTopic, newPeer, this.getContentTopics());
            await this.sendLightPushMessage(newPeer);
            this.peerFailures.delete(peerIdStr);
            return newPeer;
        }
        catch (error) {
            log$h.error(`Failed to renew peer ${peerIdStr}: ${error}.`);
            return;
        }
        finally {
            this.peerRenewalLocks.delete(peerIdStr);
        }
    }
}

class ReliabilityMonitorManager {
    static receiverMonitors = new Map();
    static createReceiverMonitor(pubsubTopic, getPeers, renewPeer, getContentTopics, protocolSubscribe, addLibp2pEventListener, sendLightPushMessage) {
        if (ReliabilityMonitorManager.receiverMonitors.has(pubsubTopic)) {
            return ReliabilityMonitorManager.receiverMonitors.get(pubsubTopic);
        }
        const monitor = new ReceiverReliabilityMonitor(pubsubTopic, getPeers, renewPeer, getContentTopics, protocolSubscribe, addLibp2pEventListener, sendLightPushMessage);
        ReliabilityMonitorManager.receiverMonitors.set(pubsubTopic, monitor);
        return monitor;
    }
    constructor() { }
    static stop(pubsubTopic) {
        this.receiverMonitors.delete(pubsubTopic);
    }
    static stopAll() {
        for (const [pubsubTopic, monitor] of this.receiverMonitors) {
            monitor.setMaxPingFailures(undefined);
            this.receiverMonitors.delete(pubsubTopic);
        }
    }
}

const log$g = new Logger$1("sdk:filter:subscription_manager");
class SubscriptionManager {
    pubsubTopic;
    protocol;
    connectionManager;
    getPeers;
    renewPeer;
    libp2p;
    lightPush;
    reliabilityMonitor;
    keepAliveTimeout = DEFAULT_KEEP_ALIVE;
    keepAliveInterval = null;
    enableLightPushFilterCheck = DEFAULT_LIGHT_PUSH_FILTER_CHECK;
    subscriptionCallbacks;
    constructor(pubsubTopic, protocol, connectionManager, getPeers, renewPeer, libp2p, lightPush) {
        this.pubsubTopic = pubsubTopic;
        this.protocol = protocol;
        this.connectionManager = connectionManager;
        this.getPeers = getPeers;
        this.renewPeer = renewPeer;
        this.libp2p = libp2p;
        this.lightPush = lightPush;
        this.pubsubTopic = pubsubTopic;
        this.subscriptionCallbacks = new Map();
        this.reliabilityMonitor = ReliabilityMonitorManager.createReceiverMonitor(this.pubsubTopic, this.getPeers.bind(this), this.renewPeer.bind(this), () => Array.from(this.subscriptionCallbacks.keys()), this.protocol.subscribe.bind(this.protocol), this.protocol.addLibp2pEventListener.bind(this.protocol), this.sendLightPushCheckMessage.bind(this));
    }
    async subscribe(decoders, callback, options = DEFAULT_SUBSCRIBE_OPTIONS) {
        this.reliabilityMonitor.setMaxPingFailures(options.pingsBeforePeerRenewed);
        this.keepAliveTimeout = options.keepAlive || DEFAULT_KEEP_ALIVE;
        this.enableLightPushFilterCheck =
            options?.enableLightPushFilterCheck || DEFAULT_LIGHT_PUSH_FILTER_CHECK;
        const decodersArray = Array.isArray(decoders) ? decoders : [decoders];
        // check that all decoders are configured for the same pubsub topic as this subscription
        for (const decoder of decodersArray) {
            if (decoder.pubsubTopic !== this.pubsubTopic) {
                return {
                    failures: [
                        {
                            error: ProtocolError.TOPIC_DECODER_MISMATCH
                        }
                    ],
                    successes: []
                };
            }
        }
        if (this.enableLightPushFilterCheck) {
            decodersArray.push(createDecoder(this.buildLightPushContentTopic(), this.pubsubTopic));
        }
        const decodersGroupedByCT = groupByContentTopic(decodersArray);
        const contentTopics = Array.from(decodersGroupedByCT.keys());
        const promises = this.getPeers().map(async (peer) => this.subscribeWithPeerVerification(peer, contentTopics));
        const results = await Promise.allSettled(promises);
        const finalResult = this.handleResult(results, "subscribe");
        // Save the callback functions by content topics so they
        // can easily be removed (reciprocally replaced) if `unsubscribe` (reciprocally `subscribe`)
        // is called for those content topics
        decodersGroupedByCT.forEach((decoders, contentTopic) => {
            // Cast the type because a given `subscriptionCallbacks` map may hold
            // Decoder that decode to different implementations of `IDecodedMessage`
            const subscriptionCallback = {
                decoders,
                callback
            };
            // don't handle case of internal content topic
            if (contentTopic === this.buildLightPushContentTopic()) {
                return;
            }
            // The callback and decoder may override previous values, this is on
            // purpose as the user may call `subscribe` to refresh the subscription
            this.subscriptionCallbacks.set(contentTopic, subscriptionCallback);
        });
        this.startSubscriptionsMaintenance(this.keepAliveTimeout);
        return finalResult;
    }
    async unsubscribe(contentTopics) {
        const promises = this.getPeers().map(async (peer) => {
            const response = await this.protocol.unsubscribe(this.pubsubTopic, peer, contentTopics);
            contentTopics.forEach((contentTopic) => {
                this.subscriptionCallbacks.delete(contentTopic);
            });
            return response;
        });
        const results = await Promise.allSettled(promises);
        const finalResult = this.handleResult(results, "unsubscribe");
        if (this.subscriptionCallbacks.size === 0) {
            this.stopSubscriptionsMaintenance();
        }
        return finalResult;
    }
    async ping(peerId) {
        log$g.info("Sending keep-alive ping");
        const peers = peerId ? [peerId] : this.getPeers().map((peer) => peer.id);
        const promises = peers.map((peerId) => this.pingSpecificPeer(peerId));
        const results = await Promise.allSettled(promises);
        return this.handleResult(results, "ping");
    }
    async unsubscribeAll() {
        const promises = this.getPeers().map(async (peer) => this.protocol.unsubscribeAll(this.pubsubTopic, peer));
        const results = await Promise.allSettled(promises);
        this.subscriptionCallbacks.clear();
        const finalResult = this.handleResult(results, "unsubscribeAll");
        this.stopSubscriptionsMaintenance();
        return finalResult;
    }
    async processIncomingMessage(message, peerIdStr) {
        const alreadyReceived = this.reliabilityMonitor.notifyMessageReceived(peerIdStr, message);
        if (alreadyReceived) {
            log$g.info("Message already received, skipping");
            return;
        }
        const { contentTopic } = message;
        const subscriptionCallback = this.subscriptionCallbacks.get(contentTopic);
        if (!subscriptionCallback) {
            log$g.error("No subscription callback available for ", contentTopic);
            return;
        }
        log$g.info("Processing message with content topic ", contentTopic, " on pubsub topic ", this.pubsubTopic);
        await pushMessage(subscriptionCallback, this.pubsubTopic, message);
    }
    async subscribeWithPeerVerification(peer, contentTopics) {
        const result = await this.protocol.subscribe(this.pubsubTopic, peer, contentTopics);
        await this.sendLightPushCheckMessage(peer);
        return result;
    }
    handleResult(results, type) {
        const result = { failures: [], successes: [] };
        for (const promiseResult of results) {
            if (promiseResult.status === "rejected") {
                log$g.error(`Failed to resolve ${type} promise successfully: `, promiseResult.reason);
                result.failures.push({ error: ProtocolError.GENERIC_FAIL });
            }
            else {
                const coreResult = promiseResult.value;
                if (coreResult.failure) {
                    result.failures.push(coreResult.failure);
                }
                else {
                    result.successes.push(coreResult.success);
                }
            }
        }
        return result;
    }
    async pingSpecificPeer(peerId) {
        const peer = this.getPeers().find((p) => p.id.equals(peerId));
        if (!peer) {
            return {
                success: null,
                failure: {
                    peerId,
                    error: ProtocolError.NO_PEER_AVAILABLE
                }
            };
        }
        let result;
        try {
            result = await this.protocol.ping(peer);
        }
        catch (error) {
            result = {
                success: null,
                failure: {
                    peerId,
                    error: ProtocolError.GENERIC_FAIL
                }
            };
        }
        log$g.info(`Received result from filter ping peerId:${peerId.toString()}\tsuccess:${result.success?.toString()}\tfailure:${result.failure?.error}`);
        await this.reliabilityMonitor.handlePingResult(peerId, result);
        return result;
    }
    startSubscriptionsMaintenance(timeout) {
        log$g.info("Starting subscriptions maintenance");
        this.startKeepAlivePings(timeout);
        this.startConnectionListener();
    }
    stopSubscriptionsMaintenance() {
        log$g.info("Stopping subscriptions maintenance");
        this.stopKeepAlivePings();
        this.stopConnectionListener();
    }
    startConnectionListener() {
        this.connectionManager.addEventListener(EConnectionStateEvents.CONNECTION_STATUS, this.connectionListener.bind(this));
    }
    stopConnectionListener() {
        this.connectionManager.removeEventListener(EConnectionStateEvents.CONNECTION_STATUS, this.connectionListener.bind(this));
    }
    async connectionListener({ detail: isConnected }) {
        if (!isConnected) {
            this.stopKeepAlivePings();
            return;
        }
        try {
            // we do nothing here, as the renewal process is managed internally by `this.ping()`
            await this.ping();
        }
        catch (err) {
            log$g.error(`networkStateListener failed to recover: ${err}`);
        }
        this.startKeepAlivePings(this.keepAliveTimeout);
    }
    startKeepAlivePings(timeout) {
        if (this.keepAliveInterval) {
            log$g.info("Recurring pings already set up.");
            return;
        }
        this.keepAliveInterval = setInterval(() => {
            void this.ping();
        }, timeout);
    }
    stopKeepAlivePings() {
        if (!this.keepAliveInterval) {
            log$g.info("Already stopped recurring pings.");
            return;
        }
        log$g.info("Stopping recurring pings.");
        clearInterval(this.keepAliveInterval);
        this.keepAliveInterval = null;
    }
    async sendLightPushCheckMessage(peer) {
        if (this.lightPush &&
            this.libp2p &&
            this.reliabilityMonitor.shouldVerifyPeer(peer.id)) {
            const encoder = createEncoder({
                contentTopic: this.buildLightPushContentTopic(),
                pubsubTopic: this.pubsubTopic,
                ephemeral: true
            });
            const message = { payload: new Uint8Array(1) };
            const protoMessage = await encoder.toProtoObj(message);
            // make a delay to be sure message is send when subscription is in place
            setTimeout((async () => {
                const result = await this.lightPush.protocol.send(encoder, message, peer);
                this.reliabilityMonitor.notifyMessageSent(peer.id, protoMessage);
                if (result.failure) {
                    log$g.error(`failed to send lightPush ping message to peer:${peer.id.toString()}\t${result.failure.error}`);
                    return;
                }
            }), DEFAULT_LIGHT_PUSH_FILTER_CHECK_INTERVAL);
        }
    }
    buildLightPushContentTopic() {
        return `/js-waku-subscription-ping/1/${this.libp2p.peerId.toString()}/utf8`;
    }
}
async function pushMessage(subscriptionCallback, pubsubTopic, message) {
    const { decoders, callback } = subscriptionCallback;
    const { contentTopic } = message;
    if (!contentTopic) {
        log$g.warn("Message has no content topic, skipping");
        return;
    }
    try {
        const decodePromises = decoders.map((dec) => dec
            .fromProtoObj(pubsubTopic, message)
            .then((decoded) => decoded || Promise.reject("Decoding failed")));
        const decodedMessage = await Promise.any(decodePromises);
        await callback(decodedMessage);
    }
    catch (e) {
        log$g.error("Error decoding message", e);
    }
}

const log$f = new Logger$1("sdk:filter");
class Filter extends BaseProtocolSDK {
    libp2p;
    lightPush;
    protocol;
    activeSubscriptions = new Map();
    constructor(connectionManager, libp2p, lightPush, options) {
        super(new FilterCore(async (pubsubTopic, wakuMessage, peerIdStr) => {
            const subscription = this.getActiveSubscription(pubsubTopic);
            if (!subscription) {
                log$f.error(`No subscription locally registered for topic ${pubsubTopic}`);
                return;
            }
            await subscription.processIncomingMessage(wakuMessage, peerIdStr);
        }, connectionManager.configuredPubsubTopics, libp2p), connectionManager, { numPeersToUse: options?.numPeersToUse });
        this.libp2p = libp2p;
        this.lightPush = lightPush;
        this.protocol = this.core;
        this.activeSubscriptions = new Map();
    }
    /**
     * Opens a subscription with the Filter protocol using the provided decoders and callback.
     * This method combines the functionality of creating a subscription and subscribing to it.
     *
     * @param {IDecoder<T> | IDecoder<T>[]} decoders - A single decoder or an array of decoders to use for decoding messages.
     * @param {Callback<T>} callback - The callback function to be invoked with decoded messages.
     * @param {ProtocolUseOptions} [protocolUseOptions] - Optional settings for using the protocol.
     * @param {SubscribeOptions} [subscribeOptions=DEFAULT_SUBSCRIBE_OPTIONS] - Options for the subscription.
     *
     * @returns {Promise<SubscribeResult>} A promise that resolves to an object containing:
     *   - subscription: The created subscription object if successful, or null if failed.
     *   - error: A ProtocolError if the subscription creation failed, or null if successful.
     *   - results: An object containing arrays of failures and successes from the subscription process.
     *     Only present if the subscription was created successfully.
     *
     * @throws {Error} If there's an unexpected error during the subscription process.
     *
     * @remarks
     * This method attempts to create a subscription using the pubsub topic derived from the provided decoders,
     * then tries to subscribe using the created subscription. The return value should be interpreted as follows:
     * - If `subscription` is null and `error` is non-null, a critical error occurred and the subscription failed completely.
     * - If `subscription` is non-null and `error` is null, the subscription was created successfully.
     *   In this case, check the `results` field for detailed information about successes and failures during the subscription process.
     * - Even if the subscription was created successfully, there might be some failures in the results.
     *
     * @example
     * ```typescript
     * const {subscription, error, results} = await waku.filter.subscribe(decoders, callback);
     * if (!subscription || error) {
     *   console.error("Failed to create subscription:", error);
     * }
     * console.log("Subscription created successfully");
     * if (results.failures.length > 0) {
     *   console.warn("Some errors occurred during subscription:", results.failures);
     * }
     * console.log("Successful subscriptions:", results.successes);
     *
     * ```
     */
    async subscribe(decoders, callback, protocolUseOptions, subscribeOptions = DEFAULT_SUBSCRIBE_OPTIONS) {
        const uniquePubsubTopics = this.getUniquePubsubTopics(decoders);
        if (uniquePubsubTopics.length !== 1) {
            return {
                subscription: null,
                error: ProtocolError.INVALID_DECODER_TOPICS,
                results: null
            };
        }
        const pubsubTopic = uniquePubsubTopics[0];
        const { subscription, error } = await this.createSubscription(pubsubTopic, protocolUseOptions);
        if (error) {
            return {
                subscription: null,
                error: error,
                results: null
            };
        }
        const { failures, successes } = await subscription.subscribe(decoders, callback, subscribeOptions);
        return {
            subscription,
            error: null,
            results: {
                failures: failures,
                successes: successes
            }
        };
    }
    /**
     * Creates a new subscription to the given pubsub topic.
     * The subscription is made to multiple peers for decentralization.
     * @param pubsubTopicShardInfo The pubsub topic to subscribe to.
     * @returns The subscription object.
     */
    async createSubscription(pubsubTopicShardInfo, options) {
        options = {
            autoRetry: true,
            ...options
        };
        const pubsubTopic = typeof pubsubTopicShardInfo == "string"
            ? pubsubTopicShardInfo
            : shardInfoToPubsubTopics(pubsubTopicShardInfo)?.[0];
        ensurePubsubTopicIsConfigured(pubsubTopic, this.protocol.pubsubTopics);
        const hasPeers = await this.hasPeers(options);
        if (!hasPeers) {
            return {
                error: ProtocolError.NO_PEER_AVAILABLE,
                subscription: null
            };
        }
        log$f.info(`Creating filter subscription with ${this.connectedPeers.length} peers: `, this.connectedPeers.map((peer) => peer.id.toString()));
        const subscription = this.getActiveSubscription(pubsubTopic) ??
            this.setActiveSubscription(pubsubTopic, new SubscriptionManager(pubsubTopic, this.protocol, this.connectionManager, () => this.connectedPeers, this.renewPeer.bind(this), this.libp2p, this.lightPush));
        return {
            error: null,
            subscription
        };
    }
    /**
     * This method is used to satisfy the `IReceiver` interface.
     *
     * @hidden
     *
     * @param decoders The decoders to use for the subscription.
     * @param callback The callback function to use for the subscription.
     * @param opts Optional protocol options for the subscription.
     *
     * @returns A Promise that resolves to a function that unsubscribes from the subscription.
     *
     * @remarks
     * This method should not be used directly.
     * Instead, use `createSubscription` to create a new subscription.
     */
    async subscribeWithUnsubscribe(decoders, callback, options = DEFAULT_SUBSCRIBE_OPTIONS) {
        const uniquePubsubTopics = this.getUniquePubsubTopics(decoders);
        if (uniquePubsubTopics.length === 0) {
            throw Error("Failed to subscribe: no pubsubTopic found on decoders provided.");
        }
        if (uniquePubsubTopics.length > 1) {
            throw Error("Failed to subscribe: all decoders should have the same pubsub topic. Use createSubscription to be more agile.");
        }
        const { subscription, error } = await this.createSubscription(uniquePubsubTopics[0]);
        if (error) {
            throw Error(`Failed to create subscription: ${error}`);
        }
        await subscription.subscribe(decoders, callback, options);
        const contentTopics = Array.from(groupByContentTopic(Array.isArray(decoders) ? decoders : [decoders]).keys());
        return async () => {
            await subscription.unsubscribe(contentTopics);
        };
    }
    toSubscriptionIterator(decoders) {
        return toAsyncIterator(this, decoders);
    }
    //TODO: move to SubscriptionManager
    getActiveSubscription(pubsubTopic) {
        return this.activeSubscriptions.get(pubsubTopic);
    }
    setActiveSubscription(pubsubTopic, subscription) {
        this.activeSubscriptions.set(pubsubTopic, subscription);
        return subscription;
    }
    getUniquePubsubTopics(decoders) {
        if (!Array.isArray(decoders)) {
            return [decoders.pubsubTopic];
        }
        if (decoders.length === 0) {
            return [];
        }
        const pubsubTopics = new Set(decoders.map((d) => d.pubsubTopic));
        return [...pubsubTopics];
    }
}
function wakuFilter(connectionManager, lightPush, init) {
    return (libp2p) => new Filter(connectionManager, libp2p, lightPush, init);
}

const log$e = new Logger$1("sdk:light-push");
const DEFAULT_MAX_ATTEMPTS = 3;
const DEFAULT_SEND_OPTIONS = {
    autoRetry: false,
    maxAttempts: DEFAULT_MAX_ATTEMPTS
};
class LightPush {
    libp2p;
    numPeersToUse = DEFAULT_NUM_PEERS_TO_USE;
    protocol;
    constructor(connectionManager, libp2p, options) {
        this.libp2p = libp2p;
        this.numPeersToUse = options?.numPeersToUse ?? DEFAULT_NUM_PEERS_TO_USE;
        this.protocol = new LightPushCore(connectionManager.configuredPubsubTopics, libp2p);
    }
    async send(encoder, message, options = DEFAULT_SEND_OPTIONS) {
        const successes = [];
        const failures = [];
        const { pubsubTopic } = encoder;
        try {
            ensurePubsubTopicIsConfigured(pubsubTopic, this.protocol.pubsubTopics);
        }
        catch (error) {
            log$e.error("Failed to send waku light push: pubsub topic not configured");
            return {
                successes,
                failures: [
                    {
                        error: ProtocolError.TOPIC_NOT_CONFIGURED
                    }
                ]
            };
        }
        const peers = await this.getConnectedPeers();
        if (peers.length === 0) {
            return {
                successes,
                failures: [
                    {
                        error: ProtocolError.NO_PEER_AVAILABLE
                    }
                ]
            };
        }
        const results = await Promise.allSettled(peers.map((peer) => this.protocol.send(encoder, message, peer)));
        for (const result of results) {
            if (result.status !== "fulfilled") {
                log$e.error("Failed unexpectedly while sending:", result.reason);
                failures.push({ error: ProtocolError.GENERIC_FAIL });
                continue;
            }
            const { failure, success } = result.value;
            if (success) {
                successes.push(success);
                continue;
            }
            if (failure) {
                failures.push(failure);
                if (options?.autoRetry) {
                    void this.attemptRetries((peer) => this.protocol.send(encoder, message, peer), options.maxAttempts);
                }
            }
        }
        getHealthManager().updateProtocolHealth(this.protocol.multicodec, successes.length);
        return {
            successes,
            failures
        };
    }
    async attemptRetries(fn, maxAttempts) {
        maxAttempts = maxAttempts || DEFAULT_MAX_ATTEMPTS;
        const connectedPeers = await this.getConnectedPeers();
        if (connectedPeers.length === 0) {
            log$e.warn("Cannot retry with no connected peers.");
            return;
        }
        for (let i = 0; i < maxAttempts; i++) {
            const peer = connectedPeers[i % connectedPeers.length]; // always present as we checked for the length already
            const response = await fn(peer);
            if (response.success) {
                return;
            }
            log$e.info(`Attempted retry for peer:${peer.id} failed with:${response?.failure?.error}`);
        }
    }
    async getConnectedPeers() {
        const peerIDs = this.libp2p.getPeers();
        if (peerIDs.length === 0) {
            return [];
        }
        const peers = await Promise.all(peerIDs.map(async (id) => {
            try {
                return await this.libp2p.peerStore.get(id);
            }
            catch (e) {
                return null;
            }
        }));
        return peers
            .filter((p) => !!p)
            .filter((p) => p.protocols.includes(LightPushCodec))
            .slice(0, this.numPeersToUse);
    }
}
function wakuLightPush(connectionManager, init = {}) {
    return (libp2p) => new LightPush(connectionManager, libp2p, init);
}

const DEFAULT_NUM_PEERS = 1;
const log$d = new Logger$1("waku:store:sdk");
/**
 * StoreSDK is an implementation of the IStoreSDK interface.
 * It provides methods to interact with the Waku Store protocol.
 */
class Store extends BaseProtocolSDK {
    protocol;
    constructor(connectionManager, libp2p) {
        super(new StoreCore(connectionManager.configuredPubsubTopics, libp2p), connectionManager, {
            numPeersToUse: DEFAULT_NUM_PEERS
        });
        this.protocol = this.core;
    }
    /**
     * Queries the Waku Store for historical messages using the provided decoders and options.
     * Returns an asynchronous generator that yields promises of decoded messages.
     *
     * @param decoders - An array of message decoders.
     * @param options - Optional query parameters.
     * @returns An asynchronous generator of promises of decoded messages.
     * @throws If no peers are available to query or if an error occurs during the query.
     */
    async *queryGenerator(decoders, options) {
        const { pubsubTopic, contentTopics, decodersAsMap } = this.validateDecodersAndPubsubTopic(decoders);
        const queryOpts = {
            pubsubTopic,
            contentTopics,
            includeData: true,
            paginationForward: true,
            ...options
        };
        const peer = (await this.protocol.getPeers({
            numPeers: this.numPeersToUse,
            maxBootstrapPeers: 1
        }))[0];
        if (!peer) {
            log$d.error("No peers available to query");
            throw new Error("No peers available to query");
        }
        log$d.info(`Querying store with options: ${JSON.stringify(options)}`);
        const responseGenerator = this.protocol.queryPerPage(queryOpts, decodersAsMap, peer);
        for await (const messages of responseGenerator) {
            yield messages;
        }
    }
    /**
     * Queries the Waku Store for historical messages and processes them with the provided callback in order.
     *
     * @param decoders - An array of message decoders.
     * @param callback - A callback function to process each decoded message.
     * @param options - Optional query parameters.
     * @returns A promise that resolves when the query and message processing are completed.
     */
    async queryWithOrderedCallback(decoders, callback, options) {
        log$d.info("Querying store with ordered callback");
        for await (const promises of this.queryGenerator(decoders, options)) {
            if (await this.processMessages(promises, callback))
                break;
        }
    }
    /**
     * Queries the Waku Store for historical messages and processes them with the provided callback using promises.
     *
     * @param decoders - An array of message decoders.
     * @param callback - A callback function to process each promise of a decoded message.
     * @param options - Optional query parameters.
     * @returns A promise that resolves when the query and message processing are completed.
     */
    async queryWithPromiseCallback(decoders, callback, options) {
        log$d.info("Querying store with promise callback");
        let abort = false;
        for await (const page of this.queryGenerator(decoders, options)) {
            const _promises = page.map(async (msgPromise) => {
                if (abort)
                    return;
                abort = Boolean(await callback(msgPromise));
            });
            await Promise.all(_promises);
            if (abort)
                break;
        }
    }
    /**
     * Processes messages based on the provided callback and options.
     *
     * @param messages - An array of promises of decoded messages.
     * @param callback - A callback function to process each decoded message.
     * @returns A promise that resolves to a boolean indicating whether the processing should abort.
     * @private
     */
    async processMessages(messages, callback) {
        let abort = false;
        const messagesOrUndef = await Promise.all(messages);
        const processedMessages = messagesOrUndef.filter(isDefined);
        await Promise.all(processedMessages.map(async (msg) => {
            if (msg && !abort) {
                abort = Boolean(await callback(msg));
            }
        }));
        return abort;
    }
    /**
     * Creates a cursor based on the provided decoded message.
     *
     * @param message - The decoded message.
     * @returns A StoreCursor representing the message.
     */
    createCursor(message) {
        return messageHash(message.pubsubTopic, message);
    }
    /**
     * Validates the provided decoders and pubsub topic.
     *
     * @param decoders - An array of message decoders.
     * @returns An object containing the pubsub topic, content topics, and a map of decoders.
     * @throws If no decoders are provided, if multiple pubsub topics are provided, or if no decoders are found for the pubsub topic.
     * @private
     */
    validateDecodersAndPubsubTopic(decoders) {
        if (decoders.length === 0) {
            log$d.error("No decoders provided");
            throw new Error("No decoders provided");
        }
        const uniquePubsubTopicsInQuery = Array.from(new Set(decoders.map((decoder) => decoder.pubsubTopic)));
        if (uniquePubsubTopicsInQuery.length > 1) {
            log$d.error("API does not support querying multiple pubsub topics at once");
            throw new Error("API does not support querying multiple pubsub topics at once");
        }
        const pubsubTopicForQuery = uniquePubsubTopicsInQuery[0];
        ensurePubsubTopicIsConfigured(pubsubTopicForQuery, this.protocol.pubsubTopics);
        const decodersAsMap = new Map();
        decoders.forEach((dec) => {
            if (decodersAsMap.has(dec.contentTopic)) {
                log$d.error("API does not support different decoder per content topic");
                throw new Error("API does not support different decoder per content topic");
            }
            decodersAsMap.set(dec.contentTopic, dec);
        });
        const contentTopics = decoders
            .filter((decoder) => decoder.pubsubTopic === pubsubTopicForQuery)
            .map((dec) => dec.contentTopic);
        if (contentTopics.length === 0) {
            log$d.error(`No decoders found for topic ${pubsubTopicForQuery}`);
            throw new Error("No decoders found for topic " + pubsubTopicForQuery);
        }
        return {
            pubsubTopic: pubsubTopicForQuery,
            contentTopics,
            decodersAsMap
        };
    }
}
/**
 * Factory function to create an instance of the StoreSDK.
 *
 * @param init - Partial options for protocol creation.
 * @returns A function that takes a Libp2p instance and returns a StoreSDK instance.
 */
function wakuStore(connectionManager) {
    return (libp2p) => {
        return new Store(connectionManager, libp2p);
    };
}

const log$c = new Logger$1("wait-for-remote-peer");
/**
 * @deprecated Since @waku/sdk 0.29.0. Will be removed from 0.31.0
 *
 * Wait for a remote peer to be ready given the passed protocols.
 * Must be used after attempting to connect to nodes, using
 * {@link @waku/sdk!WakuNode.dial} or a bootstrap method with
 * {@link @waku/sdk!createLightNode}.
 *
 * If the passed protocols is a GossipSub protocol, then it resolves only once
 * a peer is in a mesh, to help ensure that other peers will send and receive
 * message to us.
 *
 * @param waku The Waku Node
 * @param protocols The protocols that need to be enabled by remote peers.
 * @param timeoutMs A timeout value in milliseconds..
 *
 * @returns A promise that **resolves** if all desired protocols are fulfilled by
 * remote nodes, **rejects** if the timeoutMs is reached.
 * @throws If passing a protocol that is not mounted
 * @default Wait for remote peers with protocols enabled locally and no time out is applied.
 */
async function waitForRemotePeer(waku, protocols, timeoutMs) {
    // if no protocols or empty array passed - try to derive from mounted
    protocols = protocols?.length ? protocols : getEnabledProtocols(waku);
    const connections = waku.libp2p.getConnections();
    if (!waku.isStarted()) {
        throw Error("Waku node is not started");
    }
    if (connections.length > 0 && !protocols.includes(Protocols.Relay)) {
        const success = await waitForMetadata(waku, protocols);
        if (success) {
            return;
        }
    }
    const promises = [];
    if (protocols.includes(Protocols.Relay)) {
        if (!waku.relay) {
            throw Error("Cannot wait for Relay peer: protocol not mounted");
        }
        promises.push(waku.relay.waitForPeers());
    }
    if (protocols.includes(Protocols.Store)) {
        if (!waku.store) {
            throw Error("Cannot wait for Store peer: protocol not mounted");
        }
        promises.push(waitForConnectedPeer(StoreCodec, waku.libp2p));
    }
    if (protocols.includes(Protocols.LightPush)) {
        if (!waku.lightPush) {
            throw Error("Cannot wait for LightPush peer: protocol not mounted");
        }
        promises.push(waitForConnectedPeer(LightPushCodec, waku.libp2p));
    }
    if (protocols.includes(Protocols.Filter)) {
        if (!waku.filter) {
            throw new Error("Cannot wait for Filter peer: protocol not mounted");
        }
        promises.push(waitForConnectedPeer(FilterCodecs.SUBSCRIBE, waku.libp2p));
    }
    if (timeoutMs) {
        await rejectOnTimeout(Promise.all(promises), timeoutMs, "Timed out waiting for a remote peer.");
    }
    else {
        await Promise.all(promises);
    }
}
/**
 * Wait for a peer with the given protocol to be connected.
 * If sharding is enabled on the node, it will also wait for the peer to be confirmed by the metadata service.
 */
async function waitForConnectedPeer(codec, libp2p) {
    log$c.info(`Waiting for ${codec} peer.`);
    await new Promise((resolve) => {
        const cb = (async (evt) => {
            if (evt.detail?.protocols?.includes(codec)) {
                const metadataService = libp2p.services.metadata;
                if (!metadataService) {
                    libp2p.removeEventListener("peer:identify", cb);
                    resolve();
                    return;
                }
                try {
                    await metadataService.confirmOrAttemptHandshake(evt.detail.peerId);
                    libp2p.removeEventListener("peer:identify", cb);
                    resolve();
                }
                catch (e) {
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    if (e.code === "ERR_CONNECTION_BEING_CLOSED") {
                        log$c.error("Connection closed. Some peers can be on different shard.");
                    }
                    log$c.error(`Error waiting for metadata: ${e}`);
                }
            }
        });
        libp2p.addEventListener("peer:identify", cb);
    });
}
/**
 * Waits for the metadata from the remote peer.
 */
async function waitForMetadata(waku, protocols) {
    const connectedPeers = waku.libp2p.getPeers();
    const metadataService = waku.libp2p.services.metadata;
    const enabledCodes = mapProtocolsToCodecs(protocols);
    if (!connectedPeers.length || !metadataService) {
        log$c.info(`Skipping waitForMetadata due to missing connections:${connectedPeers.length} or metadataService:${!!metadataService}`);
        return false;
    }
    for (const peerId of connectedPeers) {
        try {
            const peer = await waku.libp2p.peerStore.get(peerId);
            const hasSomeCodes = peer.protocols.some((c) => enabledCodes.has(c));
            if (hasSomeCodes) {
                const response = await metadataService.confirmOrAttemptHandshake(peerId);
                if (!response.error) {
                    peer.protocols.forEach((c) => {
                        if (enabledCodes.has(c)) {
                            enabledCodes.set(c, true);
                        }
                    });
                    const confirmedAllCodecs = Array.from(enabledCodes.values()).every((v) => v);
                    if (confirmedAllCodecs) {
                        return true;
                    }
                }
            }
        }
        catch (e) {
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            if (e.code === "ERR_CONNECTION_BEING_CLOSED") {
                log$c.error("Connection closed. Some peers can be on different shard.");
            }
            log$c.error(`Error while iterating through peers: ${e}`);
            continue;
        }
    }
    return false;
}
const awaitTimeout = (ms, rejectReason) => new Promise((_resolve, reject) => setTimeout(() => reject(Error(rejectReason)), ms));
async function rejectOnTimeout(promise, timeoutMs, rejectReason) {
    await Promise.race([promise, awaitTimeout(timeoutMs, rejectReason)]);
}
function getEnabledProtocols(waku) {
    const protocols = [];
    if (waku.relay) {
        protocols.push(Protocols.Relay);
    }
    if (waku.filter) {
        protocols.push(Protocols.Filter);
    }
    if (waku.store) {
        protocols.push(Protocols.Store);
    }
    if (waku.lightPush) {
        protocols.push(Protocols.LightPush);
    }
    return protocols;
}
function mapProtocolsToCodecs(protocols) {
    const codecs = new Map();
    const protocolToCodec = {
        [Protocols.Filter]: FilterCodecs.SUBSCRIBE,
        [Protocols.LightPush]: LightPushCodec,
        [Protocols.Store]: StoreCodec
    };
    for (const protocol of protocols) {
        if (protocolToCodec[protocol]) {
            codecs.set(protocolToCodec[protocol], false);
        }
    }
    return codecs;
}

const DefaultPingKeepAliveValueSecs = 5 * 60;
const DefaultRelayKeepAliveValueSecs = 5 * 60;
const DefaultUserAgent = "js-waku";
const DefaultPingMaxInboundStreams = 10;
const log$b = new Logger$1("waku");
class WakuNode {
    pubsubTopics;
    libp2p;
    relay;
    store;
    filter;
    lightPush;
    connectionManager;
    health;
    constructor(pubsubTopics, options, libp2p, protocolsEnabled, relay) {
        this.pubsubTopics = pubsubTopics;
        this.relay = relay;
        this.libp2p = libp2p;
        protocolsEnabled = {
            filter: false,
            lightpush: false,
            store: false,
            ...protocolsEnabled
        };
        const pingKeepAlive = options.pingKeepAlive || DefaultPingKeepAliveValueSecs;
        const relayKeepAlive = this.relay
            ? options.relayKeepAlive || DefaultRelayKeepAliveValueSecs
            : 0;
        const peerId = this.libp2p.peerId.toString();
        this.connectionManager = ConnectionManager.create(peerId, libp2p, { pingKeepAlive, relayKeepAlive }, this.pubsubTopics, this.relay);
        this.health = getHealthManager();
        if (protocolsEnabled.store) {
            const store = wakuStore(this.connectionManager);
            this.store = store(libp2p);
        }
        if (protocolsEnabled.lightpush) {
            const lightPush = wakuLightPush(this.connectionManager, options);
            this.lightPush = lightPush(libp2p);
        }
        if (protocolsEnabled.filter) {
            const filter = wakuFilter(this.connectionManager, this.lightPush, options);
            this.filter = filter(libp2p);
        }
        log$b.info("Waku node created", peerId, `relay: ${!!this.relay}, store: ${!!this.store}, light push: ${!!this
            .lightPush}, filter: ${!!this.filter}`);
    }
    get peerId() {
        return this.libp2p.peerId;
    }
    get protocols() {
        return this.libp2p.getProtocols();
    }
    async dial(peer, protocols) {
        const _protocols = protocols ?? [];
        const peerId = this.mapToPeerIdOrMultiaddr(peer);
        if (typeof protocols === "undefined") {
            this.relay && _protocols.push(Protocols.Relay);
            this.store && _protocols.push(Protocols.Store);
            this.filter && _protocols.push(Protocols.Filter);
            this.lightPush && _protocols.push(Protocols.LightPush);
        }
        const codecs = [];
        if (_protocols.includes(Protocols.Relay)) {
            if (this.relay) {
                this.relay.gossipSub.multicodecs.forEach((codec) => codecs.push(codec));
            }
            else {
                log$b.error("Relay codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Store)) {
            if (this.store) {
                codecs.push(this.store.protocol.multicodec);
            }
            else {
                log$b.error("Store codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.LightPush)) {
            if (this.lightPush) {
                codecs.push(this.lightPush.protocol.multicodec);
            }
            else {
                log$b.error("Light Push codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Filter)) {
            if (this.filter) {
                codecs.push(this.filter.protocol.multicodec);
            }
            else {
                log$b.error("Filter codec not included in dial codec: protocol not mounted locally");
            }
        }
        log$b.info(`Dialing to ${peerId.toString()} with protocols ${_protocols}`);
        return this.libp2p.dialProtocol(peerId, codecs);
    }
    async start() {
        await this.libp2p.start();
    }
    async stop() {
        ReliabilityMonitorManager.stopAll();
        this.connectionManager.stop();
        await this.libp2p.stop();
    }
    async waitForPeers(protocols, timeoutMs) {
        return waitForRemotePeer(this, protocols, timeoutMs);
    }
    isStarted() {
        return this.libp2p.status == "started";
    }
    isConnected() {
        return this.connectionManager.isConnected();
    }
    mapToPeerIdOrMultiaddr(peerId) {
        return isPeerId(peerId) ? peerId : multiaddr(peerId);
    }
}

function isPromise$3(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}

const U32_MASK64 = /* @__PURE__ */ BigInt(2 ** 32 - 1);
const _32n = /* @__PURE__ */ BigInt(32);
// We are not using BigUint64Array, because they are extremely slow as per 2022
function fromBig(n, le = false) {
    if (le)
        return { h: Number(n & U32_MASK64), l: Number((n >> _32n) & U32_MASK64) };
    return { h: Number((n >> _32n) & U32_MASK64) | 0, l: Number(n & U32_MASK64) | 0 };
}
function split(lst, le = false) {
    let Ah = new Uint32Array(lst.length);
    let Al = new Uint32Array(lst.length);
    for (let i = 0; i < lst.length; i++) {
        const { h, l } = fromBig(lst[i], le);
        [Ah[i], Al[i]] = [h, l];
    }
    return [Ah, Al];
}
const toBig = (h, l) => (BigInt(h >>> 0) << _32n) | BigInt(l >>> 0);
// for Shift in [0, 32)
const shrSH = (h, _l, s) => h >>> s;
const shrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);
// Right rotate for Shift in [1, 32)
const rotrSH = (h, l, s) => (h >>> s) | (l << (32 - s));
const rotrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);
// Right rotate for Shift in (32, 64), NOTE: 32 is special case.
const rotrBH = (h, l, s) => (h << (64 - s)) | (l >>> (s - 32));
const rotrBL = (h, l, s) => (h >>> (s - 32)) | (l << (64 - s));
// Right rotate for shift===32 (just swaps l&h)
const rotr32H = (_h, l) => l;
const rotr32L = (h, _l) => h;
// Left rotate for Shift in [1, 32)
const rotlSH = (h, l, s) => (h << s) | (l >>> (32 - s));
const rotlSL = (h, l, s) => (l << s) | (h >>> (32 - s));
// Left rotate for Shift in (32, 64), NOTE: 32 is special case.
const rotlBH = (h, l, s) => (l << (s - 32)) | (h >>> (64 - s));
const rotlBL = (h, l, s) => (h << (s - 32)) | (l >>> (64 - s));
// JS uses 32-bit signed integers for bitwise operations which means we cannot
// simple take carry out of low bit sum by shift, we need to use division.
function add(Ah, Al, Bh, Bl) {
    const l = (Al >>> 0) + (Bl >>> 0);
    return { h: (Ah + Bh + ((l / 2 ** 32) | 0)) | 0, l: l | 0 };
}
// Addition with more than 2 elements
const add3L = (Al, Bl, Cl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0);
const add3H = (low, Ah, Bh, Ch) => (Ah + Bh + Ch + ((low / 2 ** 32) | 0)) | 0;
const add4L = (Al, Bl, Cl, Dl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0);
const add4H = (low, Ah, Bh, Ch, Dh) => (Ah + Bh + Ch + Dh + ((low / 2 ** 32) | 0)) | 0;
const add5L = (Al, Bl, Cl, Dl, El) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0) + (El >>> 0);
const add5H = (low, Ah, Bh, Ch, Dh, Eh) => (Ah + Bh + Ch + Dh + Eh + ((low / 2 ** 32) | 0)) | 0;
// prettier-ignore
const u64 = {
    fromBig, split, toBig,
    shrSH, shrSL,
    rotrSH, rotrSL, rotrBH, rotrBL,
    rotr32H, rotr32L,
    rotlSH, rotlSL, rotlBH, rotlBL,
    add, add3L, add3H, add4L, add4H, add5H, add5L,
};

// Round contants (first 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409):
// prettier-ignore
const [SHA512_Kh, SHA512_Kl] = /* @__PURE__ */ (() => u64.split([
    '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',
    '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',
    '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',
    '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',
    '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',
    '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',
    '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',
    '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',
    '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',
    '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',
    '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',
    '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',
    '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',
    '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',
    '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',
    '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',
    '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',
    '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',
    '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',
    '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'
].map(n => BigInt(n))))();
// Temporary buffer, not used to store anything between runs
const SHA512_W_H = /* @__PURE__ */ new Uint32Array(80);
const SHA512_W_L = /* @__PURE__ */ new Uint32Array(80);
class SHA512 extends HashMD {
    constructor() {
        super(128, 64, 16, false);
        // We cannot use array here since array allows indexing by variable which means optimizer/compiler cannot use registers.
        // Also looks cleaner and easier to verify with spec.
        // Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):
        // h -- high 32 bits, l -- low 32 bits
        this.Ah = 0x6a09e667 | 0;
        this.Al = 0xf3bcc908 | 0;
        this.Bh = 0xbb67ae85 | 0;
        this.Bl = 0x84caa73b | 0;
        this.Ch = 0x3c6ef372 | 0;
        this.Cl = 0xfe94f82b | 0;
        this.Dh = 0xa54ff53a | 0;
        this.Dl = 0x5f1d36f1 | 0;
        this.Eh = 0x510e527f | 0;
        this.El = 0xade682d1 | 0;
        this.Fh = 0x9b05688c | 0;
        this.Fl = 0x2b3e6c1f | 0;
        this.Gh = 0x1f83d9ab | 0;
        this.Gl = 0xfb41bd6b | 0;
        this.Hh = 0x5be0cd19 | 0;
        this.Hl = 0x137e2179 | 0;
    }
    // prettier-ignore
    get() {
        const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;
        return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];
    }
    // prettier-ignore
    set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl) {
        this.Ah = Ah | 0;
        this.Al = Al | 0;
        this.Bh = Bh | 0;
        this.Bl = Bl | 0;
        this.Ch = Ch | 0;
        this.Cl = Cl | 0;
        this.Dh = Dh | 0;
        this.Dl = Dl | 0;
        this.Eh = Eh | 0;
        this.El = El | 0;
        this.Fh = Fh | 0;
        this.Fl = Fl | 0;
        this.Gh = Gh | 0;
        this.Gl = Gl | 0;
        this.Hh = Hh | 0;
        this.Hl = Hl | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4) {
            SHA512_W_H[i] = view.getUint32(offset);
            SHA512_W_L[i] = view.getUint32((offset += 4));
        }
        for (let i = 16; i < 80; i++) {
            // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)
            const W15h = SHA512_W_H[i - 15] | 0;
            const W15l = SHA512_W_L[i - 15] | 0;
            const s0h = u64.rotrSH(W15h, W15l, 1) ^ u64.rotrSH(W15h, W15l, 8) ^ u64.shrSH(W15h, W15l, 7);
            const s0l = u64.rotrSL(W15h, W15l, 1) ^ u64.rotrSL(W15h, W15l, 8) ^ u64.shrSL(W15h, W15l, 7);
            // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)
            const W2h = SHA512_W_H[i - 2] | 0;
            const W2l = SHA512_W_L[i - 2] | 0;
            const s1h = u64.rotrSH(W2h, W2l, 19) ^ u64.rotrBH(W2h, W2l, 61) ^ u64.shrSH(W2h, W2l, 6);
            const s1l = u64.rotrSL(W2h, W2l, 19) ^ u64.rotrBL(W2h, W2l, 61) ^ u64.shrSL(W2h, W2l, 6);
            // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];
            const SUMl = u64.add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);
            const SUMh = u64.add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);
            SHA512_W_H[i] = SUMh | 0;
            SHA512_W_L[i] = SUMl | 0;
        }
        let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;
        // Compression function main loop, 80 rounds
        for (let i = 0; i < 80; i++) {
            // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)
            const sigma1h = u64.rotrSH(Eh, El, 14) ^ u64.rotrSH(Eh, El, 18) ^ u64.rotrBH(Eh, El, 41);
            const sigma1l = u64.rotrSL(Eh, El, 14) ^ u64.rotrSL(Eh, El, 18) ^ u64.rotrBL(Eh, El, 41);
            //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const CHIh = (Eh & Fh) ^ (~Eh & Gh);
            const CHIl = (El & Fl) ^ (~El & Gl);
            // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]
            // prettier-ignore
            const T1ll = u64.add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);
            const T1h = u64.add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);
            const T1l = T1ll | 0;
            // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)
            const sigma0h = u64.rotrSH(Ah, Al, 28) ^ u64.rotrBH(Ah, Al, 34) ^ u64.rotrBH(Ah, Al, 39);
            const sigma0l = u64.rotrSL(Ah, Al, 28) ^ u64.rotrBL(Ah, Al, 34) ^ u64.rotrBL(Ah, Al, 39);
            const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);
            const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);
            Hh = Gh | 0;
            Hl = Gl | 0;
            Gh = Fh | 0;
            Gl = Fl | 0;
            Fh = Eh | 0;
            Fl = El | 0;
            ({ h: Eh, l: El } = u64.add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));
            Dh = Ch | 0;
            Dl = Cl | 0;
            Ch = Bh | 0;
            Cl = Bl | 0;
            Bh = Ah | 0;
            Bl = Al | 0;
            const All = u64.add3L(T1l, sigma0l, MAJl);
            Ah = u64.add3H(All, T1h, sigma0h, MAJh);
            Al = All | 0;
        }
        // Add the compressed chunk to the current hash value
        ({ h: Ah, l: Al } = u64.add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));
        ({ h: Bh, l: Bl } = u64.add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));
        ({ h: Ch, l: Cl } = u64.add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));
        ({ h: Dh, l: Dl } = u64.add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));
        ({ h: Eh, l: El } = u64.add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));
        ({ h: Fh, l: Fl } = u64.add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));
        ({ h: Gh, l: Gl } = u64.add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));
        ({ h: Hh, l: Hl } = u64.add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));
        this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);
    }
    roundClean() {
        SHA512_W_H.fill(0);
        SHA512_W_L.fill(0);
    }
    destroy() {
        this.buffer.fill(0);
        this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
    }
}
const sha512 = /* @__PURE__ */ wrapConstructor(() => new SHA512());

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// 100 lines of code in the file are duplicated from noble-hashes (utils).
// This is OK: `abstract` directory does not use noble-hashes.
// User may opt-in into using different hashing library. This way, noble-hashes
// won't be included into their bundle.
const _0n$6 = /* @__PURE__ */ BigInt(0);
const _1n$8 = /* @__PURE__ */ BigInt(1);
const _2n$5 = /* @__PURE__ */ BigInt(2);
function isBytes$2(a) {
    return (a instanceof Uint8Array ||
        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));
}
function abytes(item) {
    if (!isBytes$2(item))
        throw new Error('Uint8Array expected');
}
function abool(title, value) {
    if (typeof value !== 'boolean')
        throw new Error(`${title} must be valid boolean, got "${value}".`);
}
// Array where index 0xf0 (240) is mapped to string 'f0'
const hexes$1 = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));
/**
 * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'
 */
function bytesToHex$1(bytes) {
    abytes(bytes);
    // pre-caching improves the speed 6x
    let hex = '';
    for (let i = 0; i < bytes.length; i++) {
        hex += hexes$1[bytes[i]];
    }
    return hex;
}
function numberToHexUnpadded$1(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? `0${hex}` : hex;
}
function hexToNumber$1(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    // Big Endian
    return BigInt(hex === '' ? '0' : `0x${hex}`);
}
// We use optimized technique to convert hex string to byte array
const asciis = { _0: 48, _9: 57, _A: 65, _F: 70, _a: 97, _f: 102 };
function asciiToBase16(char) {
    if (char >= asciis._0 && char <= asciis._9)
        return char - asciis._0;
    if (char >= asciis._A && char <= asciis._F)
        return char - (asciis._A - 10);
    if (char >= asciis._a && char <= asciis._f)
        return char - (asciis._a - 10);
    return;
}
/**
 * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])
 */
function hexToBytes$1(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    const hl = hex.length;
    const al = hl / 2;
    if (hl % 2)
        throw new Error('padded hex string expected, got unpadded hex of length ' + hl);
    const array = new Uint8Array(al);
    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {
        const n1 = asciiToBase16(hex.charCodeAt(hi));
        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));
        if (n1 === undefined || n2 === undefined) {
            const char = hex[hi] + hex[hi + 1];
            throw new Error('hex string expected, got non-hex character "' + char + '" at index ' + hi);
        }
        array[ai] = n1 * 16 + n2;
    }
    return array;
}
// BE: Big Endian, LE: Little Endian
function bytesToNumberBE(bytes) {
    return hexToNumber$1(bytesToHex$1(bytes));
}
function bytesToNumberLE(bytes) {
    abytes(bytes);
    return hexToNumber$1(bytesToHex$1(Uint8Array.from(bytes).reverse()));
}
function numberToBytesBE(n, len) {
    return hexToBytes$1(n.toString(16).padStart(len * 2, '0'));
}
function numberToBytesLE(n, len) {
    return numberToBytesBE(n, len).reverse();
}
// Unpadded, rarely used
function numberToVarBytesBE(n) {
    return hexToBytes$1(numberToHexUnpadded$1(n));
}
/**
 * Takes hex string or Uint8Array, converts to Uint8Array.
 * Validates output length.
 * Will throw error for other types.
 * @param title descriptive title for an error e.g. 'private key'
 * @param hex hex string or Uint8Array
 * @param expectedLength optional, will compare to result array's length
 * @returns
 */
function ensureBytes$1(title, hex, expectedLength) {
    let res;
    if (typeof hex === 'string') {
        try {
            res = hexToBytes$1(hex);
        }
        catch (e) {
            throw new Error(`${title} must be valid hex string, got "${hex}". Cause: ${e}`);
        }
    }
    else if (isBytes$2(hex)) {
        // Uint8Array.from() instead of hash.slice() because node.js Buffer
        // is instance of Uint8Array, and its slice() creates **mutable** copy
        res = Uint8Array.from(hex);
    }
    else {
        throw new Error(`${title} must be hex string or Uint8Array`);
    }
    const len = res.length;
    if (typeof expectedLength === 'number' && len !== expectedLength)
        throw new Error(`${title} expected ${expectedLength} bytes, got ${len}`);
    return res;
}
/**
 * Copies several Uint8Arrays into one.
 */
function concatBytes$1(...arrays) {
    let sum = 0;
    for (let i = 0; i < arrays.length; i++) {
        const a = arrays[i];
        abytes(a);
        sum += a.length;
    }
    const res = new Uint8Array(sum);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const a = arrays[i];
        res.set(a, pad);
        pad += a.length;
    }
    return res;
}
// Compares 2 u8a-s in kinda constant time
function equalBytes$1(a, b) {
    if (a.length !== b.length)
        return false;
    let diff = 0;
    for (let i = 0; i < a.length; i++)
        diff |= a[i] ^ b[i];
    return diff === 0;
}
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes$1(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
// Is positive bigint
const isPosBig = (n) => typeof n === 'bigint' && _0n$6 <= n;
function inRange(n, min, max) {
    return isPosBig(n) && isPosBig(min) && isPosBig(max) && min <= n && n < max;
}
/**
 * Asserts min <= n < max. NOTE: It's < max and not <= max.
 * @example
 * aInRange('x', x, 1n, 256n); // would assume x is in (1n..255n)
 */
function aInRange(title, n, min, max) {
    // Why min <= n < max and not a (min < n < max) OR b (min <= n <= max)?
    // consider P=256n, min=0n, max=P
    // - a for min=0 would require -1:          `inRange('x', x, -1n, P)`
    // - b would commonly require subtraction:  `inRange('x', x, 0n, P - 1n)`
    // - our way is the cleanest:               `inRange('x', x, 0n, P)
    if (!inRange(n, min, max))
        throw new Error(`expected valid ${title}: ${min} <= n < ${max}, got ${typeof n} ${n}`);
}
// Bit operations
/**
 * Calculates amount of bits in a bigint.
 * Same as `n.toString(2).length`
 */
function bitLen(n) {
    let len;
    for (len = 0; n > _0n$6; n >>= _1n$8, len += 1)
        ;
    return len;
}
/**
 * Gets single bit at position.
 * NOTE: first bit position is 0 (same as arrays)
 * Same as `!!+Array.from(n.toString(2)).reverse()[pos]`
 */
function bitGet(n, pos) {
    return (n >> BigInt(pos)) & _1n$8;
}
/**
 * Sets single bit at position.
 */
function bitSet(n, pos, value) {
    return n | ((value ? _1n$8 : _0n$6) << BigInt(pos));
}
/**
 * Calculate mask for N bits. Not using ** operator with bigints because of old engines.
 * Same as BigInt(`0b${Array(i).fill('1').join('')}`)
 */
const bitMask = (n) => (_2n$5 << BigInt(n - 1)) - _1n$8;
// DRBG
const u8n = (data) => new Uint8Array(data); // creates Uint8Array
const u8fr = (arr) => Uint8Array.from(arr); // another shortcut
/**
 * Minimal HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
 * @returns function that will call DRBG until 2nd arg returns something meaningful
 * @example
 *   const drbg = createHmacDRBG<Key>(32, 32, hmac);
 *   drbg(seed, bytesToKey); // bytesToKey must return Key or undefined
 */
function createHmacDrbg(hashLen, qByteLen, hmacFn) {
    if (typeof hashLen !== 'number' || hashLen < 2)
        throw new Error('hashLen must be a number');
    if (typeof qByteLen !== 'number' || qByteLen < 2)
        throw new Error('qByteLen must be a number');
    if (typeof hmacFn !== 'function')
        throw new Error('hmacFn must be a function');
    // Step B, Step C: set hashLen to 8*ceil(hlen/8)
    let v = u8n(hashLen); // Minimal non-full-spec HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
    let k = u8n(hashLen); // Steps B and C of RFC6979 3.2: set hashLen, in our case always same
    let i = 0; // Iterations counter, will throw when over 1000
    const reset = () => {
        v.fill(1);
        k.fill(0);
        i = 0;
    };
    const h = (...b) => hmacFn(k, v, ...b); // hmac(k)(v, ...values)
    const reseed = (seed = u8n()) => {
        // HMAC-DRBG reseed() function. Steps D-G
        k = h(u8fr([0x00]), seed); // k = hmac(k || v || 0x00 || seed)
        v = h(); // v = hmac(k || v)
        if (seed.length === 0)
            return;
        k = h(u8fr([0x01]), seed); // k = hmac(k || v || 0x01 || seed)
        v = h(); // v = hmac(k || v)
    };
    const gen = () => {
        // HMAC-DRBG generate() function
        if (i++ >= 1000)
            throw new Error('drbg: tried 1000 values');
        let len = 0;
        const out = [];
        while (len < qByteLen) {
            v = h();
            const sl = v.slice();
            out.push(sl);
            len += v.length;
        }
        return concatBytes$1(...out);
    };
    const genUntil = (seed, pred) => {
        reset();
        reseed(seed); // Steps D-G
        let res = undefined; // Step H: grind until k is in [1..n-1]
        while (!(res = pred(gen())))
            reseed();
        reset();
        return res;
    };
    return genUntil;
}
// Validating curves and fields
const validatorFns = {
    bigint: (val) => typeof val === 'bigint',
    function: (val) => typeof val === 'function',
    boolean: (val) => typeof val === 'boolean',
    string: (val) => typeof val === 'string',
    stringOrUint8Array: (val) => typeof val === 'string' || isBytes$2(val),
    isSafeInteger: (val) => Number.isSafeInteger(val),
    array: (val) => Array.isArray(val),
    field: (val, object) => object.Fp.isValid(val),
    hash: (val) => typeof val === 'function' && Number.isSafeInteger(val.outputLen),
};
// type Record<K extends string | number | symbol, T> = { [P in K]: T; }
function validateObject(object, validators, optValidators = {}) {
    const checkField = (fieldName, type, isOptional) => {
        const checkVal = validatorFns[type];
        if (typeof checkVal !== 'function')
            throw new Error(`Invalid validator "${type}", expected function`);
        const val = object[fieldName];
        if (isOptional && val === undefined)
            return;
        if (!checkVal(val, object)) {
            throw new Error(`Invalid param ${String(fieldName)}=${val} (${typeof val}), expected ${type}`);
        }
    };
    for (const [fieldName, type] of Object.entries(validators))
        checkField(fieldName, type, false);
    for (const [fieldName, type] of Object.entries(optValidators))
        checkField(fieldName, type, true);
    return object;
}
// validate type tests
// const o: { a: number; b: number; c: number } = { a: 1, b: 5, c: 6 };
// const z0 = validateObject(o, { a: 'isSafeInteger' }, { c: 'bigint' }); // Ok!
// // Should fail type-check
// const z1 = validateObject(o, { a: 'tmp' }, { c: 'zz' });
// const z2 = validateObject(o, { a: 'isSafeInteger' }, { c: 'zz' });
// const z3 = validateObject(o, { test: 'boolean', z: 'bug' });
// const z4 = validateObject(o, { a: 'boolean', z: 'bug' });
/**
 * throws not implemented error
 */
const notImplemented = () => {
    throw new Error('not implemented');
};
/**
 * Memoizes (caches) computation result.
 * Uses WeakMap: the value is going auto-cleaned by GC after last reference is removed.
 */
function memoized(fn) {
    const map = new WeakMap();
    return (arg, ...args) => {
        const val = map.get(arg);
        if (val !== undefined)
            return val;
        const computed = fn(arg, ...args);
        map.set(arg, computed);
        return computed;
    };
}

var ut = /*#__PURE__*/Object.freeze({
    __proto__: null,
    aInRange: aInRange,
    abool: abool,
    abytes: abytes,
    bitGet: bitGet,
    bitLen: bitLen,
    bitMask: bitMask,
    bitSet: bitSet,
    bytesToHex: bytesToHex$1,
    bytesToNumberBE: bytesToNumberBE,
    bytesToNumberLE: bytesToNumberLE,
    concatBytes: concatBytes$1,
    createHmacDrbg: createHmacDrbg,
    ensureBytes: ensureBytes$1,
    equalBytes: equalBytes$1,
    hexToBytes: hexToBytes$1,
    hexToNumber: hexToNumber$1,
    inRange: inRange,
    isBytes: isBytes$2,
    memoized: memoized,
    notImplemented: notImplemented,
    numberToBytesBE: numberToBytesBE,
    numberToBytesLE: numberToBytesLE,
    numberToHexUnpadded: numberToHexUnpadded$1,
    numberToVarBytesBE: numberToVarBytesBE,
    utf8ToBytes: utf8ToBytes$1,
    validateObject: validateObject
});

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Utilities for modular arithmetics and finite fields
// prettier-ignore
const _0n$5 = BigInt(0), _1n$7 = BigInt(1), _2n$4 = BigInt(2), _3n$3 = BigInt(3);
// prettier-ignore
const _4n = BigInt(4), _5n$1 = BigInt(5), _8n$3 = BigInt(8);
// prettier-ignore
BigInt(9); BigInt(16);
// Calculates a modulo b
function mod$1(a, b) {
    const result = a % b;
    return result >= _0n$5 ? result : b + result;
}
/**
 * Efficiently raise num to power and do modular division.
 * Unsafe in some contexts: uses ladder, so can expose bigint bits.
 * @example
 * pow(2n, 6n, 11n) // 64n % 11n == 9n
 */
// TODO: use field version && remove
function pow(num, power, modulo) {
    if (modulo <= _0n$5 || power < _0n$5)
        throw new Error('Expected power/modulo > 0');
    if (modulo === _1n$7)
        return _0n$5;
    let res = _1n$7;
    while (power > _0n$5) {
        if (power & _1n$7)
            res = (res * num) % modulo;
        num = (num * num) % modulo;
        power >>= _1n$7;
    }
    return res;
}
// Does x ^ (2 ^ power) mod p. pow2(30, 4) == 30 ^ (2 ^ 4)
function pow2$1(x, power, modulo) {
    let res = x;
    while (power-- > _0n$5) {
        res *= res;
        res %= modulo;
    }
    return res;
}
// Inverses number over modulo
function invert$1(number, modulo) {
    if (number === _0n$5 || modulo <= _0n$5) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    // Euclidean GCD https://brilliant.org/wiki/extended-euclidean-algorithm/
    // Fermat's little theorem "CT-like" version inv(n) = n^(m-2) mod m is 30x slower.
    let a = mod$1(number, modulo);
    let b = modulo;
    // prettier-ignore
    let x = _0n$5, u = _1n$7;
    while (a !== _0n$5) {
        // JIT applies optimization if those two lines follow each other
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        // prettier-ignore
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$7)
        throw new Error('invert: does not exist');
    return mod$1(x, modulo);
}
/**
 * Tonelli-Shanks square root search algorithm.
 * 1. https://eprint.iacr.org/2012/685.pdf (page 12)
 * 2. Square Roots from 1; 24, 51, 10 to Dan Shanks
 * Will start an infinite loop if field order P is not prime.
 * @param P field order
 * @returns function that takes field Fp (created from P) and number n
 */
function tonelliShanks(P) {
    // Legendre constant: used to calculate Legendre symbol (a | p),
    // which denotes the value of a^((p-1)/2) (mod p).
    // (a | p) ≡ 1    if a is a square (mod p)
    // (a | p) ≡ -1   if a is not a square (mod p)
    // (a | p) ≡ 0    if a ≡ 0 (mod p)
    const legendreC = (P - _1n$7) / _2n$4;
    let Q, S, Z;
    // Step 1: By factoring out powers of 2 from p - 1,
    // find q and s such that p - 1 = q*(2^s) with q odd
    for (Q = P - _1n$7, S = 0; Q % _2n$4 === _0n$5; Q /= _2n$4, S++)
        ;
    // Step 2: Select a non-square z such that (z | p) ≡ -1 and set c ≡ zq
    for (Z = _2n$4; Z < P && pow(Z, legendreC, P) !== P - _1n$7; Z++)
        ;
    // Fast-path
    if (S === 1) {
        const p1div4 = (P + _1n$7) / _4n;
        return function tonelliFast(Fp, n) {
            const root = Fp.pow(n, p1div4);
            if (!Fp.eql(Fp.sqr(root), n))
                throw new Error('Cannot find square root');
            return root;
        };
    }
    // Slow-path
    const Q1div2 = (Q + _1n$7) / _2n$4;
    return function tonelliSlow(Fp, n) {
        // Step 0: Check that n is indeed a square: (n | p) should not be ≡ -1
        if (Fp.pow(n, legendreC) === Fp.neg(Fp.ONE))
            throw new Error('Cannot find square root');
        let r = S;
        // TODO: will fail at Fp2/etc
        let g = Fp.pow(Fp.mul(Fp.ONE, Z), Q); // will update both x and b
        let x = Fp.pow(n, Q1div2); // first guess at the square root
        let b = Fp.pow(n, Q); // first guess at the fudge factor
        while (!Fp.eql(b, Fp.ONE)) {
            if (Fp.eql(b, Fp.ZERO))
                return Fp.ZERO; // https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm (4. If t = 0, return r = 0)
            // Find m such b^(2^m)==1
            let m = 1;
            for (let t2 = Fp.sqr(b); m < r; m++) {
                if (Fp.eql(t2, Fp.ONE))
                    break;
                t2 = Fp.sqr(t2); // t2 *= t2
            }
            // NOTE: r-m-1 can be bigger than 32, need to convert to bigint before shift, otherwise there will be overflow
            const ge = Fp.pow(g, _1n$7 << BigInt(r - m - 1)); // ge = 2^(r-m-1)
            g = Fp.sqr(ge); // g = ge * ge
            x = Fp.mul(x, ge); // x *= ge
            b = Fp.mul(b, g); // b *= g
            r = m;
        }
        return x;
    };
}
function FpSqrt(P) {
    // NOTE: different algorithms can give different roots, it is up to user to decide which one they want.
    // For example there is FpSqrtOdd/FpSqrtEven to choice root based on oddness (used for hash-to-curve).
    // P ≡ 3 (mod 4)
    // √n = n^((P+1)/4)
    if (P % _4n === _3n$3) {
        // Not all roots possible!
        // const ORDER =
        //   0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaabn;
        // const NUM = 72057594037927816n;
        const p1div4 = (P + _1n$7) / _4n;
        return function sqrt3mod4(Fp, n) {
            const root = Fp.pow(n, p1div4);
            // Throw if root**2 != n
            if (!Fp.eql(Fp.sqr(root), n))
                throw new Error('Cannot find square root');
            return root;
        };
    }
    // Atkin algorithm for q ≡ 5 (mod 8), https://eprint.iacr.org/2012/685.pdf (page 10)
    if (P % _8n$3 === _5n$1) {
        const c1 = (P - _5n$1) / _8n$3;
        return function sqrt5mod8(Fp, n) {
            const n2 = Fp.mul(n, _2n$4);
            const v = Fp.pow(n2, c1);
            const nv = Fp.mul(n, v);
            const i = Fp.mul(Fp.mul(nv, _2n$4), v);
            const root = Fp.mul(nv, Fp.sub(i, Fp.ONE));
            if (!Fp.eql(Fp.sqr(root), n))
                throw new Error('Cannot find square root');
            return root;
        };
    }
    // Other cases: Tonelli-Shanks algorithm
    return tonelliShanks(P);
}
// Little-endian check for first LE bit (last BE bit);
const isNegativeLE = (num, modulo) => (mod$1(num, modulo) & _1n$7) === _1n$7;
// prettier-ignore
const FIELD_FIELDS = [
    'create', 'isValid', 'is0', 'neg', 'inv', 'sqrt', 'sqr',
    'eql', 'add', 'sub', 'mul', 'pow', 'div',
    'addN', 'subN', 'mulN', 'sqrN'
];
function validateField(field) {
    const initial = {
        ORDER: 'bigint',
        MASK: 'bigint',
        BYTES: 'isSafeInteger',
        BITS: 'isSafeInteger',
    };
    const opts = FIELD_FIELDS.reduce((map, val) => {
        map[val] = 'function';
        return map;
    }, initial);
    return validateObject(field, opts);
}
// Generic field functions
/**
 * Same as `pow` but for Fp: non-constant-time.
 * Unsafe in some contexts: uses ladder, so can expose bigint bits.
 */
function FpPow(f, num, power) {
    // Should have same speed as pow for bigints
    // TODO: benchmark!
    if (power < _0n$5)
        throw new Error('Expected power > 0');
    if (power === _0n$5)
        return f.ONE;
    if (power === _1n$7)
        return num;
    let p = f.ONE;
    let d = num;
    while (power > _0n$5) {
        if (power & _1n$7)
            p = f.mul(p, d);
        d = f.sqr(d);
        power >>= _1n$7;
    }
    return p;
}
/**
 * Efficiently invert an array of Field elements.
 * `inv(0)` will return `undefined` here: make sure to throw an error.
 */
function FpInvertBatch(f, nums) {
    const tmp = new Array(nums.length);
    // Walk from first to last, multiply them by each other MOD p
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (f.is0(num))
            return acc;
        tmp[i] = acc;
        return f.mul(acc, num);
    }, f.ONE);
    // Invert last element
    const inverted = f.inv(lastMultiplied);
    // Walk from last to first, multiply them by inverted each other MOD p
    nums.reduceRight((acc, num, i) => {
        if (f.is0(num))
            return acc;
        tmp[i] = f.mul(acc, tmp[i]);
        return f.mul(acc, num);
    }, inverted);
    return tmp;
}
// CURVE.n lengths
function nLength(n, nBitLength) {
    // Bit size, byte size of CURVE.n
    const _nBitLength = nBitLength !== undefined ? nBitLength : n.toString(2).length;
    const nByteLength = Math.ceil(_nBitLength / 8);
    return { nBitLength: _nBitLength, nByteLength };
}
/**
 * Initializes a finite field over prime. **Non-primes are not supported.**
 * Do not init in loop: slow. Very fragile: always run a benchmark on a change.
 * Major performance optimizations:
 * * a) denormalized operations like mulN instead of mul
 * * b) same object shape: never add or remove keys
 * * c) Object.freeze
 * NOTE: operations don't check 'isValid' for all elements for performance reasons,
 * it is caller responsibility to check this.
 * This is low-level code, please make sure you know what you doing.
 * @param ORDER prime positive bigint
 * @param bitLen how many bits the field consumes
 * @param isLE (def: false) if encoding / decoding should be in little-endian
 * @param redef optional faster redefinitions of sqrt and other methods
 */
function Field(ORDER, bitLen, isLE = false, redef = {}) {
    if (ORDER <= _0n$5)
        throw new Error(`Expected Field ORDER > 0, got ${ORDER}`);
    const { nBitLength: BITS, nByteLength: BYTES } = nLength(ORDER, bitLen);
    if (BYTES > 2048)
        throw new Error('Field lengths over 2048 bytes are not supported');
    const sqrtP = FpSqrt(ORDER);
    const f = Object.freeze({
        ORDER,
        BITS,
        BYTES,
        MASK: bitMask(BITS),
        ZERO: _0n$5,
        ONE: _1n$7,
        create: (num) => mod$1(num, ORDER),
        isValid: (num) => {
            if (typeof num !== 'bigint')
                throw new Error(`Invalid field element: expected bigint, got ${typeof num}`);
            return _0n$5 <= num && num < ORDER; // 0 is valid element, but it's not invertible
        },
        is0: (num) => num === _0n$5,
        isOdd: (num) => (num & _1n$7) === _1n$7,
        neg: (num) => mod$1(-num, ORDER),
        eql: (lhs, rhs) => lhs === rhs,
        sqr: (num) => mod$1(num * num, ORDER),
        add: (lhs, rhs) => mod$1(lhs + rhs, ORDER),
        sub: (lhs, rhs) => mod$1(lhs - rhs, ORDER),
        mul: (lhs, rhs) => mod$1(lhs * rhs, ORDER),
        pow: (num, power) => FpPow(f, num, power),
        div: (lhs, rhs) => mod$1(lhs * invert$1(rhs, ORDER), ORDER),
        // Same as above, but doesn't normalize
        sqrN: (num) => num * num,
        addN: (lhs, rhs) => lhs + rhs,
        subN: (lhs, rhs) => lhs - rhs,
        mulN: (lhs, rhs) => lhs * rhs,
        inv: (num) => invert$1(num, ORDER),
        sqrt: redef.sqrt || ((n) => sqrtP(f, n)),
        invertBatch: (lst) => FpInvertBatch(f, lst),
        // TODO: do we really need constant cmov?
        // We don't have const-time bigints anyway, so probably will be not very useful
        cmov: (a, b, c) => (c ? b : a),
        toBytes: (num) => (isLE ? numberToBytesLE(num, BYTES) : numberToBytesBE(num, BYTES)),
        fromBytes: (bytes) => {
            if (bytes.length !== BYTES)
                throw new Error(`Fp.fromBytes: expected ${BYTES}, got ${bytes.length}`);
            return isLE ? bytesToNumberLE(bytes) : bytesToNumberBE(bytes);
        },
    });
    return Object.freeze(f);
}
/**
 * Returns total number of bytes consumed by the field element.
 * For example, 32 bytes for usual 256-bit weierstrass curve.
 * @param fieldOrder number of field elements, usually CURVE.n
 * @returns byte length of field
 */
function getFieldBytesLength(fieldOrder) {
    if (typeof fieldOrder !== 'bigint')
        throw new Error('field order must be bigint');
    const bitLength = fieldOrder.toString(2).length;
    return Math.ceil(bitLength / 8);
}
/**
 * Returns minimal amount of bytes that can be safely reduced
 * by field order.
 * Should be 2^-128 for 128-bit curve such as P256.
 * @param fieldOrder number of field elements, usually CURVE.n
 * @returns byte length of target hash
 */
function getMinHashLength(fieldOrder) {
    const length = getFieldBytesLength(fieldOrder);
    return length + Math.ceil(length / 2);
}
/**
 * "Constant-time" private key generation utility.
 * Can take (n + n/2) or more bytes of uniform input e.g. from CSPRNG or KDF
 * and convert them into private scalar, with the modulo bias being negligible.
 * Needs at least 48 bytes of input for 32-byte private key.
 * https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/
 * FIPS 186-5, A.2 https://csrc.nist.gov/publications/detail/fips/186/5/final
 * RFC 9380, https://www.rfc-editor.org/rfc/rfc9380#section-5
 * @param hash hash output from SHA3 or a similar function
 * @param groupOrder size of subgroup - (e.g. secp256k1.CURVE.n)
 * @param isLE interpret hash bytes as LE num
 * @returns valid private scalar
 */
function mapHashToField(key, fieldOrder, isLE = false) {
    const len = key.length;
    const fieldLen = getFieldBytesLength(fieldOrder);
    const minLen = getMinHashLength(fieldOrder);
    // No small numbers: need to understand bias story. No huge numbers: easier to detect JS timings.
    if (len < 16 || len < minLen || len > 1024)
        throw new Error(`expected ${minLen}-1024 bytes of input, got ${len}`);
    const num = isLE ? bytesToNumberBE(key) : bytesToNumberLE(key);
    // `mod(x, 11)` can sometimes produce 0. `mod(x, 10) + 1` is the same, but no 0
    const reduced = mod$1(num, fieldOrder - _1n$7) + _1n$7;
    return isLE ? numberToBytesLE(reduced, fieldLen) : numberToBytesBE(reduced, fieldLen);
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Abelian group utilities
const _0n$4 = BigInt(0);
const _1n$6 = BigInt(1);
// Since points in different groups cannot be equal (different object constructor),
// we can have single place to store precomputes
const pointPrecomputes$1 = new WeakMap();
const pointWindowSizes = new WeakMap(); // This allows use make points immutable (nothing changes inside)
// Elliptic curve multiplication of Point by scalar. Fragile.
// Scalars should always be less than curve order: this should be checked inside of a curve itself.
// Creates precomputation tables for fast multiplication:
// - private scalar is split by fixed size windows of W bits
// - every window point is collected from window's table & added to accumulator
// - since windows are different, same point inside tables won't be accessed more than once per calc
// - each multiplication is 'Math.ceil(CURVE_ORDER / 𝑊) + 1' point additions (fixed for any scalar)
// - +1 window is neccessary for wNAF
// - wNAF reduces table size: 2x less memory + 2x faster generation, but 10% slower multiplication
// TODO: Research returning 2d JS array of windows, instead of a single window. This would allow
// windows to be in different memory locations
function wNAF(c, bits) {
    const constTimeNegate = (condition, item) => {
        const neg = item.negate();
        return condition ? neg : item;
    };
    const validateW = (W) => {
        if (!Number.isSafeInteger(W) || W <= 0 || W > bits)
            throw new Error(`Wrong window size=${W}, should be [1..${bits}]`);
    };
    const opts = (W) => {
        validateW(W);
        const windows = Math.ceil(bits / W) + 1; // +1, because
        const windowSize = 2 ** (W - 1); // -1 because we skip zero
        return { windows, windowSize };
    };
    return {
        constTimeNegate,
        // non-const time multiplication ladder
        unsafeLadder(elm, n) {
            let p = c.ZERO;
            let d = elm;
            while (n > _0n$4) {
                if (n & _1n$6)
                    p = p.add(d);
                d = d.double();
                n >>= _1n$6;
            }
            return p;
        },
        /**
         * Creates a wNAF precomputation window. Used for caching.
         * Default window size is set by `utils.precompute()` and is equal to 8.
         * Number of precomputed points depends on the curve size:
         * 2^(𝑊−1) * (Math.ceil(𝑛 / 𝑊) + 1), where:
         * - 𝑊 is the window size
         * - 𝑛 is the bitlength of the curve order.
         * For a 256-bit curve and window size 8, the number of precomputed points is 128 * 33 = 4224.
         * @returns precomputed point tables flattened to a single array
         */
        precomputeWindow(elm, W) {
            const { windows, windowSize } = opts(W);
            const points = [];
            let p = elm;
            let base = p;
            for (let window = 0; window < windows; window++) {
                base = p;
                points.push(base);
                // =1, because we skip zero
                for (let i = 1; i < windowSize; i++) {
                    base = base.add(p);
                    points.push(base);
                }
                p = base.double();
            }
            return points;
        },
        /**
         * Implements ec multiplication using precomputed tables and w-ary non-adjacent form.
         * @param W window size
         * @param precomputes precomputed tables
         * @param n scalar (we don't check here, but should be less than curve order)
         * @returns real and fake (for const-time) points
         */
        wNAF(W, precomputes, n) {
            // TODO: maybe check that scalar is less than group order? wNAF behavious is undefined otherwise
            // But need to carefully remove other checks before wNAF. ORDER == bits here
            const { windows, windowSize } = opts(W);
            let p = c.ZERO;
            let f = c.BASE;
            const mask = BigInt(2 ** W - 1); // Create mask with W ones: 0b1111 for W=4 etc.
            const maxNumber = 2 ** W;
            const shiftBy = BigInt(W);
            for (let window = 0; window < windows; window++) {
                const offset = window * windowSize;
                // Extract W bits.
                let wbits = Number(n & mask);
                // Shift number by W bits.
                n >>= shiftBy;
                // If the bits are bigger than max size, we'll split those.
                // +224 => 256 - 32
                if (wbits > windowSize) {
                    wbits -= maxNumber;
                    n += _1n$6;
                }
                // This code was first written with assumption that 'f' and 'p' will never be infinity point:
                // since each addition is multiplied by 2 ** W, it cannot cancel each other. However,
                // there is negate now: it is possible that negated element from low value
                // would be the same as high element, which will create carry into next window.
                // It's not obvious how this can fail, but still worth investigating later.
                // Check if we're onto Zero point.
                // Add random point inside current window to f.
                const offset1 = offset;
                const offset2 = offset + Math.abs(wbits) - 1; // -1 because we skip zero
                const cond1 = window % 2 !== 0;
                const cond2 = wbits < 0;
                if (wbits === 0) {
                    // The most important part for const-time getPublicKey
                    f = f.add(constTimeNegate(cond1, precomputes[offset1]));
                }
                else {
                    p = p.add(constTimeNegate(cond2, precomputes[offset2]));
                }
            }
            // JIT-compiler should not eliminate f here, since it will later be used in normalizeZ()
            // Even if the variable is still unused, there are some checks which will
            // throw an exception, so compiler needs to prove they won't happen, which is hard.
            // At this point there is a way to F be infinity-point even if p is not,
            // which makes it less const-time: around 1 bigint multiply.
            return { p, f };
        },
        wNAFCached(P, n, transform) {
            const W = pointWindowSizes.get(P) || 1;
            // Calculate precomputes on a first run, reuse them after
            let comp = pointPrecomputes$1.get(P);
            if (!comp) {
                comp = this.precomputeWindow(P, W);
                if (W !== 1)
                    pointPrecomputes$1.set(P, transform(comp));
            }
            return this.wNAF(W, comp, n);
        },
        // We calculate precomputes for elliptic curve point multiplication
        // using windowed method. This specifies window size and
        // stores precomputed values. Usually only base point would be precomputed.
        setWindowSize(P, W) {
            validateW(W);
            pointWindowSizes.set(P, W);
            pointPrecomputes$1.delete(P);
        },
    };
}
/**
 * Pippenger algorithm for multi-scalar multiplication (MSM).
 * MSM is basically (Pa + Qb + Rc + ...).
 * 30x faster vs naive addition on L=4096, 10x faster with precomputes.
 * For N=254bit, L=1, it does: 1024 ADD + 254 DBL. For L=5: 1536 ADD + 254 DBL.
 * Algorithmically constant-time (for same L), even when 1 point + scalar, or when scalar = 0.
 * @param c Curve Point constructor
 * @param field field over CURVE.N - important that it's not over CURVE.P
 * @param points array of L curve points
 * @param scalars array of L scalars (aka private keys / bigints)
 */
function pippenger(c, field, points, scalars) {
    // If we split scalars by some window (let's say 8 bits), every chunk will only
    // take 256 buckets even if there are 4096 scalars, also re-uses double.
    // TODO:
    // - https://eprint.iacr.org/2024/750.pdf
    // - https://tches.iacr.org/index.php/TCHES/article/view/10287
    // 0 is accepted in scalars
    if (!Array.isArray(points) || !Array.isArray(scalars) || scalars.length !== points.length)
        throw new Error('arrays of points and scalars must have equal length');
    scalars.forEach((s, i) => {
        if (!field.isValid(s))
            throw new Error(`wrong scalar at index ${i}`);
    });
    points.forEach((p, i) => {
        if (!(p instanceof c))
            throw new Error(`wrong point at index ${i}`);
    });
    const wbits = bitLen(BigInt(points.length));
    const windowSize = wbits > 12 ? wbits - 3 : wbits > 4 ? wbits - 2 : wbits ? 2 : 1; // in bits
    const MASK = (1 << windowSize) - 1;
    const buckets = new Array(MASK + 1).fill(c.ZERO); // +1 for zero array
    const lastBits = Math.floor((field.BITS - 1) / windowSize) * windowSize;
    let sum = c.ZERO;
    for (let i = lastBits; i >= 0; i -= windowSize) {
        buckets.fill(c.ZERO);
        for (let j = 0; j < scalars.length; j++) {
            const scalar = scalars[j];
            const wbits = Number((scalar >> BigInt(i)) & BigInt(MASK));
            buckets[wbits] = buckets[wbits].add(points[j]);
        }
        let resI = c.ZERO; // not using this will do small speed-up, but will lose ct
        // Skip first bucket, because it is zero
        for (let j = buckets.length - 1, sumI = c.ZERO; j > 0; j--) {
            sumI = sumI.add(buckets[j]);
            resI = resI.add(sumI);
        }
        sum = sum.add(resI);
        if (i !== 0)
            for (let j = 0; j < windowSize; j++)
                sum = sum.double();
    }
    return sum;
}
function validateBasic(curve) {
    validateField(curve.Fp);
    validateObject(curve, {
        n: 'bigint',
        h: 'bigint',
        Gx: 'field',
        Gy: 'field',
    }, {
        nBitLength: 'isSafeInteger',
        nByteLength: 'isSafeInteger',
    });
    // Set defaults
    return Object.freeze({
        ...nLength(curve.n, curve.nBitLength),
        ...curve,
        ...{ p: curve.Fp.ORDER },
    });
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Twisted Edwards curve. The formula is: ax² + y² = 1 + dx²y²
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n$3 = BigInt(0), _1n$5 = BigInt(1), _2n$3 = BigInt(2), _8n$2 = BigInt(8);
// verification rule is either zip215 or rfc8032 / nist186-5. Consult fromHex:
const VERIFY_DEFAULT = { zip215: true };
function validateOpts$2(curve) {
    const opts = validateBasic(curve);
    validateObject(curve, {
        hash: 'function',
        a: 'bigint',
        d: 'bigint',
        randomBytes: 'function',
    }, {
        adjustScalarBytes: 'function',
        domain: 'function',
        uvRatio: 'function',
        mapToCurve: 'function',
    });
    // Set defaults
    return Object.freeze({ ...opts });
}
/**
 * Creates Twisted Edwards curve with EdDSA signatures.
 * @example
 * import { Field } from '@noble/curves/abstract/modular';
 * // Before that, define BigInt-s: a, d, p, n, Gx, Gy, h
 * const curve = twistedEdwards({ a, d, Fp: Field(p), n, Gx, Gy, h })
 */
function twistedEdwards(curveDef) {
    const CURVE = validateOpts$2(curveDef);
    const { Fp, n: CURVE_ORDER, prehash: prehash, hash: cHash, randomBytes, nByteLength, h: cofactor, } = CURVE;
    const MASK = _2n$3 << (BigInt(nByteLength * 8) - _1n$5);
    const modP = Fp.create; // Function overrides
    const Fn = Field(CURVE.n, CURVE.nBitLength);
    // sqrt(u/v)
    const uvRatio = CURVE.uvRatio ||
        ((u, v) => {
            try {
                return { isValid: true, value: Fp.sqrt(u * Fp.inv(v)) };
            }
            catch (e) {
                return { isValid: false, value: _0n$3 };
            }
        });
    const adjustScalarBytes = CURVE.adjustScalarBytes || ((bytes) => bytes); // NOOP
    const domain = CURVE.domain ||
        ((data, ctx, phflag) => {
            abool('phflag', phflag);
            if (ctx.length || phflag)
                throw new Error('Contexts/pre-hash are not supported');
            return data;
        }); // NOOP
    // 0 <= n < MASK
    // Coordinates larger than Fp.ORDER are allowed for zip215
    function aCoordinate(title, n) {
        aInRange('coordinate ' + title, n, _0n$3, MASK);
    }
    function assertPoint(other) {
        if (!(other instanceof Point))
            throw new Error('ExtendedPoint expected');
    }
    // Converts Extended point to default (x, y) coordinates.
    // Can accept precomputed Z^-1 - for example, from invertBatch.
    const toAffineMemo = memoized((p, iz) => {
        const { ex: x, ey: y, ez: z } = p;
        const is0 = p.is0();
        if (iz == null)
            iz = is0 ? _8n$2 : Fp.inv(z); // 8 was chosen arbitrarily
        const ax = modP(x * iz);
        const ay = modP(y * iz);
        const zz = modP(z * iz);
        if (is0)
            return { x: _0n$3, y: _1n$5 };
        if (zz !== _1n$5)
            throw new Error('invZ was invalid');
        return { x: ax, y: ay };
    });
    const assertValidMemo = memoized((p) => {
        const { a, d } = CURVE;
        if (p.is0())
            throw new Error('bad point: ZERO'); // TODO: optimize, with vars below?
        // Equation in affine coordinates: ax² + y² = 1 + dx²y²
        // Equation in projective coordinates (X/Z, Y/Z, Z):  (aX² + Y²)Z² = Z⁴ + dX²Y²
        const { ex: X, ey: Y, ez: Z, et: T } = p;
        const X2 = modP(X * X); // X²
        const Y2 = modP(Y * Y); // Y²
        const Z2 = modP(Z * Z); // Z²
        const Z4 = modP(Z2 * Z2); // Z⁴
        const aX2 = modP(X2 * a); // aX²
        const left = modP(Z2 * modP(aX2 + Y2)); // (aX² + Y²)Z²
        const right = modP(Z4 + modP(d * modP(X2 * Y2))); // Z⁴ + dX²Y²
        if (left !== right)
            throw new Error('bad point: equation left != right (1)');
        // In Extended coordinates we also have T, which is x*y=T/Z: check X*Y == Z*T
        const XY = modP(X * Y);
        const ZT = modP(Z * T);
        if (XY !== ZT)
            throw new Error('bad point: equation left != right (2)');
        return true;
    });
    // Extended Point works in extended coordinates: (x, y, z, t) ∋ (x=x/z, y=y/z, t=xy).
    // https://en.wikipedia.org/wiki/Twisted_Edwards_curve#Extended_coordinates
    class Point {
        constructor(ex, ey, ez, et) {
            this.ex = ex;
            this.ey = ey;
            this.ez = ez;
            this.et = et;
            aCoordinate('x', ex);
            aCoordinate('y', ey);
            aCoordinate('z', ez);
            aCoordinate('t', et);
            Object.freeze(this);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        static fromAffine(p) {
            if (p instanceof Point)
                throw new Error('extended point not allowed');
            const { x, y } = p || {};
            aCoordinate('x', x);
            aCoordinate('y', y);
            return new Point(x, y, _1n$5, modP(x * y));
        }
        static normalizeZ(points) {
            const toInv = Fp.invertBatch(points.map((p) => p.ez));
            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);
        }
        // Multiscalar Multiplication
        static msm(points, scalars) {
            return pippenger(Point, Fn, points, scalars);
        }
        // "Private method", don't use it directly
        _setWindowSize(windowSize) {
            wnaf.setWindowSize(this, windowSize);
        }
        // Not required for fromHex(), which always creates valid points.
        // Could be useful for fromAffine().
        assertValidity() {
            assertValidMemo(this);
        }
        // Compare one point to another.
        equals(other) {
            assertPoint(other);
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const { ex: X2, ey: Y2, ez: Z2 } = other;
            const X1Z2 = modP(X1 * Z2);
            const X2Z1 = modP(X2 * Z1);
            const Y1Z2 = modP(Y1 * Z2);
            const Y2Z1 = modP(Y2 * Z1);
            return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        negate() {
            // Flips point sign to a negative one (-x, y in affine coords)
            return new Point(modP(-this.ex), this.ey, this.ez, modP(-this.et));
        }
        // Fast algo for doubling Extended Point.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#doubling-dbl-2008-hwcd
        // Cost: 4M + 4S + 1*a + 6add + 1*2.
        double() {
            const { a } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const A = modP(X1 * X1); // A = X12
            const B = modP(Y1 * Y1); // B = Y12
            const C = modP(_2n$3 * modP(Z1 * Z1)); // C = 2*Z12
            const D = modP(a * A); // D = a*A
            const x1y1 = X1 + Y1;
            const E = modP(modP(x1y1 * x1y1) - A - B); // E = (X1+Y1)2-A-B
            const G = D + B; // G = D+B
            const F = G - C; // F = G-C
            const H = D - B; // H = D-B
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        // Fast algo for adding 2 Extended Points.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#addition-add-2008-hwcd
        // Cost: 9M + 1*a + 1*d + 7add.
        add(other) {
            assertPoint(other);
            const { a, d } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1, et: T1 } = this;
            const { ex: X2, ey: Y2, ez: Z2, et: T2 } = other;
            // Faster algo for adding 2 Extended Points when curve's a=-1.
            // http://hyperelliptic.org/EFD/g1p/auto-twisted-extended-1.html#addition-add-2008-hwcd-4
            // Cost: 8M + 8add + 2*2.
            // Note: It does not check whether the `other` point is valid.
            if (a === BigInt(-1)) {
                const A = modP((Y1 - X1) * (Y2 + X2));
                const B = modP((Y1 + X1) * (Y2 - X2));
                const F = modP(B - A);
                if (F === _0n$3)
                    return this.double(); // Same point. Tests say it doesn't affect timing
                const C = modP(Z1 * _2n$3 * T2);
                const D = modP(T1 * _2n$3 * Z2);
                const E = D + C;
                const G = B + A;
                const H = D - C;
                const X3 = modP(E * F);
                const Y3 = modP(G * H);
                const T3 = modP(E * H);
                const Z3 = modP(F * G);
                return new Point(X3, Y3, Z3, T3);
            }
            const A = modP(X1 * X2); // A = X1*X2
            const B = modP(Y1 * Y2); // B = Y1*Y2
            const C = modP(T1 * d * T2); // C = T1*d*T2
            const D = modP(Z1 * Z2); // D = Z1*Z2
            const E = modP((X1 + Y1) * (X2 + Y2) - A - B); // E = (X1+Y1)*(X2+Y2)-A-B
            const F = D - C; // F = D-C
            const G = D + C; // G = D+C
            const H = modP(B - a * A); // H = B-a*A
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        wNAF(n) {
            return wnaf.wNAFCached(this, n, Point.normalizeZ);
        }
        // Constant-time multiplication.
        multiply(scalar) {
            const n = scalar;
            aInRange('scalar', n, _1n$5, CURVE_ORDER); // 1 <= scalar < L
            const { p, f } = this.wNAF(n);
            return Point.normalizeZ([p, f])[0];
        }
        // Non-constant-time multiplication. Uses double-and-add algorithm.
        // It's faster, but should only be used when you don't care about
        // an exposed private key e.g. sig verification.
        // Does NOT allow scalars higher than CURVE.n.
        multiplyUnsafe(scalar) {
            const n = scalar;
            aInRange('scalar', n, _0n$3, CURVE_ORDER); // 0 <= scalar < L
            if (n === _0n$3)
                return I;
            if (this.equals(I) || n === _1n$5)
                return this;
            if (this.equals(G))
                return this.wNAF(n).p;
            return wnaf.unsafeLadder(this, n);
        }
        // Checks if point is of small order.
        // If you add something to small order point, you will have "dirty"
        // point with torsion component.
        // Multiplies point by cofactor and checks if the result is 0.
        isSmallOrder() {
            return this.multiplyUnsafe(cofactor).is0();
        }
        // Multiplies point by curve order and checks if the result is 0.
        // Returns `false` is the point is dirty.
        isTorsionFree() {
            return wnaf.unsafeLadder(this, CURVE_ORDER).is0();
        }
        // Converts Extended point to default (x, y) coordinates.
        // Can accept precomputed Z^-1 - for example, from invertBatch.
        toAffine(iz) {
            return toAffineMemo(this, iz);
        }
        clearCofactor() {
            const { h: cofactor } = CURVE;
            if (cofactor === _1n$5)
                return this;
            return this.multiplyUnsafe(cofactor);
        }
        // Converts hash string or Uint8Array to Point.
        // Uses algo from RFC8032 5.1.3.
        static fromHex(hex, zip215 = false) {
            const { d, a } = CURVE;
            const len = Fp.BYTES;
            hex = ensureBytes$1('pointHex', hex, len); // copy hex to a new array
            abool('zip215', zip215);
            const normed = hex.slice(); // copy again, we'll manipulate it
            const lastByte = hex[len - 1]; // select last byte
            normed[len - 1] = lastByte & ~0x80; // clear last bit
            const y = bytesToNumberLE(normed);
            // RFC8032 prohibits >= p, but ZIP215 doesn't
            // zip215=true:  0 <= y < MASK (2^256 for ed25519)
            // zip215=false: 0 <= y < P (2^255-19 for ed25519)
            const max = zip215 ? MASK : Fp.ORDER;
            aInRange('pointHex.y', y, _0n$3, max);
            // Ed25519: x² = (y²-1)/(dy²+1) mod p. Ed448: x² = (y²-1)/(dy²-1) mod p. Generic case:
            // ax²+y²=1+dx²y² => y²-1=dx²y²-ax² => y²-1=x²(dy²-a) => x²=(y²-1)/(dy²-a)
            const y2 = modP(y * y); // denominator is always non-0 mod p.
            const u = modP(y2 - _1n$5); // u = y² - 1
            const v = modP(d * y2 - a); // v = d y² + 1.
            let { isValid, value: x } = uvRatio(u, v); // √(u/v)
            if (!isValid)
                throw new Error('Point.fromHex: invalid y coordinate');
            const isXOdd = (x & _1n$5) === _1n$5; // There are 2 square roots. Use x_0 bit to select proper
            const isLastByteOdd = (lastByte & 0x80) !== 0; // x_0, last bit
            if (!zip215 && x === _0n$3 && isLastByteOdd)
                // if x=0 and x_0 = 1, fail
                throw new Error('Point.fromHex: x=0 and x_0=1');
            if (isLastByteOdd !== isXOdd)
                x = modP(-x); // if x_0 != x mod 2, set x = p-x
            return Point.fromAffine({ x, y });
        }
        static fromPrivateKey(privKey) {
            return getExtendedPublicKey(privKey).point;
        }
        toRawBytes() {
            const { x, y } = this.toAffine();
            const bytes = numberToBytesLE(y, Fp.BYTES); // each y has 2 x values (x, -y)
            bytes[bytes.length - 1] |= x & _1n$5 ? 0x80 : 0; // when compressing, it's enough to store y
            return bytes; // and use the last byte to encode sign of x
        }
        toHex() {
            return bytesToHex$1(this.toRawBytes()); // Same as toRawBytes, but returns string.
        }
    }
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, _1n$5, modP(CURVE.Gx * CURVE.Gy));
    Point.ZERO = new Point(_0n$3, _1n$5, _1n$5, _0n$3); // 0, 1, 1, 0
    const { BASE: G, ZERO: I } = Point;
    const wnaf = wNAF(Point, nByteLength * 8);
    function modN(a) {
        return mod$1(a, CURVE_ORDER);
    }
    // Little-endian SHA512 with modulo n
    function modN_LE(hash) {
        return modN(bytesToNumberLE(hash));
    }
    /** Convenience method that creates public key and other stuff. RFC8032 5.1.5 */
    function getExtendedPublicKey(key) {
        const len = nByteLength;
        key = ensureBytes$1('private key', key, len);
        // Hash private key with curve's hash function to produce uniformingly random input
        // Check byte lengths: ensure(64, h(ensure(32, key)))
        const hashed = ensureBytes$1('hashed private key', cHash(key), 2 * len);
        const head = adjustScalarBytes(hashed.slice(0, len)); // clear first half bits, produce FE
        const prefix = hashed.slice(len, 2 * len); // second half is called key prefix (5.1.6)
        const scalar = modN_LE(head); // The actual private scalar
        const point = G.multiply(scalar); // Point on Edwards curve aka public key
        const pointBytes = point.toRawBytes(); // Uint8Array representation
        return { head, prefix, scalar, point, pointBytes };
    }
    // Calculates EdDSA pub key. RFC8032 5.1.5. Privkey is hashed. Use first half with 3 bits cleared
    function getPublicKey(privKey) {
        return getExtendedPublicKey(privKey).pointBytes;
    }
    // int('LE', SHA512(dom2(F, C) || msgs)) mod N
    function hashDomainToScalar(context = new Uint8Array(), ...msgs) {
        const msg = concatBytes$1(...msgs);
        return modN_LE(cHash(domain(msg, ensureBytes$1('context', context), !!prehash)));
    }
    /** Signs message with privateKey. RFC8032 5.1.6 */
    function sign(msg, privKey, options = {}) {
        msg = ensureBytes$1('message', msg);
        if (prehash)
            msg = prehash(msg); // for ed25519ph etc.
        const { prefix, scalar, pointBytes } = getExtendedPublicKey(privKey);
        const r = hashDomainToScalar(options.context, prefix, msg); // r = dom2(F, C) || prefix || PH(M)
        const R = G.multiply(r).toRawBytes(); // R = rG
        const k = hashDomainToScalar(options.context, R, pointBytes, msg); // R || A || PH(M)
        const s = modN(r + k * scalar); // S = (r + k * s) mod L
        aInRange('signature.s', s, _0n$3, CURVE_ORDER); // 0 <= s < l
        const res = concatBytes$1(R, numberToBytesLE(s, Fp.BYTES));
        return ensureBytes$1('result', res, nByteLength * 2); // 64-byte signature
    }
    const verifyOpts = VERIFY_DEFAULT;
    function verify(sig, msg, publicKey, options = verifyOpts) {
        const { context, zip215 } = options;
        const len = Fp.BYTES; // Verifies EdDSA signature against message and public key. RFC8032 5.1.7.
        sig = ensureBytes$1('signature', sig, 2 * len); // An extended group equation is checked.
        msg = ensureBytes$1('message', msg);
        if (zip215 !== undefined)
            abool('zip215', zip215);
        if (prehash)
            msg = prehash(msg); // for ed25519ph, etc
        const s = bytesToNumberLE(sig.slice(len, 2 * len));
        // zip215: true is good for consensus-critical apps and allows points < 2^256
        // zip215: false follows RFC8032 / NIST186-5 and restricts points to CURVE.p
        let A, R, SB;
        try {
            A = Point.fromHex(publicKey, zip215);
            R = Point.fromHex(sig.slice(0, len), zip215);
            SB = G.multiplyUnsafe(s); // 0 <= s < l is done inside
        }
        catch (error) {
            return false;
        }
        if (!zip215 && A.isSmallOrder())
            return false;
        const k = hashDomainToScalar(context, R.toRawBytes(), A.toRawBytes(), msg);
        const RkA = R.add(A.multiplyUnsafe(k));
        // [8][S]B = [8]R + [8][k]A'
        return RkA.subtract(SB).clearCofactor().equals(Point.ZERO);
    }
    G._setWindowSize(8); // Enable precomputes. Slows down first publicKey computation by 20ms.
    const utils = {
        getExtendedPublicKey,
        // ed25519 private keys are uniform 32b. No need to check for modulo bias, like in secp256k1.
        randomPrivateKey: () => randomBytes(Fp.BYTES),
        /**
         * We're doing scalar multiplication (used in getPublicKey etc) with precomputed BASE_POINT
         * values. This slows down first getPublicKey() by milliseconds (see Speed section),
         * but allows to speed-up subsequent getPublicKey() calls up to 20x.
         * @param windowSize 2, 4, 8, 16
         */
        precompute(windowSize = 8, point = Point.BASE) {
            point._setWindowSize(windowSize);
            point.multiply(BigInt(3));
            return point;
        },
    };
    return {
        CURVE,
        getPublicKey,
        sign,
        verify,
        ExtendedPoint: Point,
        utils,
    };
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$2 = BigInt(0);
const _1n$4 = BigInt(1);
function validateOpts$1(curve) {
    validateObject(curve, {
        a: 'bigint',
    }, {
        montgomeryBits: 'isSafeInteger',
        nByteLength: 'isSafeInteger',
        adjustScalarBytes: 'function',
        domain: 'function',
        powPminus2: 'function',
        Gu: 'bigint',
    });
    // Set defaults
    return Object.freeze({ ...curve });
}
// NOTE: not really montgomery curve, just bunch of very specific methods for X25519/X448 (RFC 7748, https://www.rfc-editor.org/rfc/rfc7748)
// Uses only one coordinate instead of two
function montgomery(curveDef) {
    const CURVE = validateOpts$1(curveDef);
    const { P } = CURVE;
    const modP = (n) => mod$1(n, P);
    const montgomeryBits = CURVE.montgomeryBits;
    const montgomeryBytes = Math.ceil(montgomeryBits / 8);
    const fieldLen = CURVE.nByteLength;
    const adjustScalarBytes = CURVE.adjustScalarBytes || ((bytes) => bytes);
    const powPminus2 = CURVE.powPminus2 || ((x) => pow(x, P - BigInt(2), P));
    // cswap from RFC7748. But it is not from RFC7748!
    /*
      cswap(swap, x_2, x_3):
           dummy = mask(swap) AND (x_2 XOR x_3)
           x_2 = x_2 XOR dummy
           x_3 = x_3 XOR dummy
           Return (x_2, x_3)
    Where mask(swap) is the all-1 or all-0 word of the same length as x_2
     and x_3, computed, e.g., as mask(swap) = 0 - swap.
    */
    function cswap(swap, x_2, x_3) {
        const dummy = modP(swap * (x_2 - x_3));
        x_2 = modP(x_2 - dummy);
        x_3 = modP(x_3 + dummy);
        return [x_2, x_3];
    }
    // x25519 from 4
    // The constant a24 is (486662 - 2) / 4 = 121665 for curve25519/X25519
    const a24 = (CURVE.a - BigInt(2)) / BigInt(4);
    /**
     *
     * @param pointU u coordinate (x) on Montgomery Curve 25519
     * @param scalar by which the point would be multiplied
     * @returns new Point on Montgomery curve
     */
    function montgomeryLadder(u, scalar) {
        aInRange('u', u, _0n$2, P);
        aInRange('scalar', scalar, _0n$2, P);
        // Section 5: Implementations MUST accept non-canonical values and process them as
        // if they had been reduced modulo the field prime.
        const k = scalar;
        const x_1 = u;
        let x_2 = _1n$4;
        let z_2 = _0n$2;
        let x_3 = u;
        let z_3 = _1n$4;
        let swap = _0n$2;
        let sw;
        for (let t = BigInt(montgomeryBits - 1); t >= _0n$2; t--) {
            const k_t = (k >> t) & _1n$4;
            swap ^= k_t;
            sw = cswap(swap, x_2, x_3);
            x_2 = sw[0];
            x_3 = sw[1];
            sw = cswap(swap, z_2, z_3);
            z_2 = sw[0];
            z_3 = sw[1];
            swap = k_t;
            const A = x_2 + z_2;
            const AA = modP(A * A);
            const B = x_2 - z_2;
            const BB = modP(B * B);
            const E = AA - BB;
            const C = x_3 + z_3;
            const D = x_3 - z_3;
            const DA = modP(D * A);
            const CB = modP(C * B);
            const dacb = DA + CB;
            const da_cb = DA - CB;
            x_3 = modP(dacb * dacb);
            z_3 = modP(x_1 * modP(da_cb * da_cb));
            x_2 = modP(AA * BB);
            z_2 = modP(E * (AA + modP(a24 * E)));
        }
        // (x_2, x_3) = cswap(swap, x_2, x_3)
        sw = cswap(swap, x_2, x_3);
        x_2 = sw[0];
        x_3 = sw[1];
        // (z_2, z_3) = cswap(swap, z_2, z_3)
        sw = cswap(swap, z_2, z_3);
        z_2 = sw[0];
        z_3 = sw[1];
        // z_2^(p - 2)
        const z2 = powPminus2(z_2);
        // Return x_2 * (z_2^(p - 2))
        return modP(x_2 * z2);
    }
    function encodeUCoordinate(u) {
        return numberToBytesLE(modP(u), montgomeryBytes);
    }
    function decodeUCoordinate(uEnc) {
        // Section 5: When receiving such an array, implementations of X25519
        // MUST mask the most significant bit in the final byte.
        const u = ensureBytes$1('u coordinate', uEnc, montgomeryBytes);
        if (fieldLen === 32)
            u[31] &= 127; // 0b0111_1111
        return bytesToNumberLE(u);
    }
    function decodeScalar(n) {
        const bytes = ensureBytes$1('scalar', n);
        const len = bytes.length;
        if (len !== montgomeryBytes && len !== fieldLen)
            throw new Error(`Expected ${montgomeryBytes} or ${fieldLen} bytes, got ${len}`);
        return bytesToNumberLE(adjustScalarBytes(bytes));
    }
    function scalarMult(scalar, u) {
        const pointU = decodeUCoordinate(u);
        const _scalar = decodeScalar(scalar);
        const pu = montgomeryLadder(pointU, _scalar);
        // The result was not contributory
        // https://cr.yp.to/ecdh.html#validate
        if (pu === _0n$2)
            throw new Error('Invalid private or public key received');
        return encodeUCoordinate(pu);
    }
    // Computes public key from private. By doing scalar multiplication of base point.
    const GuBytes = encodeUCoordinate(CURVE.Gu);
    function scalarMultBase(scalar) {
        return scalarMult(scalar, GuBytes);
    }
    return {
        scalarMult,
        scalarMultBase,
        getSharedSecret: (privateKey, publicKey) => scalarMult(privateKey, publicKey),
        getPublicKey: (privateKey) => scalarMultBase(privateKey),
        utils: { randomPrivateKey: () => CURVE.randomBytes(CURVE.nByteLength) },
        GuBytes: GuBytes,
    };
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
/**
 * ed25519 Twisted Edwards curve with following addons:
 * - X25519 ECDH
 * - Ristretto cofactor elimination
 * - Elligator hash-to-group / point indistinguishability
 */
const ED25519_P = BigInt('57896044618658097711785492504343953926634992332820282019728792003956564819949');
// √(-1) aka √(a) aka 2^((p-1)/4)
const ED25519_SQRT_M1 = /* @__PURE__ */ BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');
// prettier-ignore
BigInt(0); const _1n$3 = BigInt(1), _2n$2 = BigInt(2), _3n$2 = BigInt(3);
// prettier-ignore
const _5n = BigInt(5), _8n$1 = BigInt(8);
function ed25519_pow_2_252_3(x) {
    // prettier-ignore
    const _10n = BigInt(10), _20n = BigInt(20), _40n = BigInt(40), _80n = BigInt(80);
    const P = ED25519_P;
    const x2 = (x * x) % P;
    const b2 = (x2 * x) % P; // x^3, 11
    const b4 = (pow2$1(b2, _2n$2, P) * b2) % P; // x^15, 1111
    const b5 = (pow2$1(b4, _1n$3, P) * x) % P; // x^31
    const b10 = (pow2$1(b5, _5n, P) * b5) % P;
    const b20 = (pow2$1(b10, _10n, P) * b10) % P;
    const b40 = (pow2$1(b20, _20n, P) * b20) % P;
    const b80 = (pow2$1(b40, _40n, P) * b40) % P;
    const b160 = (pow2$1(b80, _80n, P) * b80) % P;
    const b240 = (pow2$1(b160, _80n, P) * b80) % P;
    const b250 = (pow2$1(b240, _10n, P) * b10) % P;
    const pow_p_5_8 = (pow2$1(b250, _2n$2, P) * x) % P;
    // ^ To pow to (p+3)/8, multiply it by x.
    return { pow_p_5_8, b2 };
}
function adjustScalarBytes(bytes) {
    // Section 5: For X25519, in order to decode 32 random bytes as an integer scalar,
    // set the three least significant bits of the first byte
    bytes[0] &= 248; // 0b1111_1000
    // and the most significant bit of the last to zero,
    bytes[31] &= 127; // 0b0111_1111
    // set the second most significant bit of the last byte to 1
    bytes[31] |= 64; // 0b0100_0000
    return bytes;
}
// sqrt(u/v)
function uvRatio(u, v) {
    const P = ED25519_P;
    const v3 = mod$1(v * v * v, P); // v³
    const v7 = mod$1(v3 * v3 * v, P); // v⁷
    // (p+3)/8 and (p-5)/8
    const pow = ed25519_pow_2_252_3(u * v7).pow_p_5_8;
    let x = mod$1(u * v3 * pow, P); // (uv³)(uv⁷)^(p-5)/8
    const vx2 = mod$1(v * x * x, P); // vx²
    const root1 = x; // First root candidate
    const root2 = mod$1(x * ED25519_SQRT_M1, P); // Second root candidate
    const useRoot1 = vx2 === u; // If vx² = u (mod p), x is a square root
    const useRoot2 = vx2 === mod$1(-u, P); // If vx² = -u, set x <-- x * 2^((p-1)/4)
    const noRoot = vx2 === mod$1(-u * ED25519_SQRT_M1, P); // There is no valid root, vx² = -u√(-1)
    if (useRoot1)
        x = root1;
    if (useRoot2 || noRoot)
        x = root2; // We return root2 anyway, for const-time
    if (isNegativeLE(x, P))
        x = mod$1(-x, P);
    return { isValid: useRoot1 || useRoot2, value: x };
}
const Fp$1 = /* @__PURE__ */ (() => Field(ED25519_P, undefined, true))();
const ed25519Defaults = /* @__PURE__ */ (() => ({
    // Param: a
    a: BigInt(-1), // Fp.create(-1) is proper; our way still works and is faster
    // d is equal to -121665/121666 over finite field.
    // Negative number is P - number, and division is invert(number, P)
    d: BigInt('37095705934669439343138083508754565189542113879843219016388785533085940283555'),
    // Finite field 𝔽p over which we'll do calculations; 2n**255n - 19n
    Fp: Fp$1,
    // Subgroup order: how many points curve has
    // 2n**252n + 27742317777372353535851937790883648493n;
    n: BigInt('7237005577332262213973186563042994240857116359379907606001950938285454250989'),
    // Cofactor
    h: _8n$1,
    // Base point (x, y) aka generator point
    Gx: BigInt('15112221349535400772501151409588531511454012693041857206046113283949847762202'),
    Gy: BigInt('46316835694926478169428394003475163141307993866256225615783033603165251855960'),
    hash: sha512,
    randomBytes: randomBytes$1,
    adjustScalarBytes,
    // dom2
    // Ratio of u to v. Allows us to combine inversion and square root. Uses algo from RFC8032 5.1.3.
    // Constant-time, u/√v
    uvRatio,
}))();
/**
 * ed25519 curve with EdDSA signatures.
 */
const ed25519 = /* @__PURE__ */ (() => twistedEdwards(ed25519Defaults))();
const x25519 = /* @__PURE__ */ (() => montgomery({
    P: ED25519_P,
    a: BigInt(486662),
    montgomeryBits: 255, // n is 253 bits
    nByteLength: 32,
    Gu: BigInt(9),
    powPminus2: (x) => {
        const P = ED25519_P;
        // x^(p-2) aka x^(2^255-21)
        const { pow_p_5_8, b2 } = ed25519_pow_2_252_3(x);
        return mod$1(pow2$1(pow_p_5_8, _3n$2, P) * b2, P);
    },
    adjustScalarBytes,
    randomBytes: randomBytes$1,
}))();

const PUBLIC_KEY_BYTE_LENGTH = 32;
const PRIVATE_KEY_BYTE_LENGTH = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH = 32;
function generateKey$2() {
    // the actual private key (32 bytes)
    const privateKeyRaw = ed25519.utils.randomPrivateKey();
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
function generateKeyFromSeed(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
function hashAndSign$2(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH);
    return ed25519.sign(msg instanceof Uint8Array ? msg : msg.subarray(), privateKeyRaw);
}
function hashAndVerify$2(publicKey, sig, msg) {
    return ed25519.verify(sig, msg instanceof Uint8Array ? msg : msg.subarray(), publicKey);
}
function concatKeys(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH);
    for (let i = 0; i < KEYS_BYTE_LENGTH; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH + i] = publicKey[i];
    }
    return privateKey;
}

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto?.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p/blob/main/packages/crypto/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create(opts) {
    const algorithm = 'AES-GCM';
    let keyLength = 16;
    const nonceLength = 12;
    const digest = 'SHA-256';
    const saltLength = 16;
    const iterations = 32767;
    const crypto = webcrypto.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter(privateKey, password) {
    const cipher = create();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType || (KeyType = {}));
var __KeyTypeValues;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues || (__KeyTypeValues = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues);
    };
})(KeyType || (KeyType = {}));
var PublicKey;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage(buf, PublicKey.codec());
    };
})(PublicKey || (PublicKey = {}));
var PrivateKey;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage(buf, PrivateKey.codec());
    };
})(PrivateKey || (PrivateKey = {}));

class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey(key, PUBLIC_KEY_BYTE_LENGTH);
    }
    verify(data, sig) {
        return hashAndVerify$2(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals(this.bytes, key.bytes);
    }
    hash() {
        const p = sha256$1.digest(this.bytes);
        if (isPromise$3(p)) {
            return p.then(({ bytes }) => bytes);
        }
        return p.bytes;
    }
}
class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey(key, PRIVATE_KEY_BYTE_LENGTH);
        this._publicKey = ensureKey(publicKey, PUBLIC_KEY_BYTE_LENGTH);
    }
    sign(message) {
        return hashAndSign$2(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals(this.bytes, key.bytes);
    }
    async hash() {
        const p = sha256$1.digest(this.bytes);
        let bytes;
        if (isPromise$3(p)) {
            ({ bytes } = await p);
        }
        else {
            bytes = p.bytes;
        }
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity.digest(this.public.bytes);
        return base58btc.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter(this.bytes, password);
        }
        else {
            throw new CodeError$1(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
function unmarshalEd25519PrivateKey(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH) {
        bytes = ensureKey(bytes, PRIVATE_KEY_BYTE_LENGTH + PUBLIC_KEY_BYTE_LENGTH);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH, bytes.length);
        return new Ed25519PrivateKey(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey(bytes, PRIVATE_KEY_BYTE_LENGTH);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PrivateKey(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey(bytes) {
    bytes = ensureKey(bytes, PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PublicKey(bytes);
}
async function generateKeyPair$3() {
    const { privateKey, publicKey } = generateKey$2();
    return new Ed25519PrivateKey(privateKey, publicKey);
}
async function generateKeyPairFromSeed(seed) {
    const { privateKey, publicKey } = generateKeyFromSeed(seed);
    return new Ed25519PrivateKey(privateKey, publicKey);
}
function ensureKey(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$1(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey,
    Ed25519PublicKey: Ed25519PublicKey,
    generateKeyPair: generateKeyPair$3,
    generateKeyPairFromSeed: generateKeyPairFromSeed,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey
});

/**
 * Generates a Uint8Array with length `number` populated by random bytes
 */
function randomBytes(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$1('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return randomBytes$1(length);
}

// HMAC (RFC 2104)
class HMAC extends Hash {
    constructor(hash$1, _key) {
        super();
        this.finished = false;
        this.destroyed = false;
        hash(hash$1);
        const key = toBytes$2(_key);
        this.iHash = hash$1.create();
        if (typeof this.iHash.update !== 'function')
            throw new Error('Expected instance of class which extends utils.Hash');
        this.blockLen = this.iHash.blockLen;
        this.outputLen = this.iHash.outputLen;
        const blockLen = this.blockLen;
        const pad = new Uint8Array(blockLen);
        // blockLen can be bigger than outputLen
        pad.set(key.length > blockLen ? hash$1.create().update(key).digest() : key);
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36;
        this.iHash.update(pad);
        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone
        this.oHash = hash$1.create();
        // Undo internal XOR && apply outer XOR
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36 ^ 0x5c;
        this.oHash.update(pad);
        pad.fill(0);
    }
    update(buf) {
        exists$1(this);
        this.iHash.update(buf);
        return this;
    }
    digestInto(out) {
        exists$1(this);
        bytes$1(out, this.outputLen);
        this.finished = true;
        this.iHash.digestInto(out);
        this.oHash.update(out);
        this.oHash.digestInto(out);
        this.destroy();
    }
    digest() {
        const out = new Uint8Array(this.oHash.outputLen);
        this.digestInto(out);
        return out;
    }
    _cloneInto(to) {
        // Create new instance without calling constructor since key already in state and we don't know it.
        to || (to = Object.create(Object.getPrototypeOf(this), {}));
        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;
        to = to;
        to.finished = finished;
        to.destroyed = destroyed;
        to.blockLen = blockLen;
        to.outputLen = outputLen;
        to.oHash = oHash._cloneInto(to.oHash);
        to.iHash = iHash._cloneInto(to.iHash);
        return to;
    }
    destroy() {
        this.destroyed = true;
        this.oHash.destroy();
        this.iHash.destroy();
    }
}
/**
 * HMAC: RFC2104 message authentication code.
 * @param hash - function that would be used e.g. sha256
 * @param key - message key
 * @param message - message data
 * @example
 * import { hmac } from '@noble/hashes/hmac';
 * import { sha256 } from '@noble/hashes/sha2';
 * const mac1 = hmac(sha256, 'key', 'message');
 */
const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();
hmac.create = (hash, key) => new HMAC(hash, key);

// Common prologue and epilogue for sync/async functions
function pbkdf2Init(hash$1, _password, _salt, _opts) {
    hash(hash$1);
    const opts = checkOpts$1({ dkLen: 32, asyncTick: 10 }, _opts);
    const { c, dkLen, asyncTick } = opts;
    number$2(c);
    number$2(dkLen);
    number$2(asyncTick);
    if (c < 1)
        throw new Error('PBKDF2: iterations (c) should be >= 1');
    const password = toBytes$2(_password);
    const salt = toBytes$2(_salt);
    // DK = PBKDF2(PRF, Password, Salt, c, dkLen);
    const DK = new Uint8Array(dkLen);
    // U1 = PRF(Password, Salt + INT_32_BE(i))
    const PRF = hmac.create(hash$1, password);
    const PRFSalt = PRF._cloneInto().update(salt);
    return { c, dkLen, asyncTick, DK, PRF, PRFSalt };
}
function pbkdf2Output(PRF, PRFSalt, DK, prfW, u) {
    PRF.destroy();
    PRFSalt.destroy();
    if (prfW)
        prfW.destroy();
    u.fill(0);
    return DK;
}
async function pbkdf2Async(hash, password, salt, opts) {
    const { c, dkLen, asyncTick, DK, PRF, PRFSalt } = pbkdf2Init(hash, password, salt, opts);
    let prfW; // Working copy
    const arr = new Uint8Array(4);
    const view = createView$1(arr);
    const u = new Uint8Array(PRF.outputLen);
    // DK = T1 + T2 + ⋯ + Tdklen/hlen
    for (let ti = 1, pos = 0; pos < dkLen; ti++, pos += PRF.outputLen) {
        // Ti = F(Password, Salt, c, i)
        const Ti = DK.subarray(pos, pos + PRF.outputLen);
        view.setInt32(0, ti, false);
        // F(Password, Salt, c, i) = U1 ^ U2 ^ ⋯ ^ Uc
        // U1 = PRF(Password, Salt + INT_32_BE(i))
        (prfW = PRFSalt._cloneInto(prfW)).update(arr).digestInto(u);
        Ti.set(u.subarray(0, Ti.length));
        await asyncLoop(c - 1, asyncTick, () => {
            // Uc = PRF(Password, Uc−1)
            PRF._cloneInto(prfW).update(u).digestInto(u);
            for (let i = 0; i < Ti.length; i++)
                Ti[i] ^= u[i];
        });
    }
    return pbkdf2Output(PRF, PRFSalt, DK, prfW, u);
}

/*!
 * MIT License
 * 
 * Copyright (c) 2017-2022 Peculiar Ventures, LLC
 * 
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 * 
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 * 
 */

const ARRAY_BUFFER_NAME = "[object ArrayBuffer]";
class BufferSourceConverter {
    static isArrayBuffer(data) {
        return Object.prototype.toString.call(data) === ARRAY_BUFFER_NAME;
    }
    static toArrayBuffer(data) {
        if (this.isArrayBuffer(data)) {
            return data;
        }
        if (data.byteLength === data.buffer.byteLength) {
            return data.buffer;
        }
        if (data.byteOffset === 0 && data.byteLength === data.buffer.byteLength) {
            return data.buffer;
        }
        return this.toUint8Array(data.buffer)
            .slice(data.byteOffset, data.byteOffset + data.byteLength)
            .buffer;
    }
    static toUint8Array(data) {
        return this.toView(data, Uint8Array);
    }
    static toView(data, type) {
        if (data.constructor === type) {
            return data;
        }
        if (this.isArrayBuffer(data)) {
            return new type(data);
        }
        if (this.isArrayBufferView(data)) {
            return new type(data.buffer, data.byteOffset, data.byteLength);
        }
        throw new TypeError("The provided value is not of type '(ArrayBuffer or ArrayBufferView)'");
    }
    static isBufferSource(data) {
        return this.isArrayBufferView(data)
            || this.isArrayBuffer(data);
    }
    static isArrayBufferView(data) {
        return ArrayBuffer.isView(data)
            || (data && this.isArrayBuffer(data.buffer));
    }
    static isEqual(a, b) {
        const aView = BufferSourceConverter.toUint8Array(a);
        const bView = BufferSourceConverter.toUint8Array(b);
        if (aView.length !== bView.byteLength) {
            return false;
        }
        for (let i = 0; i < aView.length; i++) {
            if (aView[i] !== bView[i]) {
                return false;
            }
        }
        return true;
    }
    static concat(...args) {
        let buffers;
        if (Array.isArray(args[0]) && !(args[1] instanceof Function)) {
            buffers = args[0];
        }
        else if (Array.isArray(args[0]) && args[1] instanceof Function) {
            buffers = args[0];
        }
        else {
            if (args[args.length - 1] instanceof Function) {
                buffers = args.slice(0, args.length - 1);
            }
            else {
                buffers = args;
            }
        }
        let size = 0;
        for (const buffer of buffers) {
            size += buffer.byteLength;
        }
        const res = new Uint8Array(size);
        let offset = 0;
        for (const buffer of buffers) {
            const view = this.toUint8Array(buffer);
            res.set(view, offset);
            offset += view.length;
        }
        if (args[args.length - 1] instanceof Function) {
            return this.toView(res, args[args.length - 1]);
        }
        return res.buffer;
    }
}

const STRING_TYPE = "string";
const HEX_REGEX = /^[0-9a-f]+$/i;
const BASE64_REGEX = /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/;
const BASE64URL_REGEX = /^[a-zA-Z0-9-_]+$/;
class Utf8Converter {
    static fromString(text) {
        const s = unescape(encodeURIComponent(text));
        const uintArray = new Uint8Array(s.length);
        for (let i = 0; i < s.length; i++) {
            uintArray[i] = s.charCodeAt(i);
        }
        return uintArray.buffer;
    }
    static toString(buffer) {
        const buf = BufferSourceConverter.toUint8Array(buffer);
        let encodedString = "";
        for (let i = 0; i < buf.length; i++) {
            encodedString += String.fromCharCode(buf[i]);
        }
        const decodedString = decodeURIComponent(escape(encodedString));
        return decodedString;
    }
}
class Utf16Converter {
    static toString(buffer, littleEndian = false) {
        const arrayBuffer = BufferSourceConverter.toArrayBuffer(buffer);
        const dataView = new DataView(arrayBuffer);
        let res = "";
        for (let i = 0; i < arrayBuffer.byteLength; i += 2) {
            const code = dataView.getUint16(i, littleEndian);
            res += String.fromCharCode(code);
        }
        return res;
    }
    static fromString(text, littleEndian = false) {
        const res = new ArrayBuffer(text.length * 2);
        const dataView = new DataView(res);
        for (let i = 0; i < text.length; i++) {
            dataView.setUint16(i * 2, text.charCodeAt(i), littleEndian);
        }
        return res;
    }
}
class Convert {
    static isHex(data) {
        return typeof data === STRING_TYPE
            && HEX_REGEX.test(data);
    }
    static isBase64(data) {
        return typeof data === STRING_TYPE
            && BASE64_REGEX.test(data);
    }
    static isBase64Url(data) {
        return typeof data === STRING_TYPE
            && BASE64URL_REGEX.test(data);
    }
    static ToString(buffer, enc = "utf8") {
        const buf = BufferSourceConverter.toUint8Array(buffer);
        switch (enc.toLowerCase()) {
            case "utf8":
                return this.ToUtf8String(buf);
            case "binary":
                return this.ToBinary(buf);
            case "hex":
                return this.ToHex(buf);
            case "base64":
                return this.ToBase64(buf);
            case "base64url":
                return this.ToBase64Url(buf);
            case "utf16le":
                return Utf16Converter.toString(buf, true);
            case "utf16":
            case "utf16be":
                return Utf16Converter.toString(buf);
            default:
                throw new Error(`Unknown type of encoding '${enc}'`);
        }
    }
    static FromString(str, enc = "utf8") {
        if (!str) {
            return new ArrayBuffer(0);
        }
        switch (enc.toLowerCase()) {
            case "utf8":
                return this.FromUtf8String(str);
            case "binary":
                return this.FromBinary(str);
            case "hex":
                return this.FromHex(str);
            case "base64":
                return this.FromBase64(str);
            case "base64url":
                return this.FromBase64Url(str);
            case "utf16le":
                return Utf16Converter.fromString(str, true);
            case "utf16":
            case "utf16be":
                return Utf16Converter.fromString(str);
            default:
                throw new Error(`Unknown type of encoding '${enc}'`);
        }
    }
    static ToBase64(buffer) {
        const buf = BufferSourceConverter.toUint8Array(buffer);
        if (typeof btoa !== "undefined") {
            const binary = this.ToString(buf, "binary");
            return btoa(binary);
        }
        else {
            return Buffer.from(buf).toString("base64");
        }
    }
    static FromBase64(base64) {
        const formatted = this.formatString(base64);
        if (!formatted) {
            return new ArrayBuffer(0);
        }
        if (!Convert.isBase64(formatted)) {
            throw new TypeError("Argument 'base64Text' is not Base64 encoded");
        }
        if (typeof atob !== "undefined") {
            return this.FromBinary(atob(formatted));
        }
        else {
            return new Uint8Array(Buffer.from(formatted, "base64")).buffer;
        }
    }
    static FromBase64Url(base64url) {
        const formatted = this.formatString(base64url);
        if (!formatted) {
            return new ArrayBuffer(0);
        }
        if (!Convert.isBase64Url(formatted)) {
            throw new TypeError("Argument 'base64url' is not Base64Url encoded");
        }
        return this.FromBase64(this.Base64Padding(formatted.replace(/\-/g, "+").replace(/\_/g, "/")));
    }
    static ToBase64Url(data) {
        return this.ToBase64(data).replace(/\+/g, "-").replace(/\//g, "_").replace(/\=/g, "");
    }
    static FromUtf8String(text, encoding = Convert.DEFAULT_UTF8_ENCODING) {
        switch (encoding) {
            case "ascii":
                return this.FromBinary(text);
            case "utf8":
                return Utf8Converter.fromString(text);
            case "utf16":
            case "utf16be":
                return Utf16Converter.fromString(text);
            case "utf16le":
            case "usc2":
                return Utf16Converter.fromString(text, true);
            default:
                throw new Error(`Unknown type of encoding '${encoding}'`);
        }
    }
    static ToUtf8String(buffer, encoding = Convert.DEFAULT_UTF8_ENCODING) {
        switch (encoding) {
            case "ascii":
                return this.ToBinary(buffer);
            case "utf8":
                return Utf8Converter.toString(buffer);
            case "utf16":
            case "utf16be":
                return Utf16Converter.toString(buffer);
            case "utf16le":
            case "usc2":
                return Utf16Converter.toString(buffer, true);
            default:
                throw new Error(`Unknown type of encoding '${encoding}'`);
        }
    }
    static FromBinary(text) {
        const stringLength = text.length;
        const resultView = new Uint8Array(stringLength);
        for (let i = 0; i < stringLength; i++) {
            resultView[i] = text.charCodeAt(i);
        }
        return resultView.buffer;
    }
    static ToBinary(buffer) {
        const buf = BufferSourceConverter.toUint8Array(buffer);
        let res = "";
        for (let i = 0; i < buf.length; i++) {
            res += String.fromCharCode(buf[i]);
        }
        return res;
    }
    static ToHex(buffer) {
        const buf = BufferSourceConverter.toUint8Array(buffer);
        let result = "";
        const len = buf.length;
        for (let i = 0; i < len; i++) {
            const byte = buf[i];
            if (byte < 16) {
                result += "0";
            }
            result += byte.toString(16);
        }
        return result;
    }
    static FromHex(hexString) {
        let formatted = this.formatString(hexString);
        if (!formatted) {
            return new ArrayBuffer(0);
        }
        if (!Convert.isHex(formatted)) {
            throw new TypeError("Argument 'hexString' is not HEX encoded");
        }
        if (formatted.length % 2) {
            formatted = `0${formatted}`;
        }
        const res = new Uint8Array(formatted.length / 2);
        for (let i = 0; i < formatted.length; i = i + 2) {
            const c = formatted.slice(i, i + 2);
            res[i / 2] = parseInt(c, 16);
        }
        return res.buffer;
    }
    static ToUtf16String(buffer, littleEndian = false) {
        return Utf16Converter.toString(buffer, littleEndian);
    }
    static FromUtf16String(text, littleEndian = false) {
        return Utf16Converter.fromString(text, littleEndian);
    }
    static Base64Padding(base64) {
        const padCount = 4 - (base64.length % 4);
        if (padCount < 4) {
            for (let i = 0; i < padCount; i++) {
                base64 += "=";
            }
        }
        return base64;
    }
    static formatString(data) {
        return (data === null || data === void 0 ? void 0 : data.replace(/[\n\r\t ]/g, "")) || "";
    }
}
Convert.DEFAULT_UTF8_ENCODING = "utf8";

var BufferSourceConverter_1 = BufferSourceConverter;
var Convert_1 = Convert;

/*!
 Copyright (c) Peculiar Ventures, LLC
*/

function utilFromBase(inputBuffer, inputBase) {
    let result = 0;
    if (inputBuffer.length === 1) {
        return inputBuffer[0];
    }
    for (let i = (inputBuffer.length - 1); i >= 0; i--) {
        result += inputBuffer[(inputBuffer.length - 1) - i] * Math.pow(2, inputBase * i);
    }
    return result;
}
function utilToBase(value, base, reserved = (-1)) {
    const internalReserved = reserved;
    let internalValue = value;
    let result = 0;
    let biggest = Math.pow(2, base);
    for (let i = 1; i < 8; i++) {
        if (value < biggest) {
            let retBuf;
            if (internalReserved < 0) {
                retBuf = new ArrayBuffer(i);
                result = i;
            }
            else {
                if (internalReserved < i) {
                    return (new ArrayBuffer(0));
                }
                retBuf = new ArrayBuffer(internalReserved);
                result = internalReserved;
            }
            const retView = new Uint8Array(retBuf);
            for (let j = (i - 1); j >= 0; j--) {
                const basis = Math.pow(2, j * base);
                retView[result - j - 1] = Math.floor(internalValue / basis);
                internalValue -= (retView[result - j - 1]) * basis;
            }
            return retBuf;
        }
        biggest *= Math.pow(2, base);
    }
    return new ArrayBuffer(0);
}
function utilConcatView(...views) {
    let outputLength = 0;
    let prevLength = 0;
    for (const view of views) {
        outputLength += view.length;
    }
    const retBuf = new ArrayBuffer(outputLength);
    const retView = new Uint8Array(retBuf);
    for (const view of views) {
        retView.set(view, prevLength);
        prevLength += view.length;
    }
    return retView;
}
function utilDecodeTC() {
    const buf = new Uint8Array(this.valueHex);
    if (this.valueHex.byteLength >= 2) {
        const condition1 = (buf[0] === 0xFF) && (buf[1] & 0x80);
        const condition2 = (buf[0] === 0x00) && ((buf[1] & 0x80) === 0x00);
        if (condition1 || condition2) {
            this.warnings.push("Needlessly long format");
        }
    }
    const bigIntBuffer = new ArrayBuffer(this.valueHex.byteLength);
    const bigIntView = new Uint8Array(bigIntBuffer);
    for (let i = 0; i < this.valueHex.byteLength; i++) {
        bigIntView[i] = 0;
    }
    bigIntView[0] = (buf[0] & 0x80);
    const bigInt = utilFromBase(bigIntView, 8);
    const smallIntBuffer = new ArrayBuffer(this.valueHex.byteLength);
    const smallIntView = new Uint8Array(smallIntBuffer);
    for (let j = 0; j < this.valueHex.byteLength; j++) {
        smallIntView[j] = buf[j];
    }
    smallIntView[0] &= 0x7F;
    const smallInt = utilFromBase(smallIntView, 8);
    return (smallInt - bigInt);
}
function utilEncodeTC(value) {
    const modValue = (value < 0) ? (value * (-1)) : value;
    let bigInt = 128;
    for (let i = 1; i < 8; i++) {
        if (modValue <= bigInt) {
            if (value < 0) {
                const smallInt = bigInt - modValue;
                const retBuf = utilToBase(smallInt, 8, i);
                const retView = new Uint8Array(retBuf);
                retView[0] |= 0x80;
                return retBuf;
            }
            let retBuf = utilToBase(modValue, 8, i);
            let retView = new Uint8Array(retBuf);
            if (retView[0] & 0x80) {
                const tempBuf = retBuf.slice(0);
                const tempView = new Uint8Array(tempBuf);
                retBuf = new ArrayBuffer(retBuf.byteLength + 1);
                retView = new Uint8Array(retBuf);
                for (let k = 0; k < tempBuf.byteLength; k++) {
                    retView[k + 1] = tempView[k];
                }
                retView[0] = 0x00;
            }
            return retBuf;
        }
        bigInt *= Math.pow(2, 8);
    }
    return (new ArrayBuffer(0));
}
function isEqualBuffer(inputBuffer1, inputBuffer2) {
    if (inputBuffer1.byteLength !== inputBuffer2.byteLength) {
        return false;
    }
    const view1 = new Uint8Array(inputBuffer1);
    const view2 = new Uint8Array(inputBuffer2);
    for (let i = 0; i < view1.length; i++) {
        if (view1[i] !== view2[i]) {
            return false;
        }
    }
    return true;
}
function padNumber(inputNumber, fullLength) {
    const str = inputNumber.toString(10);
    if (fullLength < str.length) {
        return "";
    }
    const dif = fullLength - str.length;
    const padding = new Array(dif);
    for (let i = 0; i < dif; i++) {
        padding[i] = "0";
    }
    const paddingString = padding.join("");
    return paddingString.concat(str);
}

/*!
 * Copyright (c) 2014, GMO GlobalSign
 * Copyright (c) 2015-2022, Peculiar Ventures
 * All rights reserved.
 * 
 * Author 2014-2019, Yury Strozhevsky
 * 
 * Redistribution and use in source and binary forms, with or without modification,
 * are permitted provided that the following conditions are met:
 * 
 * * Redistributions of source code must retain the above copyright notice, this
 *   list of conditions and the following disclaimer.
 * 
 * * Redistributions in binary form must reproduce the above copyright notice, this
 *   list of conditions and the following disclaimer in the documentation and/or
 *   other materials provided with the distribution.
 * 
 * * Neither the name of the copyright holder nor the names of its
 *   contributors may be used to endorse or promote products derived from
 *   this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 * 
 */


function assertBigInt() {
    if (typeof BigInt === "undefined") {
        throw new Error("BigInt is not defined. Your environment doesn't implement BigInt.");
    }
}
function concat(buffers) {
    let outputLength = 0;
    let prevLength = 0;
    for (let i = 0; i < buffers.length; i++) {
        const buffer = buffers[i];
        outputLength += buffer.byteLength;
    }
    const retView = new Uint8Array(outputLength);
    for (let i = 0; i < buffers.length; i++) {
        const buffer = buffers[i];
        retView.set(new Uint8Array(buffer), prevLength);
        prevLength += buffer.byteLength;
    }
    return retView.buffer;
}
function checkBufferParams(baseBlock, inputBuffer, inputOffset, inputLength) {
    if (!(inputBuffer instanceof Uint8Array)) {
        baseBlock.error = "Wrong parameter: inputBuffer must be 'Uint8Array'";
        return false;
    }
    if (!inputBuffer.byteLength) {
        baseBlock.error = "Wrong parameter: inputBuffer has zero length";
        return false;
    }
    if (inputOffset < 0) {
        baseBlock.error = "Wrong parameter: inputOffset less than zero";
        return false;
    }
    if (inputLength < 0) {
        baseBlock.error = "Wrong parameter: inputLength less than zero";
        return false;
    }
    if ((inputBuffer.byteLength - inputOffset - inputLength) < 0) {
        baseBlock.error = "End of input reached before message was fully decoded (inconsistent offset and length values)";
        return false;
    }
    return true;
}

class ViewWriter {
    constructor() {
        this.items = [];
    }
    write(buf) {
        this.items.push(buf);
    }
    final() {
        return concat(this.items);
    }
}

const powers2 = [new Uint8Array([1])];
const digitsString = "0123456789";
const EMPTY_STRING = "";
const EMPTY_BUFFER$1 = new ArrayBuffer(0);
const EMPTY_VIEW = new Uint8Array(0);
const END_OF_CONTENT_NAME = "EndOfContent";
const OCTET_STRING_NAME = "OCTET STRING";
const BIT_STRING_NAME = "BIT STRING";

function HexBlock(BaseClass) {
    var _a;
    return _a = class Some extends BaseClass {
            constructor(...args) {
                var _a;
                super(...args);
                const params = args[0] || {};
                this.isHexOnly = (_a = params.isHexOnly) !== null && _a !== void 0 ? _a : false;
                this.valueHexView = params.valueHex ? BufferSourceConverter_1.toUint8Array(params.valueHex) : EMPTY_VIEW;
            }
            get valueHex() {
                return this.valueHexView.slice().buffer;
            }
            set valueHex(value) {
                this.valueHexView = new Uint8Array(value);
            }
            fromBER(inputBuffer, inputOffset, inputLength) {
                const view = inputBuffer instanceof ArrayBuffer ? new Uint8Array(inputBuffer) : inputBuffer;
                if (!checkBufferParams(this, view, inputOffset, inputLength)) {
                    return -1;
                }
                const endLength = inputOffset + inputLength;
                this.valueHexView = view.subarray(inputOffset, endLength);
                if (!this.valueHexView.length) {
                    this.warnings.push("Zero buffer length");
                    return inputOffset;
                }
                this.blockLength = inputLength;
                return endLength;
            }
            toBER(sizeOnly = false) {
                if (!this.isHexOnly) {
                    this.error = "Flag 'isHexOnly' is not set, abort";
                    return EMPTY_BUFFER$1;
                }
                if (sizeOnly) {
                    return new ArrayBuffer(this.valueHexView.byteLength);
                }
                return (this.valueHexView.byteLength === this.valueHexView.buffer.byteLength)
                    ? this.valueHexView.buffer
                    : this.valueHexView.slice().buffer;
            }
            toJSON() {
                return {
                    ...super.toJSON(),
                    isHexOnly: this.isHexOnly,
                    valueHex: Convert_1.ToHex(this.valueHexView),
                };
            }
        },
        _a.NAME = "hexBlock",
        _a;
}

class LocalBaseBlock {
    constructor({ blockLength = 0, error = EMPTY_STRING, warnings = [], valueBeforeDecode = EMPTY_VIEW, } = {}) {
        this.blockLength = blockLength;
        this.error = error;
        this.warnings = warnings;
        this.valueBeforeDecodeView = BufferSourceConverter_1.toUint8Array(valueBeforeDecode);
    }
    static blockName() {
        return this.NAME;
    }
    get valueBeforeDecode() {
        return this.valueBeforeDecodeView.slice().buffer;
    }
    set valueBeforeDecode(value) {
        this.valueBeforeDecodeView = new Uint8Array(value);
    }
    toJSON() {
        return {
            blockName: this.constructor.NAME,
            blockLength: this.blockLength,
            error: this.error,
            warnings: this.warnings,
            valueBeforeDecode: Convert_1.ToHex(this.valueBeforeDecodeView),
        };
    }
}
LocalBaseBlock.NAME = "baseBlock";

class ValueBlock extends LocalBaseBlock {
    fromBER(inputBuffer, inputOffset, inputLength) {
        throw TypeError("User need to make a specific function in a class which extends 'ValueBlock'");
    }
    toBER(sizeOnly, writer) {
        throw TypeError("User need to make a specific function in a class which extends 'ValueBlock'");
    }
}
ValueBlock.NAME = "valueBlock";

class LocalIdentificationBlock extends HexBlock(LocalBaseBlock) {
    constructor({ idBlock = {}, } = {}) {
        var _a, _b, _c, _d;
        super();
        if (idBlock) {
            this.isHexOnly = (_a = idBlock.isHexOnly) !== null && _a !== void 0 ? _a : false;
            this.valueHexView = idBlock.valueHex ? BufferSourceConverter_1.toUint8Array(idBlock.valueHex) : EMPTY_VIEW;
            this.tagClass = (_b = idBlock.tagClass) !== null && _b !== void 0 ? _b : -1;
            this.tagNumber = (_c = idBlock.tagNumber) !== null && _c !== void 0 ? _c : -1;
            this.isConstructed = (_d = idBlock.isConstructed) !== null && _d !== void 0 ? _d : false;
        }
        else {
            this.tagClass = -1;
            this.tagNumber = -1;
            this.isConstructed = false;
        }
    }
    toBER(sizeOnly = false) {
        let firstOctet = 0;
        switch (this.tagClass) {
            case 1:
                firstOctet |= 0x00;
                break;
            case 2:
                firstOctet |= 0x40;
                break;
            case 3:
                firstOctet |= 0x80;
                break;
            case 4:
                firstOctet |= 0xC0;
                break;
            default:
                this.error = "Unknown tag class";
                return EMPTY_BUFFER$1;
        }
        if (this.isConstructed)
            firstOctet |= 0x20;
        if (this.tagNumber < 31 && !this.isHexOnly) {
            const retView = new Uint8Array(1);
            if (!sizeOnly) {
                let number = this.tagNumber;
                number &= 0x1F;
                firstOctet |= number;
                retView[0] = firstOctet;
            }
            return retView.buffer;
        }
        if (!this.isHexOnly) {
            const encodedBuf = utilToBase(this.tagNumber, 7);
            const encodedView = new Uint8Array(encodedBuf);
            const size = encodedBuf.byteLength;
            const retView = new Uint8Array(size + 1);
            retView[0] = (firstOctet | 0x1F);
            if (!sizeOnly) {
                for (let i = 0; i < (size - 1); i++)
                    retView[i + 1] = encodedView[i] | 0x80;
                retView[size] = encodedView[size - 1];
            }
            return retView.buffer;
        }
        const retView = new Uint8Array(this.valueHexView.byteLength + 1);
        retView[0] = (firstOctet | 0x1F);
        if (!sizeOnly) {
            const curView = this.valueHexView;
            for (let i = 0; i < (curView.length - 1); i++)
                retView[i + 1] = curView[i] | 0x80;
            retView[this.valueHexView.byteLength] = curView[curView.length - 1];
        }
        return retView.buffer;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const inputView = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {
            return -1;
        }
        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);
        if (intBuffer.length === 0) {
            this.error = "Zero buffer length";
            return -1;
        }
        const tagClassMask = intBuffer[0] & 0xC0;
        switch (tagClassMask) {
            case 0x00:
                this.tagClass = (1);
                break;
            case 0x40:
                this.tagClass = (2);
                break;
            case 0x80:
                this.tagClass = (3);
                break;
            case 0xC0:
                this.tagClass = (4);
                break;
            default:
                this.error = "Unknown tag class";
                return -1;
        }
        this.isConstructed = (intBuffer[0] & 0x20) === 0x20;
        this.isHexOnly = false;
        const tagNumberMask = intBuffer[0] & 0x1F;
        if (tagNumberMask !== 0x1F) {
            this.tagNumber = (tagNumberMask);
            this.blockLength = 1;
        }
        else {
            let count = 1;
            let intTagNumberBuffer = this.valueHexView = new Uint8Array(255);
            let tagNumberBufferMaxLength = 255;
            while (intBuffer[count] & 0x80) {
                intTagNumberBuffer[count - 1] = intBuffer[count] & 0x7F;
                count++;
                if (count >= intBuffer.length) {
                    this.error = "End of input reached before message was fully decoded";
                    return -1;
                }
                if (count === tagNumberBufferMaxLength) {
                    tagNumberBufferMaxLength += 255;
                    const tempBufferView = new Uint8Array(tagNumberBufferMaxLength);
                    for (let i = 0; i < intTagNumberBuffer.length; i++)
                        tempBufferView[i] = intTagNumberBuffer[i];
                    intTagNumberBuffer = this.valueHexView = new Uint8Array(tagNumberBufferMaxLength);
                }
            }
            this.blockLength = (count + 1);
            intTagNumberBuffer[count - 1] = intBuffer[count] & 0x7F;
            const tempBufferView = new Uint8Array(count);
            for (let i = 0; i < count; i++)
                tempBufferView[i] = intTagNumberBuffer[i];
            intTagNumberBuffer = this.valueHexView = new Uint8Array(count);
            intTagNumberBuffer.set(tempBufferView);
            if (this.blockLength <= 9)
                this.tagNumber = utilFromBase(intTagNumberBuffer, 7);
            else {
                this.isHexOnly = true;
                this.warnings.push("Tag too long, represented as hex-coded");
            }
        }
        if (((this.tagClass === 1)) &&
            (this.isConstructed)) {
            switch (this.tagNumber) {
                case 1:
                case 2:
                case 5:
                case 6:
                case 9:
                case 13:
                case 14:
                case 23:
                case 24:
                case 31:
                case 32:
                case 33:
                case 34:
                    this.error = "Constructed encoding used for primitive type";
                    return -1;
            }
        }
        return (inputOffset + this.blockLength);
    }
    toJSON() {
        return {
            ...super.toJSON(),
            tagClass: this.tagClass,
            tagNumber: this.tagNumber,
            isConstructed: this.isConstructed,
        };
    }
}
LocalIdentificationBlock.NAME = "identificationBlock";

class LocalLengthBlock extends LocalBaseBlock {
    constructor({ lenBlock = {}, } = {}) {
        var _a, _b, _c;
        super();
        this.isIndefiniteForm = (_a = lenBlock.isIndefiniteForm) !== null && _a !== void 0 ? _a : false;
        this.longFormUsed = (_b = lenBlock.longFormUsed) !== null && _b !== void 0 ? _b : false;
        this.length = (_c = lenBlock.length) !== null && _c !== void 0 ? _c : 0;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const view = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, view, inputOffset, inputLength)) {
            return -1;
        }
        const intBuffer = view.subarray(inputOffset, inputOffset + inputLength);
        if (intBuffer.length === 0) {
            this.error = "Zero buffer length";
            return -1;
        }
        if (intBuffer[0] === 0xFF) {
            this.error = "Length block 0xFF is reserved by standard";
            return -1;
        }
        this.isIndefiniteForm = intBuffer[0] === 0x80;
        if (this.isIndefiniteForm) {
            this.blockLength = 1;
            return (inputOffset + this.blockLength);
        }
        this.longFormUsed = !!(intBuffer[0] & 0x80);
        if (this.longFormUsed === false) {
            this.length = (intBuffer[0]);
            this.blockLength = 1;
            return (inputOffset + this.blockLength);
        }
        const count = intBuffer[0] & 0x7F;
        if (count > 8) {
            this.error = "Too big integer";
            return -1;
        }
        if ((count + 1) > intBuffer.length) {
            this.error = "End of input reached before message was fully decoded";
            return -1;
        }
        const lenOffset = inputOffset + 1;
        const lengthBufferView = view.subarray(lenOffset, lenOffset + count);
        if (lengthBufferView[count - 1] === 0x00)
            this.warnings.push("Needlessly long encoded length");
        this.length = utilFromBase(lengthBufferView, 8);
        if (this.longFormUsed && (this.length <= 127))
            this.warnings.push("Unnecessary usage of long length form");
        this.blockLength = count + 1;
        return (inputOffset + this.blockLength);
    }
    toBER(sizeOnly = false) {
        let retBuf;
        let retView;
        if (this.length > 127)
            this.longFormUsed = true;
        if (this.isIndefiniteForm) {
            retBuf = new ArrayBuffer(1);
            if (sizeOnly === false) {
                retView = new Uint8Array(retBuf);
                retView[0] = 0x80;
            }
            return retBuf;
        }
        if (this.longFormUsed) {
            const encodedBuf = utilToBase(this.length, 8);
            if (encodedBuf.byteLength > 127) {
                this.error = "Too big length";
                return (EMPTY_BUFFER$1);
            }
            retBuf = new ArrayBuffer(encodedBuf.byteLength + 1);
            if (sizeOnly)
                return retBuf;
            const encodedView = new Uint8Array(encodedBuf);
            retView = new Uint8Array(retBuf);
            retView[0] = encodedBuf.byteLength | 0x80;
            for (let i = 0; i < encodedBuf.byteLength; i++)
                retView[i + 1] = encodedView[i];
            return retBuf;
        }
        retBuf = new ArrayBuffer(1);
        if (sizeOnly === false) {
            retView = new Uint8Array(retBuf);
            retView[0] = this.length;
        }
        return retBuf;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            isIndefiniteForm: this.isIndefiniteForm,
            longFormUsed: this.longFormUsed,
            length: this.length,
        };
    }
}
LocalLengthBlock.NAME = "lengthBlock";

const typeStore = {};

class BaseBlock extends LocalBaseBlock {
    constructor({ name = EMPTY_STRING, optional = false, primitiveSchema, ...parameters } = {}, valueBlockType) {
        super(parameters);
        this.name = name;
        this.optional = optional;
        if (primitiveSchema) {
            this.primitiveSchema = primitiveSchema;
        }
        this.idBlock = new LocalIdentificationBlock(parameters);
        this.lenBlock = new LocalLengthBlock(parameters);
        this.valueBlock = valueBlockType ? new valueBlockType(parameters) : new ValueBlock(parameters);
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const resultOffset = this.valueBlock.fromBER(inputBuffer, inputOffset, (this.lenBlock.isIndefiniteForm) ? inputLength : this.lenBlock.length);
        if (resultOffset === -1) {
            this.error = this.valueBlock.error;
            return resultOffset;
        }
        if (!this.idBlock.error.length)
            this.blockLength += this.idBlock.blockLength;
        if (!this.lenBlock.error.length)
            this.blockLength += this.lenBlock.blockLength;
        if (!this.valueBlock.error.length)
            this.blockLength += this.valueBlock.blockLength;
        return resultOffset;
    }
    toBER(sizeOnly, writer) {
        const _writer = writer || new ViewWriter();
        if (!writer) {
            prepareIndefiniteForm(this);
        }
        const idBlockBuf = this.idBlock.toBER(sizeOnly);
        _writer.write(idBlockBuf);
        if (this.lenBlock.isIndefiniteForm) {
            _writer.write(new Uint8Array([0x80]).buffer);
            this.valueBlock.toBER(sizeOnly, _writer);
            _writer.write(new ArrayBuffer(2));
        }
        else {
            const valueBlockBuf = this.valueBlock.toBER(sizeOnly);
            this.lenBlock.length = valueBlockBuf.byteLength;
            const lenBlockBuf = this.lenBlock.toBER(sizeOnly);
            _writer.write(lenBlockBuf);
            _writer.write(valueBlockBuf);
        }
        if (!writer) {
            return _writer.final();
        }
        return EMPTY_BUFFER$1;
    }
    toJSON() {
        const object = {
            ...super.toJSON(),
            idBlock: this.idBlock.toJSON(),
            lenBlock: this.lenBlock.toJSON(),
            valueBlock: this.valueBlock.toJSON(),
            name: this.name,
            optional: this.optional,
        };
        if (this.primitiveSchema)
            object.primitiveSchema = this.primitiveSchema.toJSON();
        return object;
    }
    toString(encoding = "ascii") {
        if (encoding === "ascii") {
            return this.onAsciiEncoding();
        }
        return Convert_1.ToHex(this.toBER());
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : ${Convert_1.ToHex(this.valueBlock.valueBeforeDecodeView)}`;
    }
    isEqual(other) {
        if (this === other) {
            return true;
        }
        if (!(other instanceof this.constructor)) {
            return false;
        }
        const thisRaw = this.toBER();
        const otherRaw = other.toBER();
        return isEqualBuffer(thisRaw, otherRaw);
    }
}
BaseBlock.NAME = "BaseBlock";
function prepareIndefiniteForm(baseBlock) {
    if (baseBlock instanceof typeStore.Constructed) {
        for (const value of baseBlock.valueBlock.value) {
            if (prepareIndefiniteForm(value)) {
                baseBlock.lenBlock.isIndefiniteForm = true;
            }
        }
    }
    return !!baseBlock.lenBlock.isIndefiniteForm;
}

class BaseStringBlock extends BaseBlock {
    constructor({ value = EMPTY_STRING, ...parameters } = {}, stringValueBlockType) {
        super(parameters, stringValueBlockType);
        if (value) {
            this.fromString(value);
        }
    }
    getValue() {
        return this.valueBlock.value;
    }
    setValue(value) {
        this.valueBlock.value = value;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const resultOffset = this.valueBlock.fromBER(inputBuffer, inputOffset, (this.lenBlock.isIndefiniteForm) ? inputLength : this.lenBlock.length);
        if (resultOffset === -1) {
            this.error = this.valueBlock.error;
            return resultOffset;
        }
        this.fromBuffer(this.valueBlock.valueHexView);
        if (!this.idBlock.error.length)
            this.blockLength += this.idBlock.blockLength;
        if (!this.lenBlock.error.length)
            this.blockLength += this.lenBlock.blockLength;
        if (!this.valueBlock.error.length)
            this.blockLength += this.valueBlock.blockLength;
        return resultOffset;
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : '${this.valueBlock.value}'`;
    }
}
BaseStringBlock.NAME = "BaseStringBlock";

class LocalPrimitiveValueBlock extends HexBlock(ValueBlock) {
    constructor({ isHexOnly = true, ...parameters } = {}) {
        super(parameters);
        this.isHexOnly = isHexOnly;
    }
}
LocalPrimitiveValueBlock.NAME = "PrimitiveValueBlock";

var _a$w;
class Primitive extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalPrimitiveValueBlock);
        this.idBlock.isConstructed = false;
    }
}
_a$w = Primitive;
(() => {
    typeStore.Primitive = _a$w;
})();
Primitive.NAME = "PRIMITIVE";

function localChangeType(inputObject, newType) {
    if (inputObject instanceof newType) {
        return inputObject;
    }
    const newObject = new newType();
    newObject.idBlock = inputObject.idBlock;
    newObject.lenBlock = inputObject.lenBlock;
    newObject.warnings = inputObject.warnings;
    newObject.valueBeforeDecodeView = inputObject.valueBeforeDecodeView;
    return newObject;
}
function localFromBER(inputBuffer, inputOffset = 0, inputLength = inputBuffer.length) {
    const incomingOffset = inputOffset;
    let returnObject = new BaseBlock({}, ValueBlock);
    const baseBlock = new LocalBaseBlock();
    if (!checkBufferParams(baseBlock, inputBuffer, inputOffset, inputLength)) {
        returnObject.error = baseBlock.error;
        return {
            offset: -1,
            result: returnObject
        };
    }
    const intBuffer = inputBuffer.subarray(inputOffset, inputOffset + inputLength);
    if (!intBuffer.length) {
        returnObject.error = "Zero buffer length";
        return {
            offset: -1,
            result: returnObject
        };
    }
    let resultOffset = returnObject.idBlock.fromBER(inputBuffer, inputOffset, inputLength);
    if (returnObject.idBlock.warnings.length) {
        returnObject.warnings.concat(returnObject.idBlock.warnings);
    }
    if (resultOffset === -1) {
        returnObject.error = returnObject.idBlock.error;
        return {
            offset: -1,
            result: returnObject
        };
    }
    inputOffset = resultOffset;
    inputLength -= returnObject.idBlock.blockLength;
    resultOffset = returnObject.lenBlock.fromBER(inputBuffer, inputOffset, inputLength);
    if (returnObject.lenBlock.warnings.length) {
        returnObject.warnings.concat(returnObject.lenBlock.warnings);
    }
    if (resultOffset === -1) {
        returnObject.error = returnObject.lenBlock.error;
        return {
            offset: -1,
            result: returnObject
        };
    }
    inputOffset = resultOffset;
    inputLength -= returnObject.lenBlock.blockLength;
    if (!returnObject.idBlock.isConstructed &&
        returnObject.lenBlock.isIndefiniteForm) {
        returnObject.error = "Indefinite length form used for primitive encoding form";
        return {
            offset: -1,
            result: returnObject
        };
    }
    let newASN1Type = BaseBlock;
    switch (returnObject.idBlock.tagClass) {
        case 1:
            if ((returnObject.idBlock.tagNumber >= 37) &&
                (returnObject.idBlock.isHexOnly === false)) {
                returnObject.error = "UNIVERSAL 37 and upper tags are reserved by ASN.1 standard";
                return {
                    offset: -1,
                    result: returnObject
                };
            }
            switch (returnObject.idBlock.tagNumber) {
                case 0:
                    if ((returnObject.idBlock.isConstructed) &&
                        (returnObject.lenBlock.length > 0)) {
                        returnObject.error = "Type [UNIVERSAL 0] is reserved";
                        return {
                            offset: -1,
                            result: returnObject
                        };
                    }
                    newASN1Type = typeStore.EndOfContent;
                    break;
                case 1:
                    newASN1Type = typeStore.Boolean;
                    break;
                case 2:
                    newASN1Type = typeStore.Integer;
                    break;
                case 3:
                    newASN1Type = typeStore.BitString;
                    break;
                case 4:
                    newASN1Type = typeStore.OctetString;
                    break;
                case 5:
                    newASN1Type = typeStore.Null;
                    break;
                case 6:
                    newASN1Type = typeStore.ObjectIdentifier;
                    break;
                case 10:
                    newASN1Type = typeStore.Enumerated;
                    break;
                case 12:
                    newASN1Type = typeStore.Utf8String;
                    break;
                case 13:
                    newASN1Type = typeStore.RelativeObjectIdentifier;
                    break;
                case 14:
                    newASN1Type = typeStore.TIME;
                    break;
                case 15:
                    returnObject.error = "[UNIVERSAL 15] is reserved by ASN.1 standard";
                    return {
                        offset: -1,
                        result: returnObject
                    };
                case 16:
                    newASN1Type = typeStore.Sequence;
                    break;
                case 17:
                    newASN1Type = typeStore.Set;
                    break;
                case 18:
                    newASN1Type = typeStore.NumericString;
                    break;
                case 19:
                    newASN1Type = typeStore.PrintableString;
                    break;
                case 20:
                    newASN1Type = typeStore.TeletexString;
                    break;
                case 21:
                    newASN1Type = typeStore.VideotexString;
                    break;
                case 22:
                    newASN1Type = typeStore.IA5String;
                    break;
                case 23:
                    newASN1Type = typeStore.UTCTime;
                    break;
                case 24:
                    newASN1Type = typeStore.GeneralizedTime;
                    break;
                case 25:
                    newASN1Type = typeStore.GraphicString;
                    break;
                case 26:
                    newASN1Type = typeStore.VisibleString;
                    break;
                case 27:
                    newASN1Type = typeStore.GeneralString;
                    break;
                case 28:
                    newASN1Type = typeStore.UniversalString;
                    break;
                case 29:
                    newASN1Type = typeStore.CharacterString;
                    break;
                case 30:
                    newASN1Type = typeStore.BmpString;
                    break;
                case 31:
                    newASN1Type = typeStore.DATE;
                    break;
                case 32:
                    newASN1Type = typeStore.TimeOfDay;
                    break;
                case 33:
                    newASN1Type = typeStore.DateTime;
                    break;
                case 34:
                    newASN1Type = typeStore.Duration;
                    break;
                default: {
                    const newObject = returnObject.idBlock.isConstructed
                        ? new typeStore.Constructed()
                        : new typeStore.Primitive();
                    newObject.idBlock = returnObject.idBlock;
                    newObject.lenBlock = returnObject.lenBlock;
                    newObject.warnings = returnObject.warnings;
                    returnObject = newObject;
                }
            }
            break;
        case 2:
        case 3:
        case 4:
        default: {
            newASN1Type = returnObject.idBlock.isConstructed
                ? typeStore.Constructed
                : typeStore.Primitive;
        }
    }
    returnObject = localChangeType(returnObject, newASN1Type);
    resultOffset = returnObject.fromBER(inputBuffer, inputOffset, returnObject.lenBlock.isIndefiniteForm ? inputLength : returnObject.lenBlock.length);
    returnObject.valueBeforeDecodeView = inputBuffer.subarray(incomingOffset, incomingOffset + returnObject.blockLength);
    return {
        offset: resultOffset,
        result: returnObject
    };
}
function fromBER(inputBuffer) {
    if (!inputBuffer.byteLength) {
        const result = new BaseBlock({}, ValueBlock);
        result.error = "Input buffer has zero length";
        return {
            offset: -1,
            result
        };
    }
    return localFromBER(BufferSourceConverter_1.toUint8Array(inputBuffer).slice(), 0, inputBuffer.byteLength);
}

function checkLen(indefiniteLength, length) {
    if (indefiniteLength) {
        return 1;
    }
    return length;
}
class LocalConstructedValueBlock extends ValueBlock {
    constructor({ value = [], isIndefiniteForm = false, ...parameters } = {}) {
        super(parameters);
        this.value = value;
        this.isIndefiniteForm = isIndefiniteForm;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const view = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, view, inputOffset, inputLength)) {
            return -1;
        }
        this.valueBeforeDecodeView = view.subarray(inputOffset, inputOffset + inputLength);
        if (this.valueBeforeDecodeView.length === 0) {
            this.warnings.push("Zero buffer length");
            return inputOffset;
        }
        let currentOffset = inputOffset;
        while (checkLen(this.isIndefiniteForm, inputLength) > 0) {
            const returnObject = localFromBER(view, currentOffset, inputLength);
            if (returnObject.offset === -1) {
                this.error = returnObject.result.error;
                this.warnings.concat(returnObject.result.warnings);
                return -1;
            }
            currentOffset = returnObject.offset;
            this.blockLength += returnObject.result.blockLength;
            inputLength -= returnObject.result.blockLength;
            this.value.push(returnObject.result);
            if (this.isIndefiniteForm && returnObject.result.constructor.NAME === END_OF_CONTENT_NAME) {
                break;
            }
        }
        if (this.isIndefiniteForm) {
            if (this.value[this.value.length - 1].constructor.NAME === END_OF_CONTENT_NAME) {
                this.value.pop();
            }
            else {
                this.warnings.push("No EndOfContent block encoded");
            }
        }
        return currentOffset;
    }
    toBER(sizeOnly, writer) {
        const _writer = writer || new ViewWriter();
        for (let i = 0; i < this.value.length; i++) {
            this.value[i].toBER(sizeOnly, _writer);
        }
        if (!writer) {
            return _writer.final();
        }
        return EMPTY_BUFFER$1;
    }
    toJSON() {
        const object = {
            ...super.toJSON(),
            isIndefiniteForm: this.isIndefiniteForm,
            value: [],
        };
        for (const value of this.value) {
            object.value.push(value.toJSON());
        }
        return object;
    }
}
LocalConstructedValueBlock.NAME = "ConstructedValueBlock";

var _a$v;
class Constructed extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalConstructedValueBlock);
        this.idBlock.isConstructed = true;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        this.valueBlock.isIndefiniteForm = this.lenBlock.isIndefiniteForm;
        const resultOffset = this.valueBlock.fromBER(inputBuffer, inputOffset, (this.lenBlock.isIndefiniteForm) ? inputLength : this.lenBlock.length);
        if (resultOffset === -1) {
            this.error = this.valueBlock.error;
            return resultOffset;
        }
        if (!this.idBlock.error.length)
            this.blockLength += this.idBlock.blockLength;
        if (!this.lenBlock.error.length)
            this.blockLength += this.lenBlock.blockLength;
        if (!this.valueBlock.error.length)
            this.blockLength += this.valueBlock.blockLength;
        return resultOffset;
    }
    onAsciiEncoding() {
        const values = [];
        for (const value of this.valueBlock.value) {
            values.push(value.toString("ascii").split("\n").map(o => `  ${o}`).join("\n"));
        }
        const blockName = this.idBlock.tagClass === 3
            ? `[${this.idBlock.tagNumber}]`
            : this.constructor.NAME;
        return values.length
            ? `${blockName} :\n${values.join("\n")}`
            : `${blockName} :`;
    }
}
_a$v = Constructed;
(() => {
    typeStore.Constructed = _a$v;
})();
Constructed.NAME = "CONSTRUCTED";

class LocalEndOfContentValueBlock extends ValueBlock {
    fromBER(inputBuffer, inputOffset, inputLength) {
        return inputOffset;
    }
    toBER(sizeOnly) {
        return EMPTY_BUFFER$1;
    }
}
LocalEndOfContentValueBlock.override = "EndOfContentValueBlock";

var _a$u;
class EndOfContent extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalEndOfContentValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 0;
    }
}
_a$u = EndOfContent;
(() => {
    typeStore.EndOfContent = _a$u;
})();
EndOfContent.NAME = END_OF_CONTENT_NAME;

var _a$t;
class Null extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, ValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 5;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        if (this.lenBlock.length > 0)
            this.warnings.push("Non-zero length of value block for Null type");
        if (!this.idBlock.error.length)
            this.blockLength += this.idBlock.blockLength;
        if (!this.lenBlock.error.length)
            this.blockLength += this.lenBlock.blockLength;
        this.blockLength += inputLength;
        if ((inputOffset + inputLength) > inputBuffer.byteLength) {
            this.error = "End of input reached before message was fully decoded (inconsistent offset and length values)";
            return -1;
        }
        return (inputOffset + inputLength);
    }
    toBER(sizeOnly, writer) {
        const retBuf = new ArrayBuffer(2);
        if (!sizeOnly) {
            const retView = new Uint8Array(retBuf);
            retView[0] = 0x05;
            retView[1] = 0x00;
        }
        if (writer) {
            writer.write(retBuf);
        }
        return retBuf;
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME}`;
    }
}
_a$t = Null;
(() => {
    typeStore.Null = _a$t;
})();
Null.NAME = "NULL";

class LocalBooleanValueBlock extends HexBlock(ValueBlock) {
    constructor({ value, ...parameters } = {}) {
        super(parameters);
        if (parameters.valueHex) {
            this.valueHexView = BufferSourceConverter_1.toUint8Array(parameters.valueHex);
        }
        else {
            this.valueHexView = new Uint8Array(1);
        }
        if (value) {
            this.value = value;
        }
    }
    get value() {
        for (const octet of this.valueHexView) {
            if (octet > 0) {
                return true;
            }
        }
        return false;
    }
    set value(value) {
        this.valueHexView[0] = value ? 0xFF : 0x00;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const inputView = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {
            return -1;
        }
        this.valueHexView = inputView.subarray(inputOffset, inputOffset + inputLength);
        if (inputLength > 1)
            this.warnings.push("Boolean value encoded in more then 1 octet");
        this.isHexOnly = true;
        utilDecodeTC.call(this);
        this.blockLength = inputLength;
        return (inputOffset + inputLength);
    }
    toBER() {
        return this.valueHexView.slice();
    }
    toJSON() {
        return {
            ...super.toJSON(),
            value: this.value,
        };
    }
}
LocalBooleanValueBlock.NAME = "BooleanValueBlock";

var _a$s;
let Boolean$1 = class Boolean extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalBooleanValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 1;
    }
    getValue() {
        return this.valueBlock.value;
    }
    setValue(value) {
        this.valueBlock.value = value;
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : ${this.getValue}`;
    }
};
_a$s = Boolean$1;
(() => {
    typeStore.Boolean = _a$s;
})();
Boolean$1.NAME = "BOOLEAN";

class LocalOctetStringValueBlock extends HexBlock(LocalConstructedValueBlock) {
    constructor({ isConstructed = false, ...parameters } = {}) {
        super(parameters);
        this.isConstructed = isConstructed;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        let resultOffset = 0;
        if (this.isConstructed) {
            this.isHexOnly = false;
            resultOffset = LocalConstructedValueBlock.prototype.fromBER.call(this, inputBuffer, inputOffset, inputLength);
            if (resultOffset === -1)
                return resultOffset;
            for (let i = 0; i < this.value.length; i++) {
                const currentBlockName = this.value[i].constructor.NAME;
                if (currentBlockName === END_OF_CONTENT_NAME) {
                    if (this.isIndefiniteForm)
                        break;
                    else {
                        this.error = "EndOfContent is unexpected, OCTET STRING may consists of OCTET STRINGs only";
                        return -1;
                    }
                }
                if (currentBlockName !== OCTET_STRING_NAME) {
                    this.error = "OCTET STRING may consists of OCTET STRINGs only";
                    return -1;
                }
            }
        }
        else {
            this.isHexOnly = true;
            resultOffset = super.fromBER(inputBuffer, inputOffset, inputLength);
            this.blockLength = inputLength;
        }
        return resultOffset;
    }
    toBER(sizeOnly, writer) {
        if (this.isConstructed)
            return LocalConstructedValueBlock.prototype.toBER.call(this, sizeOnly, writer);
        return sizeOnly
            ? new ArrayBuffer(this.valueHexView.byteLength)
            : this.valueHexView.slice().buffer;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            isConstructed: this.isConstructed,
        };
    }
}
LocalOctetStringValueBlock.NAME = "OctetStringValueBlock";

var _a$r;
class OctetString extends BaseBlock {
    constructor({ idBlock = {}, lenBlock = {}, ...parameters } = {}) {
        var _b, _c;
        (_b = parameters.isConstructed) !== null && _b !== void 0 ? _b : (parameters.isConstructed = !!((_c = parameters.value) === null || _c === void 0 ? void 0 : _c.length));
        super({
            idBlock: {
                isConstructed: parameters.isConstructed,
                ...idBlock,
            },
            lenBlock: {
                ...lenBlock,
                isIndefiniteForm: !!parameters.isIndefiniteForm,
            },
            ...parameters,
        }, LocalOctetStringValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 4;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        this.valueBlock.isConstructed = this.idBlock.isConstructed;
        this.valueBlock.isIndefiniteForm = this.lenBlock.isIndefiniteForm;
        if (inputLength === 0) {
            if (this.idBlock.error.length === 0)
                this.blockLength += this.idBlock.blockLength;
            if (this.lenBlock.error.length === 0)
                this.blockLength += this.lenBlock.blockLength;
            return inputOffset;
        }
        if (!this.valueBlock.isConstructed) {
            const view = inputBuffer instanceof ArrayBuffer ? new Uint8Array(inputBuffer) : inputBuffer;
            const buf = view.subarray(inputOffset, inputOffset + inputLength);
            try {
                if (buf.byteLength) {
                    const asn = localFromBER(buf, 0, buf.byteLength);
                    if (asn.offset !== -1 && asn.offset === inputLength) {
                        this.valueBlock.value = [asn.result];
                    }
                }
            }
            catch (e) {
            }
        }
        return super.fromBER(inputBuffer, inputOffset, inputLength);
    }
    onAsciiEncoding() {
        if (this.valueBlock.isConstructed || (this.valueBlock.value && this.valueBlock.value.length)) {
            return Constructed.prototype.onAsciiEncoding.call(this);
        }
        return `${this.constructor.NAME} : ${Convert_1.ToHex(this.valueBlock.valueHexView)}`;
    }
    getValue() {
        if (!this.idBlock.isConstructed) {
            return this.valueBlock.valueHexView.slice().buffer;
        }
        const array = [];
        for (const content of this.valueBlock.value) {
            if (content instanceof OctetString) {
                array.push(content.valueBlock.valueHexView);
            }
        }
        return BufferSourceConverter_1.concat(array);
    }
}
_a$r = OctetString;
(() => {
    typeStore.OctetString = _a$r;
})();
OctetString.NAME = OCTET_STRING_NAME;

class LocalBitStringValueBlock extends HexBlock(LocalConstructedValueBlock) {
    constructor({ unusedBits = 0, isConstructed = false, ...parameters } = {}) {
        super(parameters);
        this.unusedBits = unusedBits;
        this.isConstructed = isConstructed;
        this.blockLength = this.valueHexView.byteLength;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        if (!inputLength) {
            return inputOffset;
        }
        let resultOffset = -1;
        if (this.isConstructed) {
            resultOffset = LocalConstructedValueBlock.prototype.fromBER.call(this, inputBuffer, inputOffset, inputLength);
            if (resultOffset === -1)
                return resultOffset;
            for (const value of this.value) {
                const currentBlockName = value.constructor.NAME;
                if (currentBlockName === END_OF_CONTENT_NAME) {
                    if (this.isIndefiniteForm)
                        break;
                    else {
                        this.error = "EndOfContent is unexpected, BIT STRING may consists of BIT STRINGs only";
                        return -1;
                    }
                }
                if (currentBlockName !== BIT_STRING_NAME) {
                    this.error = "BIT STRING may consists of BIT STRINGs only";
                    return -1;
                }
                const valueBlock = value.valueBlock;
                if ((this.unusedBits > 0) && (valueBlock.unusedBits > 0)) {
                    this.error = "Using of \"unused bits\" inside constructive BIT STRING allowed for least one only";
                    return -1;
                }
                this.unusedBits = valueBlock.unusedBits;
            }
            return resultOffset;
        }
        const inputView = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {
            return -1;
        }
        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);
        this.unusedBits = intBuffer[0];
        if (this.unusedBits > 7) {
            this.error = "Unused bits for BitString must be in range 0-7";
            return -1;
        }
        if (!this.unusedBits) {
            const buf = intBuffer.subarray(1);
            try {
                if (buf.byteLength) {
                    const asn = localFromBER(buf, 0, buf.byteLength);
                    if (asn.offset !== -1 && asn.offset === (inputLength - 1)) {
                        this.value = [asn.result];
                    }
                }
            }
            catch (e) {
            }
        }
        this.valueHexView = intBuffer.subarray(1);
        this.blockLength = intBuffer.length;
        return (inputOffset + inputLength);
    }
    toBER(sizeOnly, writer) {
        if (this.isConstructed) {
            return LocalConstructedValueBlock.prototype.toBER.call(this, sizeOnly, writer);
        }
        if (sizeOnly) {
            return new ArrayBuffer(this.valueHexView.byteLength + 1);
        }
        if (!this.valueHexView.byteLength) {
            return EMPTY_BUFFER$1;
        }
        const retView = new Uint8Array(this.valueHexView.length + 1);
        retView[0] = this.unusedBits;
        retView.set(this.valueHexView, 1);
        return retView.buffer;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            unusedBits: this.unusedBits,
            isConstructed: this.isConstructed,
        };
    }
}
LocalBitStringValueBlock.NAME = "BitStringValueBlock";

var _a$q;
class BitString extends BaseBlock {
    constructor({ idBlock = {}, lenBlock = {}, ...parameters } = {}) {
        var _b, _c;
        (_b = parameters.isConstructed) !== null && _b !== void 0 ? _b : (parameters.isConstructed = !!((_c = parameters.value) === null || _c === void 0 ? void 0 : _c.length));
        super({
            idBlock: {
                isConstructed: parameters.isConstructed,
                ...idBlock,
            },
            lenBlock: {
                ...lenBlock,
                isIndefiniteForm: !!parameters.isIndefiniteForm,
            },
            ...parameters,
        }, LocalBitStringValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 3;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        this.valueBlock.isConstructed = this.idBlock.isConstructed;
        this.valueBlock.isIndefiniteForm = this.lenBlock.isIndefiniteForm;
        return super.fromBER(inputBuffer, inputOffset, inputLength);
    }
    onAsciiEncoding() {
        if (this.valueBlock.isConstructed || (this.valueBlock.value && this.valueBlock.value.length)) {
            return Constructed.prototype.onAsciiEncoding.call(this);
        }
        else {
            const bits = [];
            const valueHex = this.valueBlock.valueHexView;
            for (const byte of valueHex) {
                bits.push(byte.toString(2).padStart(8, "0"));
            }
            const bitsStr = bits.join("");
            return `${this.constructor.NAME} : ${bitsStr.substring(0, bitsStr.length - this.valueBlock.unusedBits)}`;
        }
    }
}
_a$q = BitString;
(() => {
    typeStore.BitString = _a$q;
})();
BitString.NAME = BIT_STRING_NAME;

var _a$p;
function viewAdd(first, second) {
    const c = new Uint8Array([0]);
    const firstView = new Uint8Array(first);
    const secondView = new Uint8Array(second);
    let firstViewCopy = firstView.slice(0);
    const firstViewCopyLength = firstViewCopy.length - 1;
    const secondViewCopy = secondView.slice(0);
    const secondViewCopyLength = secondViewCopy.length - 1;
    let value = 0;
    const max = (secondViewCopyLength < firstViewCopyLength) ? firstViewCopyLength : secondViewCopyLength;
    let counter = 0;
    for (let i = max; i >= 0; i--, counter++) {
        switch (true) {
            case (counter < secondViewCopy.length):
                value = firstViewCopy[firstViewCopyLength - counter] + secondViewCopy[secondViewCopyLength - counter] + c[0];
                break;
            default:
                value = firstViewCopy[firstViewCopyLength - counter] + c[0];
        }
        c[0] = value / 10;
        switch (true) {
            case (counter >= firstViewCopy.length):
                firstViewCopy = utilConcatView(new Uint8Array([value % 10]), firstViewCopy);
                break;
            default:
                firstViewCopy[firstViewCopyLength - counter] = value % 10;
        }
    }
    if (c[0] > 0)
        firstViewCopy = utilConcatView(c, firstViewCopy);
    return firstViewCopy;
}
function power2(n) {
    if (n >= powers2.length) {
        for (let p = powers2.length; p <= n; p++) {
            const c = new Uint8Array([0]);
            let digits = (powers2[p - 1]).slice(0);
            for (let i = (digits.length - 1); i >= 0; i--) {
                const newValue = new Uint8Array([(digits[i] << 1) + c[0]]);
                c[0] = newValue[0] / 10;
                digits[i] = newValue[0] % 10;
            }
            if (c[0] > 0)
                digits = utilConcatView(c, digits);
            powers2.push(digits);
        }
    }
    return powers2[n];
}
function viewSub(first, second) {
    let b = 0;
    const firstView = new Uint8Array(first);
    const secondView = new Uint8Array(second);
    const firstViewCopy = firstView.slice(0);
    const firstViewCopyLength = firstViewCopy.length - 1;
    const secondViewCopy = secondView.slice(0);
    const secondViewCopyLength = secondViewCopy.length - 1;
    let value;
    let counter = 0;
    for (let i = secondViewCopyLength; i >= 0; i--, counter++) {
        value = firstViewCopy[firstViewCopyLength - counter] - secondViewCopy[secondViewCopyLength - counter] - b;
        switch (true) {
            case (value < 0):
                b = 1;
                firstViewCopy[firstViewCopyLength - counter] = value + 10;
                break;
            default:
                b = 0;
                firstViewCopy[firstViewCopyLength - counter] = value;
        }
    }
    if (b > 0) {
        for (let i = (firstViewCopyLength - secondViewCopyLength + 1); i >= 0; i--, counter++) {
            value = firstViewCopy[firstViewCopyLength - counter] - b;
            if (value < 0) {
                b = 1;
                firstViewCopy[firstViewCopyLength - counter] = value + 10;
            }
            else {
                b = 0;
                firstViewCopy[firstViewCopyLength - counter] = value;
                break;
            }
        }
    }
    return firstViewCopy.slice();
}
class LocalIntegerValueBlock extends HexBlock(ValueBlock) {
    constructor({ value, ...parameters } = {}) {
        super(parameters);
        this._valueDec = 0;
        if (parameters.valueHex) {
            this.setValueHex();
        }
        if (value !== undefined) {
            this.valueDec = value;
        }
    }
    setValueHex() {
        if (this.valueHexView.length >= 4) {
            this.warnings.push("Too big Integer for decoding, hex only");
            this.isHexOnly = true;
            this._valueDec = 0;
        }
        else {
            this.isHexOnly = false;
            if (this.valueHexView.length > 0) {
                this._valueDec = utilDecodeTC.call(this);
            }
        }
    }
    set valueDec(v) {
        this._valueDec = v;
        this.isHexOnly = false;
        this.valueHexView = new Uint8Array(utilEncodeTC(v));
    }
    get valueDec() {
        return this._valueDec;
    }
    fromDER(inputBuffer, inputOffset, inputLength, expectedLength = 0) {
        const offset = this.fromBER(inputBuffer, inputOffset, inputLength);
        if (offset === -1)
            return offset;
        const view = this.valueHexView;
        if ((view[0] === 0x00) && ((view[1] & 0x80) !== 0)) {
            this.valueHexView = view.subarray(1);
        }
        else {
            if (expectedLength !== 0) {
                if (view.length < expectedLength) {
                    if ((expectedLength - view.length) > 1)
                        expectedLength = view.length + 1;
                    this.valueHexView = view.subarray(expectedLength - view.length);
                }
            }
        }
        return offset;
    }
    toDER(sizeOnly = false) {
        const view = this.valueHexView;
        switch (true) {
            case ((view[0] & 0x80) !== 0):
                {
                    const updatedView = new Uint8Array(this.valueHexView.length + 1);
                    updatedView[0] = 0x00;
                    updatedView.set(view, 1);
                    this.valueHexView = updatedView;
                }
                break;
            case ((view[0] === 0x00) && ((view[1] & 0x80) === 0)):
                {
                    this.valueHexView = this.valueHexView.subarray(1);
                }
                break;
        }
        return this.toBER(sizeOnly);
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        const resultOffset = super.fromBER(inputBuffer, inputOffset, inputLength);
        if (resultOffset === -1) {
            return resultOffset;
        }
        this.setValueHex();
        return resultOffset;
    }
    toBER(sizeOnly) {
        return sizeOnly
            ? new ArrayBuffer(this.valueHexView.length)
            : this.valueHexView.slice().buffer;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            valueDec: this.valueDec,
        };
    }
    toString() {
        const firstBit = (this.valueHexView.length * 8) - 1;
        let digits = new Uint8Array((this.valueHexView.length * 8) / 3);
        let bitNumber = 0;
        let currentByte;
        const asn1View = this.valueHexView;
        let result = "";
        let flag = false;
        for (let byteNumber = (asn1View.byteLength - 1); byteNumber >= 0; byteNumber--) {
            currentByte = asn1View[byteNumber];
            for (let i = 0; i < 8; i++) {
                if ((currentByte & 1) === 1) {
                    switch (bitNumber) {
                        case firstBit:
                            digits = viewSub(power2(bitNumber), digits);
                            result = "-";
                            break;
                        default:
                            digits = viewAdd(digits, power2(bitNumber));
                    }
                }
                bitNumber++;
                currentByte >>= 1;
            }
        }
        for (let i = 0; i < digits.length; i++) {
            if (digits[i])
                flag = true;
            if (flag)
                result += digitsString.charAt(digits[i]);
        }
        if (flag === false)
            result += digitsString.charAt(0);
        return result;
    }
}
_a$p = LocalIntegerValueBlock;
LocalIntegerValueBlock.NAME = "IntegerValueBlock";
(() => {
    Object.defineProperty(_a$p.prototype, "valueHex", {
        set: function (v) {
            this.valueHexView = new Uint8Array(v);
            this.setValueHex();
        },
        get: function () {
            return this.valueHexView.slice().buffer;
        },
    });
})();

var _a$o;
class Integer extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalIntegerValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 2;
    }
    toBigInt() {
        assertBigInt();
        return BigInt(this.valueBlock.toString());
    }
    static fromBigInt(value) {
        assertBigInt();
        const bigIntValue = BigInt(value);
        const writer = new ViewWriter();
        const hex = bigIntValue.toString(16).replace(/^-/, "");
        const view = new Uint8Array(Convert_1.FromHex(hex));
        if (bigIntValue < 0) {
            const first = new Uint8Array(view.length + (view[0] & 0x80 ? 1 : 0));
            first[0] |= 0x80;
            const firstInt = BigInt(`0x${Convert_1.ToHex(first)}`);
            const secondInt = firstInt + bigIntValue;
            const second = BufferSourceConverter_1.toUint8Array(Convert_1.FromHex(secondInt.toString(16)));
            second[0] |= 0x80;
            writer.write(second);
        }
        else {
            if (view[0] & 0x80) {
                writer.write(new Uint8Array([0]));
            }
            writer.write(view);
        }
        const res = new Integer({
            valueHex: writer.final(),
        });
        return res;
    }
    convertToDER() {
        const integer = new Integer({ valueHex: this.valueBlock.valueHexView });
        integer.valueBlock.toDER();
        return integer;
    }
    convertFromDER() {
        return new Integer({
            valueHex: this.valueBlock.valueHexView[0] === 0
                ? this.valueBlock.valueHexView.subarray(1)
                : this.valueBlock.valueHexView,
        });
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : ${this.valueBlock.toString()}`;
    }
}
_a$o = Integer;
(() => {
    typeStore.Integer = _a$o;
})();
Integer.NAME = "INTEGER";

var _a$n;
class Enumerated extends Integer {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 10;
    }
}
_a$n = Enumerated;
(() => {
    typeStore.Enumerated = _a$n;
})();
Enumerated.NAME = "ENUMERATED";

class LocalSidValueBlock extends HexBlock(ValueBlock) {
    constructor({ valueDec = -1, isFirstSid = false, ...parameters } = {}) {
        super(parameters);
        this.valueDec = valueDec;
        this.isFirstSid = isFirstSid;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        if (!inputLength) {
            return inputOffset;
        }
        const inputView = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {
            return -1;
        }
        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);
        this.valueHexView = new Uint8Array(inputLength);
        for (let i = 0; i < inputLength; i++) {
            this.valueHexView[i] = intBuffer[i] & 0x7F;
            this.blockLength++;
            if ((intBuffer[i] & 0x80) === 0x00)
                break;
        }
        const tempView = new Uint8Array(this.blockLength);
        for (let i = 0; i < this.blockLength; i++) {
            tempView[i] = this.valueHexView[i];
        }
        this.valueHexView = tempView;
        if ((intBuffer[this.blockLength - 1] & 0x80) !== 0x00) {
            this.error = "End of input reached before message was fully decoded";
            return -1;
        }
        if (this.valueHexView[0] === 0x00)
            this.warnings.push("Needlessly long format of SID encoding");
        if (this.blockLength <= 8)
            this.valueDec = utilFromBase(this.valueHexView, 7);
        else {
            this.isHexOnly = true;
            this.warnings.push("Too big SID for decoding, hex only");
        }
        return (inputOffset + this.blockLength);
    }
    set valueBigInt(value) {
        assertBigInt();
        let bits = BigInt(value).toString(2);
        while (bits.length % 7) {
            bits = "0" + bits;
        }
        const bytes = new Uint8Array(bits.length / 7);
        for (let i = 0; i < bytes.length; i++) {
            bytes[i] = parseInt(bits.slice(i * 7, i * 7 + 7), 2) + (i + 1 < bytes.length ? 0x80 : 0);
        }
        this.fromBER(bytes.buffer, 0, bytes.length);
    }
    toBER(sizeOnly) {
        if (this.isHexOnly) {
            if (sizeOnly)
                return (new ArrayBuffer(this.valueHexView.byteLength));
            const curView = this.valueHexView;
            const retView = new Uint8Array(this.blockLength);
            for (let i = 0; i < (this.blockLength - 1); i++)
                retView[i] = curView[i] | 0x80;
            retView[this.blockLength - 1] = curView[this.blockLength - 1];
            return retView.buffer;
        }
        const encodedBuf = utilToBase(this.valueDec, 7);
        if (encodedBuf.byteLength === 0) {
            this.error = "Error during encoding SID value";
            return EMPTY_BUFFER$1;
        }
        const retView = new Uint8Array(encodedBuf.byteLength);
        if (!sizeOnly) {
            const encodedView = new Uint8Array(encodedBuf);
            const len = encodedBuf.byteLength - 1;
            for (let i = 0; i < len; i++)
                retView[i] = encodedView[i] | 0x80;
            retView[len] = encodedView[len];
        }
        return retView;
    }
    toString() {
        let result = "";
        if (this.isHexOnly)
            result = Convert_1.ToHex(this.valueHexView);
        else {
            if (this.isFirstSid) {
                let sidValue = this.valueDec;
                if (this.valueDec <= 39)
                    result = "0.";
                else {
                    if (this.valueDec <= 79) {
                        result = "1.";
                        sidValue -= 40;
                    }
                    else {
                        result = "2.";
                        sidValue -= 80;
                    }
                }
                result += sidValue.toString();
            }
            else
                result = this.valueDec.toString();
        }
        return result;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            valueDec: this.valueDec,
            isFirstSid: this.isFirstSid,
        };
    }
}
LocalSidValueBlock.NAME = "sidBlock";

class LocalObjectIdentifierValueBlock extends ValueBlock {
    constructor({ value = EMPTY_STRING, ...parameters } = {}) {
        super(parameters);
        this.value = [];
        if (value) {
            this.fromString(value);
        }
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        let resultOffset = inputOffset;
        while (inputLength > 0) {
            const sidBlock = new LocalSidValueBlock();
            resultOffset = sidBlock.fromBER(inputBuffer, resultOffset, inputLength);
            if (resultOffset === -1) {
                this.blockLength = 0;
                this.error = sidBlock.error;
                return resultOffset;
            }
            if (this.value.length === 0)
                sidBlock.isFirstSid = true;
            this.blockLength += sidBlock.blockLength;
            inputLength -= sidBlock.blockLength;
            this.value.push(sidBlock);
        }
        return resultOffset;
    }
    toBER(sizeOnly) {
        const retBuffers = [];
        for (let i = 0; i < this.value.length; i++) {
            const valueBuf = this.value[i].toBER(sizeOnly);
            if (valueBuf.byteLength === 0) {
                this.error = this.value[i].error;
                return EMPTY_BUFFER$1;
            }
            retBuffers.push(valueBuf);
        }
        return concat(retBuffers);
    }
    fromString(string) {
        this.value = [];
        let pos1 = 0;
        let pos2 = 0;
        let sid = "";
        let flag = false;
        do {
            pos2 = string.indexOf(".", pos1);
            if (pos2 === -1)
                sid = string.substring(pos1);
            else
                sid = string.substring(pos1, pos2);
            pos1 = pos2 + 1;
            if (flag) {
                const sidBlock = this.value[0];
                let plus = 0;
                switch (sidBlock.valueDec) {
                    case 0:
                        break;
                    case 1:
                        plus = 40;
                        break;
                    case 2:
                        plus = 80;
                        break;
                    default:
                        this.value = [];
                        return;
                }
                const parsedSID = parseInt(sid, 10);
                if (isNaN(parsedSID))
                    return;
                sidBlock.valueDec = parsedSID + plus;
                flag = false;
            }
            else {
                const sidBlock = new LocalSidValueBlock();
                if (sid > Number.MAX_SAFE_INTEGER) {
                    assertBigInt();
                    const sidValue = BigInt(sid);
                    sidBlock.valueBigInt = sidValue;
                }
                else {
                    sidBlock.valueDec = parseInt(sid, 10);
                    if (isNaN(sidBlock.valueDec))
                        return;
                }
                if (!this.value.length) {
                    sidBlock.isFirstSid = true;
                    flag = true;
                }
                this.value.push(sidBlock);
            }
        } while (pos2 !== -1);
    }
    toString() {
        let result = "";
        let isHexOnly = false;
        for (let i = 0; i < this.value.length; i++) {
            isHexOnly = this.value[i].isHexOnly;
            let sidStr = this.value[i].toString();
            if (i !== 0)
                result = `${result}.`;
            if (isHexOnly) {
                sidStr = `{${sidStr}}`;
                if (this.value[i].isFirstSid)
                    result = `2.{${sidStr} - 80}`;
                else
                    result += sidStr;
            }
            else
                result += sidStr;
        }
        return result;
    }
    toJSON() {
        const object = {
            ...super.toJSON(),
            value: this.toString(),
            sidArray: [],
        };
        for (let i = 0; i < this.value.length; i++) {
            object.sidArray.push(this.value[i].toJSON());
        }
        return object;
    }
}
LocalObjectIdentifierValueBlock.NAME = "ObjectIdentifierValueBlock";

var _a$m;
class ObjectIdentifier extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalObjectIdentifierValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 6;
    }
    getValue() {
        return this.valueBlock.toString();
    }
    setValue(value) {
        this.valueBlock.fromString(value);
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : ${this.valueBlock.toString() || "empty"}`;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            value: this.getValue(),
        };
    }
}
_a$m = ObjectIdentifier;
(() => {
    typeStore.ObjectIdentifier = _a$m;
})();
ObjectIdentifier.NAME = "OBJECT IDENTIFIER";

class LocalRelativeSidValueBlock extends HexBlock(LocalBaseBlock) {
    constructor({ valueDec = 0, ...parameters } = {}) {
        super(parameters);
        this.valueDec = valueDec;
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        if (inputLength === 0)
            return inputOffset;
        const inputView = BufferSourceConverter_1.toUint8Array(inputBuffer);
        if (!checkBufferParams(this, inputView, inputOffset, inputLength))
            return -1;
        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);
        this.valueHexView = new Uint8Array(inputLength);
        for (let i = 0; i < inputLength; i++) {
            this.valueHexView[i] = intBuffer[i] & 0x7F;
            this.blockLength++;
            if ((intBuffer[i] & 0x80) === 0x00)
                break;
        }
        const tempView = new Uint8Array(this.blockLength);
        for (let i = 0; i < this.blockLength; i++)
            tempView[i] = this.valueHexView[i];
        this.valueHexView = tempView;
        if ((intBuffer[this.blockLength - 1] & 0x80) !== 0x00) {
            this.error = "End of input reached before message was fully decoded";
            return -1;
        }
        if (this.valueHexView[0] === 0x00)
            this.warnings.push("Needlessly long format of SID encoding");
        if (this.blockLength <= 8)
            this.valueDec = utilFromBase(this.valueHexView, 7);
        else {
            this.isHexOnly = true;
            this.warnings.push("Too big SID for decoding, hex only");
        }
        return (inputOffset + this.blockLength);
    }
    toBER(sizeOnly) {
        if (this.isHexOnly) {
            if (sizeOnly)
                return (new ArrayBuffer(this.valueHexView.byteLength));
            const curView = this.valueHexView;
            const retView = new Uint8Array(this.blockLength);
            for (let i = 0; i < (this.blockLength - 1); i++)
                retView[i] = curView[i] | 0x80;
            retView[this.blockLength - 1] = curView[this.blockLength - 1];
            return retView.buffer;
        }
        const encodedBuf = utilToBase(this.valueDec, 7);
        if (encodedBuf.byteLength === 0) {
            this.error = "Error during encoding SID value";
            return EMPTY_BUFFER$1;
        }
        const retView = new Uint8Array(encodedBuf.byteLength);
        if (!sizeOnly) {
            const encodedView = new Uint8Array(encodedBuf);
            const len = encodedBuf.byteLength - 1;
            for (let i = 0; i < len; i++)
                retView[i] = encodedView[i] | 0x80;
            retView[len] = encodedView[len];
        }
        return retView.buffer;
    }
    toString() {
        let result = "";
        if (this.isHexOnly)
            result = Convert_1.ToHex(this.valueHexView);
        else {
            result = this.valueDec.toString();
        }
        return result;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            valueDec: this.valueDec,
        };
    }
}
LocalRelativeSidValueBlock.NAME = "relativeSidBlock";

class LocalRelativeObjectIdentifierValueBlock extends ValueBlock {
    constructor({ value = EMPTY_STRING, ...parameters } = {}) {
        super(parameters);
        this.value = [];
        if (value) {
            this.fromString(value);
        }
    }
    fromBER(inputBuffer, inputOffset, inputLength) {
        let resultOffset = inputOffset;
        while (inputLength > 0) {
            const sidBlock = new LocalRelativeSidValueBlock();
            resultOffset = sidBlock.fromBER(inputBuffer, resultOffset, inputLength);
            if (resultOffset === -1) {
                this.blockLength = 0;
                this.error = sidBlock.error;
                return resultOffset;
            }
            this.blockLength += sidBlock.blockLength;
            inputLength -= sidBlock.blockLength;
            this.value.push(sidBlock);
        }
        return resultOffset;
    }
    toBER(sizeOnly, writer) {
        const retBuffers = [];
        for (let i = 0; i < this.value.length; i++) {
            const valueBuf = this.value[i].toBER(sizeOnly);
            if (valueBuf.byteLength === 0) {
                this.error = this.value[i].error;
                return EMPTY_BUFFER$1;
            }
            retBuffers.push(valueBuf);
        }
        return concat(retBuffers);
    }
    fromString(string) {
        this.value = [];
        let pos1 = 0;
        let pos2 = 0;
        let sid = "";
        do {
            pos2 = string.indexOf(".", pos1);
            if (pos2 === -1)
                sid = string.substring(pos1);
            else
                sid = string.substring(pos1, pos2);
            pos1 = pos2 + 1;
            const sidBlock = new LocalRelativeSidValueBlock();
            sidBlock.valueDec = parseInt(sid, 10);
            if (isNaN(sidBlock.valueDec))
                return true;
            this.value.push(sidBlock);
        } while (pos2 !== -1);
        return true;
    }
    toString() {
        let result = "";
        let isHexOnly = false;
        for (let i = 0; i < this.value.length; i++) {
            isHexOnly = this.value[i].isHexOnly;
            let sidStr = this.value[i].toString();
            if (i !== 0)
                result = `${result}.`;
            if (isHexOnly) {
                sidStr = `{${sidStr}}`;
                result += sidStr;
            }
            else
                result += sidStr;
        }
        return result;
    }
    toJSON() {
        const object = {
            ...super.toJSON(),
            value: this.toString(),
            sidArray: [],
        };
        for (let i = 0; i < this.value.length; i++)
            object.sidArray.push(this.value[i].toJSON());
        return object;
    }
}
LocalRelativeObjectIdentifierValueBlock.NAME = "RelativeObjectIdentifierValueBlock";

var _a$l;
class RelativeObjectIdentifier extends BaseBlock {
    constructor(parameters = {}) {
        super(parameters, LocalRelativeObjectIdentifierValueBlock);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 13;
    }
    getValue() {
        return this.valueBlock.toString();
    }
    setValue(value) {
        this.valueBlock.fromString(value);
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : ${this.valueBlock.toString() || "empty"}`;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            value: this.getValue(),
        };
    }
}
_a$l = RelativeObjectIdentifier;
(() => {
    typeStore.RelativeObjectIdentifier = _a$l;
})();
RelativeObjectIdentifier.NAME = "RelativeObjectIdentifier";

var _a$k;
class Sequence extends Constructed {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 16;
    }
}
_a$k = Sequence;
(() => {
    typeStore.Sequence = _a$k;
})();
Sequence.NAME = "SEQUENCE";

var _a$j;
let Set$1 = class Set extends Constructed {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 17;
    }
};
_a$j = Set$1;
(() => {
    typeStore.Set = _a$j;
})();
Set$1.NAME = "SET";

class LocalStringValueBlock extends HexBlock(ValueBlock) {
    constructor({ ...parameters } = {}) {
        super(parameters);
        this.isHexOnly = true;
        this.value = EMPTY_STRING;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            value: this.value,
        };
    }
}
LocalStringValueBlock.NAME = "StringValueBlock";

class LocalSimpleStringValueBlock extends LocalStringValueBlock {
}
LocalSimpleStringValueBlock.NAME = "SimpleStringValueBlock";

class LocalSimpleStringBlock extends BaseStringBlock {
    constructor({ ...parameters } = {}) {
        super(parameters, LocalSimpleStringValueBlock);
    }
    fromBuffer(inputBuffer) {
        this.valueBlock.value = String.fromCharCode.apply(null, BufferSourceConverter_1.toUint8Array(inputBuffer));
    }
    fromString(inputString) {
        const strLen = inputString.length;
        const view = this.valueBlock.valueHexView = new Uint8Array(strLen);
        for (let i = 0; i < strLen; i++)
            view[i] = inputString.charCodeAt(i);
        this.valueBlock.value = inputString;
    }
}
LocalSimpleStringBlock.NAME = "SIMPLE STRING";

class LocalUtf8StringValueBlock extends LocalSimpleStringBlock {
    fromBuffer(inputBuffer) {
        this.valueBlock.valueHexView = BufferSourceConverter_1.toUint8Array(inputBuffer);
        try {
            this.valueBlock.value = Convert_1.ToUtf8String(inputBuffer);
        }
        catch (ex) {
            this.warnings.push(`Error during "decodeURIComponent": ${ex}, using raw string`);
            this.valueBlock.value = Convert_1.ToBinary(inputBuffer);
        }
    }
    fromString(inputString) {
        this.valueBlock.valueHexView = new Uint8Array(Convert_1.FromUtf8String(inputString));
        this.valueBlock.value = inputString;
    }
}
LocalUtf8StringValueBlock.NAME = "Utf8StringValueBlock";

var _a$i;
class Utf8String extends LocalUtf8StringValueBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 12;
    }
}
_a$i = Utf8String;
(() => {
    typeStore.Utf8String = _a$i;
})();
Utf8String.NAME = "UTF8String";

class LocalBmpStringValueBlock extends LocalSimpleStringBlock {
    fromBuffer(inputBuffer) {
        this.valueBlock.value = Convert_1.ToUtf16String(inputBuffer);
        this.valueBlock.valueHexView = BufferSourceConverter_1.toUint8Array(inputBuffer);
    }
    fromString(inputString) {
        this.valueBlock.value = inputString;
        this.valueBlock.valueHexView = new Uint8Array(Convert_1.FromUtf16String(inputString));
    }
}
LocalBmpStringValueBlock.NAME = "BmpStringValueBlock";

var _a$h;
class BmpString extends LocalBmpStringValueBlock {
    constructor({ ...parameters } = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 30;
    }
}
_a$h = BmpString;
(() => {
    typeStore.BmpString = _a$h;
})();
BmpString.NAME = "BMPString";

class LocalUniversalStringValueBlock extends LocalSimpleStringBlock {
    fromBuffer(inputBuffer) {
        const copyBuffer = ArrayBuffer.isView(inputBuffer) ? inputBuffer.slice().buffer : inputBuffer.slice(0);
        const valueView = new Uint8Array(copyBuffer);
        for (let i = 0; i < valueView.length; i += 4) {
            valueView[i] = valueView[i + 3];
            valueView[i + 1] = valueView[i + 2];
            valueView[i + 2] = 0x00;
            valueView[i + 3] = 0x00;
        }
        this.valueBlock.value = String.fromCharCode.apply(null, new Uint32Array(copyBuffer));
    }
    fromString(inputString) {
        const strLength = inputString.length;
        const valueHexView = this.valueBlock.valueHexView = new Uint8Array(strLength * 4);
        for (let i = 0; i < strLength; i++) {
            const codeBuf = utilToBase(inputString.charCodeAt(i), 8);
            const codeView = new Uint8Array(codeBuf);
            if (codeView.length > 4)
                continue;
            const dif = 4 - codeView.length;
            for (let j = (codeView.length - 1); j >= 0; j--)
                valueHexView[i * 4 + j + dif] = codeView[j];
        }
        this.valueBlock.value = inputString;
    }
}
LocalUniversalStringValueBlock.NAME = "UniversalStringValueBlock";

var _a$g;
class UniversalString extends LocalUniversalStringValueBlock {
    constructor({ ...parameters } = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 28;
    }
}
_a$g = UniversalString;
(() => {
    typeStore.UniversalString = _a$g;
})();
UniversalString.NAME = "UniversalString";

var _a$f;
class NumericString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 18;
    }
}
_a$f = NumericString;
(() => {
    typeStore.NumericString = _a$f;
})();
NumericString.NAME = "NumericString";

var _a$e;
class PrintableString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 19;
    }
}
_a$e = PrintableString;
(() => {
    typeStore.PrintableString = _a$e;
})();
PrintableString.NAME = "PrintableString";

var _a$d;
class TeletexString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 20;
    }
}
_a$d = TeletexString;
(() => {
    typeStore.TeletexString = _a$d;
})();
TeletexString.NAME = "TeletexString";

var _a$c;
class VideotexString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 21;
    }
}
_a$c = VideotexString;
(() => {
    typeStore.VideotexString = _a$c;
})();
VideotexString.NAME = "VideotexString";

var _a$b;
class IA5String extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 22;
    }
}
_a$b = IA5String;
(() => {
    typeStore.IA5String = _a$b;
})();
IA5String.NAME = "IA5String";

var _a$a;
class GraphicString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 25;
    }
}
_a$a = GraphicString;
(() => {
    typeStore.GraphicString = _a$a;
})();
GraphicString.NAME = "GraphicString";

var _a$9;
class VisibleString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 26;
    }
}
_a$9 = VisibleString;
(() => {
    typeStore.VisibleString = _a$9;
})();
VisibleString.NAME = "VisibleString";

var _a$8;
class GeneralString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 27;
    }
}
_a$8 = GeneralString;
(() => {
    typeStore.GeneralString = _a$8;
})();
GeneralString.NAME = "GeneralString";

var _a$7;
class CharacterString extends LocalSimpleStringBlock {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 29;
    }
}
_a$7 = CharacterString;
(() => {
    typeStore.CharacterString = _a$7;
})();
CharacterString.NAME = "CharacterString";

var _a$6;
class UTCTime extends VisibleString {
    constructor({ value, valueDate, ...parameters } = {}) {
        super(parameters);
        this.year = 0;
        this.month = 0;
        this.day = 0;
        this.hour = 0;
        this.minute = 0;
        this.second = 0;
        if (value) {
            this.fromString(value);
            this.valueBlock.valueHexView = new Uint8Array(value.length);
            for (let i = 0; i < value.length; i++)
                this.valueBlock.valueHexView[i] = value.charCodeAt(i);
        }
        if (valueDate) {
            this.fromDate(valueDate);
            this.valueBlock.valueHexView = new Uint8Array(this.toBuffer());
        }
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 23;
    }
    fromBuffer(inputBuffer) {
        this.fromString(String.fromCharCode.apply(null, BufferSourceConverter_1.toUint8Array(inputBuffer)));
    }
    toBuffer() {
        const str = this.toString();
        const buffer = new ArrayBuffer(str.length);
        const view = new Uint8Array(buffer);
        for (let i = 0; i < str.length; i++)
            view[i] = str.charCodeAt(i);
        return buffer;
    }
    fromDate(inputDate) {
        this.year = inputDate.getUTCFullYear();
        this.month = inputDate.getUTCMonth() + 1;
        this.day = inputDate.getUTCDate();
        this.hour = inputDate.getUTCHours();
        this.minute = inputDate.getUTCMinutes();
        this.second = inputDate.getUTCSeconds();
    }
    toDate() {
        return (new Date(Date.UTC(this.year, this.month - 1, this.day, this.hour, this.minute, this.second)));
    }
    fromString(inputString) {
        const parser = /(\d{2})(\d{2})(\d{2})(\d{2})(\d{2})(\d{2})Z/ig;
        const parserArray = parser.exec(inputString);
        if (parserArray === null) {
            this.error = "Wrong input string for conversion";
            return;
        }
        const year = parseInt(parserArray[1], 10);
        if (year >= 50)
            this.year = 1900 + year;
        else
            this.year = 2000 + year;
        this.month = parseInt(parserArray[2], 10);
        this.day = parseInt(parserArray[3], 10);
        this.hour = parseInt(parserArray[4], 10);
        this.minute = parseInt(parserArray[5], 10);
        this.second = parseInt(parserArray[6], 10);
    }
    toString(encoding = "iso") {
        if (encoding === "iso") {
            const outputArray = new Array(7);
            outputArray[0] = padNumber(((this.year < 2000) ? (this.year - 1900) : (this.year - 2000)), 2);
            outputArray[1] = padNumber(this.month, 2);
            outputArray[2] = padNumber(this.day, 2);
            outputArray[3] = padNumber(this.hour, 2);
            outputArray[4] = padNumber(this.minute, 2);
            outputArray[5] = padNumber(this.second, 2);
            outputArray[6] = "Z";
            return outputArray.join("");
        }
        return super.toString(encoding);
    }
    onAsciiEncoding() {
        return `${this.constructor.NAME} : ${this.toDate().toISOString()}`;
    }
    toJSON() {
        return {
            ...super.toJSON(),
            year: this.year,
            month: this.month,
            day: this.day,
            hour: this.hour,
            minute: this.minute,
            second: this.second,
        };
    }
}
_a$6 = UTCTime;
(() => {
    typeStore.UTCTime = _a$6;
})();
UTCTime.NAME = "UTCTime";

var _a$5;
class GeneralizedTime extends UTCTime {
    constructor(parameters = {}) {
        var _b;
        super(parameters);
        (_b = this.millisecond) !== null && _b !== void 0 ? _b : (this.millisecond = 0);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 24;
    }
    fromDate(inputDate) {
        super.fromDate(inputDate);
        this.millisecond = inputDate.getUTCMilliseconds();
    }
    toDate() {
        return (new Date(Date.UTC(this.year, this.month - 1, this.day, this.hour, this.minute, this.second, this.millisecond)));
    }
    fromString(inputString) {
        let isUTC = false;
        let timeString = "";
        let dateTimeString = "";
        let fractionPart = 0;
        let parser;
        let hourDifference = 0;
        let minuteDifference = 0;
        if (inputString[inputString.length - 1] === "Z") {
            timeString = inputString.substring(0, inputString.length - 1);
            isUTC = true;
        }
        else {
            const number = new Number(inputString[inputString.length - 1]);
            if (isNaN(number.valueOf()))
                throw new Error("Wrong input string for conversion");
            timeString = inputString;
        }
        if (isUTC) {
            if (timeString.indexOf("+") !== -1)
                throw new Error("Wrong input string for conversion");
            if (timeString.indexOf("-") !== -1)
                throw new Error("Wrong input string for conversion");
        }
        else {
            let multiplier = 1;
            let differencePosition = timeString.indexOf("+");
            let differenceString = "";
            if (differencePosition === -1) {
                differencePosition = timeString.indexOf("-");
                multiplier = -1;
            }
            if (differencePosition !== -1) {
                differenceString = timeString.substring(differencePosition + 1);
                timeString = timeString.substring(0, differencePosition);
                if ((differenceString.length !== 2) && (differenceString.length !== 4))
                    throw new Error("Wrong input string for conversion");
                let number = parseInt(differenceString.substring(0, 2), 10);
                if (isNaN(number.valueOf()))
                    throw new Error("Wrong input string for conversion");
                hourDifference = multiplier * number;
                if (differenceString.length === 4) {
                    number = parseInt(differenceString.substring(2, 4), 10);
                    if (isNaN(number.valueOf()))
                        throw new Error("Wrong input string for conversion");
                    minuteDifference = multiplier * number;
                }
            }
        }
        let fractionPointPosition = timeString.indexOf(".");
        if (fractionPointPosition === -1)
            fractionPointPosition = timeString.indexOf(",");
        if (fractionPointPosition !== -1) {
            const fractionPartCheck = new Number(`0${timeString.substring(fractionPointPosition)}`);
            if (isNaN(fractionPartCheck.valueOf()))
                throw new Error("Wrong input string for conversion");
            fractionPart = fractionPartCheck.valueOf();
            dateTimeString = timeString.substring(0, fractionPointPosition);
        }
        else
            dateTimeString = timeString;
        switch (true) {
            case (dateTimeString.length === 8):
                parser = /(\d{4})(\d{2})(\d{2})/ig;
                if (fractionPointPosition !== -1)
                    throw new Error("Wrong input string for conversion");
                break;
            case (dateTimeString.length === 10):
                parser = /(\d{4})(\d{2})(\d{2})(\d{2})/ig;
                if (fractionPointPosition !== -1) {
                    let fractionResult = 60 * fractionPart;
                    this.minute = Math.floor(fractionResult);
                    fractionResult = 60 * (fractionResult - this.minute);
                    this.second = Math.floor(fractionResult);
                    fractionResult = 1000 * (fractionResult - this.second);
                    this.millisecond = Math.floor(fractionResult);
                }
                break;
            case (dateTimeString.length === 12):
                parser = /(\d{4})(\d{2})(\d{2})(\d{2})(\d{2})/ig;
                if (fractionPointPosition !== -1) {
                    let fractionResult = 60 * fractionPart;
                    this.second = Math.floor(fractionResult);
                    fractionResult = 1000 * (fractionResult - this.second);
                    this.millisecond = Math.floor(fractionResult);
                }
                break;
            case (dateTimeString.length === 14):
                parser = /(\d{4})(\d{2})(\d{2})(\d{2})(\d{2})(\d{2})/ig;
                if (fractionPointPosition !== -1) {
                    const fractionResult = 1000 * fractionPart;
                    this.millisecond = Math.floor(fractionResult);
                }
                break;
            default:
                throw new Error("Wrong input string for conversion");
        }
        const parserArray = parser.exec(dateTimeString);
        if (parserArray === null)
            throw new Error("Wrong input string for conversion");
        for (let j = 1; j < parserArray.length; j++) {
            switch (j) {
                case 1:
                    this.year = parseInt(parserArray[j], 10);
                    break;
                case 2:
                    this.month = parseInt(parserArray[j], 10);
                    break;
                case 3:
                    this.day = parseInt(parserArray[j], 10);
                    break;
                case 4:
                    this.hour = parseInt(parserArray[j], 10) + hourDifference;
                    break;
                case 5:
                    this.minute = parseInt(parserArray[j], 10) + minuteDifference;
                    break;
                case 6:
                    this.second = parseInt(parserArray[j], 10);
                    break;
                default:
                    throw new Error("Wrong input string for conversion");
            }
        }
        if (isUTC === false) {
            const tempDate = new Date(this.year, this.month, this.day, this.hour, this.minute, this.second, this.millisecond);
            this.year = tempDate.getUTCFullYear();
            this.month = tempDate.getUTCMonth();
            this.day = tempDate.getUTCDay();
            this.hour = tempDate.getUTCHours();
            this.minute = tempDate.getUTCMinutes();
            this.second = tempDate.getUTCSeconds();
            this.millisecond = tempDate.getUTCMilliseconds();
        }
    }
    toString(encoding = "iso") {
        if (encoding === "iso") {
            const outputArray = [];
            outputArray.push(padNumber(this.year, 4));
            outputArray.push(padNumber(this.month, 2));
            outputArray.push(padNumber(this.day, 2));
            outputArray.push(padNumber(this.hour, 2));
            outputArray.push(padNumber(this.minute, 2));
            outputArray.push(padNumber(this.second, 2));
            if (this.millisecond !== 0) {
                outputArray.push(".");
                outputArray.push(padNumber(this.millisecond, 3));
            }
            outputArray.push("Z");
            return outputArray.join("");
        }
        return super.toString(encoding);
    }
    toJSON() {
        return {
            ...super.toJSON(),
            millisecond: this.millisecond,
        };
    }
}
_a$5 = GeneralizedTime;
(() => {
    typeStore.GeneralizedTime = _a$5;
})();
GeneralizedTime.NAME = "GeneralizedTime";

var _a$4;
class DATE extends Utf8String {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 31;
    }
}
_a$4 = DATE;
(() => {
    typeStore.DATE = _a$4;
})();
DATE.NAME = "DATE";

var _a$3;
class TimeOfDay extends Utf8String {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 32;
    }
}
_a$3 = TimeOfDay;
(() => {
    typeStore.TimeOfDay = _a$3;
})();
TimeOfDay.NAME = "TimeOfDay";

var _a$2;
class DateTime extends Utf8String {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 33;
    }
}
_a$2 = DateTime;
(() => {
    typeStore.DateTime = _a$2;
})();
DateTime.NAME = "DateTime";

var _a$1;
class Duration extends Utf8String {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 34;
    }
}
_a$1 = Duration;
(() => {
    typeStore.Duration = _a$1;
})();
Duration.NAME = "Duration";

var _a;
class TIME extends Utf8String {
    constructor(parameters = {}) {
        super(parameters);
        this.idBlock.tagClass = 1;
        this.idBlock.tagNumber = 14;
    }
}
_a = TIME;
(() => {
    typeStore.TIME = _a;
})();
TIME.NAME = "TIME";

/**
 * Convert a PKCS#1 in ASN1 DER format to a JWK key
 */
function pkcs1ToJwk(bytes) {
    const { result } = fromBER(bytes);
    // @ts-expect-error this looks fragile but DER is a canonical format so we are
    // safe to have deeply property chains like this
    const values = result.valueBlock.value;
    const key = {
        n: toString$6(bnToBuf(values[1].toBigInt()), 'base64url'),
        e: toString$6(bnToBuf(values[2].toBigInt()), 'base64url'),
        d: toString$6(bnToBuf(values[3].toBigInt()), 'base64url'),
        p: toString$6(bnToBuf(values[4].toBigInt()), 'base64url'),
        q: toString$6(bnToBuf(values[5].toBigInt()), 'base64url'),
        dp: toString$6(bnToBuf(values[6].toBigInt()), 'base64url'),
        dq: toString$6(bnToBuf(values[7].toBigInt()), 'base64url'),
        qi: toString$6(bnToBuf(values[8].toBigInt()), 'base64url'),
        kty: 'RSA',
        alg: 'RS256'
    };
    return key;
}
/**
 * Convert a JWK key into PKCS#1 in ASN1 DER format
 */
function jwkToPkcs1(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$1('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const root = new Sequence({
        value: [
            new Integer({ value: 0 }),
            Integer.fromBigInt(bufToBn(fromString(jwk.n, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.e, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.d, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.p, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.q, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.dp, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.dq, 'base64url'))),
            Integer.fromBigInt(bufToBn(fromString(jwk.qi, 'base64url')))
        ]
    });
    const der = root.toBER();
    return new Uint8Array(der, 0, der.byteLength);
}
/**
 * Convert a PKCIX in ASN1 DER format to a JWK key
 */
function pkixToJwk(bytes) {
    const { result } = fromBER(bytes);
    // @ts-expect-error this looks fragile but DER is a canonical format so we are
    // safe to have deeply property chains like this
    const values = result.valueBlock.value[1].valueBlock.value[0].valueBlock.value;
    return {
        kty: 'RSA',
        n: toString$6(bnToBuf(values[0].toBigInt()), 'base64url'),
        e: toString$6(bnToBuf(values[1].toBigInt()), 'base64url')
    };
}
/**
 * Convert a JWK key to PKCIX in ASN1 DER format
 */
function jwkToPkix(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$1('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const root = new Sequence({
        value: [
            new Sequence({
                value: [
                    // rsaEncryption
                    new ObjectIdentifier({
                        value: '1.2.840.113549.1.1.1'
                    }),
                    new Null()
                ]
            }),
            // this appears to be a bug in asn1js.js - this should really be a Sequence
            // and not a BitString but it generates the same bytes as node-forge so 🤷‍♂️
            new BitString({
                valueHex: new Sequence({
                    value: [
                        Integer.fromBigInt(bufToBn(fromString(jwk.n, 'base64url'))),
                        Integer.fromBigInt(bufToBn(fromString(jwk.e, 'base64url')))
                    ]
                }).toBER()
            })
        ]
    });
    const der = root.toBER();
    return new Uint8Array(der, 0, der.byteLength);
}
function bnToBuf(bn) {
    let hex = bn.toString(16);
    if (hex.length % 2 > 0) {
        hex = `0${hex}`;
    }
    const len = hex.length / 2;
    const u8 = new Uint8Array(len);
    let i = 0;
    let j = 0;
    while (i < len) {
        u8[i] = parseInt(hex.slice(j, j + 2), 16);
        i += 1;
        j += 2;
    }
    return u8;
}
function bufToBn(u8) {
    const hex = [];
    u8.forEach(function (i) {
        let h = i.toString(16);
        if (h.length % 2 > 0) {
            h = `0${h}`;
        }
        hex.push(h);
    });
    return BigInt('0x' + hex.join(''));
}
const SALT_LENGTH = 16;
const KEY_SIZE = 32;
const ITERATIONS = 10000;
async function exportToPem(privateKey, password) {
    const crypto = webcrypto.get();
    // PrivateKeyInfo
    const keyWrapper = new Sequence({
        value: [
            // version (0)
            new Integer({ value: 0 }),
            // privateKeyAlgorithm
            new Sequence({
                value: [
                    // rsaEncryption OID
                    new ObjectIdentifier({
                        value: '1.2.840.113549.1.1.1'
                    }),
                    new Null()
                ]
            }),
            // PrivateKey
            new OctetString({
                valueHex: privateKey.marshal()
            })
        ]
    });
    const keyBuf = keyWrapper.toBER();
    const keyArr = new Uint8Array(keyBuf, 0, keyBuf.byteLength);
    const salt = randomBytes(SALT_LENGTH);
    const encryptionKey = await pbkdf2Async(sha512, password, salt, {
        c: ITERATIONS,
        dkLen: KEY_SIZE
    });
    const iv = randomBytes(16);
    const cryptoKey = await crypto.subtle.importKey('raw', encryptionKey, 'AES-CBC', false, ['encrypt']);
    const encrypted = await crypto.subtle.encrypt({
        name: 'AES-CBC',
        iv
    }, cryptoKey, keyArr);
    const pbkdf2Params = new Sequence({
        value: [
            // salt
            new OctetString({ valueHex: salt }),
            // iteration count
            new Integer({ value: ITERATIONS }),
            // key length
            new Integer({ value: KEY_SIZE }),
            // AlgorithmIdentifier
            new Sequence({
                value: [
                    // hmacWithSHA512
                    new ObjectIdentifier({ value: '1.2.840.113549.2.11' }),
                    new Null()
                ]
            })
        ]
    });
    const encryptionAlgorithm = new Sequence({
        value: [
            // pkcs5PBES2
            new ObjectIdentifier({
                value: '1.2.840.113549.1.5.13'
            }),
            new Sequence({
                value: [
                    // keyDerivationFunc
                    new Sequence({
                        value: [
                            // pkcs5PBKDF2
                            new ObjectIdentifier({
                                value: '1.2.840.113549.1.5.12'
                            }),
                            // PBKDF2-params
                            pbkdf2Params
                        ]
                    }),
                    // encryptionScheme
                    new Sequence({
                        value: [
                            // aes256-CBC
                            new ObjectIdentifier({
                                value: '2.16.840.1.101.3.4.1.42'
                            }),
                            // iv
                            new OctetString({
                                valueHex: iv
                            })
                        ]
                    })
                ]
            })
        ]
    });
    const finalWrapper = new Sequence({
        value: [
            encryptionAlgorithm,
            new OctetString({ valueHex: encrypted })
        ]
    });
    const finalWrapperBuf = finalWrapper.toBER();
    const finalWrapperArr = new Uint8Array(finalWrapperBuf, 0, finalWrapperBuf.byteLength);
    return [
        '-----BEGIN ENCRYPTED PRIVATE KEY-----',
        ...toString$6(finalWrapperArr, 'base64pad').split(/(.{64})/).filter(Boolean),
        '-----END ENCRYPTED PRIVATE KEY-----'
    ].join('\n');
}

async function generateKey$1(bits) {
    const pair = await webcrypto.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$1(key) {
    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate(key)
    ];
    const keys = await exportKey({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$1(key, msg) {
    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, msg instanceof Uint8Array ? msg : msg.subarray());
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$1(key, sig, msg) {
    const publicKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg instanceof Uint8Array ? msg : msg.subarray());
}
async function exportKey(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$1('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate(jwKey) {
    return webcrypto.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
function keySize(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$1('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$1('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_RSA_KEY_SIZE = 8192;
class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    verify(data, sig) {
        return hashAndVerify$1(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix(this._key);
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals(this.bytes, key.bytes);
    }
    hash() {
        const p = sha256$1.digest(this.bytes);
        if (isPromise$3(p)) {
            return p.then(({ bytes }) => bytes);
        }
        return p.bytes;
    }
}
class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes(16);
    }
    sign(message) {
        return hashAndSign$1(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$1('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey(this._publicKey);
    }
    marshal() {
        return jwkToPkcs1(this._key);
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals(this.bytes, key.bytes);
    }
    hash() {
        const p = sha256$1.digest(this.bytes);
        if (isPromise$3(p)) {
            return p.then(({ bytes }) => bytes);
        }
        return p.bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$6(hash, 'base58btc');
    }
    /**
     * Exports the key as libp2p-key - a aes-gcm encrypted value with the key
     * derived from the password.
     *
     * To export it as a password protected PEM file, please use the `exportPEM`
     * function from `@libp2p/rsa`.
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            return exportToPem(this, password);
        }
        else if (format === 'libp2p-key') {
            return exporter(this.bytes, password);
        }
        else {
            throw new CodeError$1(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
async function unmarshalRsaPrivateKey(bytes) {
    const jwk = pkcs1ToJwk(bytes);
    if (keySize(jwk) > MAX_RSA_KEY_SIZE) {
        throw new CodeError$1('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$1(jwk);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey(bytes) {
    const jwk = pkixToJwk(bytes);
    if (keySize(jwk) > MAX_RSA_KEY_SIZE) {
        throw new CodeError$1('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey(jwk);
}
async function fromJwk(jwk) {
    if (keySize(jwk) > MAX_RSA_KEY_SIZE) {
        throw new CodeError$1('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$1(jwk);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$2(bits) {
    if (bits > MAX_RSA_KEY_SIZE) {
        throw new CodeError$1('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$1(bits);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}

var RSA = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_RSA_KEY_SIZE: MAX_RSA_KEY_SIZE,
    RsaPrivateKey: RsaPrivateKey,
    RsaPublicKey: RsaPublicKey,
    fromJwk: fromJwk,
    generateKeyPair: generateKeyPair$2,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey
});

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Short Weierstrass curve. The formula is: y² = x³ + ax + b
function validateSigVerOpts(opts) {
    if (opts.lowS !== undefined)
        abool('lowS', opts.lowS);
    if (opts.prehash !== undefined)
        abool('prehash', opts.prehash);
}
function validatePointOpts(curve) {
    const opts = validateBasic(curve);
    validateObject(opts, {
        a: 'field',
        b: 'field',
    }, {
        allowedPrivateKeyLengths: 'array',
        wrapPrivateKey: 'boolean',
        isTorsionFree: 'function',
        clearCofactor: 'function',
        allowInfinityPoint: 'boolean',
        fromBytes: 'function',
        toBytes: 'function',
    });
    const { endo, Fp, a } = opts;
    if (endo) {
        if (!Fp.eql(a, Fp.ZERO)) {
            throw new Error('Endomorphism can only be defined for Koblitz curves that have a=0');
        }
        if (typeof endo !== 'object' ||
            typeof endo.beta !== 'bigint' ||
            typeof endo.splitScalar !== 'function') {
            throw new Error('Expected endomorphism with beta: bigint and splitScalar: function');
        }
    }
    return Object.freeze({ ...opts });
}
const { bytesToNumberBE: b2n, hexToBytes: h2b } = ut;
/**
 * ASN.1 DER encoding utilities. ASN is very complex & fragile. Format:
 *
 *     [0x30 (SEQUENCE), bytelength, 0x02 (INTEGER), intLength, R, 0x02 (INTEGER), intLength, S]
 *
 * Docs: https://letsencrypt.org/docs/a-warm-welcome-to-asn1-and-der/, https://luca.ntop.org/Teaching/Appunti/asn1.html
 */
const DER = {
    // asn.1 DER encoding utils
    Err: class DERErr extends Error {
        constructor(m = '') {
            super(m);
        }
    },
    // Basic building block is TLV (Tag-Length-Value)
    _tlv: {
        encode: (tag, data) => {
            const { Err: E } = DER;
            if (tag < 0 || tag > 256)
                throw new E('tlv.encode: wrong tag');
            if (data.length & 1)
                throw new E('tlv.encode: unpadded data');
            const dataLen = data.length / 2;
            const len = numberToHexUnpadded$1(dataLen);
            if ((len.length / 2) & 128)
                throw new E('tlv.encode: long form length too big');
            // length of length with long form flag
            const lenLen = dataLen > 127 ? numberToHexUnpadded$1((len.length / 2) | 128) : '';
            return `${numberToHexUnpadded$1(tag)}${lenLen}${len}${data}`;
        },
        // v - value, l - left bytes (unparsed)
        decode(tag, data) {
            const { Err: E } = DER;
            let pos = 0;
            if (tag < 0 || tag > 256)
                throw new E('tlv.encode: wrong tag');
            if (data.length < 2 || data[pos++] !== tag)
                throw new E('tlv.decode: wrong tlv');
            const first = data[pos++];
            const isLong = !!(first & 128); // First bit of first length byte is flag for short/long form
            let length = 0;
            if (!isLong)
                length = first;
            else {
                // Long form: [longFlag(1bit), lengthLength(7bit), length (BE)]
                const lenLen = first & 127;
                if (!lenLen)
                    throw new E('tlv.decode(long): indefinite length not supported');
                if (lenLen > 4)
                    throw new E('tlv.decode(long): byte length is too big'); // this will overflow u32 in js
                const lengthBytes = data.subarray(pos, pos + lenLen);
                if (lengthBytes.length !== lenLen)
                    throw new E('tlv.decode: length bytes not complete');
                if (lengthBytes[0] === 0)
                    throw new E('tlv.decode(long): zero leftmost byte');
                for (const b of lengthBytes)
                    length = (length << 8) | b;
                pos += lenLen;
                if (length < 128)
                    throw new E('tlv.decode(long): not minimal encoding');
            }
            const v = data.subarray(pos, pos + length);
            if (v.length !== length)
                throw new E('tlv.decode: wrong value length');
            return { v, l: data.subarray(pos + length) };
        },
    },
    // https://crypto.stackexchange.com/a/57734 Leftmost bit of first byte is 'negative' flag,
    // since we always use positive integers here. It must always be empty:
    // - add zero byte if exists
    // - if next byte doesn't have a flag, leading zero is not allowed (minimal encoding)
    _int: {
        encode(num) {
            const { Err: E } = DER;
            if (num < _0n$1)
                throw new E('integer: negative integers are not allowed');
            let hex = numberToHexUnpadded$1(num);
            // Pad with zero byte if negative flag is present
            if (Number.parseInt(hex[0], 16) & 0b1000)
                hex = '00' + hex;
            if (hex.length & 1)
                throw new E('unexpected assertion');
            return hex;
        },
        decode(data) {
            const { Err: E } = DER;
            if (data[0] & 128)
                throw new E('Invalid signature integer: negative');
            if (data[0] === 0x00 && !(data[1] & 128))
                throw new E('Invalid signature integer: unnecessary leading zero');
            return b2n(data);
        },
    },
    toSig(hex) {
        // parse DER signature
        const { Err: E, _int: int, _tlv: tlv } = DER;
        const data = typeof hex === 'string' ? h2b(hex) : hex;
        abytes(data);
        const { v: seqBytes, l: seqLeftBytes } = tlv.decode(0x30, data);
        if (seqLeftBytes.length)
            throw new E('Invalid signature: left bytes after parsing');
        const { v: rBytes, l: rLeftBytes } = tlv.decode(0x02, seqBytes);
        const { v: sBytes, l: sLeftBytes } = tlv.decode(0x02, rLeftBytes);
        if (sLeftBytes.length)
            throw new E('Invalid signature: left bytes after parsing');
        return { r: int.decode(rBytes), s: int.decode(sBytes) };
    },
    hexFromSig(sig) {
        const { _tlv: tlv, _int: int } = DER;
        const seq = `${tlv.encode(0x02, int.encode(sig.r))}${tlv.encode(0x02, int.encode(sig.s))}`;
        return tlv.encode(0x30, seq);
    },
};
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n$1 = BigInt(0), _1n$2 = BigInt(1); BigInt(2); const _3n$1 = BigInt(3); BigInt(4);
function weierstrassPoints(opts) {
    const CURVE = validatePointOpts(opts);
    const { Fp } = CURVE; // All curves has same field / group length as for now, but they can differ
    const Fn = Field(CURVE.n, CURVE.nBitLength);
    const toBytes = CURVE.toBytes ||
        ((_c, point, _isCompressed) => {
            const a = point.toAffine();
            return concatBytes$1(Uint8Array.from([0x04]), Fp.toBytes(a.x), Fp.toBytes(a.y));
        });
    const fromBytes = CURVE.fromBytes ||
        ((bytes) => {
            // const head = bytes[0];
            const tail = bytes.subarray(1);
            // if (head !== 0x04) throw new Error('Only non-compressed encoding is supported');
            const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));
            const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));
            return { x, y };
        });
    /**
     * y² = x³ + ax + b: Short weierstrass curve formula
     * @returns y²
     */
    function weierstrassEquation(x) {
        const { a, b } = CURVE;
        const x2 = Fp.sqr(x); // x * x
        const x3 = Fp.mul(x2, x); // x2 * x
        return Fp.add(Fp.add(x3, Fp.mul(x, a)), b); // x3 + a * x + b
    }
    // Validate whether the passed curve params are valid.
    // We check if curve equation works for generator point.
    // `assertValidity()` won't work: `isTorsionFree()` is not available at this point in bls12-381.
    // ProjectivePoint class has not been initialized yet.
    if (!Fp.eql(Fp.sqr(CURVE.Gy), weierstrassEquation(CURVE.Gx)))
        throw new Error('bad generator point: equation left != right');
    // Valid group elements reside in range 1..n-1
    function isWithinCurveOrder(num) {
        return inRange(num, _1n$2, CURVE.n);
    }
    // Validates if priv key is valid and converts it to bigint.
    // Supports options allowedPrivateKeyLengths and wrapPrivateKey.
    function normPrivateKeyToScalar(key) {
        const { allowedPrivateKeyLengths: lengths, nByteLength, wrapPrivateKey, n: N } = CURVE;
        if (lengths && typeof key !== 'bigint') {
            if (isBytes$2(key))
                key = bytesToHex$1(key);
            // Normalize to hex string, pad. E.g. P521 would norm 130-132 char hex to 132-char bytes
            if (typeof key !== 'string' || !lengths.includes(key.length))
                throw new Error('Invalid key');
            key = key.padStart(nByteLength * 2, '0');
        }
        let num;
        try {
            num =
                typeof key === 'bigint'
                    ? key
                    : bytesToNumberBE(ensureBytes$1('private key', key, nByteLength));
        }
        catch (error) {
            throw new Error(`private key must be ${nByteLength} bytes, hex or bigint, not ${typeof key}`);
        }
        if (wrapPrivateKey)
            num = mod$1(num, N); // disabled by default, enabled for BLS
        aInRange('private key', num, _1n$2, N); // num in range [1..N-1]
        return num;
    }
    function assertPrjPoint(other) {
        if (!(other instanceof Point))
            throw new Error('ProjectivePoint expected');
    }
    // Memoized toAffine / validity check. They are heavy. Points are immutable.
    // Converts Projective point to affine (x, y) coordinates.
    // Can accept precomputed Z^-1 - for example, from invertBatch.
    // (x, y, z) ∋ (x=x/z, y=y/z)
    const toAffineMemo = memoized((p, iz) => {
        const { px: x, py: y, pz: z } = p;
        // Fast-path for normalized points
        if (Fp.eql(z, Fp.ONE))
            return { x, y };
        const is0 = p.is0();
        // If invZ was 0, we return zero point. However we still want to execute
        // all operations, so we replace invZ with a random number, 1.
        if (iz == null)
            iz = is0 ? Fp.ONE : Fp.inv(z);
        const ax = Fp.mul(x, iz);
        const ay = Fp.mul(y, iz);
        const zz = Fp.mul(z, iz);
        if (is0)
            return { x: Fp.ZERO, y: Fp.ZERO };
        if (!Fp.eql(zz, Fp.ONE))
            throw new Error('invZ was invalid');
        return { x: ax, y: ay };
    });
    // NOTE: on exception this will crash 'cached' and no value will be set.
    // Otherwise true will be return
    const assertValidMemo = memoized((p) => {
        if (p.is0()) {
            // (0, 1, 0) aka ZERO is invalid in most contexts.
            // In BLS, ZERO can be serialized, so we allow it.
            // (0, 0, 0) is wrong representation of ZERO and is always invalid.
            if (CURVE.allowInfinityPoint && !Fp.is0(p.py))
                return;
            throw new Error('bad point: ZERO');
        }
        // Some 3rd-party test vectors require different wording between here & `fromCompressedHex`
        const { x, y } = p.toAffine();
        // Check if x, y are valid field elements
        if (!Fp.isValid(x) || !Fp.isValid(y))
            throw new Error('bad point: x or y not FE');
        const left = Fp.sqr(y); // y²
        const right = weierstrassEquation(x); // x³ + ax + b
        if (!Fp.eql(left, right))
            throw new Error('bad point: equation left != right');
        if (!p.isTorsionFree())
            throw new Error('bad point: not in prime-order subgroup');
        return true;
    });
    /**
     * Projective Point works in 3d / projective (homogeneous) coordinates: (x, y, z) ∋ (x=x/z, y=y/z)
     * Default Point works in 2d / affine coordinates: (x, y)
     * We're doing calculations in projective, because its operations don't require costly inversion.
     */
    class Point {
        constructor(px, py, pz) {
            this.px = px;
            this.py = py;
            this.pz = pz;
            if (px == null || !Fp.isValid(px))
                throw new Error('x required');
            if (py == null || !Fp.isValid(py))
                throw new Error('y required');
            if (pz == null || !Fp.isValid(pz))
                throw new Error('z required');
            Object.freeze(this);
        }
        // Does not validate if the point is on-curve.
        // Use fromHex instead, or call assertValidity() later.
        static fromAffine(p) {
            const { x, y } = p || {};
            if (!p || !Fp.isValid(x) || !Fp.isValid(y))
                throw new Error('invalid affine point');
            if (p instanceof Point)
                throw new Error('projective point not allowed');
            const is0 = (i) => Fp.eql(i, Fp.ZERO);
            // fromAffine(x:0, y:0) would produce (x:0, y:0, z:1), but we need (x:0, y:1, z:0)
            if (is0(x) && is0(y))
                return Point.ZERO;
            return new Point(x, y, Fp.ONE);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        /**
         * Takes a bunch of Projective Points but executes only one
         * inversion on all of them. Inversion is very slow operation,
         * so this improves performance massively.
         * Optimization: converts a list of projective points to a list of identical points with Z=1.
         */
        static normalizeZ(points) {
            const toInv = Fp.invertBatch(points.map((p) => p.pz));
            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);
        }
        /**
         * Converts hash string or Uint8Array to Point.
         * @param hex short/long ECDSA hex
         */
        static fromHex(hex) {
            const P = Point.fromAffine(fromBytes(ensureBytes$1('pointHex', hex)));
            P.assertValidity();
            return P;
        }
        // Multiplies generator point by privateKey.
        static fromPrivateKey(privateKey) {
            return Point.BASE.multiply(normPrivateKeyToScalar(privateKey));
        }
        // Multiscalar Multiplication
        static msm(points, scalars) {
            return pippenger(Point, Fn, points, scalars);
        }
        // "Private method", don't use it directly
        _setWindowSize(windowSize) {
            wnaf.setWindowSize(this, windowSize);
        }
        // A point on curve is valid if it conforms to equation.
        assertValidity() {
            assertValidMemo(this);
        }
        hasEvenY() {
            const { y } = this.toAffine();
            if (Fp.isOdd)
                return !Fp.isOdd(y);
            throw new Error("Field doesn't support isOdd");
        }
        /**
         * Compare one point to another.
         */
        equals(other) {
            assertPrjPoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            const U1 = Fp.eql(Fp.mul(X1, Z2), Fp.mul(X2, Z1));
            const U2 = Fp.eql(Fp.mul(Y1, Z2), Fp.mul(Y2, Z1));
            return U1 && U2;
        }
        /**
         * Flips point to one corresponding to (x, -y) in Affine coordinates.
         */
        negate() {
            return new Point(this.px, Fp.neg(this.py), this.pz);
        }
        // Renes-Costello-Batina exception-free doubling formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 3
        // Cost: 8M + 3S + 3*a + 2*b3 + 15add.
        double() {
            const { a, b } = CURVE;
            const b3 = Fp.mul(b, _3n$1);
            const { px: X1, py: Y1, pz: Z1 } = this;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            let t0 = Fp.mul(X1, X1); // step 1
            let t1 = Fp.mul(Y1, Y1);
            let t2 = Fp.mul(Z1, Z1);
            let t3 = Fp.mul(X1, Y1);
            t3 = Fp.add(t3, t3); // step 5
            Z3 = Fp.mul(X1, Z1);
            Z3 = Fp.add(Z3, Z3);
            X3 = Fp.mul(a, Z3);
            Y3 = Fp.mul(b3, t2);
            Y3 = Fp.add(X3, Y3); // step 10
            X3 = Fp.sub(t1, Y3);
            Y3 = Fp.add(t1, Y3);
            Y3 = Fp.mul(X3, Y3);
            X3 = Fp.mul(t3, X3);
            Z3 = Fp.mul(b3, Z3); // step 15
            t2 = Fp.mul(a, t2);
            t3 = Fp.sub(t0, t2);
            t3 = Fp.mul(a, t3);
            t3 = Fp.add(t3, Z3);
            Z3 = Fp.add(t0, t0); // step 20
            t0 = Fp.add(Z3, t0);
            t0 = Fp.add(t0, t2);
            t0 = Fp.mul(t0, t3);
            Y3 = Fp.add(Y3, t0);
            t2 = Fp.mul(Y1, Z1); // step 25
            t2 = Fp.add(t2, t2);
            t0 = Fp.mul(t2, t3);
            X3 = Fp.sub(X3, t0);
            Z3 = Fp.mul(t2, t1);
            Z3 = Fp.add(Z3, Z3); // step 30
            Z3 = Fp.add(Z3, Z3);
            return new Point(X3, Y3, Z3);
        }
        // Renes-Costello-Batina exception-free addition formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 1
        // Cost: 12M + 0S + 3*a + 3*b3 + 23add.
        add(other) {
            assertPrjPoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            const a = CURVE.a;
            const b3 = Fp.mul(CURVE.b, _3n$1);
            let t0 = Fp.mul(X1, X2); // step 1
            let t1 = Fp.mul(Y1, Y2);
            let t2 = Fp.mul(Z1, Z2);
            let t3 = Fp.add(X1, Y1);
            let t4 = Fp.add(X2, Y2); // step 5
            t3 = Fp.mul(t3, t4);
            t4 = Fp.add(t0, t1);
            t3 = Fp.sub(t3, t4);
            t4 = Fp.add(X1, Z1);
            let t5 = Fp.add(X2, Z2); // step 10
            t4 = Fp.mul(t4, t5);
            t5 = Fp.add(t0, t2);
            t4 = Fp.sub(t4, t5);
            t5 = Fp.add(Y1, Z1);
            X3 = Fp.add(Y2, Z2); // step 15
            t5 = Fp.mul(t5, X3);
            X3 = Fp.add(t1, t2);
            t5 = Fp.sub(t5, X3);
            Z3 = Fp.mul(a, t4);
            X3 = Fp.mul(b3, t2); // step 20
            Z3 = Fp.add(X3, Z3);
            X3 = Fp.sub(t1, Z3);
            Z3 = Fp.add(t1, Z3);
            Y3 = Fp.mul(X3, Z3);
            t1 = Fp.add(t0, t0); // step 25
            t1 = Fp.add(t1, t0);
            t2 = Fp.mul(a, t2);
            t4 = Fp.mul(b3, t4);
            t1 = Fp.add(t1, t2);
            t2 = Fp.sub(t0, t2); // step 30
            t2 = Fp.mul(a, t2);
            t4 = Fp.add(t4, t2);
            t0 = Fp.mul(t1, t4);
            Y3 = Fp.add(Y3, t0);
            t0 = Fp.mul(t5, t4); // step 35
            X3 = Fp.mul(t3, X3);
            X3 = Fp.sub(X3, t0);
            t0 = Fp.mul(t3, t1);
            Z3 = Fp.mul(t5, Z3);
            Z3 = Fp.add(Z3, t0); // step 40
            return new Point(X3, Y3, Z3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        wNAF(n) {
            return wnaf.wNAFCached(this, n, Point.normalizeZ);
        }
        /**
         * Non-constant-time multiplication. Uses double-and-add algorithm.
         * It's faster, but should only be used when you don't care about
         * an exposed private key e.g. sig verification, which works over *public* keys.
         */
        multiplyUnsafe(sc) {
            aInRange('scalar', sc, _0n$1, CURVE.n);
            const I = Point.ZERO;
            if (sc === _0n$1)
                return I;
            if (sc === _1n$2)
                return this;
            const { endo } = CURVE;
            if (!endo)
                return wnaf.unsafeLadder(this, sc);
            // Apply endomorphism
            let { k1neg, k1, k2neg, k2 } = endo.splitScalar(sc);
            let k1p = I;
            let k2p = I;
            let d = this;
            while (k1 > _0n$1 || k2 > _0n$1) {
                if (k1 & _1n$2)
                    k1p = k1p.add(d);
                if (k2 & _1n$2)
                    k2p = k2p.add(d);
                d = d.double();
                k1 >>= _1n$2;
                k2 >>= _1n$2;
            }
            if (k1neg)
                k1p = k1p.negate();
            if (k2neg)
                k2p = k2p.negate();
            k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);
            return k1p.add(k2p);
        }
        /**
         * Constant time multiplication.
         * Uses wNAF method. Windowed method may be 10% faster,
         * but takes 2x longer to generate and consumes 2x memory.
         * Uses precomputes when available.
         * Uses endomorphism for Koblitz curves.
         * @param scalar by which the point would be multiplied
         * @returns New point
         */
        multiply(scalar) {
            const { endo, n: N } = CURVE;
            aInRange('scalar', scalar, _1n$2, N);
            let point, fake; // Fake point is used to const-time mult
            if (endo) {
                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(scalar);
                let { p: k1p, f: f1p } = this.wNAF(k1);
                let { p: k2p, f: f2p } = this.wNAF(k2);
                k1p = wnaf.constTimeNegate(k1neg, k1p);
                k2p = wnaf.constTimeNegate(k2neg, k2p);
                k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);
                point = k1p.add(k2p);
                fake = f1p.add(f2p);
            }
            else {
                const { p, f } = this.wNAF(scalar);
                point = p;
                fake = f;
            }
            // Normalize `z` for both points, but return only real one
            return Point.normalizeZ([point, fake])[0];
        }
        /**
         * Efficiently calculate `aP + bQ`. Unsafe, can expose private key, if used incorrectly.
         * Not using Strauss-Shamir trick: precomputation tables are faster.
         * The trick could be useful if both P and Q are not G (not in our case).
         * @returns non-zero affine point
         */
        multiplyAndAddUnsafe(Q, a, b) {
            const G = Point.BASE; // No Strauss-Shamir trick: we have 10% faster G precomputes
            const mul = (P, a // Select faster multiply() method
            ) => (a === _0n$1 || a === _1n$2 || !P.equals(G) ? P.multiplyUnsafe(a) : P.multiply(a));
            const sum = mul(this, a).add(mul(Q, b));
            return sum.is0() ? undefined : sum;
        }
        // Converts Projective point to affine (x, y) coordinates.
        // Can accept precomputed Z^-1 - for example, from invertBatch.
        // (x, y, z) ∋ (x=x/z, y=y/z)
        toAffine(iz) {
            return toAffineMemo(this, iz);
        }
        isTorsionFree() {
            const { h: cofactor, isTorsionFree } = CURVE;
            if (cofactor === _1n$2)
                return true; // No subgroups, always torsion-free
            if (isTorsionFree)
                return isTorsionFree(Point, this);
            throw new Error('isTorsionFree() has not been declared for the elliptic curve');
        }
        clearCofactor() {
            const { h: cofactor, clearCofactor } = CURVE;
            if (cofactor === _1n$2)
                return this; // Fast-path
            if (clearCofactor)
                return clearCofactor(Point, this);
            return this.multiplyUnsafe(CURVE.h);
        }
        toRawBytes(isCompressed = true) {
            abool('isCompressed', isCompressed);
            this.assertValidity();
            return toBytes(Point, this, isCompressed);
        }
        toHex(isCompressed = true) {
            abool('isCompressed', isCompressed);
            return bytesToHex$1(this.toRawBytes(isCompressed));
        }
    }
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, Fp.ONE);
    Point.ZERO = new Point(Fp.ZERO, Fp.ONE, Fp.ZERO);
    const _bits = CURVE.nBitLength;
    const wnaf = wNAF(Point, CURVE.endo ? Math.ceil(_bits / 2) : _bits);
    // Validate if generator point is on curve
    return {
        CURVE,
        ProjectivePoint: Point,
        normPrivateKeyToScalar,
        weierstrassEquation,
        isWithinCurveOrder,
    };
}
function validateOpts(curve) {
    const opts = validateBasic(curve);
    validateObject(opts, {
        hash: 'hash',
        hmac: 'function',
        randomBytes: 'function',
    }, {
        bits2int: 'function',
        bits2int_modN: 'function',
        lowS: 'boolean',
    });
    return Object.freeze({ lowS: true, ...opts });
}
/**
 * Creates short weierstrass curve and ECDSA signature methods for it.
 * @example
 * import { Field } from '@noble/curves/abstract/modular';
 * // Before that, define BigInt-s: a, b, p, n, Gx, Gy
 * const curve = weierstrass({ a, b, Fp: Field(p), n, Gx, Gy, h: 1n })
 */
function weierstrass$1(curveDef) {
    const CURVE = validateOpts(curveDef);
    const { Fp, n: CURVE_ORDER } = CURVE;
    const compressedLen = Fp.BYTES + 1; // e.g. 33 for 32
    const uncompressedLen = 2 * Fp.BYTES + 1; // e.g. 65 for 32
    function modN(a) {
        return mod$1(a, CURVE_ORDER);
    }
    function invN(a) {
        return invert$1(a, CURVE_ORDER);
    }
    const { ProjectivePoint: Point, normPrivateKeyToScalar, weierstrassEquation, isWithinCurveOrder, } = weierstrassPoints({
        ...CURVE,
        toBytes(_c, point, isCompressed) {
            const a = point.toAffine();
            const x = Fp.toBytes(a.x);
            const cat = concatBytes$1;
            abool('isCompressed', isCompressed);
            if (isCompressed) {
                return cat(Uint8Array.from([point.hasEvenY() ? 0x02 : 0x03]), x);
            }
            else {
                return cat(Uint8Array.from([0x04]), x, Fp.toBytes(a.y));
            }
        },
        fromBytes(bytes) {
            const len = bytes.length;
            const head = bytes[0];
            const tail = bytes.subarray(1);
            // this.assertValidity() is done inside of fromHex
            if (len === compressedLen && (head === 0x02 || head === 0x03)) {
                const x = bytesToNumberBE(tail);
                if (!inRange(x, _1n$2, Fp.ORDER))
                    throw new Error('Point is not on curve');
                const y2 = weierstrassEquation(x); // y² = x³ + ax + b
                let y;
                try {
                    y = Fp.sqrt(y2); // y = y² ^ (p+1)/4
                }
                catch (sqrtError) {
                    const suffix = sqrtError instanceof Error ? ': ' + sqrtError.message : '';
                    throw new Error('Point is not on curve' + suffix);
                }
                const isYOdd = (y & _1n$2) === _1n$2;
                // ECDSA
                const isHeadOdd = (head & 1) === 1;
                if (isHeadOdd !== isYOdd)
                    y = Fp.neg(y);
                return { x, y };
            }
            else if (len === uncompressedLen && head === 0x04) {
                const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));
                const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));
                return { x, y };
            }
            else {
                throw new Error(`Point of length ${len} was invalid. Expected ${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes`);
            }
        },
    });
    const numToNByteStr = (num) => bytesToHex$1(numberToBytesBE(num, CURVE.nByteLength));
    function isBiggerThanHalfOrder(number) {
        const HALF = CURVE_ORDER >> _1n$2;
        return number > HALF;
    }
    function normalizeS(s) {
        return isBiggerThanHalfOrder(s) ? modN(-s) : s;
    }
    // slice bytes num
    const slcNum = (b, from, to) => bytesToNumberBE(b.slice(from, to));
    /**
     * ECDSA signature with its (r, s) properties. Supports DER & compact representations.
     */
    class Signature {
        constructor(r, s, recovery) {
            this.r = r;
            this.s = s;
            this.recovery = recovery;
            this.assertValidity();
        }
        // pair (bytes of r, bytes of s)
        static fromCompact(hex) {
            const l = CURVE.nByteLength;
            hex = ensureBytes$1('compactSignature', hex, l * 2);
            return new Signature(slcNum(hex, 0, l), slcNum(hex, l, 2 * l));
        }
        // DER encoded ECDSA signature
        // https://bitcoin.stackexchange.com/questions/57644/what-are-the-parts-of-a-bitcoin-transaction-input-script
        static fromDER(hex) {
            const { r, s } = DER.toSig(ensureBytes$1('DER', hex));
            return new Signature(r, s);
        }
        assertValidity() {
            aInRange('r', this.r, _1n$2, CURVE_ORDER); // r in [1..N]
            aInRange('s', this.s, _1n$2, CURVE_ORDER); // s in [1..N]
        }
        addRecoveryBit(recovery) {
            return new Signature(this.r, this.s, recovery);
        }
        recoverPublicKey(msgHash) {
            const { r, s, recovery: rec } = this;
            const h = bits2int_modN(ensureBytes$1('msgHash', msgHash)); // Truncate hash
            if (rec == null || ![0, 1, 2, 3].includes(rec))
                throw new Error('recovery id invalid');
            const radj = rec === 2 || rec === 3 ? r + CURVE.n : r;
            if (radj >= Fp.ORDER)
                throw new Error('recovery id 2 or 3 invalid');
            const prefix = (rec & 1) === 0 ? '02' : '03';
            const R = Point.fromHex(prefix + numToNByteStr(radj));
            const ir = invN(radj); // r^-1
            const u1 = modN(-h * ir); // -hr^-1
            const u2 = modN(s * ir); // sr^-1
            const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2); // (sr^-1)R-(hr^-1)G = -(hr^-1)G + (sr^-1)
            if (!Q)
                throw new Error('point at infinify'); // unsafe is fine: no priv data leaked
            Q.assertValidity();
            return Q;
        }
        // Signatures should be low-s, to prevent malleability.
        hasHighS() {
            return isBiggerThanHalfOrder(this.s);
        }
        normalizeS() {
            return this.hasHighS() ? new Signature(this.r, modN(-this.s), this.recovery) : this;
        }
        // DER-encoded
        toDERRawBytes() {
            return hexToBytes$1(this.toDERHex());
        }
        toDERHex() {
            return DER.hexFromSig({ r: this.r, s: this.s });
        }
        // padded bytes of r, then padded bytes of s
        toCompactRawBytes() {
            return hexToBytes$1(this.toCompactHex());
        }
        toCompactHex() {
            return numToNByteStr(this.r) + numToNByteStr(this.s);
        }
    }
    const utils = {
        isValidPrivateKey(privateKey) {
            try {
                normPrivateKeyToScalar(privateKey);
                return true;
            }
            catch (error) {
                return false;
            }
        },
        normPrivateKeyToScalar: normPrivateKeyToScalar,
        /**
         * Produces cryptographically secure private key from random of size
         * (groupLen + ceil(groupLen / 2)) with modulo bias being negligible.
         */
        randomPrivateKey: () => {
            const length = getMinHashLength(CURVE.n);
            return mapHashToField(CURVE.randomBytes(length), CURVE.n);
        },
        /**
         * Creates precompute table for an arbitrary EC point. Makes point "cached".
         * Allows to massively speed-up `point.multiply(scalar)`.
         * @returns cached point
         * @example
         * const fast = utils.precompute(8, ProjectivePoint.fromHex(someonesPubKey));
         * fast.multiply(privKey); // much faster ECDH now
         */
        precompute(windowSize = 8, point = Point.BASE) {
            point._setWindowSize(windowSize);
            point.multiply(BigInt(3)); // 3 is arbitrary, just need any number here
            return point;
        },
    };
    /**
     * Computes public key for a private key. Checks for validity of the private key.
     * @param privateKey private key
     * @param isCompressed whether to return compact (default), or full key
     * @returns Public key, full when isCompressed=false; short when isCompressed=true
     */
    function getPublicKey(privateKey, isCompressed = true) {
        return Point.fromPrivateKey(privateKey).toRawBytes(isCompressed);
    }
    /**
     * Quick and dirty check for item being public key. Does not validate hex, or being on-curve.
     */
    function isProbPub(item) {
        const arr = isBytes$2(item);
        const str = typeof item === 'string';
        const len = (arr || str) && item.length;
        if (arr)
            return len === compressedLen || len === uncompressedLen;
        if (str)
            return len === 2 * compressedLen || len === 2 * uncompressedLen;
        if (item instanceof Point)
            return true;
        return false;
    }
    /**
     * ECDH (Elliptic Curve Diffie Hellman).
     * Computes shared public key from private key and public key.
     * Checks: 1) private key validity 2) shared key is on-curve.
     * Does NOT hash the result.
     * @param privateA private key
     * @param publicB different public key
     * @param isCompressed whether to return compact (default), or full key
     * @returns shared public key
     */
    function getSharedSecret(privateA, publicB, isCompressed = true) {
        if (isProbPub(privateA))
            throw new Error('first arg must be private key');
        if (!isProbPub(publicB))
            throw new Error('second arg must be public key');
        const b = Point.fromHex(publicB); // check for being on-curve
        return b.multiply(normPrivateKeyToScalar(privateA)).toRawBytes(isCompressed);
    }
    // RFC6979: ensure ECDSA msg is X bytes and < N. RFC suggests optional truncating via bits2octets.
    // FIPS 186-4 4.6 suggests the leftmost min(nBitLen, outLen) bits, which matches bits2int.
    // bits2int can produce res>N, we can do mod(res, N) since the bitLen is the same.
    // int2octets can't be used; pads small msgs with 0: unacceptatble for trunc as per RFC vectors
    const bits2int = CURVE.bits2int ||
        function (bytes) {
            // For curves with nBitLength % 8 !== 0: bits2octets(bits2octets(m)) !== bits2octets(m)
            // for some cases, since bytes.length * 8 is not actual bitLength.
            const num = bytesToNumberBE(bytes); // check for == u8 done here
            const delta = bytes.length * 8 - CURVE.nBitLength; // truncate to nBitLength leftmost bits
            return delta > 0 ? num >> BigInt(delta) : num;
        };
    const bits2int_modN = CURVE.bits2int_modN ||
        function (bytes) {
            return modN(bits2int(bytes)); // can't use bytesToNumberBE here
        };
    // NOTE: pads output with zero as per spec
    const ORDER_MASK = bitMask(CURVE.nBitLength);
    /**
     * Converts to bytes. Checks if num in `[0..ORDER_MASK-1]` e.g.: `[0..2^256-1]`.
     */
    function int2octets(num) {
        aInRange(`num < 2^${CURVE.nBitLength}`, num, _0n$1, ORDER_MASK);
        // works with order, can have different size than numToField!
        return numberToBytesBE(num, CURVE.nByteLength);
    }
    // Steps A, D of RFC6979 3.2
    // Creates RFC6979 seed; converts msg/privKey to numbers.
    // Used only in sign, not in verify.
    // NOTE: we cannot assume here that msgHash has same amount of bytes as curve order, this will be wrong at least for P521.
    // Also it can be bigger for P224 + SHA256
    function prepSig(msgHash, privateKey, opts = defaultSigOpts) {
        if (['recovered', 'canonical'].some((k) => k in opts))
            throw new Error('sign() legacy options not supported');
        const { hash, randomBytes } = CURVE;
        let { lowS, prehash, extraEntropy: ent } = opts; // generates low-s sigs by default
        if (lowS == null)
            lowS = true; // RFC6979 3.2: we skip step A, because we already provide hash
        msgHash = ensureBytes$1('msgHash', msgHash);
        validateSigVerOpts(opts);
        if (prehash)
            msgHash = ensureBytes$1('prehashed msgHash', hash(msgHash));
        // We can't later call bits2octets, since nested bits2int is broken for curves
        // with nBitLength % 8 !== 0. Because of that, we unwrap it here as int2octets call.
        // const bits2octets = (bits) => int2octets(bits2int_modN(bits))
        const h1int = bits2int_modN(msgHash);
        const d = normPrivateKeyToScalar(privateKey); // validate private key, convert to bigint
        const seedArgs = [int2octets(d), int2octets(h1int)];
        // extraEntropy. RFC6979 3.6: additional k' (optional).
        if (ent != null && ent !== false) {
            // K = HMAC_K(V || 0x00 || int2octets(x) || bits2octets(h1) || k')
            const e = ent === true ? randomBytes(Fp.BYTES) : ent; // generate random bytes OR pass as-is
            seedArgs.push(ensureBytes$1('extraEntropy', e)); // check for being bytes
        }
        const seed = concatBytes$1(...seedArgs); // Step D of RFC6979 3.2
        const m = h1int; // NOTE: no need to call bits2int second time here, it is inside truncateHash!
        // Converts signature params into point w r/s, checks result for validity.
        function k2sig(kBytes) {
            // RFC 6979 Section 3.2, step 3: k = bits2int(T)
            const k = bits2int(kBytes); // Cannot use fields methods, since it is group element
            if (!isWithinCurveOrder(k))
                return; // Important: all mod() calls here must be done over N
            const ik = invN(k); // k^-1 mod n
            const q = Point.BASE.multiply(k).toAffine(); // q = Gk
            const r = modN(q.x); // r = q.x mod n
            if (r === _0n$1)
                return;
            // Can use scalar blinding b^-1(bm + bdr) where b ∈ [1,q−1] according to
            // https://tches.iacr.org/index.php/TCHES/article/view/7337/6509. We've decided against it:
            // a) dependency on CSPRNG b) 15% slowdown c) doesn't really help since bigints are not CT
            const s = modN(ik * modN(m + r * d)); // Not using blinding here
            if (s === _0n$1)
                return;
            let recovery = (q.x === r ? 0 : 2) | Number(q.y & _1n$2); // recovery bit (2 or 3, when q.x > n)
            let normS = s;
            if (lowS && isBiggerThanHalfOrder(s)) {
                normS = normalizeS(s); // if lowS was passed, ensure s is always
                recovery ^= 1; // // in the bottom half of N
            }
            return new Signature(r, normS, recovery); // use normS, not s
        }
        return { seed, k2sig };
    }
    const defaultSigOpts = { lowS: CURVE.lowS, prehash: false };
    const defaultVerOpts = { lowS: CURVE.lowS, prehash: false };
    /**
     * Signs message hash with a private key.
     * ```
     * sign(m, d, k) where
     *   (x, y) = G × k
     *   r = x mod n
     *   s = (m + dr)/k mod n
     * ```
     * @param msgHash NOT message. msg needs to be hashed to `msgHash`, or use `prehash`.
     * @param privKey private key
     * @param opts lowS for non-malleable sigs. extraEntropy for mixing randomness into k. prehash will hash first arg.
     * @returns signature with recovery param
     */
    function sign(msgHash, privKey, opts = defaultSigOpts) {
        const { seed, k2sig } = prepSig(msgHash, privKey, opts); // Steps A, D of RFC6979 3.2.
        const C = CURVE;
        const drbg = createHmacDrbg(C.hash.outputLen, C.nByteLength, C.hmac);
        return drbg(seed, k2sig); // Steps B, C, D, E, F, G
    }
    // Enable precomputes. Slows down first publicKey computation by 20ms.
    Point.BASE._setWindowSize(8);
    // utils.precompute(8, ProjectivePoint.BASE)
    /**
     * Verifies a signature against message hash and public key.
     * Rejects lowS signatures by default: to override,
     * specify option `{lowS: false}`. Implements section 4.1.4 from https://www.secg.org/sec1-v2.pdf:
     *
     * ```
     * verify(r, s, h, P) where
     *   U1 = hs^-1 mod n
     *   U2 = rs^-1 mod n
     *   R = U1⋅G - U2⋅P
     *   mod(R.x, n) == r
     * ```
     */
    function verify(signature, msgHash, publicKey, opts = defaultVerOpts) {
        const sg = signature;
        msgHash = ensureBytes$1('msgHash', msgHash);
        publicKey = ensureBytes$1('publicKey', publicKey);
        if ('strict' in opts)
            throw new Error('options.strict was renamed to lowS');
        validateSigVerOpts(opts);
        const { lowS, prehash } = opts;
        let _sig = undefined;
        let P;
        try {
            if (typeof sg === 'string' || isBytes$2(sg)) {
                // Signature can be represented in 2 ways: compact (2*nByteLength) & DER (variable-length).
                // Since DER can also be 2*nByteLength bytes, we check for it first.
                try {
                    _sig = Signature.fromDER(sg);
                }
                catch (derError) {
                    if (!(derError instanceof DER.Err))
                        throw derError;
                    _sig = Signature.fromCompact(sg);
                }
            }
            else if (typeof sg === 'object' && typeof sg.r === 'bigint' && typeof sg.s === 'bigint') {
                const { r, s } = sg;
                _sig = new Signature(r, s);
            }
            else {
                throw new Error('PARSE');
            }
            P = Point.fromHex(publicKey);
        }
        catch (error) {
            if (error.message === 'PARSE')
                throw new Error(`signature must be Signature instance, Uint8Array or hex string`);
            return false;
        }
        if (lowS && _sig.hasHighS())
            return false;
        if (prehash)
            msgHash = CURVE.hash(msgHash);
        const { r, s } = _sig;
        const h = bits2int_modN(msgHash); // Cannot use fields methods, since it is group element
        const is = invN(s); // s^-1
        const u1 = modN(h * is); // u1 = hs^-1 mod n
        const u2 = modN(r * is); // u2 = rs^-1 mod n
        const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2)?.toAffine(); // R = u1⋅G + u2⋅P
        if (!R)
            return false;
        const v = modN(R.x);
        return v === r;
    }
    return {
        CURVE,
        getPublicKey,
        getSharedSecret,
        sign,
        verify,
        ProjectivePoint: Point,
        Signature,
        utils,
    };
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// connects noble-curves to noble-hashes
function getHash(hash) {
    return {
        hash,
        hmac: (key, ...msgs) => hmac(hash, key, concatBytes$2(...msgs)),
        randomBytes: randomBytes$1,
    };
}
function createCurve(curveDef, defHash) {
    const create = (hash) => weierstrass$1({ ...curveDef, ...getHash(hash) });
    return Object.freeze({ ...create(defHash), create });
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const secp256k1P = BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f');
const secp256k1N = BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141');
const _1n$1 = BigInt(1);
const _2n$1 = BigInt(2);
const divNearest$1 = (a, b) => (a + b / _2n$1) / b;
/**
 * √n = n^((p+1)/4) for fields p = 3 mod 4. We unwrap the loop and multiply bit-by-bit.
 * (P+1n/4n).toString(2) would produce bits [223x 1, 0, 22x 1, 4x 0, 11, 00]
 */
function sqrtMod$1(y) {
    const P = secp256k1P;
    // prettier-ignore
    const _3n = BigInt(3), _6n = BigInt(6), _11n = BigInt(11), _22n = BigInt(22);
    // prettier-ignore
    const _23n = BigInt(23), _44n = BigInt(44), _88n = BigInt(88);
    const b2 = (y * y * y) % P; // x^3, 11
    const b3 = (b2 * b2 * y) % P; // x^7
    const b6 = (pow2$1(b3, _3n, P) * b3) % P;
    const b9 = (pow2$1(b6, _3n, P) * b3) % P;
    const b11 = (pow2$1(b9, _2n$1, P) * b2) % P;
    const b22 = (pow2$1(b11, _11n, P) * b11) % P;
    const b44 = (pow2$1(b22, _22n, P) * b22) % P;
    const b88 = (pow2$1(b44, _44n, P) * b44) % P;
    const b176 = (pow2$1(b88, _88n, P) * b88) % P;
    const b220 = (pow2$1(b176, _44n, P) * b44) % P;
    const b223 = (pow2$1(b220, _3n, P) * b3) % P;
    const t1 = (pow2$1(b223, _23n, P) * b22) % P;
    const t2 = (pow2$1(t1, _6n, P) * b2) % P;
    const root = pow2$1(t2, _2n$1, P);
    if (!Fp.eql(Fp.sqr(root), y))
        throw new Error('Cannot find square root');
    return root;
}
const Fp = Field(secp256k1P, undefined, undefined, { sqrt: sqrtMod$1 });
/**
 * secp256k1 short weierstrass curve and ECDSA signatures over it.
 */
const secp256k1 = createCurve({
    a: BigInt(0), // equation params: a, b
    b: BigInt(7), // Seem to be rigid: bitcointalk.org/index.php?topic=289795.msg3183975#msg3183975
    Fp, // Field's prime: 2n**256n - 2n**32n - 2n**9n - 2n**8n - 2n**7n - 2n**6n - 2n**4n - 1n
    n: secp256k1N, // Curve order, total count of valid points in the field
    // Base point (x, y) aka generator point
    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),
    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),
    h: BigInt(1), // Cofactor
    lowS: true, // Allow only low-S signatures by default in sign() and verify()
    /**
     * secp256k1 belongs to Koblitz curves: it has efficiently computable endomorphism.
     * Endomorphism uses 2x less RAM, speeds up precomputation by 2x and ECDH / key recovery by 20%.
     * For precomputed wNAF it trades off 1/2 init time & 1/3 ram for 20% perf hit.
     * Explanation: https://gist.github.com/paulmillr/eb670806793e84df628a7c434a873066
     */
    endo: {
        beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
        splitScalar: (k) => {
            const n = secp256k1N;
            const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
            const b1 = -_1n$1 * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
            const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
            const b2 = a1;
            const POW_2_128 = BigInt('0x100000000000000000000000000000000'); // (2n**128n).toString(16)
            const c1 = divNearest$1(b2 * k, n);
            const c2 = divNearest$1(-b1 * k, n);
            let k1 = mod$1(k - c1 * a1 - c2 * a2, n);
            let k2 = mod$1(-c1 * b1 - c2 * b2, n);
            const k1neg = k1 > POW_2_128;
            const k2neg = k2 > POW_2_128;
            if (k1neg)
                k1 = n - k1;
            if (k2neg)
                k2 = n - k2;
            if (k1 > POW_2_128 || k2 > POW_2_128) {
                throw new Error('splitScalar: Endomorphism failed, k=' + k);
            }
            return { k1neg, k1, k2neg, k2 };
        },
    },
}, sha256);
// Schnorr signatures are superior to ECDSA from above. Below is Schnorr-specific BIP0340 code.
// https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki
BigInt(0);
secp256k1.ProjectivePoint;

function generateKey() {
    return secp256k1.utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
function hashAndSign(key, msg) {
    const p = sha256$1.digest(msg instanceof Uint8Array ? msg : msg.subarray());
    if (isPromise$3(p)) {
        return p.then(({ digest }) => secp256k1.sign(digest, key).toDERRawBytes())
            .catch(err => {
            throw new CodeError$1(String(err), 'ERR_INVALID_INPUT');
        });
    }
    try {
        return secp256k1.sign(p.digest, key).toDERRawBytes();
    }
    catch (err) {
        throw new CodeError$1(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
function hashAndVerify(key, sig, msg) {
    const p = sha256$1.digest(msg instanceof Uint8Array ? msg : msg.subarray());
    if (isPromise$3(p)) {
        return p.then(({ digest }) => secp256k1.verify(sig, digest, key))
            .catch(err => {
            throw new CodeError$1(String(err), 'ERR_INVALID_INPUT');
        });
    }
    try {
        return secp256k1.verify(sig, p.digest, key);
    }
    catch (err) {
        throw new CodeError$1(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey(key) {
    try {
        secp256k1.getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$1(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
    }
    catch (err) {
        throw new CodeError$1(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey(privateKey) {
    try {
        return secp256k1.getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$1(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey(key);
        this._key = key;
    }
    verify(data, sig) {
        return hashAndVerify(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey(this._key);
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals(this.bytes, key.bytes);
    }
    async hash() {
        const p = sha256$1.digest(this.bytes);
        let bytes;
        if (isPromise$3(p)) {
            ({ bytes } = await p);
        }
        else {
            bytes = p.bytes;
        }
        return bytes;
    }
}
class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey(key);
        validatePrivateKey(this._key);
        validatePublicKey(this._publicKey);
    }
    sign(message) {
        return hashAndSign(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals(this.bytes, key.bytes);
    }
    hash() {
        const p = sha256$1.digest(this.bytes);
        if (isPromise$3(p)) {
            return p.then(({ bytes }) => bytes);
        }
        return p.bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$6(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter(this.bytes, password);
        }
        else {
            throw new CodeError$1(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
function unmarshalSecp256k1PrivateKey(bytes) {
    return new Secp256k1PrivateKey(bytes);
}
function unmarshalSecp256k1PublicKey(bytes) {
    return new Secp256k1PublicKey(bytes);
}
async function generateKeyPair$1() {
    const privateKeyBytes = generateKey();
    return new Secp256k1PrivateKey(privateKeyBytes);
}

var Secp256k1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey,
    Secp256k1PublicKey: Secp256k1PublicKey,
    generateKeyPair: generateKeyPair$1,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey
});

/**
 * @packageDocumentation
 *
 * **Supported Key Types**
 *
 * The {@link generateKeyPair}, {@link marshalPublicKey}, and {@link marshalPrivateKey} functions accept a string `type` argument.
 *
 * Currently the `'RSA'`, `'ed25519'`, and `secp256k1` types are supported, although ed25519 and secp256k1 keys support only signing and verification of messages.
 *
 * For encryption / decryption support, RSA keys should be used.
 */
const supportedKeys = {
    rsa: RSA,
    ed25519: Ed25519,
    secp256k1: Secp256k1
};
function unsupportedKey(type) {
    const supported = Object.keys(supportedKeys).join(' / ');
    return new CodeError$1(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
function typeToKey(type) {
    type = type.toLowerCase();
    if (type === 'rsa' || type === 'ed25519' || type === 'secp256k1') {
        return supportedKeys[type];
    }
    throw unsupportedKey(type);
}
/**
 * Generates a keypair of the given type and bitsize
 */
async function generateKeyPair(type, bits) {
    return typeToKey(type).generateKeyPair(2048);
}
/**
 * Converts a protobuf serialized public key into its representative object
 */
function unmarshalPublicKey(buf) {
    const decoded = PublicKey.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType.RSA:
            return supportedKeys.rsa.unmarshalRsaPublicKey(data);
        case KeyType.Ed25519:
            return supportedKeys.ed25519.unmarshalEd25519PublicKey(data);
        case KeyType.Secp256k1:
            return supportedKeys.secp256k1.unmarshalSecp256k1PublicKey(data);
        default:
            throw unsupportedKey(decoded.Type ?? 'unknown');
    }
}
/**
 * Converts a public key object into a protobuf serialized public key
 */
function marshalPublicKey(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey(type); // check type
    return key.bytes;
}
/**
 * Converts a protobuf serialized private key into its representative object
 */
async function unmarshalPrivateKey(buf) {
    const decoded = PrivateKey.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType.RSA:
            return supportedKeys.rsa.unmarshalRsaPrivateKey(data);
        case KeyType.Ed25519:
            return supportedKeys.ed25519.unmarshalEd25519PrivateKey(data);
        case KeyType.Secp256k1:
            return supportedKeys.secp256k1.unmarshalSecp256k1PrivateKey(data);
        default:
            throw unsupportedKey(decoded.Type ?? 'RSA');
    }
}
/**
 * Converts a private key object into a protobuf serialized private key
 */
function marshalPrivateKey(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey(type); // check type
    return key.bytes;
}

/**
 * @packageDocumentation
 *
 * An implementation of a peer id
 *
 * @example
 *
 * ```TypeScript
 * import { peerIdFromString } from '@libp2p/peer-id'
 * const peer = peerIdFromString('k51qzi5uqu5dkwkqm42v9j9kqcam2jiuvloi16g72i4i4amoo2m8u3ol3mqu6s')
 *
 * console.log(peer.toCID()) // CID(bafzaa...)
 * console.log(peer.toString()) // "12D3K..."
 * ```
 */
const inspect = Symbol.for('nodejs.util.inspect.custom');
const baseDecoder = Object
    .values(bases)
    .map(codec => codec.decoder)
    // @ts-expect-error https://github.com/multiformats/js-multiformats/issues/141
    .reduce((acc, curr) => acc.or(curr), bases.identity.decoder);
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE = 0x72;
const MARSHALLED_ED225519_PUBLIC_KEY_LENGTH = 36;
const MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH = 37;
class PeerIdImpl {
    type;
    multihash;
    privateKey;
    publicKey;
    string;
    constructor(init) {
        this.type = init.type;
        this.multihash = init.multihash;
        this.privateKey = init.privateKey;
        // mark string cache as non-enumerable
        Object.defineProperty(this, 'string', {
            enumerable: false,
            writable: true
        });
    }
    get [Symbol.toStringTag]() {
        return `PeerId(${this.toString()})`;
    }
    [peerIdSymbol] = true;
    toString() {
        if (this.string == null) {
            this.string = base58btc.encode(this.multihash.bytes).slice(1);
        }
        return this.string;
    }
    // return self-describing String representation
    // in default format from RFC 0001: https://github.com/libp2p/specs/pull/209
    toCID() {
        return CID.createV1(LIBP2P_KEY_CODE, this.multihash);
    }
    toBytes() {
        return this.multihash.bytes;
    }
    /**
     * Returns Multiaddr as a JSON string
     */
    toJSON() {
        return this.toString();
    }
    /**
     * Checks the equality of `this` peer against a given PeerId
     */
    equals(id) {
        if (id == null) {
            return false;
        }
        if (id instanceof Uint8Array) {
            return equals(this.multihash.bytes, id);
        }
        else if (typeof id === 'string') {
            return peerIdFromString(id).equals(this);
        }
        else if (id?.multihash?.bytes != null) {
            return equals(this.multihash.bytes, id.multihash.bytes);
        }
        else {
            throw new Error('not valid Id');
        }
    }
    /**
     * Returns PeerId as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```TypeScript
     * import { peerIdFromString } from '@libp2p/peer-id'
     *
     * console.info(peerIdFromString('QmFoo'))
     * // 'PeerId(QmFoo)'
     * ```
     */
    [inspect]() {
        return `PeerId(${this.toString()})`;
    }
}
class RSAPeerIdImpl extends PeerIdImpl {
    type = 'RSA';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'RSA' });
        this.publicKey = init.publicKey;
    }
}
class Ed25519PeerIdImpl extends PeerIdImpl {
    type = 'Ed25519';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'Ed25519' });
        this.publicKey = init.multihash.digest;
    }
}
class Secp256k1PeerIdImpl extends PeerIdImpl {
    type = 'secp256k1';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'secp256k1' });
        this.publicKey = init.multihash.digest;
    }
}
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const TRANSPORT_IPFS_GATEWAY_HTTP_CODE = 0x0920;
class URLPeerIdImpl {
    type = 'url';
    multihash;
    privateKey;
    publicKey;
    url;
    constructor(url) {
        this.url = url.toString();
        this.multihash = identity.digest(fromString(this.url));
    }
    [inspect]() {
        return `PeerId(${this.url})`;
    }
    [peerIdSymbol] = true;
    toString() {
        return this.toCID().toString();
    }
    toCID() {
        return CID.createV1(TRANSPORT_IPFS_GATEWAY_HTTP_CODE, this.multihash);
    }
    toBytes() {
        return this.toCID().bytes;
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (other instanceof Uint8Array) {
            other = toString$6(other);
        }
        return other.toString() === this.toString();
    }
}
function peerIdFromPeerId(other) {
    if (other.type === 'RSA') {
        return new RSAPeerIdImpl(other);
    }
    if (other.type === 'Ed25519') {
        return new Ed25519PeerIdImpl(other);
    }
    if (other.type === 'secp256k1') {
        return new Secp256k1PeerIdImpl(other);
    }
    throw new CodeError$1('Not a PeerId', 'ERR_INVALID_PARAMETERS');
}
function peerIdFromString(str, decoder) {
    if (str.charAt(0) === '1' || str.charAt(0) === 'Q') {
        // identity hash ed25519/secp256k1 key or sha2-256 hash of
        // rsa public key - base58btc encoded either way
        const multihash = decode$5(base58btc.decode(`z${str}`));
        if (str.startsWith('12D')) {
            return new Ed25519PeerIdImpl({ multihash });
        }
        else if (str.startsWith('16U')) {
            return new Secp256k1PeerIdImpl({ multihash });
        }
        else {
            return new RSAPeerIdImpl({ multihash });
        }
    }
    return peerIdFromBytes(baseDecoder.decode(str));
}
function peerIdFromBytes(buf) {
    try {
        const multihash = decode$5(buf);
        if (multihash.code === identity.code) {
            if (multihash.digest.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
                return new Ed25519PeerIdImpl({ multihash });
            }
            else if (multihash.digest.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
                return new Secp256k1PeerIdImpl({ multihash });
            }
        }
        if (multihash.code === sha256$1.code) {
            return new RSAPeerIdImpl({ multihash });
        }
    }
    catch {
        return peerIdFromCID(CID.decode(buf));
    }
    throw new Error('Supplied PeerID CID is invalid');
}
function peerIdFromCID(cid) {
    if (cid?.multihash == null || cid.version == null || (cid.version === 1 && (cid.code !== LIBP2P_KEY_CODE) && cid.code !== TRANSPORT_IPFS_GATEWAY_HTTP_CODE)) {
        throw new Error('Supplied PeerID CID is invalid');
    }
    if (cid.code === TRANSPORT_IPFS_GATEWAY_HTTP_CODE) {
        const url = toString$6(cid.multihash.digest);
        return new URLPeerIdImpl(new URL(url));
    }
    const multihash = cid.multihash;
    if (multihash.code === sha256$1.code) {
        return new RSAPeerIdImpl({ multihash: cid.multihash });
    }
    else if (multihash.code === identity.code) {
        if (multihash.digest.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
            return new Ed25519PeerIdImpl({ multihash: cid.multihash });
        }
        else if (multihash.digest.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
            return new Secp256k1PeerIdImpl({ multihash: cid.multihash });
        }
    }
    throw new Error('Supplied PeerID CID is invalid');
}
/**
 * @param publicKey - A marshalled public key
 * @param privateKey - A marshalled private key
 */
async function peerIdFromKeys(publicKey, privateKey) {
    if (publicKey.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
        return new Ed25519PeerIdImpl({ multihash: create$1(identity.code, publicKey), privateKey });
    }
    if (publicKey.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
        return new Secp256k1PeerIdImpl({ multihash: create$1(identity.code, publicKey), privateKey });
    }
    return new RSAPeerIdImpl({ multihash: await sha256$1.digest(publicKey), publicKey, privateKey });
}

/**
 * An abort error class that extends error
 */
let AbortError$4 = class AbortError extends Error {
    type;
    code;
    constructor(message, code, name) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.name = name ?? 'AbortError';
        this.code = code ?? 'ABORT_ERR';
    }
};
/**
 * Race a promise against an abort signal
 */
async function raceSignal(promise, signal, opts) {
    if (signal == null) {
        return promise;
    }
    if (signal.aborted) {
        return Promise.reject(new AbortError$4(opts?.errorMessage, opts?.errorCode, opts?.errorName));
    }
    let listener;
    // create the error here so we have more context in the stack trace
    const error = new AbortError$4(opts?.errorMessage, opts?.errorCode, opts?.errorName);
    try {
        return await Promise.race([
            promise,
            new Promise((resolve, reject) => {
                listener = () => {
                    reject(error);
                };
                signal.addEventListener('abort', listener);
            })
        ]);
    }
    finally {
        if (listener != null) {
            signal.removeEventListener('abort', listener);
        }
    }
}

/**
 * @packageDocumentation
 *
 * A pushable async generator that waits until the current value is consumed
 * before allowing a new value to be pushed.
 *
 * Useful for when you don't want to keep memory usage under control and/or
 * allow a downstream consumer to dictate how fast data flows through a pipe,
 * but you want to be able to apply a transform to that data.
 *
 * @example
 *
 * ```typescript
 * import { queuelessPushable } from 'it-queueless-pushable'
 *
 * const pushable = queuelessPushable<string>()
 *
 * // run asynchronously
 * Promise.resolve().then(async () => {
 *   // push a value - the returned promise will not resolve until the value is
 *   // read from the pushable
 *   await pushable.push('hello')
 * })
 *
 * // read a value
 * const result = await pushable.next()
 * console.info(result) // { done: false, value: 'hello' }
 * ```
 */
class QueuelessPushable {
    readNext;
    haveNext;
    ended;
    nextResult;
    constructor() {
        this.ended = false;
        this.readNext = pDefer();
        this.haveNext = pDefer();
    }
    [Symbol.asyncIterator]() {
        return this;
    }
    async next() {
        if (this.nextResult == null) {
            // wait for the supplier to push a value
            await this.haveNext.promise;
        }
        if (this.nextResult == null) {
            throw new Error('HaveNext promise resolved but nextResult was undefined');
        }
        const nextResult = this.nextResult;
        this.nextResult = undefined;
        // signal to the supplier that we read the value
        this.readNext.resolve();
        this.readNext = pDefer();
        return nextResult;
    }
    async throw(err) {
        this.ended = true;
        if (err != null) {
            // this can cause unhandled promise rejections if nothing is awaiting the
            // next value so attach a dummy catch listener to the promise
            this.haveNext.promise.catch(() => { });
            this.haveNext.reject(err);
        }
        const result = {
            done: true,
            value: undefined
        };
        return result;
    }
    async return() {
        const result = {
            done: true,
            value: undefined
        };
        await this._push(undefined);
        return result;
    }
    async push(value, options) {
        await this._push(value, options);
    }
    async end(err, options) {
        if (err != null) {
            await this.throw(err);
        }
        else {
            // abortable return
            await this._push(undefined, options);
        }
    }
    async _push(value, options) {
        if (value != null && this.ended) {
            throw new Error('Cannot push value onto an ended pushable');
        }
        // wait for all values to be read
        while (this.nextResult != null) {
            await this.readNext.promise;
        }
        if (value != null) {
            this.nextResult = { done: false, value };
        }
        else {
            this.ended = true;
            this.nextResult = { done: true, value: undefined };
        }
        // let the consumer know we have a new value
        this.haveNext.resolve();
        this.haveNext = pDefer();
        // wait for the consumer to have finished processing the value and requested
        // the next one or for the passed signal to abort the waiting
        await raceSignal(this.readNext.promise, options?.signal, options);
    }
}
function queuelessPushable() {
    return new QueuelessPushable();
}

/**
 * The incoming stream ended before the expected number of bytes were read
 */
class UnexpectedEOFError extends Error {
    name = 'UnexpectedEOFError';
    code = 'ERR_UNEXPECTED_EOF';
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive bytes over streams.
 *
 * @example
 *
 * ```typescript
 * import { byteStream } from 'it-byte-stream'
 *
 * const stream = byteStream(duplex)
 *
 * // read the next chunk
 * const bytes = await stream.read()
 *
 * // read the next five bytes
 * const fiveBytes = await stream.read(5)
 *
 * // write bytes into the stream
 * await stream.write(Uint8Array.from([0, 1, 2, 3, 4]))
 * ```
 */
/**
 * @deprecated This will not be exported in a future release
 */
class CodeError extends Error {
    code;
    constructor(message, code) {
        super(message);
        this.code = code;
    }
}
/**
 * @deprecated This will not be exported in a future release
 */
let AbortError$3 = class AbortError extends CodeError {
    type;
    constructor(message) {
        super(message, 'ABORT_ERR');
        this.type = 'aborted';
        this.name = 'AbortError';
    }
};
function byteStream(duplex, opts) {
    const write = queuelessPushable();
    duplex.sink(write).catch(async (err) => {
        await write.end(err);
    });
    duplex.sink = async (source) => {
        for await (const buf of source) {
            await write.push(buf);
        }
        await write.end();
    };
    let source = duplex.source;
    if (duplex.source[Symbol.iterator] != null) {
        source = duplex.source[Symbol.iterator]();
    }
    else if (duplex.source[Symbol.asyncIterator] != null) {
        source = duplex.source[Symbol.asyncIterator]();
    }
    const readBuffer = new Uint8ArrayList();
    const W = {
        read: async (bytes, options) => {
            options?.signal?.throwIfAborted();
            let listener;
            const abortPromise = new Promise((resolve, reject) => {
                listener = () => {
                    reject(new AbortError$3('Read aborted'));
                };
                options?.signal?.addEventListener('abort', listener);
            });
            try {
                if (bytes == null) {
                    // just read whatever arrives
                    const { done, value } = await Promise.race([
                        source.next(),
                        abortPromise
                    ]);
                    if (done === true) {
                        return new Uint8ArrayList();
                    }
                    return value;
                }
                while (readBuffer.byteLength < bytes) {
                    const { value, done } = await Promise.race([
                        source.next(),
                        abortPromise
                    ]);
                    if (done === true) {
                        throw new UnexpectedEOFError('unexpected end of input');
                    }
                    readBuffer.append(value);
                }
                const buf = readBuffer.sublist(0, bytes);
                readBuffer.consume(bytes);
                return buf;
            }
            finally {
                if (listener != null) {
                    options?.signal?.removeEventListener('abort', listener);
                }
            }
        },
        write: async (data, options) => {
            options?.signal?.throwIfAborted();
            // just write
            if (data instanceof Uint8Array) {
                await write.push(data, options);
            }
            else {
                await write.push(data.subarray(), options);
            }
        },
        unwrap: () => {
            if (readBuffer.byteLength > 0) {
                const originalStream = duplex.source;
                duplex.source = (async function* () {
                    if (opts?.yieldBytes === false) {
                        yield readBuffer;
                    }
                    else {
                        yield* readBuffer;
                    }
                    yield* originalStream;
                }());
            }
            return duplex;
        }
    };
    return W;
}

/**
 * The reported length of the next data message was not a positive integer
 */
class InvalidMessageLengthError extends Error {
    name = 'InvalidMessageLengthError';
    code = 'ERR_INVALID_MSG_LENGTH';
}
/**
 * The reported length of the next data message was larger than the configured
 * max allowable value
 */
class InvalidDataLengthError extends Error {
    name = 'InvalidDataLengthError';
    code = 'ERR_MSG_DATA_TOO_LONG';
}
/**
 * The varint used to specify the length of the next data message contained more
 * bytes than the configured max allowable value
 */
class InvalidDataLengthLengthError extends Error {
    name = 'InvalidDataLengthLengthError';
    code = 'ERR_MSG_LENGTH_TOO_LONG';
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive length-prefixed byte arrays over streams.
 *
 * @example
 *
 * ```typescript
 * import { lpStream } from 'it-length-prefixed-stream'
 *
 * const stream = lpStream(duplex)
 *
 * // read the next length-prefixed chunk
 * const bytes = await stream.read()
 *
 * // write a length-prefixed chunk
 * await stream.write(Uint8Array.from([0, 1, 2, 3, 4]))
 *
 * // write several chunks, all individually length-prefixed
 * await stream.writeV([
 *   Uint8Array.from([0, 1, 2, 3, 4]),
 *   Uint8Array.from([5, 6, 7, 8, 9])
 * ])
 * ```
 */
function lpStream(duplex, opts = {}) {
    const bytes = byteStream(duplex, opts);
    if (opts.maxDataLength != null && opts.maxLengthLength == null) {
        // if max data length is set but max length length is not, calculate the
        // max length length needed to encode max data length
        opts.maxLengthLength = encodingLength$3(opts.maxDataLength);
    }
    const decodeLength = opts?.lengthDecoder ?? decode$a;
    const encodeLength = opts?.lengthEncoder ?? encode$a;
    const W = {
        read: async (options) => {
            let dataLength = -1;
            const lengthBuffer = new Uint8ArrayList();
            while (true) {
                // read one byte at a time until we can decode a varint
                lengthBuffer.append(await bytes.read(1, options));
                try {
                    dataLength = decodeLength(lengthBuffer);
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        continue;
                    }
                    throw err;
                }
                if (dataLength < 0) {
                    throw new InvalidMessageLengthError('Invalid message length');
                }
                if (opts?.maxLengthLength != null && lengthBuffer.byteLength > opts.maxLengthLength) {
                    throw new InvalidDataLengthLengthError('message length length too long');
                }
                if (dataLength > -1) {
                    break;
                }
            }
            if (opts?.maxDataLength != null && dataLength > opts.maxDataLength) {
                throw new InvalidDataLengthError('message length too long');
            }
            return bytes.read(dataLength, options);
        },
        write: async (data, options) => {
            // encode, write
            await bytes.write(new Uint8ArrayList(encodeLength(data.byteLength), data), options);
        },
        writeV: async (data, options) => {
            const list = new Uint8ArrayList(...data.flatMap(buf => ([encodeLength(buf.byteLength), buf])));
            // encode, write
            await bytes.write(list, options);
        },
        unwrap: () => {
            return bytes.unwrap();
        }
    };
    return W;
}

/**
 * A pair of streams where one drains from the other
 */
function pair() {
    const deferred = pDefer();
    let piped = false;
    return {
        sink: async (source) => {
            if (piped) {
                throw new Error('already piped');
            }
            piped = true;
            deferred.resolve(source);
        },
        source: (async function* () {
            const source = await deferred.promise;
            yield* source;
        }())
    };
}

/**
 * Two duplex streams that are attached to each other
 */
function duplexPair() {
    const a = pair();
    const b = pair();
    return [
        {
            source: a.source,
            sink: b.sink
        },
        {
            source: b.source,
            sink: a.sink
        }
    ];
}

const NOISE_MSG_MAX_LENGTH_BYTES = 65535;
const NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG = NOISE_MSG_MAX_LENGTH_BYTES - 16;
const DUMP_SESSION_KEYS = Boolean(globalThis.process?.env?.DUMP_SESSION_KEYS);

function number$1(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error(`positive integer expected, not ${n}`);
}
function bool(b) {
    if (typeof b !== 'boolean')
        throw new Error(`boolean expected, not ${b}`);
}
function isBytes$1(a) {
    return (a instanceof Uint8Array ||
        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));
}
function bytes(b, ...lengths) {
    if (!isBytes$1(b))
        throw new Error('Uint8Array expected');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error(`Uint8Array expected of length ${lengths}, not of length=${b.length}`);
}
function exists(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output(out, instance) {
    bytes(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}

/*! noble-ciphers - MIT License (c) 2023 Paul Miller (paulmillr.com) */
const u32 = (arr) => new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));
// Cast array to view
const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// big-endian hardware is rare. Just in case someone still decides to run ciphers:
// early-throw an error because we don't support BE yet.
const isLE = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
if (!isLE)
    throw new Error('Non little-endian hardware is not supported');
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes(str) {
    if (typeof str !== 'string')
        throw new Error(`string expected, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes(data) {
    if (typeof data === 'string')
        data = utf8ToBytes(data);
    else if (isBytes$1(data))
        data = copyBytes(data);
    else
        throw new Error(`Uint8Array expected, got ${typeof data}`);
    return data;
}
function checkOpts(defaults, opts) {
    if (opts == null || typeof opts !== 'object')
        throw new Error('options must be defined');
    const merged = Object.assign(defaults, opts);
    return merged;
}
// Compares 2 u8a-s in kinda constant time
function equalBytes(a, b) {
    if (a.length !== b.length)
        return false;
    let diff = 0;
    for (let i = 0; i < a.length; i++)
        diff |= a[i] ^ b[i];
    return diff === 0;
}
/**
 * @__NO_SIDE_EFFECTS__
 */
const wrapCipher = (params, c) => {
    Object.assign(c, params);
    return c;
};
// Polyfill for Safari 14
function setBigUint64(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = 4 ;
    const l = 0 ;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
// copy bytes to new u8a (aligned). Because Buffer.slice is broken.
function copyBytes(bytes) {
    return Uint8Array.from(bytes);
}
function clean(...arrays) {
    for (let i = 0; i < arrays.length; i++) {
        arrays[i].fill(0);
    }
}

// Basic utils for ARX (add-rotate-xor) salsa and chacha ciphers.
/*
RFC8439 requires multi-step cipher stream, where
authKey starts with counter: 0, actual msg with counter: 1.

For this, we need a way to re-use nonce / counter:

    const counter = new Uint8Array(4);
    chacha(..., counter, ...); // counter is now 1
    chacha(..., counter, ...); // counter is now 2

This is complicated:

- 32-bit counters are enough, no need for 64-bit: max ArrayBuffer size in JS is 4GB
- Original papers don't allow mutating counters
- Counter overflow is undefined [^1]
- Idea A: allow providing (nonce | counter) instead of just nonce, re-use it
- Caveat: Cannot be re-used through all cases:
- * chacha has (counter | nonce)
- * xchacha has (nonce16 | counter | nonce16)
- Idea B: separate nonce / counter and provide separate API for counter re-use
- Caveat: there are different counter sizes depending on an algorithm.
- salsa & chacha also differ in structures of key & sigma:
  salsa20:      s[0] | k(4) | s[1] | nonce(2) | ctr(2) | s[2] | k(4) | s[3]
  chacha:       s(4) | k(8) | ctr(1) | nonce(3)
  chacha20orig: s(4) | k(8) | ctr(2) | nonce(2)
- Idea C: helper method such as `setSalsaState(key, nonce, sigma, data)`
- Caveat: we can't re-use counter array

xchacha [^2] uses the subkey and remaining 8 byte nonce with ChaCha20 as normal
(prefixed by 4 NUL bytes, since [RFC8439] specifies a 12-byte nonce).

[^1]: https://mailarchive.ietf.org/arch/msg/cfrg/gsOnTJzcbgG6OqD8Sc0GO5aR_tU/
[^2]: https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-xchacha#appendix-A.2
*/
// We can't make top-level var depend on utils.utf8ToBytes
// because it's not present in all envs. Creating a similar fn here
const _utf8ToBytes = (str) => Uint8Array.from(str.split('').map((c) => c.charCodeAt(0)));
const sigma16 = _utf8ToBytes('expand 16-byte k');
const sigma32 = _utf8ToBytes('expand 32-byte k');
const sigma16_32 = u32(sigma16);
const sigma32_32 = u32(sigma32);
sigma32_32.slice();
function rotl(a, b) {
    return (a << b) | (a >>> (32 - b));
}
// Is byte array aligned to 4 byte offset (u32)?
function isAligned32(b) {
    return b.byteOffset % 4 === 0;
}
// Salsa and Chacha block length is always 512-bit
const BLOCK_LEN = 64;
const BLOCK_LEN32 = 16;
// new Uint32Array([2**32])   // => Uint32Array(1) [ 0 ]
// new Uint32Array([2**32-1]) // => Uint32Array(1) [ 4294967295 ]
const MAX_COUNTER = 2 ** 32 - 1;
const U32_EMPTY = new Uint32Array();
function runCipher(core, sigma, key, nonce, data, output, counter, rounds) {
    const len = data.length;
    const block = new Uint8Array(BLOCK_LEN);
    const b32 = u32(block);
    // Make sure that buffers aligned to 4 bytes
    const isAligned = isAligned32(data) && isAligned32(output);
    const d32 = isAligned ? u32(data) : U32_EMPTY;
    const o32 = isAligned ? u32(output) : U32_EMPTY;
    for (let pos = 0; pos < len; counter++) {
        core(sigma, key, nonce, b32, counter, rounds);
        if (counter >= MAX_COUNTER)
            throw new Error('arx: counter overflow');
        const take = Math.min(BLOCK_LEN, len - pos);
        // aligned to 4 bytes
        if (isAligned && take === BLOCK_LEN) {
            const pos32 = pos / 4;
            if (pos % 4 !== 0)
                throw new Error('arx: invalid block position');
            for (let j = 0, posj; j < BLOCK_LEN32; j++) {
                posj = pos32 + j;
                o32[posj] = d32[posj] ^ b32[j];
            }
            pos += BLOCK_LEN;
            continue;
        }
        for (let j = 0, posj; j < take; j++) {
            posj = pos + j;
            output[posj] = data[posj] ^ block[j];
        }
        pos += take;
    }
}
function createCipher(core, opts) {
    const { allowShortKeys, extendNonceFn, counterLength, counterRight, rounds } = checkOpts({ allowShortKeys: false, counterLength: 8, counterRight: false, rounds: 20 }, opts);
    if (typeof core !== 'function')
        throw new Error('core must be a function');
    number$1(counterLength);
    number$1(rounds);
    bool(counterRight);
    bool(allowShortKeys);
    return (key, nonce, data, output, counter = 0) => {
        bytes(key);
        bytes(nonce);
        bytes(data);
        const len = data.length;
        if (output === undefined)
            output = new Uint8Array(len);
        bytes(output);
        number$1(counter);
        if (counter < 0 || counter >= MAX_COUNTER)
            throw new Error('arx: counter overflow');
        if (output.length < len)
            throw new Error(`arx: output (${output.length}) is shorter than data (${len})`);
        const toClean = [];
        // Key & sigma
        // key=16 -> sigma16, k=key|key
        // key=32 -> sigma32, k=key
        let l = key.length, k, sigma;
        if (l === 32) {
            toClean.push((k = copyBytes(key)));
            sigma = sigma32_32;
        }
        else if (l === 16 && allowShortKeys) {
            k = new Uint8Array(32);
            k.set(key);
            k.set(key, 16);
            sigma = sigma16_32;
            toClean.push(k);
        }
        else {
            throw new Error(`arx: invalid 32-byte key, got length=${l}`);
        }
        // Nonce
        // salsa20:      8   (8-byte counter)
        // chacha20orig: 8   (8-byte counter)
        // chacha20:     12  (4-byte counter)
        // xsalsa20:     24  (16 -> hsalsa,  8 -> old nonce)
        // xchacha20:    24  (16 -> hchacha, 8 -> old nonce)
        // Align nonce to 4 bytes
        if (!isAligned32(nonce))
            toClean.push((nonce = copyBytes(nonce)));
        const k32 = u32(k);
        // hsalsa & hchacha: handle extended nonce
        if (extendNonceFn) {
            if (nonce.length !== 24)
                throw new Error(`arx: extended nonce must be 24 bytes`);
            extendNonceFn(sigma, k32, u32(nonce.subarray(0, 16)), k32);
            nonce = nonce.subarray(16);
        }
        // Handle nonce counter
        const nonceNcLen = 16 - counterLength;
        if (nonceNcLen !== nonce.length)
            throw new Error(`arx: nonce must be ${nonceNcLen} or 16 bytes`);
        // Pad counter when nonce is 64 bit
        if (nonceNcLen !== 12) {
            const nc = new Uint8Array(12);
            nc.set(nonce, counterRight ? 0 : 12 - nonce.length);
            nonce = nc;
            toClean.push(nonce);
        }
        const n32 = u32(nonce);
        runCipher(core, sigma, k32, n32, data, output, counter, rounds);
        clean(...toClean);
        return output;
    };
}

// Poly1305 is a fast and parallel secret-key message-authentication code.
// https://cr.yp.to/mac.html, https://cr.yp.to/mac/poly1305-20050329.pdf
// https://datatracker.ietf.org/doc/html/rfc8439
// Based on Public Domain poly1305-donna https://github.com/floodyberry/poly1305-donna
const u8to16 = (a, i) => (a[i++] & 0xff) | ((a[i++] & 0xff) << 8);
class Poly1305 {
    constructor(key) {
        this.blockLen = 16;
        this.outputLen = 16;
        this.buffer = new Uint8Array(16);
        this.r = new Uint16Array(10);
        this.h = new Uint16Array(10);
        this.pad = new Uint16Array(8);
        this.pos = 0;
        this.finished = false;
        key = toBytes(key);
        bytes(key, 32);
        const t0 = u8to16(key, 0);
        const t1 = u8to16(key, 2);
        const t2 = u8to16(key, 4);
        const t3 = u8to16(key, 6);
        const t4 = u8to16(key, 8);
        const t5 = u8to16(key, 10);
        const t6 = u8to16(key, 12);
        const t7 = u8to16(key, 14);
        // https://github.com/floodyberry/poly1305-donna/blob/e6ad6e091d30d7f4ec2d4f978be1fcfcbce72781/poly1305-donna-16.h#L47
        this.r[0] = t0 & 0x1fff;
        this.r[1] = ((t0 >>> 13) | (t1 << 3)) & 0x1fff;
        this.r[2] = ((t1 >>> 10) | (t2 << 6)) & 0x1f03;
        this.r[3] = ((t2 >>> 7) | (t3 << 9)) & 0x1fff;
        this.r[4] = ((t3 >>> 4) | (t4 << 12)) & 0x00ff;
        this.r[5] = (t4 >>> 1) & 0x1ffe;
        this.r[6] = ((t4 >>> 14) | (t5 << 2)) & 0x1fff;
        this.r[7] = ((t5 >>> 11) | (t6 << 5)) & 0x1f81;
        this.r[8] = ((t6 >>> 8) | (t7 << 8)) & 0x1fff;
        this.r[9] = (t7 >>> 5) & 0x007f;
        for (let i = 0; i < 8; i++)
            this.pad[i] = u8to16(key, 16 + 2 * i);
    }
    process(data, offset, isLast = false) {
        const hibit = isLast ? 0 : 1 << 11;
        const { h, r } = this;
        const r0 = r[0];
        const r1 = r[1];
        const r2 = r[2];
        const r3 = r[3];
        const r4 = r[4];
        const r5 = r[5];
        const r6 = r[6];
        const r7 = r[7];
        const r8 = r[8];
        const r9 = r[9];
        const t0 = u8to16(data, offset + 0);
        const t1 = u8to16(data, offset + 2);
        const t2 = u8to16(data, offset + 4);
        const t3 = u8to16(data, offset + 6);
        const t4 = u8to16(data, offset + 8);
        const t5 = u8to16(data, offset + 10);
        const t6 = u8to16(data, offset + 12);
        const t7 = u8to16(data, offset + 14);
        let h0 = h[0] + (t0 & 0x1fff);
        let h1 = h[1] + (((t0 >>> 13) | (t1 << 3)) & 0x1fff);
        let h2 = h[2] + (((t1 >>> 10) | (t2 << 6)) & 0x1fff);
        let h3 = h[3] + (((t2 >>> 7) | (t3 << 9)) & 0x1fff);
        let h4 = h[4] + (((t3 >>> 4) | (t4 << 12)) & 0x1fff);
        let h5 = h[5] + ((t4 >>> 1) & 0x1fff);
        let h6 = h[6] + (((t4 >>> 14) | (t5 << 2)) & 0x1fff);
        let h7 = h[7] + (((t5 >>> 11) | (t6 << 5)) & 0x1fff);
        let h8 = h[8] + (((t6 >>> 8) | (t7 << 8)) & 0x1fff);
        let h9 = h[9] + ((t7 >>> 5) | hibit);
        let c = 0;
        let d0 = c + h0 * r0 + h1 * (5 * r9) + h2 * (5 * r8) + h3 * (5 * r7) + h4 * (5 * r6);
        c = d0 >>> 13;
        d0 &= 0x1fff;
        d0 += h5 * (5 * r5) + h6 * (5 * r4) + h7 * (5 * r3) + h8 * (5 * r2) + h9 * (5 * r1);
        c += d0 >>> 13;
        d0 &= 0x1fff;
        let d1 = c + h0 * r1 + h1 * r0 + h2 * (5 * r9) + h3 * (5 * r8) + h4 * (5 * r7);
        c = d1 >>> 13;
        d1 &= 0x1fff;
        d1 += h5 * (5 * r6) + h6 * (5 * r5) + h7 * (5 * r4) + h8 * (5 * r3) + h9 * (5 * r2);
        c += d1 >>> 13;
        d1 &= 0x1fff;
        let d2 = c + h0 * r2 + h1 * r1 + h2 * r0 + h3 * (5 * r9) + h4 * (5 * r8);
        c = d2 >>> 13;
        d2 &= 0x1fff;
        d2 += h5 * (5 * r7) + h6 * (5 * r6) + h7 * (5 * r5) + h8 * (5 * r4) + h9 * (5 * r3);
        c += d2 >>> 13;
        d2 &= 0x1fff;
        let d3 = c + h0 * r3 + h1 * r2 + h2 * r1 + h3 * r0 + h4 * (5 * r9);
        c = d3 >>> 13;
        d3 &= 0x1fff;
        d3 += h5 * (5 * r8) + h6 * (5 * r7) + h7 * (5 * r6) + h8 * (5 * r5) + h9 * (5 * r4);
        c += d3 >>> 13;
        d3 &= 0x1fff;
        let d4 = c + h0 * r4 + h1 * r3 + h2 * r2 + h3 * r1 + h4 * r0;
        c = d4 >>> 13;
        d4 &= 0x1fff;
        d4 += h5 * (5 * r9) + h6 * (5 * r8) + h7 * (5 * r7) + h8 * (5 * r6) + h9 * (5 * r5);
        c += d4 >>> 13;
        d4 &= 0x1fff;
        let d5 = c + h0 * r5 + h1 * r4 + h2 * r3 + h3 * r2 + h4 * r1;
        c = d5 >>> 13;
        d5 &= 0x1fff;
        d5 += h5 * r0 + h6 * (5 * r9) + h7 * (5 * r8) + h8 * (5 * r7) + h9 * (5 * r6);
        c += d5 >>> 13;
        d5 &= 0x1fff;
        let d6 = c + h0 * r6 + h1 * r5 + h2 * r4 + h3 * r3 + h4 * r2;
        c = d6 >>> 13;
        d6 &= 0x1fff;
        d6 += h5 * r1 + h6 * r0 + h7 * (5 * r9) + h8 * (5 * r8) + h9 * (5 * r7);
        c += d6 >>> 13;
        d6 &= 0x1fff;
        let d7 = c + h0 * r7 + h1 * r6 + h2 * r5 + h3 * r4 + h4 * r3;
        c = d7 >>> 13;
        d7 &= 0x1fff;
        d7 += h5 * r2 + h6 * r1 + h7 * r0 + h8 * (5 * r9) + h9 * (5 * r8);
        c += d7 >>> 13;
        d7 &= 0x1fff;
        let d8 = c + h0 * r8 + h1 * r7 + h2 * r6 + h3 * r5 + h4 * r4;
        c = d8 >>> 13;
        d8 &= 0x1fff;
        d8 += h5 * r3 + h6 * r2 + h7 * r1 + h8 * r0 + h9 * (5 * r9);
        c += d8 >>> 13;
        d8 &= 0x1fff;
        let d9 = c + h0 * r9 + h1 * r8 + h2 * r7 + h3 * r6 + h4 * r5;
        c = d9 >>> 13;
        d9 &= 0x1fff;
        d9 += h5 * r4 + h6 * r3 + h7 * r2 + h8 * r1 + h9 * r0;
        c += d9 >>> 13;
        d9 &= 0x1fff;
        c = ((c << 2) + c) | 0;
        c = (c + d0) | 0;
        d0 = c & 0x1fff;
        c = c >>> 13;
        d1 += c;
        h[0] = d0;
        h[1] = d1;
        h[2] = d2;
        h[3] = d3;
        h[4] = d4;
        h[5] = d5;
        h[6] = d6;
        h[7] = d7;
        h[8] = d8;
        h[9] = d9;
    }
    finalize() {
        const { h, pad } = this;
        const g = new Uint16Array(10);
        let c = h[1] >>> 13;
        h[1] &= 0x1fff;
        for (let i = 2; i < 10; i++) {
            h[i] += c;
            c = h[i] >>> 13;
            h[i] &= 0x1fff;
        }
        h[0] += c * 5;
        c = h[0] >>> 13;
        h[0] &= 0x1fff;
        h[1] += c;
        c = h[1] >>> 13;
        h[1] &= 0x1fff;
        h[2] += c;
        g[0] = h[0] + 5;
        c = g[0] >>> 13;
        g[0] &= 0x1fff;
        for (let i = 1; i < 10; i++) {
            g[i] = h[i] + c;
            c = g[i] >>> 13;
            g[i] &= 0x1fff;
        }
        g[9] -= 1 << 13;
        let mask = (c ^ 1) - 1;
        for (let i = 0; i < 10; i++)
            g[i] &= mask;
        mask = ~mask;
        for (let i = 0; i < 10; i++)
            h[i] = (h[i] & mask) | g[i];
        h[0] = (h[0] | (h[1] << 13)) & 0xffff;
        h[1] = ((h[1] >>> 3) | (h[2] << 10)) & 0xffff;
        h[2] = ((h[2] >>> 6) | (h[3] << 7)) & 0xffff;
        h[3] = ((h[3] >>> 9) | (h[4] << 4)) & 0xffff;
        h[4] = ((h[4] >>> 12) | (h[5] << 1) | (h[6] << 14)) & 0xffff;
        h[5] = ((h[6] >>> 2) | (h[7] << 11)) & 0xffff;
        h[6] = ((h[7] >>> 5) | (h[8] << 8)) & 0xffff;
        h[7] = ((h[8] >>> 8) | (h[9] << 5)) & 0xffff;
        let f = h[0] + pad[0];
        h[0] = f & 0xffff;
        for (let i = 1; i < 8; i++) {
            f = (((h[i] + pad[i]) | 0) + (f >>> 16)) | 0;
            h[i] = f & 0xffff;
        }
        clean(g);
    }
    update(data) {
        exists(this);
        const { buffer, blockLen } = this;
        data = toBytes(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input
            if (take === blockLen) {
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(data, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(buffer, 0, false);
                this.pos = 0;
            }
        }
        return this;
    }
    destroy() {
        clean(this.h, this.r, this.buffer, this.pad);
    }
    digestInto(out) {
        exists(this);
        output(out, this);
        this.finished = true;
        const { buffer, h } = this;
        let { pos } = this;
        if (pos) {
            buffer[pos++] = 1;
            for (; pos < 16; pos++)
                buffer[pos] = 0;
            this.process(buffer, 0, true);
        }
        this.finalize();
        let opos = 0;
        for (let i = 0; i < 8; i++) {
            out[opos++] = h[i] >>> 0;
            out[opos++] = h[i] >>> 8;
        }
        return out;
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
}
function wrapConstructorWithKey(hashCons) {
    const hashC = (msg, key) => hashCons(key).update(toBytes(msg)).digest();
    const tmp = hashCons(new Uint8Array(32));
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = (key) => hashCons(key);
    return hashC;
}
const poly1305 = wrapConstructorWithKey((key) => new Poly1305(key));

// prettier-ignore
// ChaCha20 stream cipher was released in 2008. ChaCha aims to increase
// the diffusion per round, but had slightly less cryptanalysis.
// https://cr.yp.to/chacha.html, http://cr.yp.to/chacha/chacha-20080128.pdf
/**
 * ChaCha core function.
 */
// prettier-ignore
function chachaCore(s, k, n, out, cnt, rounds = 20) {
    let y00 = s[0], y01 = s[1], y02 = s[2], y03 = s[3], // "expa"   "nd 3"  "2-by"  "te k"
    y04 = k[0], y05 = k[1], y06 = k[2], y07 = k[3], // Key      Key     Key     Key
    y08 = k[4], y09 = k[5], y10 = k[6], y11 = k[7], // Key      Key     Key     Key
    y12 = cnt, y13 = n[0], y14 = n[1], y15 = n[2]; // Counter  Counter	Nonce   Nonce
    // Save state to temporary variables
    let x00 = y00, x01 = y01, x02 = y02, x03 = y03, x04 = y04, x05 = y05, x06 = y06, x07 = y07, x08 = y08, x09 = y09, x10 = y10, x11 = y11, x12 = y12, x13 = y13, x14 = y14, x15 = y15;
    for (let r = 0; r < rounds; r += 2) {
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 16);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 12);
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 8);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 7);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 16);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 12);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 8);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 7);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 16);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 12);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 8);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 7);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 16);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 12);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 8);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 7);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 16);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 12);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 8);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 7);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 16);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 12);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 8);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 7);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 16);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 12);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 8);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 7);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 16);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 12);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 8);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 7);
    }
    // Write output
    let oi = 0;
    out[oi++] = (y00 + x00) | 0;
    out[oi++] = (y01 + x01) | 0;
    out[oi++] = (y02 + x02) | 0;
    out[oi++] = (y03 + x03) | 0;
    out[oi++] = (y04 + x04) | 0;
    out[oi++] = (y05 + x05) | 0;
    out[oi++] = (y06 + x06) | 0;
    out[oi++] = (y07 + x07) | 0;
    out[oi++] = (y08 + x08) | 0;
    out[oi++] = (y09 + x09) | 0;
    out[oi++] = (y10 + x10) | 0;
    out[oi++] = (y11 + x11) | 0;
    out[oi++] = (y12 + x12) | 0;
    out[oi++] = (y13 + x13) | 0;
    out[oi++] = (y14 + x14) | 0;
    out[oi++] = (y15 + x15) | 0;
}
/**
 * ChaCha stream cipher. Conforms to RFC 8439 (IETF, TLS). 12-byte nonce, 4-byte counter.
 * With 12-byte nonce, it's not safe to use fill it with random (CSPRNG), due to collision chance.
 */
const chacha20 = /* @__PURE__ */ createCipher(chachaCore, {
    counterRight: false,
    counterLength: 4,
    allowShortKeys: false,
});
const ZEROS16 = /* @__PURE__ */ new Uint8Array(16);
// Pad to digest size with zeros
const updatePadded = (h, msg) => {
    h.update(msg);
    const left = msg.length % 16;
    if (left)
        h.update(ZEROS16.subarray(left));
};
const ZEROS32 = /* @__PURE__ */ new Uint8Array(32);
function computeTag(fn, key, nonce, data, AAD) {
    const authKey = fn(key, nonce, ZEROS32);
    const h = poly1305.create(authKey);
    if (AAD)
        updatePadded(h, AAD);
    updatePadded(h, data);
    const num = new Uint8Array(16);
    const view = createView(num);
    setBigUint64(view, 0, BigInt(AAD ? AAD.length : 0), true);
    setBigUint64(view, 8, BigInt(data.length), true);
    h.update(num);
    const res = h.digest();
    clean(authKey, num);
    return res;
}
/**
 * AEAD algorithm from RFC 8439.
 * Salsa20 and chacha (RFC 8439) use poly1305 differently.
 * We could have composed them similar to:
 * https://github.com/paulmillr/scure-base/blob/b266c73dde977b1dd7ef40ef7a23cc15aab526b3/index.ts#L250
 * But it's hard because of authKey:
 * In salsa20, authKey changes position in salsa stream.
 * In chacha, authKey can't be computed inside computeTag, it modifies the counter.
 */
const _poly1305_aead = (xorStream) => (key, nonce, AAD) => {
    const tagLength = 16;
    bytes(key, 32);
    bytes(nonce);
    return {
        encrypt(plaintext, output) {
            const plength = plaintext.length;
            const clength = plength + tagLength;
            if (output) {
                bytes(output, clength);
            }
            else {
                output = new Uint8Array(clength);
            }
            xorStream(key, nonce, plaintext, output, 1);
            const tag = computeTag(xorStream, key, nonce, output.subarray(0, -tagLength), AAD);
            output.set(tag, plength); // append tag
            clean(tag);
            return output;
        },
        decrypt(ciphertext, output) {
            const clength = ciphertext.length;
            const plength = clength - tagLength;
            if (clength < tagLength)
                throw new Error(`encrypted data must be at least ${tagLength} bytes`);
            if (output) {
                bytes(output, plength);
            }
            else {
                output = new Uint8Array(plength);
            }
            const data = ciphertext.subarray(0, -tagLength);
            const passedTag = ciphertext.subarray(-tagLength);
            const tag = computeTag(xorStream, key, nonce, data, AAD);
            if (!equalBytes(passedTag, tag))
                throw new Error('invalid tag');
            xorStream(key, nonce, data, output, 1);
            clean(tag);
            return output;
        },
    };
};
/**
 * ChaCha20-Poly1305 from RFC 8439.
 * With 12-byte nonce, it's not safe to use fill it with random (CSPRNG), due to collision chance.
 */
const chacha20poly1305 = /* @__PURE__ */ wrapCipher({ blockSize: 64, nonceLength: 12, tagLength: 16 }, _poly1305_aead(chacha20));

// HKDF (RFC 5869)
// https://soatok.blog/2021/11/17/understanding-hkdf/
/**
 * HKDF-Extract(IKM, salt) -> PRK
 * Arguments position differs from spec (IKM is first one, since it is not optional)
 * @param hash
 * @param ikm
 * @param salt
 * @returns
 */
function extract(hash$1, ikm, salt) {
    hash(hash$1);
    // NOTE: some libraries treat zero-length array as 'not provided';
    // we don't, since we have undefined as 'not provided'
    // https://github.com/RustCrypto/KDFs/issues/15
    if (salt === undefined)
        salt = new Uint8Array(hash$1.outputLen); // if not provided, it is set to a string of HashLen zeros
    return hmac(hash$1, toBytes$2(salt), toBytes$2(ikm));
}
// HKDF-Expand(PRK, info, L) -> OKM
const HKDF_COUNTER = /* @__PURE__ */ new Uint8Array([0]);
const EMPTY_BUFFER = /* @__PURE__ */ new Uint8Array();
/**
 * HKDF-expand from the spec.
 * @param prk - a pseudorandom key of at least HashLen octets (usually, the output from the extract step)
 * @param info - optional context and application specific information (can be a zero-length string)
 * @param length - length of output keying material in octets
 */
function expand(hash$1, prk, info, length = 32) {
    hash(hash$1);
    number$2(length);
    if (length > 255 * hash$1.outputLen)
        throw new Error('Length should be <= 255*HashLen');
    const blocks = Math.ceil(length / hash$1.outputLen);
    if (info === undefined)
        info = EMPTY_BUFFER;
    // first L(ength) octets of T
    const okm = new Uint8Array(blocks * hash$1.outputLen);
    // Re-use HMAC instance between blocks
    const HMAC = hmac.create(hash$1, prk);
    const HMACTmp = HMAC._cloneInto();
    const T = new Uint8Array(HMAC.outputLen);
    for (let counter = 0; counter < blocks; counter++) {
        HKDF_COUNTER[0] = counter + 1;
        // T(0) = empty string (zero length)
        // T(N) = HMAC-Hash(PRK, T(N-1) | info | N)
        HMACTmp.update(counter === 0 ? EMPTY_BUFFER : T)
            .update(info)
            .update(HKDF_COUNTER)
            .digestInto(T);
        okm.set(T, hash$1.outputLen * counter);
        HMAC._cloneInto(HMACTmp);
    }
    HMAC.destroy();
    HMACTmp.destroy();
    T.fill(0);
    HKDF_COUNTER.fill(0);
    return okm.slice(0, length);
}

const pureJsCrypto = {
    hashSHA256(data) {
        return sha256(data.subarray());
    },
    getHKDF(ck, ikm) {
        const prk = extract(sha256, ikm, ck);
        const okmU8Array = expand(sha256, prk, undefined, 96);
        const okm = okmU8Array;
        const k1 = okm.subarray(0, 32);
        const k2 = okm.subarray(32, 64);
        const k3 = okm.subarray(64, 96);
        return [k1, k2, k3];
    },
    generateX25519KeyPair() {
        const secretKey = x25519.utils.randomPrivateKey();
        const publicKey = x25519.getPublicKey(secretKey);
        return {
            publicKey,
            privateKey: secretKey
        };
    },
    generateX25519KeyPairFromSeed(seed) {
        const publicKey = x25519.getPublicKey(seed);
        return {
            publicKey,
            privateKey: seed
        };
    },
    generateX25519SharedKey(privateKey, publicKey) {
        return x25519.getSharedSecret(privateKey.subarray(), publicKey.subarray());
    },
    chaCha20Poly1305Encrypt(plaintext, nonce, ad, k) {
        return chacha20poly1305(k, nonce, ad).encrypt(plaintext.subarray());
    },
    chaCha20Poly1305Decrypt(ciphertext, nonce, ad, k, dst) {
        return chacha20poly1305(k, nonce, ad).decrypt(ciphertext.subarray(), dst);
    }
};

const defaultCrypto = pureJsCrypto;

function wrapCrypto(crypto) {
    return {
        generateKeypair: crypto.generateX25519KeyPair,
        dh: (keypair, publicKey) => crypto.generateX25519SharedKey(keypair.privateKey, publicKey).subarray(0, 32),
        encrypt: crypto.chaCha20Poly1305Encrypt,
        decrypt: crypto.chaCha20Poly1305Decrypt,
        hash: crypto.hashSHA256,
        hkdf: crypto.getHKDF
    };
}

const uint16BEEncode = (value) => {
    const target = allocUnsafe(2);
    target[0] = value >> 8;
    target[1] = value;
    return target;
};
uint16BEEncode.bytes = 2;
const uint16BEDecode = (data) => {
    if (data.length < 2)
        throw RangeError('Could not decode int16BE');
    if (data instanceof Uint8Array) {
        let value = 0;
        value += data[0] << 8;
        value += data[1];
        return value;
    }
    return data.getUint16(0);
};
uint16BEDecode.bytes = 2;

function registerMetrics(metrics) {
    return {
        xxHandshakeSuccesses: metrics.registerCounter('libp2p_noise_xxhandshake_successes_total', {
            help: 'Total count of noise xxHandshakes successes_'
        }),
        xxHandshakeErrors: metrics.registerCounter('libp2p_noise_xxhandshake_error_total', {
            help: 'Total count of noise xxHandshakes errors'
        }),
        encryptedPackets: metrics.registerCounter('libp2p_noise_encrypted_packets_total', {
            help: 'Total count of noise encrypted packets successfully'
        }),
        decryptedPackets: metrics.registerCounter('libp2p_noise_decrypted_packets_total', {
            help: 'Total count of noise decrypted packets'
        }),
        decryptErrors: metrics.registerCounter('libp2p_noise_decrypt_errors_total', {
            help: 'Total count of noise decrypt errors'
        })
    };
}

function logLocalStaticKeys(s, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (s) {
        keyLogger(`LOCAL_STATIC_PUBLIC_KEY ${toString$6(s.publicKey, 'hex')}`);
        keyLogger(`LOCAL_STATIC_PRIVATE_KEY ${toString$6(s.privateKey, 'hex')}`);
    }
    else {
        keyLogger('Missing local static keys.');
    }
}
function logLocalEphemeralKeys(e, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (e) {
        keyLogger(`LOCAL_PUBLIC_EPHEMERAL_KEY ${toString$6(e.publicKey, 'hex')}`);
        keyLogger(`LOCAL_PRIVATE_EPHEMERAL_KEY ${toString$6(e.privateKey, 'hex')}`);
    }
    else {
        keyLogger('Missing local ephemeral keys.');
    }
}
function logRemoteStaticKey(rs, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (rs) {
        keyLogger(`REMOTE_STATIC_PUBLIC_KEY ${toString$6(rs.subarray(), 'hex')}`);
    }
    else {
        keyLogger('Missing remote static public key.');
    }
}
function logRemoteEphemeralKey(re, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    if (re) {
        keyLogger(`REMOTE_EPHEMERAL_PUBLIC_KEY ${toString$6(re.subarray(), 'hex')}`);
    }
    else {
        keyLogger('Missing remote ephemeral keys.');
    }
}
function logCipherState(cs1, cs2, keyLogger) {
    if (!keyLogger.enabled || !DUMP_SESSION_KEYS) {
        return;
    }
    keyLogger(`CIPHER_STATE_1 ${cs1.n.getUint64()} ${cs1.k && toString$6(cs1.k, 'hex')}`);
    keyLogger(`CIPHER_STATE_2 ${cs2.n.getUint64()} ${cs2.k && toString$6(cs2.k, 'hex')}`);
}

class UnexpectedPeerError extends Error {
    code;
    constructor(message = 'Unexpected Peer') {
        super(message);
        this.code = UnexpectedPeerError.code;
    }
    static code = 'ERR_UNEXPECTED_PEER';
}
class InvalidCryptoExchangeError extends Error {
    code;
    constructor(message = 'Invalid crypto exchange') {
        super(message);
        this.code = InvalidCryptoExchangeError.code;
    }
    static code = 'ERR_INVALID_CRYPTO_EXCHANGE';
}

const MIN_NONCE = 0;
// For performance reasons, the nonce is represented as a JS `number`
// Although JS `number` can safely represent integers up to 2 ** 53 - 1, we choose to only use
// 4 bytes to store the data for performance reason.
// This is a slight deviation from the noise spec, which describes the max nonce as 2 ** 64 - 2
// The effect is that this implementation will need a new handshake to be performed after fewer messages are exchanged than other implementations with full uint64 nonces.
// this MAX_NONCE is still a large number of messages, so the practical effect of this is negligible.
const MAX_NONCE = 0xffffffff;
const ERR_MAX_NONCE = 'Cipherstate has reached maximum n, a new handshake must be performed';
/**
 * The nonce is an uint that's increased over time.
 * Maintaining different representations help improve performance.
 */
class Nonce {
    n;
    bytes;
    view;
    constructor(n = MIN_NONCE) {
        this.n = n;
        this.bytes = alloc$2(12);
        this.view = new DataView(this.bytes.buffer, this.bytes.byteOffset, this.bytes.byteLength);
        this.view.setUint32(4, n, true);
    }
    increment() {
        this.n++;
        // Even though we're treating the nonce as 8 bytes, RFC7539 specifies 12 bytes for a nonce.
        this.view.setUint32(4, this.n, true);
    }
    getBytes() {
        return this.bytes;
    }
    getUint64() {
        return this.n;
    }
    assertValue() {
        if (this.n > MAX_NONCE) {
            throw new Error(ERR_MAX_NONCE);
        }
    }
}

// Code in this file is a direct translation of a subset of the noise protocol https://noiseprotocol.org/noise.html,
// agnostic to libp2p's usage of noise
const ZEROLEN = alloc$2(0);
class CipherState {
    k;
    n;
    crypto;
    constructor(crypto, k = undefined, n = 0) {
        this.crypto = crypto;
        this.k = k;
        this.n = new Nonce(n);
    }
    hasKey() {
        return Boolean(this.k);
    }
    encryptWithAd(ad, plaintext) {
        if (!this.hasKey()) {
            return plaintext;
        }
        this.n.assertValue();
        const e = this.crypto.encrypt(plaintext, this.n.getBytes(), ad, this.k);
        this.n.increment();
        return e;
    }
    decryptWithAd(ad, ciphertext, dst) {
        if (!this.hasKey()) {
            return ciphertext;
        }
        this.n.assertValue();
        const plaintext = this.crypto.decrypt(ciphertext, this.n.getBytes(), ad, this.k, dst);
        this.n.increment();
        return plaintext;
    }
}
class SymmetricState {
    cs;
    ck;
    h;
    crypto;
    constructor(crypto, protocolName) {
        this.crypto = crypto;
        const protocolNameBytes = fromString(protocolName, 'utf-8');
        this.h = hashProtocolName(crypto, protocolNameBytes);
        this.ck = this.h;
        this.cs = new CipherState(crypto);
    }
    mixKey(ikm) {
        const [ck, tempK] = this.crypto.hkdf(this.ck, ikm);
        this.ck = ck;
        this.cs = new CipherState(this.crypto, tempK);
    }
    mixHash(data) {
        this.h = this.crypto.hash(new Uint8ArrayList(this.h, data));
    }
    encryptAndHash(plaintext) {
        const ciphertext = this.cs.encryptWithAd(this.h, plaintext);
        this.mixHash(ciphertext);
        return ciphertext;
    }
    decryptAndHash(ciphertext) {
        const plaintext = this.cs.decryptWithAd(this.h, ciphertext);
        this.mixHash(ciphertext);
        return plaintext;
    }
    split() {
        const [tempK1, tempK2] = this.crypto.hkdf(this.ck, ZEROLEN);
        return [new CipherState(this.crypto, tempK1), new CipherState(this.crypto, tempK2)];
    }
}
class AbstractHandshakeState {
    ss;
    s;
    e;
    rs;
    re;
    initiator;
    crypto;
    constructor(init) {
        const { crypto, protocolName, prologue, initiator, s, e, rs, re } = init;
        this.crypto = crypto;
        this.ss = new SymmetricState(crypto, protocolName);
        this.ss.mixHash(prologue);
        this.initiator = initiator;
        this.s = s;
        this.e = e;
        this.rs = rs;
        this.re = re;
    }
    writeE() {
        if (this.e) {
            throw new Error('ephemeral keypair is already set');
        }
        const e = this.crypto.generateKeypair();
        this.ss.mixHash(e.publicKey);
        this.e = e;
        return e.publicKey;
    }
    writeS() {
        if (!this.s) {
            throw new Error('static keypair is not set');
        }
        return this.ss.encryptAndHash(this.s.publicKey);
    }
    writeEE() {
        if (!this.e) {
            throw new Error('ephemeral keypair is not set');
        }
        if (!this.re) {
            throw new Error('remote ephemeral public key is not set');
        }
        this.ss.mixKey(this.crypto.dh(this.e, this.re));
    }
    writeES() {
        if (this.initiator) {
            if (!this.e) {
                throw new Error('ephemeral keypair is not set');
            }
            if (!this.rs) {
                throw new Error('remote static public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.e, this.rs));
        }
        else {
            if (!this.s) {
                throw new Error('static keypair is not set');
            }
            if (!this.re) {
                throw new Error('remote ephemeral public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.s, this.re));
        }
    }
    writeSE() {
        if (this.initiator) {
            if (!this.s) {
                throw new Error('static keypair is not set');
            }
            if (!this.re) {
                throw new Error('remote ephemeral public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.s, this.re));
        }
        else {
            if (!this.e) {
                throw new Error('ephemeral keypair is not set');
            }
            if (!this.rs) {
                throw new Error('remote static public key is not set');
            }
            this.ss.mixKey(this.crypto.dh(this.e, this.rs));
        }
    }
    readE(message, offset = 0) {
        if (this.re) {
            throw new Error('remote ephemeral public key is already set');
        }
        if (message.byteLength < offset + 32) {
            throw new Error('message is not long enough');
        }
        this.re = message.sublist(offset, offset + 32);
        this.ss.mixHash(this.re);
    }
    readS(message, offset = 0) {
        if (this.rs) {
            throw new Error('remote static public key is already set');
        }
        const cipherLength = 32 + (this.ss.cs.hasKey() ? 16 : 0);
        if (message.byteLength < offset + cipherLength) {
            throw new Error('message is not long enough');
        }
        const temp = message.sublist(offset, offset + cipherLength);
        this.rs = this.ss.decryptAndHash(temp);
        return cipherLength;
    }
    readEE() {
        this.writeEE();
    }
    readES() {
        this.writeES();
    }
    readSE() {
        this.writeSE();
    }
}
/**
 * A IHandshakeState that's optimized for the XX pattern
 */
class XXHandshakeState extends AbstractHandshakeState {
    // e
    writeMessageA(payload) {
        return new Uint8ArrayList(this.writeE(), this.ss.encryptAndHash(payload));
    }
    // e, ee, s, es
    writeMessageB(payload) {
        const e = this.writeE();
        this.writeEE();
        const encS = this.writeS();
        this.writeES();
        return new Uint8ArrayList(e, encS, this.ss.encryptAndHash(payload));
    }
    // s, se
    writeMessageC(payload) {
        const encS = this.writeS();
        this.writeSE();
        return new Uint8ArrayList(encS, this.ss.encryptAndHash(payload));
    }
    // e
    readMessageA(message) {
        try {
            this.readE(message);
            return this.ss.decryptAndHash(message.sublist(32));
        }
        catch (e) {
            throw new InvalidCryptoExchangeError(`handshake stage 0 validation fail: ${e.message}`);
        }
    }
    // e, ee, s, es
    readMessageB(message) {
        try {
            this.readE(message);
            this.readEE();
            const consumed = this.readS(message, 32);
            this.readES();
            return this.ss.decryptAndHash(message.sublist(32 + consumed));
        }
        catch (e) {
            throw new InvalidCryptoExchangeError(`handshake stage 1 validation fail: ${e.message}`);
        }
    }
    // s, se
    readMessageC(message) {
        try {
            const consumed = this.readS(message);
            this.readSE();
            return this.ss.decryptAndHash(message.sublist(consumed));
        }
        catch (e) {
            throw new InvalidCryptoExchangeError(`handshake stage 2 validation fail: ${e.message}`);
        }
    }
}
function hashProtocolName(crypto, protocolName) {
    if (protocolName.length <= 32) {
        const h = alloc$2(32);
        h.set(protocolName);
        return h;
    }
    else {
        return crypto.hash(protocolName);
    }
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var NoiseExtensions;
(function (NoiseExtensions) {
    let _codec;
    NoiseExtensions.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.webtransportCerthashes != null) {
                    for (const value of obj.webtransportCerthashes) {
                        w.uint32(10);
                        w.bytes(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    webtransportCerthashes: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.webtransportCerthashes.push(reader.bytes());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseExtensions.encode = (obj) => {
        return encodeMessage(obj, NoiseExtensions.codec());
    };
    NoiseExtensions.decode = (buf) => {
        return decodeMessage(buf, NoiseExtensions.codec());
    };
})(NoiseExtensions || (NoiseExtensions = {}));
var NoiseHandshakePayload;
(function (NoiseHandshakePayload) {
    let _codec;
    NoiseHandshakePayload.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.identityKey != null && obj.identityKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.identityKey);
                }
                if ((obj.identitySig != null && obj.identitySig.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.identitySig);
                }
                if (obj.extensions != null) {
                    w.uint32(34);
                    NoiseExtensions.codec().encode(obj.extensions, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    identityKey: alloc$2(0),
                    identitySig: alloc$2(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1: {
                            obj.identityKey = reader.bytes();
                            break;
                        }
                        case 2: {
                            obj.identitySig = reader.bytes();
                            break;
                        }
                        case 4: {
                            obj.extensions = NoiseExtensions.codec().decode(reader, reader.uint32());
                            break;
                        }
                        default: {
                            reader.skipType(tag & 7);
                            break;
                        }
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseHandshakePayload.encode = (obj) => {
        return encodeMessage(obj, NoiseHandshakePayload.codec());
    };
    NoiseHandshakePayload.decode = (buf) => {
        return decodeMessage(buf, NoiseHandshakePayload.codec());
    };
})(NoiseHandshakePayload || (NoiseHandshakePayload = {}));

async function createHandshakePayload(privateKey, staticPublicKey, extensions) {
    const identitySig = await privateKey.sign(getSignaturePayload(staticPublicKey));
    return NoiseHandshakePayload.encode({
        identityKey: privateKey.public.bytes,
        identitySig,
        extensions
    });
}
async function decodeHandshakePayload(payloadBytes, remoteStaticKey, remoteIdentityKey) {
    try {
        const payload = NoiseHandshakePayload.decode(payloadBytes);
        if (remoteIdentityKey) {
            const remoteIdentityKeyBytes = remoteIdentityKey.subarray();
            if (!equals(remoteIdentityKeyBytes, payload.identityKey)) {
                throw new Error(`Payload identity key ${toString$6(payload.identityKey, 'hex')} does not match expected remote identity key ${toString$6(remoteIdentityKeyBytes, 'hex')}`);
            }
        }
        if (!remoteStaticKey) {
            throw new Error('Remote static does not exist');
        }
        const signaturePayload = getSignaturePayload(remoteStaticKey);
        const publicKey = unmarshalPublicKey(payload.identityKey);
        if (!(await publicKey.verify(signaturePayload, payload.identitySig))) {
            throw new Error('Invalid payload signature');
        }
        return payload;
    }
    catch (e) {
        throw new UnexpectedPeerError(e.message);
    }
}
function getSignaturePayload(publicKey) {
    const prefix = fromString('noise-libp2p-static-key:');
    if (publicKey instanceof Uint8Array) {
        return concat$1([prefix, publicKey], prefix.length + publicKey.length);
    }
    publicKey.prepend(prefix);
    return publicKey;
}

async function performHandshakeInitiator(init, options) {
    const { log, connection, crypto, privateKey, prologue, s, remoteIdentityKey, extensions } = init;
    const payload = await createHandshakePayload(privateKey, s.publicKey, extensions);
    const xx = new XXHandshakeState({
        crypto,
        protocolName: 'Noise_XX_25519_ChaChaPoly_SHA256',
        initiator: true,
        prologue,
        s
    });
    logLocalStaticKeys(xx.s, log);
    log.trace('Stage 0 - Initiator starting to send first message.');
    await connection.write(xx.writeMessageA(ZEROLEN), options);
    log.trace('Stage 0 - Initiator finished sending first message.');
    logLocalEphemeralKeys(xx.e, log);
    log.trace('Stage 1 - Initiator waiting to receive first message from responder...');
    const plaintext = xx.readMessageB(await connection.read(options));
    log.trace('Stage 1 - Initiator received the message.');
    logRemoteEphemeralKey(xx.re, log);
    logRemoteStaticKey(xx.rs, log);
    log.trace("Initiator going to check remote's signature...");
    const receivedPayload = await decodeHandshakePayload(plaintext, xx.rs, remoteIdentityKey);
    log.trace('All good with the signature!');
    log.trace('Stage 2 - Initiator sending third handshake message.');
    await connection.write(xx.writeMessageC(payload), options);
    log.trace('Stage 2 - Initiator sent message with signed payload.');
    const [cs1, cs2] = xx.ss.split();
    logCipherState(cs1, cs2, log);
    return {
        payload: receivedPayload,
        encrypt: (plaintext) => cs1.encryptWithAd(ZEROLEN, plaintext),
        decrypt: (ciphertext, dst) => cs2.decryptWithAd(ZEROLEN, ciphertext, dst)
    };
}
async function performHandshakeResponder(init, options) {
    const { log, connection, crypto, privateKey, prologue, s, remoteIdentityKey, extensions } = init;
    const payload = await createHandshakePayload(privateKey, s.publicKey, extensions);
    const xx = new XXHandshakeState({
        crypto,
        protocolName: 'Noise_XX_25519_ChaChaPoly_SHA256',
        initiator: false,
        prologue,
        s
    });
    logLocalStaticKeys(xx.s, log);
    log.trace('Stage 0 - Responder waiting to receive first message.');
    xx.readMessageA(await connection.read(options));
    log.trace('Stage 0 - Responder received first message.');
    logRemoteEphemeralKey(xx.re, log);
    log.trace('Stage 1 - Responder sending out first message with signed payload and static key.');
    await connection.write(xx.writeMessageB(payload), options);
    log.trace('Stage 1 - Responder sent the second handshake message with signed payload.');
    logLocalEphemeralKeys(xx.e, log);
    log.trace('Stage 2 - Responder waiting for third handshake message...');
    const plaintext = xx.readMessageC(await connection.read(options));
    log.trace('Stage 2 - Responder received the message, finished handshake.');
    const receivedPayload = await decodeHandshakePayload(plaintext, xx.rs, remoteIdentityKey);
    const [cs1, cs2] = xx.ss.split();
    logCipherState(cs1, cs2, log);
    return {
        payload: receivedPayload,
        encrypt: (plaintext) => cs2.encryptWithAd(ZEROLEN, plaintext),
        decrypt: (ciphertext, dst) => cs1.decryptWithAd(ZEROLEN, ciphertext, dst)
    };
}

const CHACHA_TAG_LENGTH = 16;
// Returns generator that encrypts payload from the user
function encryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                let data;
                if (chunk instanceof Uint8Array) {
                    data = handshake.encrypt(chunk.subarray(i, end));
                }
                else {
                    data = handshake.encrypt(chunk.sublist(i, end));
                }
                metrics?.encryptedPackets.increment();
                yield new Uint8ArrayList(uint16BEEncode(data.byteLength), data);
            }
        }
    };
}
// Decrypt received payload to the user
function decryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                if (end - CHACHA_TAG_LENGTH < i) {
                    throw new Error('Invalid chunk');
                }
                const encrypted = chunk.sublist(i, end);
                // memory allocation is not cheap so reuse the encrypted Uint8Array
                // see https://github.com/ChainSafe/js-libp2p-noise/pull/242#issue-1422126164
                // this is ok because chacha20 reads bytes one by one and don't reread after that
                // it's also tested in https://github.com/ChainSafe/as-chacha20poly1305/pull/1/files#diff-25252846b58979dcaf4e41d47b3eadd7e4f335e7fb98da6c049b1f9cd011f381R48
                const dst = chunk.subarray(i, end - CHACHA_TAG_LENGTH);
                try {
                    const plaintext = handshake.decrypt(encrypted, dst);
                    metrics?.decryptedPackets.increment();
                    yield plaintext;
                }
                catch (e) {
                    metrics?.decryptErrors.increment();
                    throw e;
                }
            }
        }
    };
}

class Noise {
    protocol = '/noise';
    crypto;
    prologue;
    staticKey;
    extensions;
    metrics;
    components;
    constructor(components, init = {}) {
        const { staticNoiseKey, extensions, crypto, prologueBytes } = init;
        const { metrics } = components;
        this.components = components;
        const _crypto = crypto ?? defaultCrypto;
        this.crypto = wrapCrypto(_crypto);
        this.extensions = extensions;
        this.metrics = metrics ? registerMetrics(metrics) : undefined;
        if (staticNoiseKey) {
            // accepts x25519 private key of length 32
            this.staticKey = _crypto.generateX25519KeyPairFromSeed(staticNoiseKey);
        }
        else {
            this.staticKey = _crypto.generateX25519KeyPair();
        }
        this.prologue = prologueBytes ?? alloc$2(0);
    }
    [Symbol.toStringTag] = '@chainsafe/libp2p-noise';
    [serviceCapabilities] = [
        '@libp2p/connection-encryption',
        '@chainsafe/libp2p-noise'
    ];
    async secureOutbound(...args) {
        const { localPeer, connection, remotePeer, signal } = this.parseArgs(args);
        const wrappedConnection = lpStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        if (!localPeer.privateKey) {
            throw new CodeError$1('local peerId does not contain private key', 'ERR_NO_PRIVATE_KEY');
        }
        const privateKey = await unmarshalPrivateKey(localPeer.privateKey);
        const remoteIdentityKey = remotePeer?.publicKey;
        const handshake = await this.performHandshakeInitiator(wrappedConnection, privateKey, remoteIdentityKey, {
            signal
        });
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        connection.source = conn.source;
        connection.sink = conn.sink;
        return {
            conn: connection,
            remoteExtensions: handshake.payload.extensions,
            remotePeer: await peerIdFromKeys(handshake.payload.identityKey)
        };
    }
    async secureInbound(...args) {
        const { localPeer, connection, remotePeer, signal } = this.parseArgs(args);
        const wrappedConnection = lpStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        if (!localPeer.privateKey) {
            throw new CodeError$1('local peerId does not contain private key', 'ERR_NO_PRIVATE_KEY');
        }
        const privateKey = await unmarshalPrivateKey(localPeer.privateKey);
        const remoteIdentityKey = remotePeer?.publicKey;
        const handshake = await this.performHandshakeResponder(wrappedConnection, privateKey, remoteIdentityKey, {
            signal
        });
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        connection.source = conn.source;
        connection.sink = conn.sink;
        return {
            conn: connection,
            remoteExtensions: handshake.payload.extensions,
            remotePeer: await peerIdFromKeys(handshake.payload.identityKey)
        };
    }
    /**
     * Perform XX handshake as initiator.
     */
    async performHandshakeInitiator(connection, 
    // TODO: pass private key in noise constructor via Components
    privateKey, remoteIdentityKey, options) {
        let result;
        try {
            result = await performHandshakeInitiator({
                connection,
                privateKey,
                remoteIdentityKey,
                log: this.components.logger.forComponent('libp2p:noise:xxhandshake'),
                crypto: this.crypto,
                prologue: this.prologue,
                s: this.staticKey,
                extensions: this.extensions
            }, options);
            this.metrics?.xxHandshakeSuccesses.increment();
        }
        catch (e) {
            this.metrics?.xxHandshakeErrors.increment();
            throw e;
        }
        return result;
    }
    /**
     * Perform XX handshake as responder.
     */
    async performHandshakeResponder(connection, 
    // TODO: pass private key in noise constructor via Components
    privateKey, remoteIdentityKey, options) {
        let result;
        try {
            result = await performHandshakeResponder({
                connection,
                privateKey,
                remoteIdentityKey,
                log: this.components.logger.forComponent('libp2p:noise:xxhandshake'),
                crypto: this.crypto,
                prologue: this.prologue,
                s: this.staticKey,
                extensions: this.extensions
            }, options);
            this.metrics?.xxHandshakeSuccesses.increment();
        }
        catch (e) {
            this.metrics?.xxHandshakeErrors.increment();
            throw e;
        }
        return result;
    }
    async createSecureConnection(connection, handshake) {
        // Create encryption box/unbox wrapper
        const [secure, user] = duplexPair();
        const network = connection.unwrap();
        await pipe(secure, // write to wrapper
        encryptStream(handshake, this.metrics), // encrypt data + prefix with message length
        network, // send to the remote peer
        (source) => decode$4(source, { lengthDecoder: uint16BEDecode }), // read message length prefix
        decryptStream(handshake, this.metrics), // decrypt the incoming data
        secure // pipe to the wrapper
        );
        return user;
    }
    /**
     * Detect call signature in `libp2p@1.x.x` or `libp2p@2.x.x` style.
     *
     * TODO: remove this after `libp2p@2.x.x` is released and only support the
     * newer style
     */
    parseArgs(args) {
        // if the first argument is a peer id, we're using the libp2p@1.x.x style
        if (isPeerId(args[0])) {
            return {
                localPeer: args[0],
                connection: args[1],
                remotePeer: args[2]
            };
        }
        else {
            // handle upcoming changes in libp2p@2.x.x where the first argument is the
            // connection and the second is optionally the remote peer
            // @see https://github.com/libp2p/js-libp2p/pull/2304
            return {
                localPeer: this.components.peerId,
                connection: args[0],
                remotePeer: args[1]?.remotePeer,
                signal: args[1]?.signal
            };
        }
    }
}

function noise(init = {}) {
    return (components) => new Noise(components, init);
}

/*
 * Valid combinations
 */
const DNS4 = base('dns4');
const DNS6 = base('dns6');
const DNSADDR = base('dnsaddr');
const DNS$1 = or$1(base('dns'), DNSADDR, DNS4, DNS6);
const IP = or$1(base('ip4'), base('ip6'));
const TCP = or$1(and$1(IP, base('tcp')), and$1(DNS$1, base('tcp')));
const UDP = and$1(IP, base('udp'));
const UTP = and$1(UDP, base('utp'));
const QUIC = and$1(UDP, base('quic'));
const QUICV1 = and$1(UDP, base('quic-v1'));
const _WebSockets$1 = or$1(and$1(TCP, base('ws')), and$1(DNS$1, base('ws')));
const WebSockets$1 = or$1(and$1(_WebSockets$1, base('p2p')), _WebSockets$1);
const _WebSocketsSecure$1 = or$1(and$1(TCP, base('wss')), and$1(DNS$1, base('wss')), and$1(TCP, base('tls'), base('ws')), and$1(DNS$1, base('tls'), base('ws')));
const WebSocketsSecure = or$1(and$1(_WebSocketsSecure$1, base('p2p')), _WebSocketsSecure$1);
const HTTP = or$1(and$1(TCP, base('http')), and$1(IP, base('http')), and$1(DNS$1, base('http')));
const HTTPS = or$1(and$1(TCP, base('https')), and$1(IP, base('https')), and$1(DNS$1, base('https')));
const _WebRTCDirect$1 = and$1(UDP, base('webrtc-direct'), base('certhash'));
const WebRTCDirect = or$1(and$1(_WebRTCDirect$1, base('p2p')), _WebRTCDirect$1);
const _WebTransport$1 = and$1(QUICV1, base('webtransport'), base('certhash'), base('certhash'));
const WebTransport = or$1(and$1(_WebTransport$1, base('p2p')), _WebTransport$1);
/**
 * @deprecated
 */
const P2PWebRTCStar = or$1(and$1(WebSockets$1, base('p2p-webrtc-star'), base('p2p')), and$1(WebSocketsSecure, base('p2p-webrtc-star'), base('p2p')), and$1(WebSockets$1, base('p2p-webrtc-star')), and$1(WebSocketsSecure, base('p2p-webrtc-star')));
/**
 * @deprecated
 */
const P2PWebRTCDirect = or$1(and$1(HTTP, base('p2p-webrtc-direct'), base('p2p')), and$1(HTTPS, base('p2p-webrtc-direct'), base('p2p')), and$1(HTTP, base('p2p-webrtc-direct')), and$1(HTTPS, base('p2p-webrtc-direct')));
const Reliable = or$1(_WebSockets$1, _WebSocketsSecure$1, HTTP, HTTPS, P2PWebRTCStar, P2PWebRTCDirect, TCP, UTP, QUIC, DNS$1, WebRTCDirect, WebTransport);
const _P2P$1 = or$1(and$1(Reliable, base('p2p')), P2PWebRTCStar, P2PWebRTCDirect, WebRTCDirect, WebTransport, base('p2p'));
const _Circuit$1 = or$1(and$1(_P2P$1, base('p2p-circuit'), _P2P$1), and$1(_P2P$1, base('p2p-circuit')), and$1(base('p2p-circuit'), _P2P$1), and$1(Reliable, base('p2p-circuit')), and$1(base('p2p-circuit'), Reliable), base('p2p-circuit'));
const CircuitRecursive = () => or$1(and$1(_Circuit$1, CircuitRecursive), _Circuit$1);
const Circuit$1 = CircuitRecursive();
const P2P = or$1(and$1(Circuit$1, _P2P$1, Circuit$1), and$1(_P2P$1, Circuit$1), and$1(Circuit$1, _P2P$1), Circuit$1, _P2P$1);
/*
 * Validation funcs
 */
function makeMatchesFunction(partialMatch) {
    function matches(a) {
        let ma;
        try {
            ma = multiaddr(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const out = partialMatch(ma.protoNames());
        if (out === null) {
            return false;
        }
        if (out === true || out === false) {
            return out;
        }
        return out.length === 0;
    }
    return matches;
}
function and$1(...args) {
    function partialMatch(a) {
        if (a.length < args.length) {
            return null;
        }
        let out = a;
        args.some((arg) => {
            out = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (Array.isArray(out)) {
                a = out;
            }
            if (out === null) {
                return true;
            }
            return false;
        });
        return out;
    }
    return {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch
    };
}
function or$1(...args) {
    function partialMatch(a) {
        let out = null;
        args.some((arg) => {
            const res = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (res != null) {
                out = res;
                return true;
            }
            return false;
        });
        return out;
    }
    const result = {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch
    };
    return result;
}
function base(n) {
    const name = n;
    function matches(a) {
        let ma;
        try {
            ma = multiaddr(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const pnames = ma.protoNames();
        if (pnames.length === 1 && pnames[0] === name) {
            return true;
        }
        return false;
    }
    function partialMatch(protos) {
        if (protos.length === 0) {
            return null;
        }
        if (protos[0] === name) {
            return protos.slice(1);
        }
        return null;
    }
    return {
        toString: function () { return name; },
        matches,
        partialMatch
    };
}

/**
 * @packageDocumentation
 *
 * The configured bootstrap peers will be discovered after the configured timeout. This will ensure there are some peers in the peer store for the node to use to discover other peers.
 *
 * They will be tagged with a tag with the name `'bootstrap'` tag, the value `50` and it will expire after two minutes which means the nodes connections may be closed if the maximum number of connections is reached.
 *
 * Clients that need constant connections to bootstrap nodes (e.g. browsers) can set the TTL to `Infinity`.
 *
 * @example Configuring a list of bootstrap nodes
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { bootstrap } from '@libp2p/bootstrap'
 *
 * const libp2p = await createLibp2p({
 *   peerDiscovery: [
 *     bootstrap({
 *       list: [
 *         // a list of bootstrap peer multiaddrs to connect to on node startup
 *         '/ip4/104.131.131.82/tcp/4001/ipfs/QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ',
 *         '/dnsaddr/bootstrap.libp2p.io/ipfs/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN',
 *         '/dnsaddr/bootstrap.libp2p.io/ipfs/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa'
 *       ]
 *     })
 *   ]
 * })
 *
 * libp2p.addEventListener('peer:discovery', (evt) => {
 *   console.log('found peer: ', evt.detail.toString())
 * })
 * ```
 */
const DEFAULT_BOOTSTRAP_TAG_NAME$1 = 'bootstrap';
const DEFAULT_BOOTSTRAP_TAG_VALUE$1 = 50;
const DEFAULT_BOOTSTRAP_TAG_TTL$1 = 120000;
const DEFAULT_BOOTSTRAP_DISCOVERY_TIMEOUT = 1000;
/**
 * Emits 'peer' events on a regular interval for each peer in the provided list.
 */
class Bootstrap extends TypedEventEmitter {
    static tag = 'bootstrap';
    log;
    timer;
    list;
    timeout;
    components;
    _init;
    constructor(components, options = { list: [] }) {
        if (options.list == null || options.list.length === 0) {
            throw new Error('Bootstrap requires a list of peer addresses');
        }
        super();
        this.components = components;
        this.log = components.logger.forComponent('libp2p:bootstrap');
        this.timeout = options.timeout ?? DEFAULT_BOOTSTRAP_DISCOVERY_TIMEOUT;
        this.list = [];
        for (const candidate of options.list) {
            if (!P2P.matches(candidate)) {
                this.log.error('Invalid multiaddr');
                continue;
            }
            const ma = multiaddr(candidate);
            const peerIdStr = ma.getPeerId();
            if (peerIdStr == null) {
                this.log.error('Invalid bootstrap multiaddr without peer id');
                continue;
            }
            const peerData = {
                id: peerIdFromString(peerIdStr),
                multiaddrs: [ma]
            };
            this.list.push(peerData);
        }
        this._init = options;
    }
    [peerDiscoverySymbol] = this;
    [Symbol.toStringTag] = '@libp2p/bootstrap';
    [serviceCapabilities] = [
        '@libp2p/peer-discovery'
    ];
    isStarted() {
        return Boolean(this.timer);
    }
    /**
     * Start emitting events
     */
    start() {
        if (this.isStarted()) {
            return;
        }
        this.log('Starting bootstrap node discovery, discovering peers after %s ms', this.timeout);
        this.timer = setTimeout(() => {
            void this._discoverBootstrapPeers()
                .catch(err => {
                this.log.error(err);
            });
        }, this.timeout);
    }
    /**
     * Emit each address in the list as a PeerInfo
     */
    async _discoverBootstrapPeers() {
        if (this.timer == null) {
            return;
        }
        for (const peerData of this.list) {
            await this.components.peerStore.merge(peerData.id, {
                tags: {
                    [this._init.tagName ?? DEFAULT_BOOTSTRAP_TAG_NAME$1]: {
                        value: this._init.tagValue ?? DEFAULT_BOOTSTRAP_TAG_VALUE$1,
                        ttl: this._init.tagTTL ?? DEFAULT_BOOTSTRAP_TAG_TTL$1
                    }
                }
            });
            // check we are still running
            if (this.timer == null) {
                return;
            }
            this.safeDispatchEvent('peer', { detail: peerData });
        }
    }
    /**
     * Stop emitting events
     */
    stop() {
        if (this.timer != null) {
            clearTimeout(this.timer);
        }
        this.timer = undefined;
    }
}
function bootstrap(init) {
    return (components) => new Bootstrap(components, init);
}

const codes$2 = {
    ERR_SIGNATURE_NOT_VALID: 'ERR_SIGNATURE_NOT_VALID'
};

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Envelope;
(function (Envelope) {
    let _codec;
    Envelope.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.publicKey != null && obj.publicKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if ((obj.payloadType != null && obj.payloadType.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.payloadType);
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.payload);
                }
                if ((obj.signature != null && obj.signature.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.signature);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    publicKey: new Uint8Array(0),
                    payloadType: new Uint8Array(0),
                    payload: new Uint8Array(0),
                    signature: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.publicKey = reader.bytes();
                            break;
                        case 2:
                            obj.payloadType = reader.bytes();
                            break;
                        case 3:
                            obj.payload = reader.bytes();
                            break;
                        case 5:
                            obj.signature = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Envelope.encode = (obj) => {
        return encodeMessage(obj, Envelope.codec());
    };
    Envelope.decode = (buf) => {
        return decodeMessage(buf, Envelope.codec());
    };
})(Envelope || (Envelope = {}));

class RecordEnvelope {
    /**
     * Unmarshal a serialized Envelope protobuf message
     */
    static createFromProtobuf = async (data) => {
        const envelopeData = Envelope.decode(data);
        const peerId = await peerIdFromKeys(envelopeData.publicKey);
        return new RecordEnvelope({
            peerId,
            payloadType: envelopeData.payloadType,
            payload: envelopeData.payload,
            signature: envelopeData.signature
        });
    };
    /**
     * Seal marshals the given Record, places the marshaled bytes inside an Envelope
     * and signs it with the given peerId's private key
     */
    static seal = async (record, peerId) => {
        if (peerId.privateKey == null) {
            throw new Error('Missing private key');
        }
        const domain = record.domain;
        const payloadType = record.codec;
        const payload = record.marshal();
        const signData = formatSignaturePayload(domain, payloadType, payload);
        const key = await unmarshalPrivateKey(peerId.privateKey);
        const signature = await key.sign(signData.subarray());
        return new RecordEnvelope({
            peerId,
            payloadType,
            payload,
            signature
        });
    };
    /**
     * Open and certify a given marshalled envelope.
     * Data is unmarshalled and the signature validated for the given domain.
     */
    static openAndCertify = async (data, domain) => {
        const envelope = await RecordEnvelope.createFromProtobuf(data);
        const valid = await envelope.validate(domain);
        if (!valid) {
            throw new CodeError$1('envelope signature is not valid for the given domain', codes$2.ERR_SIGNATURE_NOT_VALID);
        }
        return envelope;
    };
    peerId;
    payloadType;
    payload;
    signature;
    marshaled;
    /**
     * The Envelope is responsible for keeping an arbitrary signed record
     * by a libp2p peer.
     */
    constructor(init) {
        const { peerId, payloadType, payload, signature } = init;
        this.peerId = peerId;
        this.payloadType = payloadType;
        this.payload = payload;
        this.signature = signature;
    }
    /**
     * Marshal the envelope content
     */
    marshal() {
        if (this.peerId.publicKey == null) {
            throw new Error('Missing public key');
        }
        if (this.marshaled == null) {
            this.marshaled = Envelope.encode({
                publicKey: this.peerId.publicKey,
                payloadType: this.payloadType,
                payload: this.payload.subarray(),
                signature: this.signature
            });
        }
        return this.marshaled;
    }
    /**
     * Verifies if the other Envelope is identical to this one
     */
    equals(other) {
        return equals(this.marshal(), other.marshal());
    }
    /**
     * Validate envelope data signature for the given domain
     */
    async validate(domain) {
        const signData = formatSignaturePayload(domain, this.payloadType, this.payload);
        if (this.peerId.publicKey == null) {
            throw new Error('Missing public key');
        }
        const key = unmarshalPublicKey(this.peerId.publicKey);
        return key.verify(signData.subarray(), this.signature);
    }
}
/**
 * Helper function that prepares a Uint8Array to sign or verify a signature
 */
const formatSignaturePayload = (domain, payloadType, payload) => {
    // When signing, a peer will prepare a Uint8Array by concatenating the following:
    // - The length of the domain separation string string in bytes
    // - The domain separation string, encoded as UTF-8
    // - The length of the payload_type field in bytes
    // - The value of the payload_type field
    // - The length of the payload field in bytes
    // - The value of the payload field
    const domainUint8Array = fromString(domain);
    const domainLength = encode$a(domainUint8Array.byteLength);
    const payloadTypeLength = encode$a(payloadType.length);
    const payloadLength = encode$a(payload.length);
    return new Uint8ArrayList(domainLength, domainUint8Array, payloadTypeLength, payloadType, payloadLength, payload);
};

/**
 * @packageDocumentation
 *
 * Provides strategies ensure arrays are equivalent.
 *
 * @example
 *
 * ```typescript
 * import { arrayEquals } from '@libp2p/utils/array-equals'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 * const ma1 = multiaddr('/ip4/127.0.0.1/tcp/9000'),
 * const ma2 = multiaddr('/ip4/82.41.53.1/tcp/9000')
 *
 * console.info(arrayEquals([ma1], [ma1])) // true
 * console.info(arrayEquals([ma1], [ma2])) // false
 * ```
 */
/**
 * Verify if two arrays of non primitive types with the "equals" function are equal.
 * Compatible with multiaddr, peer-id and others.
 */
function arrayEquals(a, b) {
    const sort = (a, b) => a.toString().localeCompare(b.toString());
    if (a.length !== b.length) {
        return false;
    }
    b.sort(sort);
    return a.sort(sort).every((item, index) => b[index].equals(item));
}

// The domain string used for peer records contained in a Envelope.
const ENVELOPE_DOMAIN_PEER_RECORD = 'libp2p-peer-record';
// The type hint used to identify peer records in a Envelope.
// Defined in https://github.com/multiformats/multicodec/blob/master/table.csv
// with name "libp2p-peer-record"
const ENVELOPE_PAYLOAD_TYPE_PEER_RECORD = Uint8Array.from([3, 1]);

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PeerRecord$1;
(function (PeerRecord) {
    (function (AddressInfo) {
        let _codec;
        AddressInfo.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                        w.uint32(10);
                        w.bytes(obj.multiaddr);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        multiaddr: new Uint8Array(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.multiaddr = reader.bytes();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        AddressInfo.encode = (obj) => {
            return encodeMessage(obj, AddressInfo.codec());
        };
        AddressInfo.decode = (buf) => {
            return decodeMessage(buf, AddressInfo.codec());
        };
    })(PeerRecord.AddressInfo || (PeerRecord.AddressInfo = {}));
    let _codec;
    PeerRecord.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.peerId != null && obj.peerId.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.peerId);
                }
                if ((obj.seq != null && obj.seq !== 0n)) {
                    w.uint32(16);
                    w.uint64(obj.seq);
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(26);
                        PeerRecord.AddressInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    peerId: new Uint8Array(0),
                    seq: 0n,
                    addresses: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.peerId = reader.bytes();
                            break;
                        case 2:
                            obj.seq = reader.uint64();
                            break;
                        case 3:
                            obj.addresses.push(PeerRecord.AddressInfo.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerRecord.encode = (obj) => {
        return encodeMessage(obj, PeerRecord.codec());
    };
    PeerRecord.decode = (buf) => {
        return decodeMessage(buf, PeerRecord.codec());
    };
})(PeerRecord$1 || (PeerRecord$1 = {}));

/**
 * The PeerRecord is used for distributing peer routing records across the network.
 * It contains the peer's reachable listen addresses.
 */
class PeerRecord {
    /**
     * Unmarshal Peer Record Protobuf
     */
    static createFromProtobuf = (buf) => {
        const peerRecord = PeerRecord$1.decode(buf);
        const peerId = peerIdFromBytes(peerRecord.peerId);
        const multiaddrs = (peerRecord.addresses ?? []).map((a) => multiaddr(a.multiaddr));
        const seqNumber = peerRecord.seq;
        return new PeerRecord({ peerId, multiaddrs, seqNumber });
    };
    static DOMAIN = ENVELOPE_DOMAIN_PEER_RECORD;
    static CODEC = ENVELOPE_PAYLOAD_TYPE_PEER_RECORD;
    peerId;
    multiaddrs;
    seqNumber;
    domain = PeerRecord.DOMAIN;
    codec = PeerRecord.CODEC;
    marshaled;
    constructor(init) {
        const { peerId, multiaddrs, seqNumber } = init;
        this.peerId = peerId;
        this.multiaddrs = multiaddrs ?? [];
        this.seqNumber = seqNumber ?? BigInt(Date.now());
    }
    /**
     * Marshal a record to be used in an envelope
     */
    marshal() {
        if (this.marshaled == null) {
            this.marshaled = PeerRecord$1.encode({
                peerId: this.peerId.toBytes(),
                seq: BigInt(this.seqNumber),
                addresses: this.multiaddrs.map((m) => ({
                    multiaddr: m.bytes
                }))
            });
        }
        return this.marshaled;
    }
    /**
     * Returns true if `this` record equals the `other`
     */
    equals(other) {
        if (!(other instanceof PeerRecord)) {
            return false;
        }
        // Validate PeerId
        if (!this.peerId.equals(other.peerId)) {
            return false;
        }
        // Validate seqNumber
        if (this.seqNumber !== other.seqNumber) {
            return false;
        }
        // Validate multiaddrs
        if (!arrayEquals(this.multiaddrs, other.multiaddrs)) {
            return false;
        }
        return true;
    }
}

/**
 * @packageDocumentation
 *
 * Mostly useful for tests or when you want to be explicit about consuming an iterable without doing anything with any yielded values.
 *
 * @example
 *
 * ```javascript
 * import drain from 'it-drain'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * drain(values)
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import drain from 'it-drain'
 *
 * const values = async function * {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * await drain(values())
 * ```
 */
function isAsyncIterable$4(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function drain(source) {
    if (isAsyncIterable$4(source)) {
        return (async () => {
            for await (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars
        })();
    }
    else {
        for (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars
    }
}

/**
 * @packageDocumentation
 *
 * Takes an (async) iterable that emits promise-returning functions, invokes them in parallel up to the concurrency limit and emits the results as they become available, optionally in the same order as the input
 *
 * @example
 *
 * ```javascript
 * import parallel from 'it-parallel'
 * import all from 'it-all'
 * import delay from 'delay'
 *
 * // This can also be an iterator, async iterator, generator, etc
 * const input = [
 *   async () => {
 *     console.info('start 1')
 *     await delay(500)
 *
 *     console.info('end 1')
 *     return 1
 *   },
 *   async () => {
 *     console.info('start 2')
 *     await delay(200)
 *
 *     console.info('end 2')
 *     return 2
 *   },
 *   async () => {
 *     console.info('start 3')
 *     await delay(100)
 *
 *     console.info('end 3')
 *     return 3
 *   }
 * ]
 *
 * const result = await all(parallel(input, {
 *   concurrency: 2
 * }))
 *
 * // output:
 * // start 1
 * // start 2
 * // end 2
 * // start 3
 * // end 3
 * // end 1
 *
 * console.info(result) // [2, 3, 1]
 * ```
 *
 * If order is important, pass `ordered: true` as an option:
 *
 * ```javascript
 * const result = await all(parallel(input, {
 *   concurrency: 2,
 *   ordered: true
 * }))
 *
 * // output:
 * // start 1
 * // start 2
 * // end 2
 * // start 3
 * // end 3
 * // end 1
 *
 * console.info(result) // [1, 2, 3]
 * ```
 */
const CustomEvent = globalThis.CustomEvent ?? Event;
/**
 * Takes an (async) iterator that emits promise-returning functions,
 * invokes them in parallel and emits the results as they become available but
 * in the same order as the input
 */
async function* parallel(source, options = {}) {
    let concurrency = options.concurrency ?? Infinity;
    if (concurrency < 1) {
        concurrency = Infinity;
    }
    const ordered = options.ordered == null ? false : options.ordered;
    const emitter = new EventTarget();
    const ops = [];
    let slotAvailable = pDefer();
    let resultAvailable = pDefer();
    let sourceFinished = false;
    let sourceErr;
    let opErred = false;
    emitter.addEventListener('task-complete', () => {
        resultAvailable.resolve();
    });
    void Promise.resolve().then(async () => {
        try {
            for await (const task of source) {
                if (ops.length === concurrency) {
                    slotAvailable = pDefer();
                    await slotAvailable.promise;
                }
                if (opErred) {
                    break;
                }
                const op = {
                    done: false
                };
                ops.push(op);
                task()
                    .then(result => {
                    op.done = true;
                    op.ok = true;
                    op.value = result;
                    emitter.dispatchEvent(new CustomEvent('task-complete'));
                }, err => {
                    op.done = true;
                    op.err = err;
                    emitter.dispatchEvent(new CustomEvent('task-complete'));
                });
            }
            sourceFinished = true;
            emitter.dispatchEvent(new CustomEvent('task-complete'));
        }
        catch (err) {
            sourceErr = err;
            emitter.dispatchEvent(new CustomEvent('task-complete'));
        }
    });
    function valuesAvailable() {
        if (ordered) {
            return ops[0]?.done;
        }
        return Boolean(ops.find(op => op.done));
    }
    function* yieldOrderedValues() {
        while ((ops.length > 0) && ops[0].done) {
            const op = ops[0];
            ops.shift();
            if (op.ok) {
                yield op.value;
            }
            else {
                // allow the source to exit
                opErred = true;
                slotAvailable.resolve();
                throw op.err;
            }
            slotAvailable.resolve();
        }
    }
    function* yieldUnOrderedValues() {
        // more values can become available while we wait for `yield`
        // to return control to this function
        while (valuesAvailable()) {
            for (let i = 0; i < ops.length; i++) {
                if (ops[i].done) {
                    const op = ops[i];
                    ops.splice(i, 1);
                    i--;
                    if (op.ok) {
                        yield op.value;
                    }
                    else {
                        opErred = true;
                        slotAvailable.resolve();
                        throw op.err;
                    }
                    slotAvailable.resolve();
                }
            }
        }
    }
    while (true) {
        if (!valuesAvailable()) {
            resultAvailable = pDefer();
            await resultAvailable.promise;
        }
        if (sourceErr != null) {
            // the source threw an error, propagate it
            throw sourceErr;
        }
        if (ordered) {
            yield* yieldOrderedValues();
        }
        else {
            yield* yieldUnOrderedValues();
        }
        if (sourceFinished && ops.length === 0) {
            // not waiting for any results and no more tasks so we are done
            break;
        }
    }
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive length-prefixed Protobuf encoded
 * messages over streams.
 *
 * @example
 *
 * ```typescript
 * import { pbStream } from 'it-protobuf-stream'
 * import { MessageType } from './src/my-message-type.js'
 *
 * // RequestType and ResponseType have been generate from `.proto` files and have
 * // `.encode` and `.decode` methods for serialization/deserialization
 *
 * const stream = pbStream(duplex)
 *
 * // write a message to the stream
 * stream.write({
 *   foo: 'bar'
 * }, MessageType)
 *
 * // read a message from the stream
 * const res = await stream.read(MessageType)
 * ```
 */
function pbStream(duplex, opts) {
    const lp = lpStream(duplex, opts);
    const W = {
        read: async (proto, options) => {
            // readLP, decode
            const value = await lp.read(options);
            return proto.decode(value);
        },
        write: async (message, proto, options) => {
            // encode, writeLP
            await lp.write(proto.encode(message), options);
        },
        writeV: async (messages, proto, options) => {
            // encode, writeLP
            await lp.writeV(messages.map(message => proto.encode(message)), options);
        },
        pb: (proto) => {
            return {
                read: async (options) => W.read(proto, options),
                write: async (d, options) => W.write(d, proto, options),
                writeV: async (d, options) => W.writeV(d, proto, options),
                unwrap: () => W
            };
        },
        unwrap: () => {
            return lp.unwrap();
        }
    };
    return W;
}

const IDENTIFY_PROTOCOL_VERSION = '0.1.0';
const MULTICODEC_IDENTIFY_PROTOCOL_NAME = 'id';
const MULTICODEC_IDENTIFY_PROTOCOL_VERSION = '1.0.0';
// https://github.com/libp2p/go-libp2p/blob/8d2e54e1637041d5cf4fac1e531287560bd1f4ac/p2p/protocol/identify/id.go#L52
const MAX_IDENTIFY_MESSAGE_SIZE = 1024 * 8;
// https://github.com/libp2p/go-libp2p/blob/0385ec924bad172f74a74db09939e97c079b1420/p2p/protocol/identify/id.go#L47C7-L47C25
const MAX_PUSH_CONCURRENCY = 32;

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Identify$1;
(function (Identify) {
    let _codec;
    Identify.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.protocolVersion != null) {
                    w.uint32(42);
                    w.string(obj.protocolVersion);
                }
                if (obj.agentVersion != null) {
                    w.uint32(50);
                    w.string(obj.agentVersion);
                }
                if (obj.publicKey != null) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if (obj.listenAddrs != null) {
                    for (const value of obj.listenAddrs) {
                        w.uint32(18);
                        w.bytes(value);
                    }
                }
                if (obj.observedAddr != null) {
                    w.uint32(34);
                    w.bytes(obj.observedAddr);
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(26);
                        w.string(value);
                    }
                }
                if (obj.signedPeerRecord != null) {
                    w.uint32(66);
                    w.bytes(obj.signedPeerRecord);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    listenAddrs: [],
                    protocols: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 5:
                            obj.protocolVersion = reader.string();
                            break;
                        case 6:
                            obj.agentVersion = reader.string();
                            break;
                        case 1:
                            obj.publicKey = reader.bytes();
                            break;
                        case 2:
                            obj.listenAddrs.push(reader.bytes());
                            break;
                        case 4:
                            obj.observedAddr = reader.bytes();
                            break;
                        case 3:
                            obj.protocols.push(reader.string());
                            break;
                        case 8:
                            obj.signedPeerRecord = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Identify.encode = (obj) => {
        return encodeMessage(obj, Identify.codec());
    };
    Identify.decode = (buf) => {
        return decodeMessage(buf, Identify.codec());
    };
})(Identify$1 || (Identify$1 = {}));

// https://github.com/electron/electron/issues/2288
function isElectron$1() {
    // Renderer process
    if (typeof window !== 'undefined' && typeof window.process === 'object' && window.process.type === 'renderer') {
        return true;
    }

    // Main process
    if (typeof process !== 'undefined' && typeof process.versions === 'object' && !!process.versions.electron) {
        return true;
    }

    // Detect the user agent when the `nodeIntegration` option is set to false
    if (typeof navigator === 'object' && typeof navigator.userAgent === 'string' && navigator.userAgent.indexOf('Electron') >= 0) {
        return true;
    }

    return false;
}

var isElectron_1 = isElectron$1;

var detectElectron = /*@__PURE__*/getDefaultExportFromCjs(isElectron_1);

const isEnvWithDom = typeof window === 'object' && typeof document === 'object' && document.nodeType === 9;
const isElectron = detectElectron();

/**
 * Detects browser main thread  **NOT** web worker or service worker
 */
const isBrowser = isEnvWithDom && !isElectron;
const isElectronMain = isElectron && !isEnvWithDom;
const isElectronRenderer = isElectron && isEnvWithDom;
const isNode = typeof globalThis.process !== 'undefined' && typeof globalThis.process.release !== 'undefined' && globalThis.process.release.name === 'node' && !isElectron;
// @ts-ignore
// eslint-disable-next-line no-undef
const isWebWorker = typeof importScripts === 'function' && typeof self !== 'undefined' && typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope;

// defeat bundlers replacing process.env.NODE_ENV with "development" or whatever
typeof globalThis.process !== 'undefined' && typeof globalThis.process.env !== 'undefined' && globalThis.process.env['NODE' + (() => '_')() + 'ENV'] === 'test';
const isReactNative = typeof navigator !== 'undefined' && navigator.product === 'ReactNative';

const defaultValues = {
    protocolPrefix: 'ipfs',
    timeout: 5000,
    maxInboundStreams: 1,
    maxOutboundStreams: 1,
    maxObservedAddresses: 10,
    maxMessageSize: MAX_IDENTIFY_MESSAGE_SIZE,
    runOnConnectionOpen: true,
    runOnSelfUpdate: true,
    runOnTransientConnection: true,
    concurrency: MAX_PUSH_CONCURRENCY
};
/**
 * Takes the `addr` and converts it to a Multiaddr if possible
 */
function getCleanMultiaddr(addr) {
    if (addr != null && addr.length > 0) {
        try {
            return multiaddr(addr);
        }
        catch {
        }
    }
}
function getAgentVersion(nodeInfo, agentVersion) {
    if (agentVersion != null) {
        return agentVersion;
    }
    agentVersion = `${nodeInfo.name}/${nodeInfo.version}`;
    // Append user agent version to default AGENT_VERSION depending on the environment
    if (isNode || isElectronMain) {
        agentVersion += ` UserAgent=${globalThis.process.version}`;
    }
    else if (isBrowser || isWebWorker || isElectronRenderer || isReactNative) {
        agentVersion += ` UserAgent=${globalThis.navigator.userAgent}`;
    }
    return agentVersion;
}
async function consumeIdentifyMessage(peerStore, events, log, connection, message) {
    log('received identify from %p', connection.remotePeer);
    if (message == null) {
        throw new CodeError$1('message was null or undefined', 'ERR_INVALID_MESSAGE');
    }
    const peer = {};
    if (message.listenAddrs.length > 0) {
        peer.addresses = message.listenAddrs.map(buf => ({
            isCertified: false,
            multiaddr: multiaddr(buf)
        }));
    }
    if (message.protocols.length > 0) {
        peer.protocols = message.protocols;
    }
    if (message.publicKey != null) {
        peer.publicKey = message.publicKey;
        const peerId = await peerIdFromKeys(message.publicKey);
        if (!peerId.equals(connection.remotePeer)) {
            throw new CodeError$1('public key did not match remote PeerId', 'ERR_INVALID_PUBLIC_KEY');
        }
    }
    let output;
    // if the peer record has been sent, prefer the addresses in the record as they are signed by the remote peer
    if (message.signedPeerRecord != null) {
        log('received signedPeerRecord from %p', connection.remotePeer);
        let peerRecordEnvelope = message.signedPeerRecord;
        const envelope = await RecordEnvelope.openAndCertify(peerRecordEnvelope, PeerRecord.DOMAIN);
        let peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
        // Verify peerId
        if (!peerRecord.peerId.equals(envelope.peerId)) {
            throw new CodeError$1('signing key does not match PeerId in the PeerRecord', 'ERR_INVALID_SIGNING_KEY');
        }
        // Make sure remote peer is the one sending the record
        if (!connection.remotePeer.equals(peerRecord.peerId)) {
            throw new CodeError$1('signing key does not match remote PeerId', 'ERR_INVALID_PEER_RECORD_KEY');
        }
        let existingPeer;
        try {
            existingPeer = await peerStore.get(peerRecord.peerId);
        }
        catch (err) {
            if (err.code !== 'ERR_NOT_FOUND') {
                throw err;
            }
        }
        if (existingPeer != null) {
            // don't lose any existing metadata
            peer.metadata = existingPeer.metadata;
            // if we have previously received a signed record for this peer, compare it to the incoming one
            if (existingPeer.peerRecordEnvelope != null) {
                const storedEnvelope = await RecordEnvelope.createFromProtobuf(existingPeer.peerRecordEnvelope);
                const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
                // ensure seq is greater than, or equal to, the last received
                if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                    log('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                    peerRecord = storedRecord;
                    peerRecordEnvelope = existingPeer.peerRecordEnvelope;
                }
            }
        }
        // store the signed record for next time
        peer.peerRecordEnvelope = peerRecordEnvelope;
        // override the stored addresses with the signed multiaddrs
        peer.addresses = peerRecord.multiaddrs.map(multiaddr => ({
            isCertified: true,
            multiaddr
        }));
        output = {
            seq: peerRecord.seqNumber,
            addresses: peerRecord.multiaddrs
        };
    }
    else {
        log('%p did not send a signed peer record', connection.remotePeer);
    }
    log('patching %p with', connection.remotePeer, peer);
    await peerStore.patch(connection.remotePeer, peer);
    if (message.agentVersion != null || message.protocolVersion != null) {
        const metadata = {};
        if (message.agentVersion != null) {
            metadata.AgentVersion = fromString(message.agentVersion);
        }
        if (message.protocolVersion != null) {
            metadata.ProtocolVersion = fromString(message.protocolVersion);
        }
        log('merging %p metadata', connection.remotePeer, metadata);
        await peerStore.merge(connection.remotePeer, {
            metadata
        });
    }
    const result = {
        peerId: connection.remotePeer,
        protocolVersion: message.protocolVersion,
        agentVersion: message.agentVersion,
        publicKey: message.publicKey,
        listenAddrs: message.listenAddrs.map(buf => multiaddr(buf)),
        observedAddr: message.observedAddr == null ? undefined : multiaddr(message.observedAddr),
        protocols: message.protocols,
        signedPeerRecord: output,
        connection
    };
    events.safeDispatchEvent('peer:identify', { detail: result });
    return result;
}
class AbstractIdentify {
    host;
    protocol;
    started;
    timeout;
    peerId;
    peerStore;
    registrar;
    addressManager;
    maxInboundStreams;
    maxOutboundStreams;
    maxMessageSize;
    maxObservedAddresses;
    events;
    runOnTransientConnection;
    log;
    constructor(components, init) {
        this.protocol = init.protocol;
        this.started = false;
        this.peerId = components.peerId;
        this.peerStore = components.peerStore;
        this.registrar = components.registrar;
        this.addressManager = components.addressManager;
        this.events = components.events;
        this.log = init.log;
        this.timeout = init.timeout ?? defaultValues.timeout;
        this.maxInboundStreams = init.maxInboundStreams ?? defaultValues.maxInboundStreams;
        this.maxOutboundStreams = init.maxOutboundStreams ?? defaultValues.maxOutboundStreams;
        this.maxMessageSize = init.maxMessageSize ?? defaultValues.maxMessageSize;
        this.maxObservedAddresses = init.maxObservedAddresses ?? defaultValues.maxObservedAddresses;
        this.runOnTransientConnection = init.runOnTransientConnection ?? defaultValues.runOnTransientConnection;
        // Store self host metadata
        this.host = {
            protocolVersion: `${init.protocolPrefix ?? defaultValues.protocolPrefix}/${IDENTIFY_PROTOCOL_VERSION}`,
            agentVersion: getAgentVersion(components.nodeInfo, init.agentVersion)
        };
    }
    isStarted() {
        return this.started;
    }
    async start() {
        if (this.started) {
            return;
        }
        await this.peerStore.merge(this.peerId, {
            metadata: {
                AgentVersion: fromString(this.host.agentVersion),
                ProtocolVersion: fromString(this.host.protocolVersion)
            }
        });
        await this.registrar.handle(this.protocol, (data) => {
            void this.handleProtocol(data).catch(err => {
                this.log.error(err);
            });
        }, {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams,
            runOnTransientConnection: this.runOnTransientConnection
        });
        this.started = true;
    }
    async stop() {
        await this.registrar.unhandle(this.protocol);
        this.started = false;
    }
}

/**
 * @packageDocumentation
 *
 * This module exports various matchers that can be used to infer the type of a
 * passed multiaddr.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS } from '@multiformats/multiaddr-matcher'
 *
 * const ma = multiaddr('/dnsaddr/example.org')
 *
 * DNS.matches(ma) // true - this is a multiaddr with a DNS address at the start
 * ```
 *
 * @example
 *
 * The default matching behaviour ignores any subsequent tuples in the multiaddr.
 * If you want stricter matching you can use `.exactMatch`:
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS, Circuit } from '@multiformats/multiaddr-matcher'
 *
 * const ma = multiaddr('/dnsaddr/example.org/p2p/QmFoo/p2p-circuit/p2p/QmBar')
 *
 * DNS.exactMatch(ma) // false - this address has extra tuples after the DNS component
 * Circuit.matches(ma) // true
 * Circuit.exactMatch(ma) // true - the extra tuples are circuit relay related
 * ```
 */
/**
 * Split a multiaddr into path components
 */
const toParts = (ma) => {
    return ma.toString().split('/').slice(1);
};
const func = (fn) => {
    return {
        match: (vals) => {
            if (vals.length < 1) {
                return false;
            }
            if (fn(vals[0])) {
                return vals.slice(1);
            }
            return false;
        },
        pattern: 'fn'
    };
};
const literal = (str) => {
    return {
        match: (vals) => func((val) => val === str).match(vals),
        pattern: str
    };
};
const string$1 = () => {
    return {
        match: (vals) => func((val) => typeof val === 'string').match(vals),
        pattern: '{string}'
    };
};
const number = () => {
    return {
        match: (vals) => func((val) => !isNaN(parseInt(val))).match(vals),
        pattern: '{number}'
    };
};
const peerId = () => {
    return {
        match: (vals) => {
            if (vals.length < 2) {
                return false;
            }
            if (vals[0] !== 'p2p' && vals[0] !== 'ipfs') {
                return false;
            }
            // Q is RSA, 1 is Ed25519 or Secp256k1
            if (vals[1].startsWith('Q') || vals[1].startsWith('1')) {
                try {
                    base58btc.decode(`z${vals[1]}`);
                }
                catch (err) {
                    return false;
                }
            }
            else {
                return false;
            }
            return vals.slice(2);
        },
        pattern: '/p2p/{peerid}'
    };
};
const certhash = () => {
    return {
        match: (vals) => {
            if (vals.length < 2) {
                return false;
            }
            if (vals[0] !== 'certhash') {
                return false;
            }
            try {
                base64url.decode(vals[1]);
            }
            catch {
                return false;
            }
            return vals.slice(2);
        },
        pattern: '/certhash/{certhash}'
    };
};
const optional = (matcher) => {
    return {
        match: (vals) => {
            const result = matcher.match(vals);
            if (result === false) {
                return vals;
            }
            return result;
        },
        pattern: `optional(${matcher.pattern})`
    };
};
const or = (...matchers) => {
    return {
        match: (vals) => {
            let matches;
            for (const matcher of matchers) {
                const result = matcher.match(vals);
                // no match
                if (result === false) {
                    continue;
                }
                // choose greediest matcher
                if (matches == null || result.length < matches.length) {
                    matches = result;
                }
            }
            if (matches == null) {
                return false;
            }
            return matches;
        },
        pattern: `or(${matchers.map(m => m.pattern).join(', ')})`
    };
};
const and = (...matchers) => {
    return {
        match: (vals) => {
            for (const matcher of matchers) {
                // pass what's left of the array
                const result = matcher.match(vals);
                // no match
                if (result === false) {
                    return false;
                }
                vals = result;
            }
            return vals;
        },
        pattern: `and(${matchers.map(m => m.pattern).join(', ')})`
    };
};
function fmt(...matchers) {
    function match(ma) {
        let parts = toParts(ma);
        for (const matcher of matchers) {
            const result = matcher.match(parts);
            if (result === false) {
                return false;
            }
            parts = result;
        }
        return parts;
    }
    function matches(ma) {
        const result = match(ma);
        return result !== false;
    }
    function exactMatch(ma) {
        const result = match(ma);
        if (result === false) {
            return false;
        }
        return result.length === 0;
    }
    return {
        matches,
        exactMatch
    };
}
/**
 * DNS matchers
 */
const _DNS4 = and(literal('dns4'), string$1());
const _DNS6 = and(literal('dns6'), string$1());
const _DNSADDR = and(literal('dnsaddr'), string$1());
const _DNS = and(literal('dns'), string$1());
/**
 * Matches dns4 addresses.
 *
 * Use {@link DNS DNS} instead to match any type of DNS address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS4 } from '@multiformats/multiaddr-matcher'
 *
 * DNS4.matches(multiaddr('/dns4/example.org')) // true
 * ```
 */
fmt(_DNS4, optional(peerId()));
/**
 * Matches dns6 addresses.
 *
 * Use {@link DNS DNS} instead to match any type of DNS address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS6 } from '@multiformats/multiaddr-matcher'
 *
 * DNS6.matches(multiaddr('/dns6/example.org')) // true
 * ```
 */
fmt(_DNS6, optional(peerId()));
/**
 * Matches dnsaddr addresses.
 *
 * Use {@link DNS DNS} instead to match any type of DNS address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNSADDR } from '@multiformats/multiaddr-matcher'
 *
 * DNSADDR.matches(multiaddr('/dnsaddr/example.org')) // true
 * DNSADDR.matches(multiaddr('/dnsaddr/example.org/p2p/Qmfoo')) // true
 * ```
 */
fmt(_DNSADDR, optional(peerId()));
/**
 * Matches any dns address.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { DNS } from '@multiformats/multiaddr-matcher'
 *
 * DNS.matches(multiaddr('/dnsaddr/example.org')) // true
 * DNS.matches(multiaddr('/dns4/example.org')) // true
 * DNS.matches(multiaddr('/dns6/example.org')) // true
 * DNS.matches(multiaddr('/dns6/example.org/p2p/Qmfoo')) // true
 * ```
 */
fmt(or(_DNS, _DNSADDR, _DNS4, _DNS6), optional(peerId()));
const _IP4 = and(literal('ip4'), func(isIPv4));
const _IP6 = and(literal('ip6'), func(isIPv6));
const _IP = or(_IP4, _IP6);
const _IP_OR_DOMAIN = or(_IP, _DNS, _DNS4, _DNS6, _DNSADDR);
/**
 * A matcher for addresses that start with IP or DNS tuples.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { IP_OR_DOMAIN } from '@multiformats/multiaddr-matcher'
 *
 * IP_OR_DOMAIN.matches(multiaddr('/ip4/123.123.123.123')) // true
 * IP_OR_DOMAIN.matches(multiaddr('/ip4/123.123.123.123/p2p/QmFoo')) // true
 * IP_OR_DOMAIN.matches(multiaddr('/dns/example.com/p2p/QmFoo')) // true
 * IP_OR_DOMAIN.matches(multiaddr('/p2p/QmFoo')) // false
 * ```
 */
const IP_OR_DOMAIN = fmt(or(_IP, and(or(_DNS, _DNSADDR, _DNS4, _DNS6), optional(peerId()))));
const _TCP = and(_IP_OR_DOMAIN, literal('tcp'), number());
const _UDP = and(_IP_OR_DOMAIN, literal('udp'), number());
/**
 * Matches TCP addresses.
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { TCP } from '@multiformats/multiaddr-matcher'
 *
 * TCP.matches(multiaddr('/ip4/123.123.123.123/tcp/1234')) // true
 * ```
 */
fmt(and(_TCP, optional(peerId())));
const _QUIC = and(_UDP, literal('quic'));
const _QUICV1 = and(_UDP, literal('quic-v1'));
const QUIC_V0_OR_V1 = or(_QUIC, _QUICV1);
const _WEB = or(_IP_OR_DOMAIN, _TCP, _UDP, _QUIC, _QUICV1);
const _WebSockets = or(and(_WEB, literal('ws'), optional(peerId())));
const _WebSocketsSecure = or(and(_WEB, literal('wss'), optional(peerId())), and(_WEB, literal('tls'), literal('ws'), optional(peerId())));
const _WebRTCDirect = and(_UDP, literal('webrtc-direct'), optional(certhash()), optional(certhash()), optional(peerId()));
const _WebTransport = and(_QUICV1, literal('webtransport'), optional(certhash()), optional(certhash()), optional(peerId()));
const _P2P = or(_WebSockets, _WebSocketsSecure, and(_TCP, optional(peerId())), and(QUIC_V0_OR_V1, optional(peerId())), and(_IP_OR_DOMAIN, optional(peerId())), _WebRTCDirect, _WebTransport, peerId());
const _Circuit = and(_P2P, literal('p2p-circuit'), peerId());
/**
 * Matches circuit relay addresses
 *
 * @example
 *
 * ```ts
 * import { multiaddr } from '@multiformats/multiaddr'
 * import { Circuit } from '@multiformats/multiaddr-matcher'
 *
 * Circuit.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmRelay/p2p-circuit/p2p/QmTarget')) // true
 * ```
 */
const Circuit = fmt(_Circuit);
or(and(_P2P, literal('p2p-circuit'), literal('webrtc'), optional(peerId())), and(_P2P, literal('webrtc'), optional(peerId())), literal('webrtc'));
or(and(_IP_OR_DOMAIN, literal('tcp'), number(), literal('http'), optional(peerId())), and(_IP_OR_DOMAIN, literal('http'), optional(peerId())));
or(and(_IP_OR_DOMAIN, literal('tcp'), or(and(literal('443'), literal('http')), and(number(), literal('https'))), optional(peerId())), and(_IP_OR_DOMAIN, literal('tls'), literal('http'), optional(peerId())), and(_IP_OR_DOMAIN, literal('https'), optional(peerId())));

/* eslint-disable complexity */
class Identify extends AbstractIdentify {
    constructor(components, init = {}) {
        super(components, {
            ...init,
            protocol: `/${init.protocolPrefix ?? defaultValues.protocolPrefix}/${MULTICODEC_IDENTIFY_PROTOCOL_NAME}/${MULTICODEC_IDENTIFY_PROTOCOL_VERSION}`,
            log: components.logger.forComponent('libp2p:identify')
        });
        if (init.runOnConnectionOpen ?? defaultValues.runOnConnectionOpen) {
            // When a new connection happens, trigger identify
            components.events.addEventListener('connection:open', (evt) => {
                const connection = evt.detail;
                this.identify(connection).catch(err => { this.log.error('error during identify trigged by connection:open', err); });
            });
        }
    }
    [serviceCapabilities] = [
        '@libp2p/identify'
    ];
    async _identify(connection, options = {}) {
        let stream;
        if (options.signal == null) {
            const signal = AbortSignal.timeout(this.timeout);
            setMaxListeners(Infinity, signal);
            options = {
                ...options,
                signal
            };
        }
        try {
            stream = await connection.newStream(this.protocol, {
                ...options,
                runOnTransientConnection: this.runOnTransientConnection
            });
            const pb = pbStream(stream, {
                maxDataLength: this.maxMessageSize
            }).pb(Identify$1);
            const message = await pb.read(options);
            await stream.close(options);
            return message;
        }
        catch (err) {
            this.log.error('error while reading identify message', err);
            stream?.abort(err);
            throw err;
        }
    }
    async identify(connection, options = {}) {
        const message = await this._identify(connection, options);
        const { publicKey, protocols, observedAddr } = message;
        if (publicKey == null) {
            throw new CodeError$1('public key was missing from identify message', 'ERR_MISSING_PUBLIC_KEY');
        }
        const id = await peerIdFromKeys(publicKey);
        if (!connection.remotePeer.equals(id)) {
            throw new CodeError$1('identified peer does not match the expected peer', 'ERR_INVALID_PEER');
        }
        if (this.peerId.equals(id)) {
            throw new CodeError$1('identified peer is our own peer id?', 'ERR_INVALID_PEER');
        }
        // Get the observedAddr if there is one
        const cleanObservedAddr = getCleanMultiaddr(observedAddr);
        this.log('identify completed for peer %p and protocols %o', id, protocols);
        this.log('our observed address is %a', cleanObservedAddr);
        if (cleanObservedAddr != null &&
            this.addressManager.getObservedAddrs().length < (this.maxObservedAddresses ?? Infinity)) {
            this.log('storing our observed address %a', cleanObservedAddr);
            this.addressManager.addObservedAddr(cleanObservedAddr);
        }
        return consumeIdentifyMessage(this.peerStore, this.events, this.log, connection, message);
    }
    /**
     * Sends the `Identify` response with the Signed Peer Record
     * to the requesting peer over the given `connection`
     */
    async handleProtocol(data) {
        const { connection, stream } = data;
        const signal = AbortSignal.timeout(this.timeout);
        setMaxListeners(Infinity, signal);
        try {
            const publicKey = this.peerId.publicKey ?? new Uint8Array(0);
            const peerData = await this.peerStore.get(this.peerId);
            const multiaddrs = this.addressManager.getAddresses().map(ma => ma.decapsulateCode(getProtocol('p2p').code));
            let signedPeerRecord = peerData.peerRecordEnvelope;
            if (multiaddrs.length > 0 && signedPeerRecord == null) {
                const peerRecord = new PeerRecord({
                    peerId: this.peerId,
                    multiaddrs
                });
                const envelope = await RecordEnvelope.seal(peerRecord, this.peerId);
                signedPeerRecord = envelope.marshal().subarray();
            }
            let observedAddr = connection.remoteAddr.bytes;
            if (!IP_OR_DOMAIN.matches(connection.remoteAddr)) {
                observedAddr = undefined;
            }
            const pb = pbStream(stream).pb(Identify$1);
            await pb.write({
                protocolVersion: this.host.protocolVersion,
                agentVersion: this.host.agentVersion,
                publicKey,
                listenAddrs: multiaddrs.map(addr => addr.bytes),
                signedPeerRecord,
                observedAddr,
                protocols: peerData.protocols
            }, {
                signal
            });
            await stream.close({
                signal
            });
        }
        catch (err) {
            this.log.error('could not respond to identify request', err);
            stream.abort(err);
        }
    }
}

/**
 * @packageDocumentation
 *
 * Use the `identify` function to add support for the [Identify protocol](https://github.com/libp2p/specs/blob/master/identify/README.md) to libp2p.
 *
 * This protocol allows network peers to discover the multiaddrs the current node listens on, and the protocols it supports.
 *
 * A second function, `identifyPush` is also exported to add support for [identify/push](https://github.com/libp2p/specs/blob/master/identify/README.md#identifypush).
 *
 * This protocol will send updates to all connected peers when the multiaddrs or protocols of the current node change.
 *
 * > [!TIP]
 * > For maximum network compatibility you should configure both protocols
 *
 * @example Enabling identify
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 * import { identify } from '@libp2p/identify'
 *
 * const node = await createLibp2p({
 *   // ...other options
 *   services: {
 *     identify: identify()
 *   }
 * })
 * ```
 *
 * @example Enabling identify push
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 * import { identifyPush } from '@libp2p/identify'
 *
 * const node = await createLibp2p({
 *   // ...other options
 *   services: {
 *     identifyPush: identifyPush()
 *   }
 * })
 * ```
 */
function identify(init = {}) {
    return (components) => new Identify(components, init);
}

function getIterator(obj) {
    if (obj != null) {
        if (typeof obj[Symbol.iterator] === 'function') {
            return obj[Symbol.iterator]();
        }
        if (typeof obj[Symbol.asyncIterator] === 'function') {
            return obj[Symbol.asyncIterator]();
        }
        if (typeof obj.next === 'function') {
            return obj; // probably an iterator
        }
    }
    throw new Error('argument is not an iterator or iterable');
}

function isPromise$2(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}

function closeSource(source, log) {
    const res = getIterator(source).return?.();
    if (isPromise$2(res)) {
        res.catch(err => {
            log.error('could not cause iterator to return', err);
        });
    }
}

// From https://github.com/sindresorhus/random-int/blob/c37741b56f76b9160b0b63dae4e9c64875128146/index.js#L13-L15

const createAbortError = () => {
	const error = new Error('Delay aborted');
	error.name = 'AbortError';
	return error;
};

const clearMethods = new WeakMap();

function createDelay({clearTimeout: defaultClear, setTimeout: defaultSet} = {}) {
	// We cannot use `async` here as we need the promise identity.
	return (milliseconds, {value, signal} = {}) => {
		// TODO: Use `signal?.throwIfAborted()` when targeting Node.js 18.
		if (signal?.aborted) {
			return Promise.reject(createAbortError());
		}

		let timeoutId;
		let settle;
		let rejectFunction;
		const clear = defaultClear ?? clearTimeout;

		const signalListener = () => {
			clear(timeoutId);
			rejectFunction(createAbortError());
		};

		const cleanup = () => {
			if (signal) {
				signal.removeEventListener('abort', signalListener);
			}
		};

		const delayPromise = new Promise((resolve, reject) => {
			settle = () => {
				cleanup();
				resolve(value);
			};

			rejectFunction = reject;
			timeoutId = (defaultSet ?? setTimeout)(settle, milliseconds);
		});

		if (signal) {
			signal.addEventListener('abort', signalListener, {once: true});
		}

		clearMethods.set(delayPromise, () => {
			clear(timeoutId);
			timeoutId = null;
			settle();
		});

		return delayPromise;
	};
}

const delay = createDelay();

class RateLimiter {
    memoryStorage;
    points;
    duration;
    blockDuration;
    execEvenly;
    execEvenlyMinDelayMs;
    keyPrefix;
    constructor(opts = {}) {
        this.points = opts.points ?? 4;
        this.duration = opts.duration ?? 1;
        this.blockDuration = opts.blockDuration ?? 0;
        this.execEvenly = opts.execEvenly ?? false;
        this.execEvenlyMinDelayMs = opts.execEvenlyMinDelayMs ?? (this.duration * 1000 / this.points);
        this.keyPrefix = opts.keyPrefix ?? 'rlflx';
        this.memoryStorage = new MemoryStorage();
    }
    async consume(key, pointsToConsume = 1, options = {}) {
        const rlKey = this.getKey(key);
        const secDuration = this._getKeySecDuration(options);
        let res = this.memoryStorage.incrby(rlKey, pointsToConsume, secDuration);
        res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        if (res.consumedPoints > this.points) {
            // Block only first time when consumed more than points
            if (this.blockDuration > 0 && res.consumedPoints <= (this.points + pointsToConsume)) {
                // Block key
                res = this.memoryStorage.set(rlKey, res.consumedPoints, this.blockDuration);
            }
            throw new CodeError$1('Rate limit exceeded', 'ERR_RATE_LIMIT_EXCEEDED', res);
        }
        else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
            // Execute evenly
            let delayMs = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
            if (delayMs < this.execEvenlyMinDelayMs) {
                delayMs = res.consumedPoints * this.execEvenlyMinDelayMs;
            }
            await delay(delayMs);
        }
        return res;
    }
    penalty(key, points = 1, options = {}) {
        const rlKey = this.getKey(key);
        const secDuration = this._getKeySecDuration(options);
        const res = this.memoryStorage.incrby(rlKey, points, secDuration);
        res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        return res;
    }
    reward(key, points = 1, options = {}) {
        const rlKey = this.getKey(key);
        const secDuration = this._getKeySecDuration(options);
        const res = this.memoryStorage.incrby(rlKey, -points, secDuration);
        res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        return res;
    }
    /**
     * Block any key for secDuration seconds
     *
     * @param key
     * @param secDuration
     */
    block(key, secDuration) {
        const msDuration = secDuration * 1000;
        const initPoints = this.points + 1;
        this.memoryStorage.set(this.getKey(key), initPoints, secDuration);
        return {
            remainingPoints: 0,
            msBeforeNext: msDuration === 0 ? -1 : msDuration,
            consumedPoints: initPoints,
            isFirstInDuration: false
        };
    }
    set(key, points, secDuration = 0) {
        const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;
        this.memoryStorage.set(this.getKey(key), points, secDuration);
        return {
            remainingPoints: 0,
            msBeforeNext: msDuration === 0 ? -1 : msDuration,
            consumedPoints: points,
            isFirstInDuration: false
        };
    }
    get(key) {
        const res = this.memoryStorage.get(this.getKey(key));
        if (res != null) {
            res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
        }
        return res;
    }
    delete(key) {
        this.memoryStorage.delete(this.getKey(key));
    }
    _getKeySecDuration(options) {
        if (options?.customDuration != null && options.customDuration >= 0) {
            return options.customDuration;
        }
        return this.duration;
    }
    getKey(key) {
        return this.keyPrefix.length > 0 ? `${this.keyPrefix}:${key}` : key;
    }
    parseKey(rlKey) {
        return rlKey.substring(this.keyPrefix.length);
    }
}
class MemoryStorage {
    storage;
    constructor() {
        this.storage = new Map();
    }
    incrby(key, value, durationSec) {
        const existing = this.storage.get(key);
        if (existing != null) {
            const msBeforeExpires = existing.expiresAt != null
                ? existing.expiresAt.getTime() - new Date().getTime()
                : -1;
            if (existing.expiresAt == null || msBeforeExpires > 0) {
                // Change value
                existing.value += value;
                return {
                    remainingPoints: 0,
                    msBeforeNext: msBeforeExpires,
                    consumedPoints: existing.value,
                    isFirstInDuration: false
                };
            }
            return this.set(key, value, durationSec);
        }
        return this.set(key, value, durationSec);
    }
    set(key, value, durationSec) {
        const durationMs = durationSec * 1000;
        const existing = this.storage.get(key);
        if (existing != null) {
            clearTimeout(existing.timeoutId);
        }
        const record = {
            value,
            expiresAt: durationMs > 0 ? new Date(Date.now() + durationMs) : undefined
        };
        this.storage.set(key, record);
        if (durationMs > 0) {
            record.timeoutId = setTimeout(() => {
                this.storage.delete(key);
            }, durationMs);
            if (record.timeoutId.unref != null) {
                record.timeoutId.unref();
            }
        }
        return {
            remainingPoints: 0,
            msBeforeNext: durationMs === 0 ? -1 : durationMs,
            consumedPoints: record.value,
            isFirstInDuration: true
        };
    }
    get(key) {
        const existing = this.storage.get(key);
        if (existing != null) {
            const msBeforeExpires = existing.expiresAt != null
                ? existing.expiresAt.getTime() - new Date().getTime()
                : -1;
            return {
                remainingPoints: 0,
                msBeforeNext: msBeforeExpires,
                consumedPoints: existing.value,
                isFirstInDuration: false
            };
        }
    }
    delete(key) {
        const record = this.storage.get(key);
        if (record != null) {
            if (record.timeoutId != null) {
                clearTimeout(record.timeoutId);
            }
            this.storage.delete(key);
            return true;
        }
        return false;
    }
}

var MessageTypes;
(function (MessageTypes) {
    MessageTypes[MessageTypes["NEW_STREAM"] = 0] = "NEW_STREAM";
    MessageTypes[MessageTypes["MESSAGE_RECEIVER"] = 1] = "MESSAGE_RECEIVER";
    MessageTypes[MessageTypes["MESSAGE_INITIATOR"] = 2] = "MESSAGE_INITIATOR";
    MessageTypes[MessageTypes["CLOSE_RECEIVER"] = 3] = "CLOSE_RECEIVER";
    MessageTypes[MessageTypes["CLOSE_INITIATOR"] = 4] = "CLOSE_INITIATOR";
    MessageTypes[MessageTypes["RESET_RECEIVER"] = 5] = "RESET_RECEIVER";
    MessageTypes[MessageTypes["RESET_INITIATOR"] = 6] = "RESET_INITIATOR";
})(MessageTypes || (MessageTypes = {}));
const MessageTypeNames = Object.freeze({
    0: 'NEW_STREAM',
    1: 'MESSAGE_RECEIVER',
    2: 'MESSAGE_INITIATOR',
    3: 'CLOSE_RECEIVER',
    4: 'CLOSE_INITIATOR',
    5: 'RESET_RECEIVER',
    6: 'RESET_INITIATOR'
});
const InitiatorMessageTypes = Object.freeze({
    NEW_STREAM: MessageTypes.NEW_STREAM,
    MESSAGE: MessageTypes.MESSAGE_INITIATOR,
    CLOSE: MessageTypes.CLOSE_INITIATOR,
    RESET: MessageTypes.RESET_INITIATOR
});
const ReceiverMessageTypes = Object.freeze({
    MESSAGE: MessageTypes.MESSAGE_RECEIVER,
    CLOSE: MessageTypes.CLOSE_RECEIVER,
    RESET: MessageTypes.RESET_RECEIVER
});

const MAX_MSG_SIZE = 1 << 20; // 1MB
const MAX_MSG_QUEUE_SIZE = 4 << 20; // 4MB
class Decoder {
    _buffer;
    _headerInfo;
    _maxMessageSize;
    _maxUnprocessedMessageQueueSize;
    constructor(maxMessageSize = MAX_MSG_SIZE, maxUnprocessedMessageQueueSize = MAX_MSG_QUEUE_SIZE) {
        this._buffer = new Uint8ArrayList();
        this._headerInfo = null;
        this._maxMessageSize = maxMessageSize;
        this._maxUnprocessedMessageQueueSize = maxUnprocessedMessageQueueSize;
    }
    write(chunk) {
        if (chunk == null || chunk.length === 0) {
            return [];
        }
        this._buffer.append(chunk);
        if (this._buffer.byteLength > this._maxUnprocessedMessageQueueSize) {
            throw Object.assign(new Error('unprocessed message queue size too large!'), { code: 'ERR_MSG_QUEUE_TOO_BIG' });
        }
        const msgs = [];
        while (this._buffer.length !== 0) {
            if (this._headerInfo == null) {
                try {
                    this._headerInfo = this._decodeHeader(this._buffer);
                }
                catch (err) {
                    if (err.code === 'ERR_MSG_TOO_BIG') {
                        throw err;
                    }
                    break; // We haven't received enough data yet
                }
            }
            const { id, type, length, offset } = this._headerInfo;
            const bufferedDataLength = this._buffer.length - offset;
            if (bufferedDataLength < length) {
                break; // not enough data yet
            }
            const msg = {
                id,
                type
            };
            if (type === MessageTypes.NEW_STREAM || type === MessageTypes.MESSAGE_INITIATOR || type === MessageTypes.MESSAGE_RECEIVER) {
                msg.data = this._buffer.sublist(offset, offset + length);
            }
            msgs.push(msg);
            this._buffer.consume(offset + length);
            this._headerInfo = null;
        }
        return msgs;
    }
    /**
     * Attempts to decode the message header from the buffer
     */
    _decodeHeader(data) {
        const { value: h, offset } = readVarInt(data);
        const { value: length, offset: end } = readVarInt(data, offset);
        const type = h & 7;
        // @ts-expect-error h is a number not a CODE
        if (MessageTypeNames[type] == null) {
            throw new Error(`Invalid type received: ${type}`);
        }
        // test message type varint + data length
        if (length > this._maxMessageSize) {
            throw Object.assign(new Error('message size too large!'), { code: 'ERR_MSG_TOO_BIG' });
        }
        // @ts-expect-error h is a number not a CODE
        return { id: h >> 3, type, offset: offset + end, length };
    }
}
const MSB = 0x80;
const REST = 0x7F;
function readVarInt(buf, offset = 0) {
    let res = 0;
    let shift = 0;
    let counter = offset;
    let b;
    const l = buf.length;
    do {
        if (counter >= l || shift > 49) {
            offset = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf.get(counter++);
        res += shift < 28
            ? (b & REST) << shift
            : (b & REST) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB);
    offset = counter - offset;
    return {
        value: res,
        offset
    };
}

const POOL_SIZE = 10 * 1024;
class Encoder {
    _pool;
    _poolOffset;
    constructor() {
        this._pool = allocUnsafe(POOL_SIZE);
        this._poolOffset = 0;
    }
    /**
     * Encodes the given message and adds it to the passed list
     */
    write(msg, list) {
        const pool = this._pool;
        let offset = this._poolOffset;
        encode$a(msg.id << 3 | msg.type, pool, offset);
        offset += encodingLength$3(msg.id << 3 | msg.type);
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            encode$a(msg.data.length, pool, offset);
            offset += encodingLength$3(msg.data.length);
        }
        else {
            encode$a(0, pool, offset);
            offset += encodingLength$3(0);
        }
        const header = pool.subarray(this._poolOffset, offset);
        if (POOL_SIZE - offset < 100) {
            this._pool = allocUnsafe(POOL_SIZE);
            this._poolOffset = 0;
        }
        else {
            this._poolOffset = offset;
        }
        list.append(header);
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            list.append(msg.data);
        }
    }
}
const encoder = new Encoder();
/**
 * Encode and yield one or more messages
 */
async function* encode$4(source) {
    for await (const message of source) {
        const list = new Uint8ArrayList();
        encoder.write(message, list);
        yield list;
    }
}

const ERR_STREAM_RESET = 'ERR_STREAM_RESET';
const ERR_SINK_INVALID_STATE = 'ERR_SINK_INVALID_STATE';
const DEFAULT_SEND_CLOSE_WRITE_TIMEOUT = 5000;
function isPromise$1(thing) {
    if (thing == null) {
        return false;
    }
    return typeof thing.then === 'function' &&
        typeof thing.catch === 'function' &&
        typeof thing.finally === 'function';
}
class AbstractStream {
    id;
    direction;
    timeline;
    protocol;
    metadata;
    source;
    status;
    readStatus;
    writeStatus;
    log;
    sinkController;
    sinkEnd;
    closed;
    endErr;
    streamSource;
    onEnd;
    onCloseRead;
    onCloseWrite;
    onReset;
    onAbort;
    sendCloseWriteTimeout;
    sendingData;
    constructor(init) {
        this.sinkController = new AbortController();
        this.sinkEnd = pDefer();
        this.closed = pDefer();
        this.log = init.log;
        // stream status
        this.status = 'open';
        this.readStatus = 'ready';
        this.writeStatus = 'ready';
        this.id = init.id;
        this.metadata = init.metadata ?? {};
        this.direction = init.direction;
        this.timeline = {
            open: Date.now()
        };
        this.sendCloseWriteTimeout = init.sendCloseWriteTimeout ?? DEFAULT_SEND_CLOSE_WRITE_TIMEOUT;
        this.onEnd = init.onEnd;
        this.onCloseRead = init?.onCloseRead;
        this.onCloseWrite = init?.onCloseWrite;
        this.onReset = init?.onReset;
        this.onAbort = init?.onAbort;
        this.source = this.streamSource = pushable({
            onEnd: (err) => {
                if (err != null) {
                    this.log.trace('source ended with error', err);
                }
                else {
                    this.log.trace('source ended');
                }
                this.onSourceEnd(err);
            }
        });
        // necessary because the libp2p upgrader wraps the sink function
        this.sink = this.sink.bind(this);
    }
    async sink(source) {
        if (this.writeStatus !== 'ready') {
            throw new CodeError$1(`writable end state is "${this.writeStatus}" not "ready"`, ERR_SINK_INVALID_STATE);
        }
        try {
            this.writeStatus = 'writing';
            const options = {
                signal: this.sinkController.signal
            };
            if (this.direction === 'outbound') { // If initiator, open a new stream
                const res = this.sendNewStream(options);
                if (isPromise$1(res)) {
                    await res;
                }
            }
            const abortListener = () => {
                closeSource(source, this.log);
            };
            try {
                this.sinkController.signal.addEventListener('abort', abortListener);
                this.log.trace('sink reading from source');
                for await (let data of source) {
                    data = data instanceof Uint8Array ? new Uint8ArrayList(data) : data;
                    const res = this.sendData(data, options);
                    if (isPromise$1(res)) {
                        this.sendingData = pDefer();
                        await res;
                        this.sendingData.resolve();
                        this.sendingData = undefined;
                    }
                }
            }
            finally {
                this.sinkController.signal.removeEventListener('abort', abortListener);
            }
            this.log.trace('sink finished reading from source, write status is "%s"', this.writeStatus);
            if (this.writeStatus === 'writing') {
                this.writeStatus = 'closing';
                this.log.trace('send close write to remote');
                await this.sendCloseWrite({
                    signal: AbortSignal.timeout(this.sendCloseWriteTimeout)
                });
                this.writeStatus = 'closed';
            }
            this.onSinkEnd();
        }
        catch (err) {
            this.log.trace('sink ended with error, calling abort with error', err);
            this.abort(err);
            throw err;
        }
        finally {
            this.log.trace('resolve sink end');
            this.sinkEnd.resolve();
        }
    }
    onSourceEnd(err) {
        if (this.timeline.closeRead != null) {
            return;
        }
        this.timeline.closeRead = Date.now();
        this.readStatus = 'closed';
        if (err != null && this.endErr == null) {
            this.endErr = err;
        }
        this.onCloseRead?.();
        if (this.timeline.closeWrite != null) {
            this.log.trace('source and sink ended');
            this.timeline.close = Date.now();
            if (this.status !== 'aborted' && this.status !== 'reset') {
                this.status = 'closed';
            }
            if (this.onEnd != null) {
                this.onEnd(this.endErr);
            }
            this.closed.resolve();
        }
        else {
            this.log.trace('source ended, waiting for sink to end');
        }
    }
    onSinkEnd(err) {
        if (this.timeline.closeWrite != null) {
            return;
        }
        this.timeline.closeWrite = Date.now();
        this.writeStatus = 'closed';
        if (err != null && this.endErr == null) {
            this.endErr = err;
        }
        this.onCloseWrite?.();
        if (this.timeline.closeRead != null) {
            this.log.trace('sink and source ended');
            this.timeline.close = Date.now();
            if (this.status !== 'aborted' && this.status !== 'reset') {
                this.status = 'closed';
            }
            if (this.onEnd != null) {
                this.onEnd(this.endErr);
            }
            this.closed.resolve();
        }
        else {
            this.log.trace('sink ended, waiting for source to end');
        }
    }
    // Close for both Reading and Writing
    async close(options) {
        this.log.trace('closing gracefully');
        this.status = 'closing';
        // wait for read and write ends to close
        await raceSignal(Promise.all([
            this.closeWrite(options),
            this.closeRead(options),
            this.closed.promise
        ]), options?.signal);
        this.status = 'closed';
        this.log.trace('closed gracefully');
    }
    async closeRead(options = {}) {
        if (this.readStatus === 'closing' || this.readStatus === 'closed') {
            return;
        }
        this.log.trace('closing readable end of stream with starting read status "%s"', this.readStatus);
        const readStatus = this.readStatus;
        this.readStatus = 'closing';
        if (this.status !== 'reset' && this.status !== 'aborted' && this.timeline.closeRead == null) {
            this.log.trace('send close read to remote');
            await this.sendCloseRead(options);
        }
        if (readStatus === 'ready') {
            this.log.trace('ending internal source queue with %d queued bytes', this.streamSource.readableLength);
            this.streamSource.end();
        }
        this.log.trace('closed readable end of stream');
    }
    async closeWrite(options = {}) {
        if (this.writeStatus === 'closing' || this.writeStatus === 'closed') {
            return;
        }
        this.log.trace('closing writable end of stream with starting write status "%s"', this.writeStatus);
        if (this.writeStatus === 'ready') {
            this.log.trace('sink was never sunk, sink an empty array');
            await raceSignal(this.sink([]), options.signal);
        }
        if (this.writeStatus === 'writing') {
            // try to let sending outgoing data succeed
            if (this.sendingData != null) {
                await raceSignal(this.sendingData.promise, options.signal);
            }
            // stop reading from the source passed to `.sink`
            this.log.trace('aborting source passed to .sink');
            this.sinkController.abort();
            await raceSignal(this.sinkEnd.promise, options.signal);
        }
        this.writeStatus = 'closed';
        this.log.trace('closed writable end of stream');
    }
    /**
     * Close immediately for reading and writing and send a reset message (local
     * error)
     */
    abort(err) {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            return;
        }
        this.log('abort with error', err);
        // try to send a reset message
        this.log('try to send reset to remote');
        const res = this.sendReset();
        if (isPromise$1(res)) {
            res.catch((err) => {
                this.log.error('error sending reset message', err);
            });
        }
        this.status = 'aborted';
        this.timeline.abort = Date.now();
        this._closeSinkAndSource(err);
        this.onAbort?.(err);
    }
    /**
     * Receive a reset message - close immediately for reading and writing (remote
     * error)
     */
    reset() {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            return;
        }
        const err = new CodeError$1('stream reset', ERR_STREAM_RESET);
        this.status = 'reset';
        this.timeline.reset = Date.now();
        this._closeSinkAndSource(err);
        this.onReset?.();
    }
    _closeSinkAndSource(err) {
        this._closeSink(err);
        this._closeSource(err);
    }
    _closeSink(err) {
        // if the sink function is running, cause it to end
        if (this.writeStatus === 'writing') {
            this.log.trace('end sink source');
            this.sinkController.abort();
        }
        this.onSinkEnd(err);
    }
    _closeSource(err) {
        // if the source is not ending, end it
        if (this.readStatus !== 'closing' && this.readStatus !== 'closed') {
            this.log.trace('ending source with %d bytes to be read by consumer', this.streamSource.readableLength);
            this.readStatus = 'closing';
            this.streamSource.end(err);
        }
    }
    /**
     * The remote closed for writing so we should expect to receive no more
     * messages
     */
    remoteCloseWrite() {
        if (this.readStatus === 'closing' || this.readStatus === 'closed') {
            this.log('received remote close write but local source is already closed');
            return;
        }
        this.log.trace('remote close write');
        this._closeSource();
    }
    /**
     * The remote closed for reading so we should not send any more
     * messages
     */
    remoteCloseRead() {
        if (this.writeStatus === 'closing' || this.writeStatus === 'closed') {
            this.log('received remote close read but local sink is already closed');
            return;
        }
        this.log.trace('remote close read');
        this._closeSink();
    }
    /**
     * The underlying muxer has closed, no more messages can be sent or will
     * be received, close immediately to free up resources
     */
    destroy() {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            this.log('received destroy but we are already closed');
            return;
        }
        this.log.trace('stream destroyed');
        this._closeSinkAndSource();
    }
    /**
     * When an extending class reads data from it's implementation-specific source,
     * call this method to allow the stream consumer to read the data.
     */
    sourcePush(data) {
        this.streamSource.push(data);
    }
    /**
     * Returns the amount of unread data - can be used to prevent large amounts of
     * data building up when the stream consumer is too slow.
     */
    sourceReadableLength() {
        return this.streamSource.readableLength;
    }
}

class MplexStream extends AbstractStream {
    name;
    streamId;
    send;
    types;
    maxDataSize;
    constructor(init) {
        super(init);
        this.types = init.direction === 'outbound' ? InitiatorMessageTypes : ReceiverMessageTypes;
        this.send = init.send;
        this.name = init.name;
        this.streamId = init.streamId;
        this.maxDataSize = init.maxDataSize;
    }
    async sendNewStream() {
        await this.send({ id: this.streamId, type: InitiatorMessageTypes.NEW_STREAM, data: new Uint8ArrayList(fromString(this.name)) });
    }
    async sendData(data) {
        data = data.sublist();
        while (data.byteLength > 0) {
            const toSend = Math.min(data.byteLength, this.maxDataSize);
            await this.send({
                id: this.streamId,
                type: this.types.MESSAGE,
                data: data.sublist(0, toSend)
            });
            data.consume(toSend);
        }
    }
    async sendReset() {
        await this.send({ id: this.streamId, type: this.types.RESET });
    }
    async sendCloseWrite() {
        await this.send({ id: this.streamId, type: this.types.CLOSE });
    }
    async sendCloseRead() {
        // mplex does not support close read, only close write
    }
}
function createStream(options) {
    const { id, name, send, onEnd, type = 'initiator', maxMsgSize = MAX_MSG_SIZE } = options;
    return new MplexStream({
        id: type === 'initiator' ? (`i${id}`) : `r${id}`,
        streamId: id,
        name: `${name ?? id}`,
        direction: type === 'initiator' ? 'outbound' : 'inbound',
        maxDataSize: maxMsgSize,
        onEnd,
        send,
        log: options.logger.forComponent(`libp2p:mplex:stream:${type}:${id}`)
    });
}

const MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAM_BUFFER_SIZE = 1024 * 1024 * 4; // 4MB
const DISCONNECT_THRESHOLD = 5;
const CLOSE_TIMEOUT$2 = 500;
function printMessage(msg) {
    const output = {
        ...msg,
        type: `${MessageTypeNames[msg.type]} (${msg.type})`
    };
    if (msg.type === MessageTypes.NEW_STREAM) {
        output.data = toString$6(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray());
    }
    if (msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) {
        output.data = toString$6(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray(), 'base16');
    }
    return output;
}
class MplexStreamMuxer {
    protocol = '/mplex/6.7.0';
    sink;
    source;
    log;
    _streamId;
    _streams;
    _init;
    _source;
    closeController;
    rateLimiter;
    closeTimeout;
    logger;
    constructor(components, init) {
        init = init ?? {};
        this.log = components.logger.forComponent('libp2p:mplex');
        this.logger = components.logger;
        this._streamId = 0;
        this._streams = {
            /**
             * Stream to ids map
             */
            initiators: new Map(),
            /**
             * Stream to ids map
             */
            receivers: new Map()
        };
        this._init = init;
        this.closeTimeout = init.closeTimeout ?? CLOSE_TIMEOUT$2;
        /**
         * An iterable sink
         */
        this.sink = this._createSink();
        /**
         * An iterable source
         */
        this._source = pushable({
            objectMode: true,
            onEnd: () => {
                // the source has ended, we can't write any more messages to gracefully
                // close streams so all we can do is destroy them
                for (const stream of this._streams.initiators.values()) {
                    stream.destroy();
                }
                for (const stream of this._streams.receivers.values()) {
                    stream.destroy();
                }
            }
        });
        this.source = pipe(this._source, source => encode$4(source));
        /**
         * Close controller
         */
        this.closeController = new AbortController();
        this.rateLimiter = new RateLimiter({
            points: init.disconnectThreshold ?? DISCONNECT_THRESHOLD,
            duration: 1
        });
    }
    /**
     * Returns a Map of streams and their ids
     */
    get streams() {
        // Inbound and Outbound streams may have the same ids, so we need to make those unique
        const streams = [];
        for (const stream of this._streams.initiators.values()) {
            streams.push(stream);
        }
        for (const stream of this._streams.receivers.values()) {
            streams.push(stream);
        }
        return streams;
    }
    /**
     * Initiate a new stream with the given name. If no name is
     * provided, the id of the stream will be used.
     */
    newStream(name) {
        if (this.closeController.signal.aborted) {
            throw new Error('Muxer already closed');
        }
        const id = this._streamId++;
        name = name == null ? id.toString() : name.toString();
        const registry = this._streams.initiators;
        return this._newStream({ id, name, type: 'initiator', registry });
    }
    /**
     * Close or abort all tracked streams and stop the muxer
     */
    async close(options) {
        if (this.closeController.signal.aborted) {
            return;
        }
        const signal = options?.signal ?? AbortSignal.timeout(this.closeTimeout);
        try {
            // try to gracefully close all streams
            await Promise.all(this.streams.map(async (s) => s.close({
                signal
            })));
            this._source.end();
            // try to gracefully close the muxer
            await this._source.onEmpty({
                signal
            });
            this.closeController.abort();
        }
        catch (err) {
            this.abort(err);
        }
    }
    abort(err) {
        if (this.closeController.signal.aborted) {
            return;
        }
        this.streams.forEach(s => { s.abort(err); });
        this.closeController.abort(err);
    }
    /**
     * Called whenever an inbound stream is created
     */
    _newReceiverStream(options) {
        const { id, name } = options;
        const registry = this._streams.receivers;
        return this._newStream({ id, name, type: 'receiver', registry });
    }
    _newStream(options) {
        const { id, name, type, registry } = options;
        this.log('new %s stream %s', type, id);
        if (type === 'initiator' && this._streams.initiators.size === (this._init.maxOutboundStreams ?? MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION)) {
            throw new CodeError$1('Too many outbound streams open', 'ERR_TOO_MANY_OUTBOUND_STREAMS');
        }
        if (registry.has(id)) {
            throw new Error(`${type} stream ${id} already exists!`);
        }
        const send = async (msg) => {
            if (this.log.enabled) {
                this.log.trace('%s stream %s send', type, id, printMessage(msg));
            }
            this._source.push(msg);
        };
        const onEnd = () => {
            this.log('%s stream with id %s and protocol %s ended', type, id, stream.protocol);
            registry.delete(id);
            if (this._init.onStreamEnd != null) {
                this._init.onStreamEnd(stream);
            }
        };
        const stream = createStream({ id, name, send, type, onEnd, maxMsgSize: this._init.maxMsgSize, logger: this.logger });
        registry.set(id, stream);
        return stream;
    }
    /**
     * Creates a sink with an abortable source. Incoming messages will
     * also have their size restricted. All messages will be varint decoded.
     */
    _createSink() {
        const sink = async (source) => {
            const abortListener = () => {
                closeSource(source, this.log);
            };
            this.closeController.signal.addEventListener('abort', abortListener);
            try {
                const decoder = new Decoder(this._init.maxMsgSize, this._init.maxUnprocessedMessageQueueSize);
                for await (const chunk of source) {
                    for (const msg of decoder.write(chunk)) {
                        await this._handleIncoming(msg);
                    }
                }
                this._source.end();
            }
            catch (err) {
                this.log('error in sink', err);
                this._source.end(err); // End the source with an error
            }
            finally {
                this.closeController.signal.removeEventListener('abort', abortListener);
            }
        };
        return sink;
    }
    async _handleIncoming(message) {
        const { id, type } = message;
        if (this.log.enabled) {
            this.log.trace('incoming message', printMessage(message));
        }
        // Create a new stream?
        if (message.type === MessageTypes.NEW_STREAM) {
            if (this._streams.receivers.size === (this._init.maxInboundStreams ?? MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION)) {
                this.log('too many inbound streams open');
                // not going to allow this stream, send the reset message manually
                // instead of setting it up just to tear it down
                this._source.push({
                    id,
                    type: MessageTypes.RESET_RECEIVER
                });
                // if we've hit our stream limit, and the remote keeps trying to open
                // more new streams, if they are doing this very quickly maybe they
                // are attacking us and we should close the connection
                try {
                    await this.rateLimiter.consume('new-stream', 1);
                }
                catch {
                    this.log('rate limit hit when opening too many new streams over the inbound stream limit - closing remote connection');
                    // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                    this.abort(new Error('Too many open streams'));
                    return;
                }
                return;
            }
            const stream = this._newReceiverStream({ id, name: toString$6(message.data instanceof Uint8Array ? message.data : message.data.subarray()) });
            if (this._init.onIncomingStream != null) {
                this._init.onIncomingStream(stream);
            }
            return;
        }
        const list = (type & 1) === 1 ? this._streams.initiators : this._streams.receivers;
        const stream = list.get(id);
        if (stream == null) {
            this.log('missing stream %s for message type %s', id, MessageTypeNames[type]);
            // if the remote keeps sending us messages for streams that have been
            // closed or were never opened they may be attacking us so if they do
            // this very quickly all we can do is close the connection
            try {
                await this.rateLimiter.consume('missing-stream', 1);
            }
            catch {
                this.log('rate limit hit when receiving messages for streams that do not exist - closing remote connection');
                // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                this.abort(new Error('Too many messages for missing streams'));
                return;
            }
            return;
        }
        const maxBufferSize = this._init.maxStreamBufferSize ?? MAX_STREAM_BUFFER_SIZE;
        try {
            switch (type) {
                case MessageTypes.MESSAGE_INITIATOR:
                case MessageTypes.MESSAGE_RECEIVER:
                    if (stream.sourceReadableLength() > maxBufferSize) {
                        // Stream buffer has got too large, reset the stream
                        this._source.push({
                            id: message.id,
                            type: type === MessageTypes.MESSAGE_INITIATOR ? MessageTypes.RESET_RECEIVER : MessageTypes.RESET_INITIATOR
                        });
                        // Inform the stream consumer they are not fast enough
                        throw new CodeError$1('Input buffer full - increase Mplex maxBufferSize to accommodate slow consumers', 'ERR_STREAM_INPUT_BUFFER_FULL');
                    }
                    // We got data from the remote, push it into our local stream
                    stream.sourcePush(message.data);
                    break;
                case MessageTypes.CLOSE_INITIATOR:
                case MessageTypes.CLOSE_RECEIVER:
                    // The remote has stopped writing, so we can stop reading
                    stream.remoteCloseWrite();
                    break;
                case MessageTypes.RESET_INITIATOR:
                case MessageTypes.RESET_RECEIVER:
                    // The remote has errored, stop reading and writing to the stream immediately
                    stream.reset();
                    break;
                default:
                    this.log('unknown message type %s', type);
            }
        }
        catch (err) {
            this.log.error('error while processing message', err);
            stream.abort(err);
        }
    }
}

/**
 * @packageDocumentation
 *
 * This is a [simple stream multiplexer(https://docs.libp2p.io/concepts/multiplex/mplex/) that has been deprecated.
 *
 * Please use [@chainsafe/libp2p-yamux](https://www.npmjs.com/package/@chainsafe/libp2p-yamux) instead.
 *
 * @example
 *
 * ```TypeScript
 * import { mplex } from '@libp2p/mplex'
 * import { pipe } from 'it-pipe'
 *
 * const factory = mplex()
 *
 * const muxer = factory.createStreamMuxer(components, {
 *   onStream: stream => { // Receive a duplex stream from the remote
 *     // ...receive data from the remote and optionally send data back
 *   },
 *   onStreamEnd: stream => {
 *     // ...handle any tracking you may need of stream closures
 *   }
 * })
 *
 * pipe(conn, muxer, conn) // conn is duplex connection to another peer
 *
 * const stream = muxer.newStream() // Create a new duplex stream to the remote
 *
 * // Use the duplex stream to send some data to the remote...
 * pipe([1, 2, 3], stream)
 * ```
 */
class Mplex {
    protocol = '/mplex/6.7.0';
    _init;
    components;
    constructor(components, init = {}) {
        this.components = components;
        this._init = init;
    }
    [Symbol.toStringTag] = '@libp2p/mplex';
    [serviceCapabilities] = [
        '@libp2p/stream-multiplexing'
    ];
    createStreamMuxer(init = {}) {
        return new MplexStreamMuxer(this.components, {
            ...init,
            ...this._init
        });
    }
}
function mplex(init = {}) {
    return (components) => new Mplex(components, init);
}

/**
 * @packageDocumentation
 *
 * Return the first value in an (async)iterable
 *
 * @example
 *
 * ```javascript
 * import first from 'it-first'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const res = first(values)
 *
 * console.info(res) // 0
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import first from 'it-first'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const res = await first(values())
 *
 * console.info(res) // 0
 * ```
 */
function isAsyncIterable$3(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function first(source) {
    if (isAsyncIterable$3(source)) {
        return (async () => {
            for await (const entry of source) { // eslint-disable-line no-unreachable-loop
                return entry;
            }
            return undefined;
        })();
    }
    for (const entry of source) { // eslint-disable-line no-unreachable-loop
        return entry;
    }
    return undefined;
}

const PING_LENGTH$1 = 32;
const PROTOCOL_VERSION$1 = '1.0.0';
const PROTOCOL_NAME$1 = 'ping';
const PROTOCOL_PREFIX$1 = 'ipfs';
const TIMEOUT = 10000;
// See https://github.com/libp2p/specs/blob/d4b5fb0152a6bb86cfd9ea/ping/ping.md?plain=1#L38-L43
// The dialing peer MUST NOT keep more than one outbound stream for the ping protocol per peer.
// The listening peer SHOULD accept at most two streams per peer since cross-stream behavior is
// non-linear and stream writes occur asynchronously. The listening peer may perceive the
// dialing peer closing and opening the wrong streams (for instance, closing stream B and
// opening stream A even though the dialing peer is opening stream B and closing stream A).
const MAX_INBOUND_STREAMS = 2;
const MAX_OUTBOUND_STREAMS = 1;
const ERR_WRONG_PING_ACK = 'ERR_WRONG_PING_ACK';

class PingService {
    protocol;
    components;
    started;
    timeout;
    maxInboundStreams;
    maxOutboundStreams;
    runOnTransientConnection;
    log;
    constructor(components, init = {}) {
        this.components = components;
        this.log = components.logger.forComponent('libp2p:ping');
        this.started = false;
        this.protocol = `/${init.protocolPrefix ?? PROTOCOL_PREFIX$1}/${PROTOCOL_NAME$1}/${PROTOCOL_VERSION$1}`;
        this.timeout = init.timeout ?? TIMEOUT;
        this.maxInboundStreams = init.maxInboundStreams ?? MAX_INBOUND_STREAMS;
        this.maxOutboundStreams = init.maxOutboundStreams ?? MAX_OUTBOUND_STREAMS;
        this.runOnTransientConnection = init.runOnTransientConnection ?? true;
        this.handleMessage = this.handleMessage.bind(this);
    }
    [Symbol.toStringTag] = '@libp2p/ping';
    async start() {
        await this.components.registrar.handle(this.protocol, this.handleMessage, {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams,
            runOnTransientConnection: this.runOnTransientConnection
        });
        this.started = true;
    }
    async stop() {
        await this.components.registrar.unhandle(this.protocol);
        this.started = false;
    }
    isStarted() {
        return this.started;
    }
    /**
     * A handler to register with Libp2p to process ping messages
     */
    handleMessage(data) {
        this.log('incoming ping from %p', data.connection.remotePeer);
        const { stream } = data;
        const start = Date.now();
        const signal = AbortSignal.timeout(this.timeout);
        signal.addEventListener('abort', () => {
            stream?.abort(new CodeError$1('ping timeout', ERR_TIMEOUT));
        });
        void pipe(stream, async function* (source) {
            let received = 0;
            for await (const buf of source) {
                received += buf.byteLength;
                if (received > PING_LENGTH$1) {
                    stream?.abort(new CodeError$1('Too much data received', ERR_INVALID_MESSAGE));
                    return;
                }
                yield buf;
            }
        }, stream)
            .catch(err => {
            this.log.error('incoming ping from %p failed with error', data.connection.remotePeer, err);
            stream?.abort(err);
        })
            .finally(() => {
            const ms = Date.now() - start;
            this.log('incoming ping from %p complete in %dms', data.connection.remotePeer, ms);
        });
    }
    /**
     * Ping a given peer and wait for its response, getting the operation latency.
     */
    async ping(peer, options = {}) {
        this.log('pinging %p', peer);
        const start = Date.now();
        const data = randomBytes(PING_LENGTH$1);
        const connection = await this.components.connectionManager.openConnection(peer, options);
        let stream;
        let onAbort = () => { };
        if (options.signal == null) {
            const signal = AbortSignal.timeout(this.timeout);
            options = {
                ...options,
                signal
            };
        }
        try {
            stream = await connection.newStream(this.protocol, {
                ...options,
                runOnTransientConnection: this.runOnTransientConnection
            });
            onAbort = () => {
                stream?.abort(new CodeError$1('ping timeout', ERR_TIMEOUT));
            };
            // make stream abortable
            options.signal?.addEventListener('abort', onAbort, { once: true });
            const result = await pipe([data], stream, async (source) => first(source));
            const ms = Date.now() - start;
            if (result == null) {
                throw new CodeError$1(`Did not receive a ping ack after ${ms}ms`, ERR_WRONG_PING_ACK);
            }
            if (!equals(data, result.subarray())) {
                throw new CodeError$1(`Received wrong ping ack after ${ms}ms`, ERR_WRONG_PING_ACK);
            }
            this.log('ping %p complete in %dms', connection.remotePeer, ms);
            return ms;
        }
        catch (err) {
            this.log.error('error while pinging %p', connection.remotePeer, err);
            stream?.abort(err);
            throw err;
        }
        finally {
            options.signal?.removeEventListener('abort', onAbort);
            if (stream != null) {
                await stream.close();
            }
        }
    }
}

/**
 * @packageDocumentation
 *
 * The ping service implements the [libp2p ping spec](https://github.com/libp2p/specs/blob/master/ping/ping.md) allowing you to make a latency measurement to a remote peer.
 *
 * @example
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 * import { ping } from '@libp2p/ping'
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const node = await createLibp2p({
 *   services: {
 *     ping: ping()
 *   }
 * })
 *
 * const rtt = await node.services.ping.ping(multiaddr('/ip4/...'))
 *
 * console.info(rtt)
 * ```
 */
function ping(init = {}) {
    return (components) => new PingService(components, init);
}

/**
 * @packageDocumentation
 *
 * This module allows easy conversion of Multiaddrs to string URIs.
 *
 * @example Converting multiaddrs to string URIs
 *
 * ```js
 * import { multiaddrToUri } from '@multiformats/multiaddr-to-uri'
 *
 * console.log(multiaddrToUri('/dnsaddr/protocol.ai/https'))
 * // -> https://protocol.ai
 *
 * console.log(multiaddrToUri('/ip4/127.0.0.1/tcp/8080'))
 * // -> http://127.0.0.1:8080
 *
 * console.log(multiaddrToUri('/ip4/127.0.0.1/tcp/8080', { assumeHttp: false }))
 * // -> tcp://127.0.0.1:8080
 * ```
 *
 * Note:
 *
 * - When `/tcp` is the last (terminating) protocol HTTP is assumed by default (implicit `assumeHttp: true`)
 *   - this means produced URIs will start with `http://` instead of `tcp://`
 *   - passing `{ assumeHttp: false }` disables this behavior
 * - Might be lossy - e.g. a DNSv6 multiaddr
 * - Can throw if the passed multiaddr:
 *   - is not a valid multiaddr
 *   - is not supported as a URI e.g. circuit
 */
const ASSUME_HTTP_CODES = [
    getProtocol('tcp').code,
    getProtocol('dns').code,
    getProtocol('dnsaddr').code,
    getProtocol('dns4').code,
    getProtocol('dns6').code
];
function extractSNI(ma) {
    let sniProtoCode;
    try {
        sniProtoCode = getProtocol('sni').code;
    }
    catch (e) {
        // No SNI protocol in multiaddr
        return null;
    }
    for (const [proto, value] of ma) {
        if (proto === sniProtoCode && value !== undefined) {
            return value;
        }
    }
    return null;
}
function hasTLS(ma) {
    return ma.some(([proto, _]) => proto === getProtocol('tls').code);
}
function interpretNext(headProtoCode, headProtoVal, restMa) {
    const interpreter = interpreters[getProtocol(headProtoCode).name];
    if (interpreter === undefined) {
        throw new Error(`Can't interpret protocol ${getProtocol(headProtoCode).name}`);
    }
    const restVal = interpreter(headProtoVal, restMa);
    if (headProtoCode === getProtocol('ip6').code) {
        return `[${restVal}]`;
    }
    return restVal;
}
const interpreters = {
    ip4: (value, restMa) => value,
    ip6: (value, restMa) => {
        if (restMa.length === 0) {
            return value;
        }
        return `[${value}]`;
    },
    tcp: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `tcp://${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}:${value}`;
    },
    udp: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `udp://${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}:${value}`;
    },
    dnsaddr: (value, restMa) => value,
    dns4: (value, restMa) => value,
    dns6: (value, restMa) => value,
    dns: (value, restMa) => value,
    ipfs: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/ipfs/${value}`;
    },
    p2p: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p/${value}`;
    },
    http: (value, restMa) => {
        const maHasTLS = hasTLS(restMa);
        const sni = extractSNI(restMa);
        if (maHasTLS && sni !== null) {
            return `https://${sni}`;
        }
        const protocol = maHasTLS ? 'https://' : 'http://';
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `${protocol}${baseVal}`;
    },
    'http-path': (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        const baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        const decodedValue = decodeURIComponent(value);
        return `${baseVal}/${decodedValue}`;
    },
    tls: (value, restMa) => {
        // Noop, the parent context knows that it's tls. We don't need to do
        // anything here
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
    },
    sni: (value, restMa) => {
        // Noop, the parent context uses the sni information, we don't need to do
        // anything here
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
    },
    https: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `https://${baseVal}`;
    },
    ws: (value, restMa) => {
        const maHasTLS = hasTLS(restMa);
        const sni = extractSNI(restMa);
        if (maHasTLS && sni !== null) {
            return `wss://${sni}`;
        }
        const protocol = maHasTLS ? 'wss://' : 'ws://';
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `${protocol}${baseVal}`;
    },
    wss: (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);
        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there
        baseVal = baseVal.replace('tcp://', '');
        return `wss://${baseVal}`;
    },
    'p2p-websocket-star': (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p-websocket-star`;
    },
    'p2p-webrtc-star': (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p-webrtc-star`;
    },
    'p2p-webrtc-direct': (value, restMa) => {
        const tailProto = restMa.pop();
        if (tailProto === undefined) {
            throw new Error('Unexpected end of multiaddr');
        }
        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p-webrtc-direct`;
    }
};
function multiaddrToUri(input, opts) {
    const ma = multiaddr(input);
    const parts = ma.stringTuples();
    const head = parts.pop();
    if (head === undefined) {
        throw new Error('Unexpected end of multiaddr');
    }
    const protocol = getProtocol(head[0]);
    const interpreter = interpreters[protocol.name];
    if (interpreter == null) {
        throw new Error(`No interpreter found for ${protocol.name}`);
    }
    let uri = interpreter(head[1] ?? '', parts);
    if (ASSUME_HTTP_CODES.includes(head[0])) {
        // strip any declared protocol
        uri = uri.replace(/^.*:\/\//, '');
        if (head[1] === '443') {
            uri = `https://${uri}`;
        }
        else {
            uri = `http://${uri}`;
        }
    }
    if (uri.startsWith('http://') || uri.startsWith('https://')) {
        // this will strip default ports while keeping paths intact
        uri = new URL(uri).toString();
        // strip trailing slash, e.g. http://127.0.0.1/ -> http://127.0.0.1
        if (uri.endsWith('/')) {
            uri = uri.substring(0, uri.length - 1);
        }
    }
    return uri;
}

var ready = async (socket) => {
    // if the socket is closing or closed, return end
    if (socket.readyState >= 2) {
        throw new Error('socket closed');
    }
    // if open, return
    if (socket.readyState === 1) {
        return;
    }
    await new Promise((resolve, reject) => {
        function cleanup() {
            socket.removeEventListener('open', handleOpen);
            socket.removeEventListener('error', handleErr);
        }
        function handleOpen() {
            cleanup();
            resolve();
        }
        function handleErr(event) {
            cleanup();
            reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`));
        }
        socket.addEventListener('open', handleOpen);
        socket.addEventListener('error', handleErr);
    });
};

var sink = (socket, options) => {
    options = options ?? {};
    options.closeOnEnd = options.closeOnEnd !== false;
    const sink = async (source) => {
        for await (const data of source) {
            try {
                await ready(socket);
            }
            catch (err) {
                if (err.message === 'socket closed')
                    break;
                throw err;
            }
            // the ready promise resolved without error but the socket was closing so
            // exit the loop and don't send data
            if (socket.readyState === socket.CLOSING || socket.readyState === socket.CLOSED) {
                break;
            }
            socket.send(data);
        }
        if (options.closeOnEnd != null && socket.readyState <= 1) {
            await new Promise((resolve, reject) => {
                socket.addEventListener('close', event => {
                    if (event.wasClean || event.code === 1006) {
                        resolve();
                    }
                    else {
                        const err = Object.assign(new Error('ws error'), { event });
                        reject(err);
                    }
                });
                setTimeout(() => { socket.close(); });
            });
        }
    };
    return sink;
};

var dom = {};

var eventIterator = {};

Object.defineProperty(eventIterator, "__esModule", { value: true });
class EventQueue {
    constructor() {
        this.pullQueue = [];
        this.pushQueue = [];
        this.eventHandlers = {};
        this.isPaused = false;
        this.isStopped = false;
    }
    push(value) {
        if (this.isStopped)
            return;
        const resolution = { value, done: false };
        if (this.pullQueue.length) {
            const placeholder = this.pullQueue.shift();
            if (placeholder)
                placeholder.resolve(resolution);
        }
        else {
            this.pushQueue.push(Promise.resolve(resolution));
            if (this.highWaterMark !== undefined &&
                this.pushQueue.length >= this.highWaterMark &&
                !this.isPaused) {
                this.isPaused = true;
                if (this.eventHandlers.highWater) {
                    this.eventHandlers.highWater();
                }
                else if (console) {
                    console.warn(`EventIterator queue reached ${this.pushQueue.length} items`);
                }
            }
        }
    }
    stop() {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        for (const placeholder of this.pullQueue) {
            placeholder.resolve({ value: undefined, done: true });
        }
        this.pullQueue.length = 0;
    }
    fail(error) {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        if (this.pullQueue.length) {
            for (const placeholder of this.pullQueue) {
                placeholder.reject(error);
            }
            this.pullQueue.length = 0;
        }
        else {
            const rejection = Promise.reject(error);
            /* Attach error handler to avoid leaking an unhandled promise rejection. */
            rejection.catch(() => { });
            this.pushQueue.push(rejection);
        }
    }
    remove() {
        Promise.resolve().then(() => {
            if (this.removeCallback)
                this.removeCallback();
        });
    }
    [Symbol.asyncIterator]() {
        return {
            next: (value) => {
                const result = this.pushQueue.shift();
                if (result) {
                    if (this.lowWaterMark !== undefined &&
                        this.pushQueue.length <= this.lowWaterMark &&
                        this.isPaused) {
                        this.isPaused = false;
                        if (this.eventHandlers.lowWater) {
                            this.eventHandlers.lowWater();
                        }
                    }
                    return result;
                }
                else if (this.isStopped) {
                    return Promise.resolve({ value: undefined, done: true });
                }
                else {
                    return new Promise((resolve, reject) => {
                        this.pullQueue.push({ resolve, reject });
                    });
                }
            },
            return: () => {
                this.isStopped = true;
                this.pushQueue.length = 0;
                this.remove();
                return Promise.resolve({ value: undefined, done: true });
            },
        };
    }
}
let EventIterator$1 = class EventIterator {
    constructor(listen, { highWaterMark = 100, lowWaterMark = 1 } = {}) {
        const queue = new EventQueue();
        queue.highWaterMark = highWaterMark;
        queue.lowWaterMark = lowWaterMark;
        queue.removeCallback =
            listen({
                push: value => queue.push(value),
                stop: () => queue.stop(),
                fail: error => queue.fail(error),
                on: (event, fn) => {
                    queue.eventHandlers[event] = fn;
                },
            }) || (() => { });
        this[Symbol.asyncIterator] = () => queue[Symbol.asyncIterator]();
        Object.freeze(this);
    }
};
eventIterator.EventIterator = EventIterator$1;
eventIterator.default = EventIterator$1;

Object.defineProperty(dom, "__esModule", { value: true });
const event_iterator_1 = eventIterator;
var EventIterator = dom.EventIterator = event_iterator_1.EventIterator;
function subscribe(event, options, evOptions) {
    return new event_iterator_1.EventIterator(({ push }) => {
        this.addEventListener(event, push, options);
        return () => this.removeEventListener(event, push, options);
    }, evOptions);
}
dom.subscribe = subscribe;
dom.default = event_iterator_1.EventIterator;

// copied from github.com/feross/buffer
// Some ArrayBuffers are not passing the instanceof check, so we need to do a bit more work :(
function isArrayBuffer(obj) {
    return (obj instanceof ArrayBuffer) ||
        (obj?.constructor?.name === 'ArrayBuffer' && typeof obj?.byteLength === 'number');
}
var source = (socket) => {
    socket.binaryType = 'arraybuffer';
    const connected = async () => {
        await new Promise((resolve, reject) => {
            if (isConnected) {
                resolve();
                return;
            }
            if (connError != null) {
                reject(connError);
                return;
            }
            const cleanUp = (cont) => {
                socket.removeEventListener('open', onOpen);
                socket.removeEventListener('error', onError);
                cont();
            };
            const onOpen = () => { cleanUp(resolve); };
            const onError = (event) => {
                cleanUp(() => { reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`)); });
            };
            socket.addEventListener('open', onOpen);
            socket.addEventListener('error', onError);
        });
    };
    const source = (async function* () {
        const messages = new EventIterator(({ push, stop, fail }) => {
            const onMessage = (event) => {
                let data = null;
                if (typeof event.data === 'string') {
                    data = fromString(event.data);
                }
                if (isArrayBuffer(event.data)) {
                    data = new Uint8Array(event.data);
                }
                if (event.data instanceof Uint8Array) {
                    data = event.data;
                }
                if (data == null) {
                    return;
                }
                push(data);
            };
            const onError = (event) => { fail(event.error ?? new Error('Socket error')); };
            socket.addEventListener('message', onMessage);
            socket.addEventListener('error', onError);
            socket.addEventListener('close', stop);
            return () => {
                socket.removeEventListener('message', onMessage);
                socket.removeEventListener('error', onError);
                socket.removeEventListener('close', stop);
            };
        }, { highWaterMark: Infinity });
        await connected();
        for await (const chunk of messages) {
            yield isArrayBuffer(chunk) ? new Uint8Array(chunk) : chunk;
        }
    }());
    let isConnected = socket.readyState === 1;
    let connError;
    socket.addEventListener('open', () => {
        isConnected = true;
        connError = null;
    });
    socket.addEventListener('close', () => {
        isConnected = false;
        connError = null;
    });
    socket.addEventListener('error', event => {
        if (!isConnected) {
            connError = event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`);
        }
    });
    return Object.assign(source, {
        connected
    });
};

var duplex = (socket, options) => {
    options = options ?? {};
    const connectedSource = source(socket);
    let remoteAddress = options.remoteAddress;
    let remotePort = options.remotePort;
    if (socket.url != null) {
        // only client->server sockets have urls, server->client connections do not
        try {
            const url = new URL(socket.url);
            remoteAddress = url.hostname;
            remotePort = parseInt(url.port, 10);
        }
        catch { }
    }
    if (remoteAddress == null || remotePort == null) {
        throw new Error('Remote connection did not have address and/or port');
    }
    const duplex = {
        sink: sink(socket, options),
        source: connectedSource,
        connected: async () => { await connectedSource.connected(); },
        close: async () => {
            if (socket.readyState === socket.CONNECTING || socket.readyState === socket.OPEN) {
                await new Promise((resolve) => {
                    socket.addEventListener('close', () => {
                        resolve();
                    });
                    socket.close();
                });
            }
        },
        destroy: () => {
            if (socket.terminate != null) {
                socket.terminate();
            }
            else {
                socket.close();
            }
        },
        remoteAddress,
        remotePort,
        socket
    };
    return duplex;
};

/* eslint-env browser */
var WebSocket$1 = WebSocket;

const map = { 'http:': 'ws:', 'https:': 'wss:' };
const defaultProtocol = 'ws:';
var wsurl = (url, location) => {
    if (url.startsWith('//')) {
        url = `${location?.protocol ?? defaultProtocol}${url}`;
    }
    if (url.startsWith('/') && location != null) {
        const proto = location.protocol ?? defaultProtocol;
        const host = location.host;
        const port = location.port != null && host?.endsWith(`:${location.port}`) !== true ? `:${location.port}` : '';
        url = `${proto}//${host}${port}${url}`;
    }
    const wsUrl = new URL(url);
    for (const [httpProto, wsProto] of Object.entries(map)) {
        if (wsUrl.protocol === httpProto) {
            wsUrl.protocol = wsProto;
        }
    }
    return wsUrl;
};

// load websocket library if we are not in the browser
function connect(addr, opts) {
    const location = typeof window === 'undefined' ? undefined : window.location;
    opts = opts ?? {};
    const url = wsurl(addr, location);
    // it's necessary to stringify the URL object otherwise react-native crashes
    const socket = new WebSocket$1(url.toString(), opts.websocket);
    return duplex(socket, opts);
}

/**
 * An implementation of the ProgressEvent interface, this is essentially
 * a typed `CustomEvent` with a `type` property that lets us disambiguate
 * events passed to `progress` callbacks.
 */
class CustomProgressEvent extends Event {
    type;
    detail;
    constructor(type, detail) {
        super(type);
        this.type = type;
        // @ts-expect-error detail may be undefined
        this.detail = detail;
    }
}

// p2p multi-address code
const CODE_P2P = 421;
const CODE_CIRCUIT = 290;
// Time to wait for a connection to close gracefully before destroying it manually
const CLOSE_TIMEOUT$1 = 500;

function all(multiaddrs) {
    return multiaddrs.filter((ma) => {
        if (ma.protoCodes().includes(CODE_CIRCUIT)) {
            return false;
        }
        const testMa = ma.decapsulateCode(CODE_P2P);
        return WebSockets$1.matches(testMa) ||
            WebSocketsSecure.matches(testMa);
    });
}
function wss(multiaddrs) {
    return multiaddrs.filter((ma) => {
        if (ma.protoCodes().includes(CODE_CIRCUIT)) {
            return false;
        }
        const testMa = ma.decapsulateCode(CODE_P2P);
        return WebSocketsSecure.matches(testMa);
    });
}

function createListener() {
    throw new Error('WebSocket Servers can not be created in the browser!');
}

// Convert a stream into a MultiaddrConnection
// https://github.com/libp2p/interface-transport#multiaddrconnection
function socketToMaConn(stream, remoteAddr, options) {
    const log = options.logger.forComponent('libp2p:websockets:maconn');
    const metrics = options.metrics;
    const metricPrefix = options.metricPrefix ?? '';
    const maConn = {
        log,
        async sink(source) {
            try {
                await stream.sink((async function* () {
                    for await (const buf of source) {
                        if (buf instanceof Uint8Array) {
                            yield buf;
                        }
                        else {
                            yield buf.subarray();
                        }
                    }
                })());
            }
            catch (err) {
                if (err.type !== 'aborted') {
                    log.error(err);
                }
            }
        },
        source: stream.source,
        remoteAddr,
        timeline: { open: Date.now() },
        async close(options = {}) {
            const start = Date.now();
            if (options.signal == null) {
                const signal = AbortSignal.timeout(CLOSE_TIMEOUT$1);
                options = {
                    ...options,
                    signal
                };
            }
            const listener = () => {
                const { host, port } = maConn.remoteAddr.toOptions();
                log('timeout closing stream to %s:%s after %dms, destroying it manually', host, port, Date.now() - start);
                this.abort(new CodeError$1('Socket close timeout', 'ERR_SOCKET_CLOSE_TIMEOUT'));
            };
            options.signal?.addEventListener('abort', listener);
            try {
                await stream.close();
            }
            catch (err) {
                log.error('error closing WebSocket gracefully', err);
                this.abort(err);
            }
            finally {
                options.signal?.removeEventListener('abort', listener);
                maConn.timeline.close = Date.now();
            }
        },
        abort(err) {
            const { host, port } = maConn.remoteAddr.toOptions();
            log('timeout closing stream to %s:%s due to error', host, port, err);
            stream.destroy();
            maConn.timeline.close = Date.now();
            // ws WebSocket.terminate does not accept an Error arg to emit an 'error'
            // event on destroy like other node streams so we can't update a metric
            // with an event listener
            // https://github.com/websockets/ws/issues/1752#issuecomment-622380981
            metrics?.increment({ [`${metricPrefix}error`]: true });
        }
    };
    stream.socket.addEventListener('close', () => {
        metrics?.increment({ [`${metricPrefix}close`]: true });
        // In instances where `close` was not explicitly called,
        // such as an iterable stream ending, ensure we have set the close
        // timeline
        if (maConn.timeline.close == null) {
            maConn.timeline.close = Date.now();
        }
    }, { once: true });
    return maConn;
}

/**
 * @packageDocumentation
 *
 * A [libp2p transport](https://docs.libp2p.io/concepts/transports/overview/) based on [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API).
 *
 * @example
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { webSockets } from '@libp2p/websockets'
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const node = await createLibp2p({
 *   transports: [
 *     webSockets()
 *   ]
 * //... other config
 * })
 * await node.start()
 *
 * const ma = multiaddr('/ip4/127.0.0.1/tcp/9090/ws')
 * await node.dial(ma)
 * ```
 *
 * ## Filters
 *
 * When run in a browser by default this module will only connect to secure web socket addresses.
 *
 * To change this you should pass a filter to the factory function.
 *
 * You can create your own address filters for this transports, or rely in the filters [provided](./src/filters.js).
 *
 * The available filters are:
 *
 * - `filters.all`
 *   - Returns all TCP and DNS based addresses, both with `ws` or `wss`.
 * - `filters.dnsWss`
 *   - Returns all DNS based addresses with `wss`.
 * - `filters.dnsWsOrWss`
 *   - Returns all DNS based addresses, both with `ws` or `wss`.
 *
 * @example Allow dialing insecure WebSockets
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { webSockets } from '@libp2p/websockets'
 * import * as filters from '@libp2p/websockets/filters'
 *
 * const node = await createLibp2p({
 *   transports: [
 *     webSockets({
 *       // connect to all sockets, even insecure ones
 *       filter: filters.all
 *     })
 *   ]
 * })
 * ```
 */
class WebSockets {
    log;
    init;
    logger;
    metrics;
    components;
    constructor(components, init) {
        this.log = components.logger.forComponent('libp2p:websockets');
        this.logger = components.logger;
        this.components = components;
        this.init = init;
        if (components.metrics != null) {
            this.metrics = {
                dialerEvents: components.metrics.registerCounterGroup('libp2p_websockets_dialer_events_total', {
                    label: 'event',
                    help: 'Total count of WebSockets dialer events by type'
                })
            };
        }
    }
    [transportSymbol] = true;
    [Symbol.toStringTag] = '@libp2p/websockets';
    [serviceCapabilities] = [
        '@libp2p/transport'
    ];
    async dial(ma, options) {
        this.log('dialing %s', ma);
        options = options ?? {};
        const socket = await this._connect(ma, options);
        const maConn = socketToMaConn(socket, ma, {
            logger: this.logger,
            metrics: this.metrics?.dialerEvents
        });
        this.log('new outbound connection %s', maConn.remoteAddr);
        const conn = await options.upgrader.upgradeOutbound(maConn, options);
        this.log('outbound connection %s upgraded', maConn.remoteAddr);
        return conn;
    }
    async _connect(ma, options) {
        options?.signal?.throwIfAborted();
        const cOpts = ma.toOptions();
        this.log('dialing %s:%s', cOpts.host, cOpts.port);
        const errorPromise = pDefer();
        const rawSocket = connect(multiaddrToUri(ma), this.init);
        rawSocket.socket.addEventListener('error', () => {
            // the WebSocket.ErrorEvent type doesn't actually give us any useful
            // information about what happened
            // https://developer.mozilla.org/en-US/docs/Web/API/WebSocket/error_event
            const err = new CodeError$1(`Could not connect to ${ma.toString()}`, 'ERR_CONNECTION_FAILED');
            this.log.error('connection error:', err);
            this.metrics?.dialerEvents.increment({ error: true });
            errorPromise.reject(err);
        });
        try {
            options.onProgress?.(new CustomProgressEvent('websockets:open-connection'));
            await raceSignal(Promise.race([rawSocket.connected(), errorPromise.promise]), options.signal);
        }
        catch (err) {
            if (options.signal?.aborted === true) {
                this.metrics?.dialerEvents.increment({ abort: true });
            }
            rawSocket.close()
                .catch(err => {
                this.log.error('error closing raw socket', err);
            });
            throw err;
        }
        this.log('connected %s', ma);
        this.metrics?.dialerEvents.increment({ connect: true });
        return rawSocket;
    }
    /**
     * Creates a Websockets listener. The provided `handler` function will be called
     * anytime a new incoming Connection has been successfully upgraded via
     * `upgrader.upgradeInbound`
     */
    createListener(options) {
        return createListener({
            logger: this.logger,
            metrics: this.components.metrics
        }, {
            ...this.init,
            ...options
        });
    }
    /**
     * Takes a list of `Multiaddr`s and returns only valid Websockets addresses.
     * By default, in a browser environment only DNS+WSS multiaddr is accepted,
     * while in a Node.js environment DNS+{WS, WSS} multiaddrs are accepted.
     */
    listenFilter(multiaddrs) {
        multiaddrs = Array.isArray(multiaddrs) ? multiaddrs : [multiaddrs];
        if (this.init?.filter != null) {
            return this.init?.filter(multiaddrs);
        }
        // Browser
        if (isBrowser || isWebWorker) {
            return wss(multiaddrs);
        }
        return all(multiaddrs);
    }
    /**
     * Filter check for all Multiaddrs that this transport can dial
     */
    dialFilter(multiaddrs) {
        return this.listenFilter(multiaddrs);
    }
}
function webSockets(init = {}) {
    return (components) => {
        return new WebSockets(components, init);
    };
}

// Helpers.
const s = 1000;
const m = s * 60;
const h = m * 60;
const d = h * 24;
const w = d * 7;
const y = d * 365.25;
function ms(value, options) {
    try {
        if (typeof value === 'string' && value.length > 0) {
            return parse(value);
        }
        else if (typeof value === 'number' && isFinite(value)) {
            return options?.long ? fmtLong(value) : fmtShort(value);
        }
        throw new Error('Value is not a string or number.');
    }
    catch (error) {
        const message = isError(error)
            ? `${error.message}. value=${JSON.stringify(value)}`
            : 'An unknown error has occured.';
        throw new Error(message);
    }
}
/**
 * Parse the given `str` and return milliseconds.
 */
function parse(str) {
    str = String(str);
    if (str.length > 100) {
        throw new Error('Value exceeds the maximum length of 100 characters.');
    }
    const match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(str);
    if (!match) {
        return NaN;
    }
    const n = parseFloat(match[1]);
    const type = (match[2] || 'ms').toLowerCase();
    switch (type) {
        case 'years':
        case 'year':
        case 'yrs':
        case 'yr':
        case 'y':
            return n * y;
        case 'weeks':
        case 'week':
        case 'w':
            return n * w;
        case 'days':
        case 'day':
        case 'd':
            return n * d;
        case 'hours':
        case 'hour':
        case 'hrs':
        case 'hr':
        case 'h':
            return n * h;
        case 'minutes':
        case 'minute':
        case 'mins':
        case 'min':
        case 'm':
            return n * m;
        case 'seconds':
        case 'second':
        case 'secs':
        case 'sec':
        case 's':
            return n * s;
        case 'milliseconds':
        case 'millisecond':
        case 'msecs':
        case 'msec':
        case 'ms':
            return n;
        default:
            // This should never occur.
            throw new Error(`The unit ${type} was matched, but no matching case exists.`);
    }
}
/**
 * Short format for `ms`.
 */
function fmtShort(ms) {
    const msAbs = Math.abs(ms);
    if (msAbs >= d) {
        return `${Math.round(ms / d)}d`;
    }
    if (msAbs >= h) {
        return `${Math.round(ms / h)}h`;
    }
    if (msAbs >= m) {
        return `${Math.round(ms / m)}m`;
    }
    if (msAbs >= s) {
        return `${Math.round(ms / s)}s`;
    }
    return `${ms}ms`;
}
/**
 * Long format for `ms`.
 */
function fmtLong(ms) {
    const msAbs = Math.abs(ms);
    if (msAbs >= d) {
        return plural(ms, msAbs, d, 'day');
    }
    if (msAbs >= h) {
        return plural(ms, msAbs, h, 'hour');
    }
    if (msAbs >= m) {
        return plural(ms, msAbs, m, 'minute');
    }
    if (msAbs >= s) {
        return plural(ms, msAbs, s, 'second');
    }
    return `${ms} ms`;
}
/**
 * Pluralization helper.
 */
function plural(ms, msAbs, n, name) {
    const isPlural = msAbs >= n * 1.5;
    return `${Math.round(ms / n)} ${name}${isPlural ? 's' : ''}`;
}
/**
 * A type guard for errors.
 */
function isError(error) {
    return typeof error === 'object' && error !== null && 'message' in error;
}

/* eslint-disable no-console */
/* eslint-disable @typescript-eslint/strict-boolean-expressions */
/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */
function setup(env) {
    createDebug.debug = createDebug;
    createDebug.default = createDebug;
    createDebug.coerce = coerce;
    createDebug.disable = disable;
    createDebug.enable = enable;
    createDebug.enabled = enabled;
    createDebug.humanize = ms;
    createDebug.destroy = destroy;
    Object.keys(env).forEach(key => {
        // @ts-expect-error cannot use string to index type
        createDebug[key] = env[key];
    });
    /**
     * The currently active debug mode names, and names to skip.
     */
    createDebug.names = [];
    createDebug.skips = [];
    /**
     * Map of special "%n" handling functions, for the debug "format" argument.
     *
     * Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
     */
    createDebug.formatters = {};
    /**
     * Selects a color for a debug namespace
     *
     * @param {string} namespace - The namespace string for the debug instance to be colored
     * @returns {number | string} An ANSI color code for the given namespace
     */
    function selectColor(namespace) {
        let hash = 0;
        for (let i = 0; i < namespace.length; i++) {
            hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
            hash |= 0; // Convert to 32bit integer
        }
        // @ts-expect-error colors is not in the types
        return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
    }
    createDebug.selectColor = selectColor;
    /**
     * Create a debugger with the given `namespace`.
     *
     * @param {string} namespace
     * @returns {Function}
     */
    function createDebug(namespace) {
        let prevTime;
        let enableOverride = null;
        let namespacesCache;
        let enabledCache;
        function debug(...args) {
            // Disabled?
            // @ts-expect-error enabled is not in the types
            if (!debug.enabled) {
                return;
            }
            const self = debug;
            // Set `diff` timestamp
            const curr = Number(new Date());
            const ms = curr - (prevTime || curr);
            self.diff = ms;
            self.prev = prevTime;
            self.curr = curr;
            prevTime = curr;
            args[0] = createDebug.coerce(args[0]);
            if (typeof args[0] !== 'string') {
                // Anything else let's inspect with %O
                args.unshift('%O');
            }
            // Apply any `formatters` transformations
            let index = 0;
            args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
                // If we encounter an escaped % then don't increase the array index
                if (match === '%%') {
                    return '%';
                }
                index++;
                // @ts-expect-error formatters is not in the types
                const formatter = createDebug.formatters[format];
                if (typeof formatter === 'function') {
                    const val = args[index];
                    match = formatter.call(self, val);
                    // Now we need to remove `args[index]` since it's inlined in the `format`
                    args.splice(index, 1);
                    index--;
                }
                return match;
            });
            // Apply env-specific formatting (colors, etc.)
            // @ts-expect-error formatArgs is not in the types
            createDebug.formatArgs.call(self, args);
            // @ts-expect-error log is not in the types
            const logFn = self.log || createDebug.log;
            logFn.apply(self, args);
        }
        debug.namespace = namespace;
        // @ts-expect-error useColors is not in the types
        debug.useColors = createDebug.useColors();
        debug.color = createDebug.selectColor(namespace);
        debug.extend = extend;
        debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.
        Object.defineProperty(debug, 'enabled', {
            enumerable: true,
            configurable: false,
            get: () => {
                if (enableOverride !== null) {
                    return enableOverride;
                }
                // @ts-expect-error namespaces is not in the types
                if (namespacesCache !== createDebug.namespaces) {
                    // @ts-expect-error namespaces is not in the types
                    namespacesCache = createDebug.namespaces;
                    enabledCache = createDebug.enabled(namespace);
                }
                return enabledCache;
            },
            set: v => {
                enableOverride = v;
            }
        });
        // Env-specific initialization logic for debug instances
        // @ts-expect-error init is not in the types
        if (typeof createDebug.init === 'function') {
            // @ts-expect-error init is not in the types
            createDebug.init(debug);
        }
        // @ts-expect-error some properties are added dynamically
        return debug;
    }
    function extend(namespace, delimiter) {
        const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
        newDebug.log = this.log;
        return newDebug;
    }
    /**
     * Enables a debug mode by namespaces. This can include modes
     * separated by a colon and wildcards.
     *
     * @param {string} namespaces
     */
    function enable(namespaces) {
        // @ts-expect-error save is not in the types
        createDebug.save(namespaces);
        // @ts-expect-error namespaces is not in the types
        createDebug.namespaces = namespaces;
        createDebug.names = [];
        createDebug.skips = [];
        let i;
        const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
        const len = split.length;
        for (i = 0; i < len; i++) {
            if (!split[i]) {
                // ignore empty strings
                continue;
            }
            namespaces = split[i].replace(/\*/g, '.*?');
            if (namespaces[0] === '-') {
                createDebug.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));
            }
            else {
                createDebug.names.push(new RegExp('^' + namespaces + '$'));
            }
        }
    }
    /**
     * Disable debug output.
     *
     * @returns {string} namespaces
     */
    function disable() {
        const namespaces = [
            ...createDebug.names.map(toNamespace),
            ...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
        ].join(',');
        createDebug.enable('');
        return namespaces;
    }
    /**
     * Returns true if the given mode name is enabled, false otherwise.
     *
     * @param {string} name
     * @returns {boolean}
     */
    function enabled(name) {
        if (name[name.length - 1] === '*') {
            return true;
        }
        let i;
        let len;
        for (i = 0, len = createDebug.skips.length; i < len; i++) {
            if (createDebug.skips[i].test(name)) {
                return false;
            }
        }
        for (i = 0, len = createDebug.names.length; i < len; i++) {
            if (createDebug.names[i].test(name)) {
                return true;
            }
        }
        return false;
    }
    /**
     * Convert regexp to namespace
     */
    function toNamespace(regexp) {
        return regexp.toString()
            .substring(2, regexp.toString().length - 2)
            .replace(/\.\*\?$/, '*');
    }
    /**
     * Coerce `val`.
     */
    function coerce(val) {
        if (val instanceof Error) {
            return val.stack ?? val.message;
        }
        return val;
    }
    /**
     * XXX DO NOT USE. This is a temporary stub function.
     * XXX It WILL be removed in the next major release.
     */
    function destroy() {
        console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
    }
    // @ts-expect-error setupFormatters is not in the types
    createDebug.setupFormatters(createDebug.formatters);
    // @ts-expect-error load is not in the types
    createDebug.enable(createDebug.load());
    // @ts-expect-error some properties are added dynamically
    return createDebug;
}

/* eslint-disable no-console */
/* eslint-disable @typescript-eslint/restrict-plus-operands */
/* eslint-disable @typescript-eslint/strict-boolean-expressions */
/* eslint-env browser */
/**
 * This is the web browser implementation of `debug()`.
 */
const storage = localstorage();
/**
 * Colors.
 */
const colors = [
    '#0000CC',
    '#0000FF',
    '#0033CC',
    '#0033FF',
    '#0066CC',
    '#0066FF',
    '#0099CC',
    '#0099FF',
    '#00CC00',
    '#00CC33',
    '#00CC66',
    '#00CC99',
    '#00CCCC',
    '#00CCFF',
    '#3300CC',
    '#3300FF',
    '#3333CC',
    '#3333FF',
    '#3366CC',
    '#3366FF',
    '#3399CC',
    '#3399FF',
    '#33CC00',
    '#33CC33',
    '#33CC66',
    '#33CC99',
    '#33CCCC',
    '#33CCFF',
    '#6600CC',
    '#6600FF',
    '#6633CC',
    '#6633FF',
    '#66CC00',
    '#66CC33',
    '#9900CC',
    '#9900FF',
    '#9933CC',
    '#9933FF',
    '#99CC00',
    '#99CC33',
    '#CC0000',
    '#CC0033',
    '#CC0066',
    '#CC0099',
    '#CC00CC',
    '#CC00FF',
    '#CC3300',
    '#CC3333',
    '#CC3366',
    '#CC3399',
    '#CC33CC',
    '#CC33FF',
    '#CC6600',
    '#CC6633',
    '#CC9900',
    '#CC9933',
    '#CCCC00',
    '#CCCC33',
    '#FF0000',
    '#FF0033',
    '#FF0066',
    '#FF0099',
    '#FF00CC',
    '#FF00FF',
    '#FF3300',
    '#FF3333',
    '#FF3366',
    '#FF3399',
    '#FF33CC',
    '#FF33FF',
    '#FF6600',
    '#FF6633',
    '#FF9900',
    '#FF9933',
    '#FFCC00',
    '#FFCC33'
];
/**
 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
 * and the Firebug extension (any Firefox version) are known
 * to support "%c" CSS customizations.
 *
 * TODO: add a `localStorage` variable to explicitly enable/disable colors
 */
// eslint-disable-next-line complexity
function useColors() {
    // NB: In an Electron preload script, document will be defined but not fully
    // initialized. Since we know we're in Chrome, we'll just detect this case
    // explicitly
    // @ts-expect-error window.process.type and window.process.__nwjs are not in the types
    if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
        return true;
    }
    // Internet Explorer and Edge do not support colors.
    if (typeof navigator !== 'undefined' && (navigator.userAgent?.toLowerCase().match(/(edge|trident)\/(\d+)/) != null)) {
        return false;
    }
    // Is webkit? http://stackoverflow.com/a/16459606/376773
    // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
    // @ts-expect-error document.documentElement.style.WebkitAppearance is not in the types
    return (typeof document !== 'undefined' && document.documentElement?.style?.WebkitAppearance) ||
        // Is firebug? http://stackoverflow.com/a/398120/376773
        // @ts-expect-error window.console.firebug and window.console.exception are not in the types
        (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
        // Is firefox >= v31?
        // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
        (typeof navigator !== 'undefined' && (navigator.userAgent?.toLowerCase().match(/firefox\/(\d+)/) != null) && parseInt(RegExp.$1, 10) >= 31) ||
        // Double check webkit in userAgent just in case we are in a worker
        (typeof navigator !== 'undefined' && navigator.userAgent?.toLowerCase().match(/applewebkit\/(\d+)/));
}
/**
 * Colorize log arguments if enabled.
 */
function formatArgs(args) {
    args[0] = (this.useColors ? '%c' : '') +
        this.namespace +
        (this.useColors ? ' %c' : ' ') +
        args[0] +
        (this.useColors ? '%c ' : ' ') +
        '+' + ms(this.diff);
    if (!this.useColors) {
        return;
    }
    const c = 'color: ' + this.color;
    args.splice(1, 0, c, 'color: inherit');
    // The final "%c" is somewhat tricky, because there could be other
    // arguments passed either before or after the %c, so we need to
    // figure out the correct index to insert the CSS into
    let index = 0;
    let lastC = 0;
    args[0].replace(/%[a-zA-Z%]/g, (match) => {
        if (match === '%%') {
            return;
        }
        index++;
        if (match === '%c') {
            // We only are interested in the *last* %c
            // (the user may have provided their own)
            lastC = index;
        }
    });
    args.splice(lastC, 0, c);
}
/**
 * Invokes `console.debug()` when available.
 * No-op when `console.debug` is not a "function".
 * If `console.debug` is not available, falls back
 * to `console.log`.
 */
const log$a = console.debug ?? console.log ?? (() => { });
/**
 * Save `namespaces`.
 *
 * @param {string} namespaces
 */
function save(namespaces) {
    try {
        if (namespaces) {
            storage?.setItem('debug', namespaces);
        }
        else {
            storage?.removeItem('debug');
        }
    }
    catch (error) {
        // Swallow
        // XXX (@Qix-) should we be logging these?
    }
}
/**
 * Load `namespaces`.
 *
 * @returns {string} returns the previously persisted debug modes
 */
function load() {
    let r;
    try {
        r = storage?.getItem('debug');
    }
    catch (error) {
        // Swallow
        // XXX (@Qix-) should we be logging these?
    }
    // If debug isn't set in LS, and we're in Electron, try to load $DEBUG
    if (!r && typeof globalThis.process !== 'undefined' && 'env' in globalThis.process) {
        r = globalThis.process.env.DEBUG;
    }
    return r;
}
/**
 * Localstorage attempts to return the localstorage.
 *
 * This is necessary because safari throws
 * when a user disables cookies/localstorage
 * and you attempt to access it.
 */
function localstorage() {
    try {
        // TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
        // The Browser also has localStorage in the global context.
        return localStorage;
    }
    catch (error) {
        // Swallow
        // XXX (@Qix-) should we be logging these?
    }
}
function setupFormatters(formatters) {
    /**
     * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
     */
    formatters.j = function (v) {
        try {
            return JSON.stringify(v);
        }
        catch (error) {
            return '[UnexpectedJSONParseError]: ' + error.message;
        }
    };
}
var weald = setup({ formatArgs, save, load, useColors, setupFormatters, colors, storage, log: log$a });

/**
 * @packageDocumentation
 *
 * A logger for libp2p based on the venerable [debug](https://www.npmjs.com/package/debug) module.
 *
 * @example
 *
 * ```TypeScript
 * import { logger } from '@libp2p/logger'
 *
 * const log = logger('libp2p:my:component:name')
 *
 * try {
 *   // an operation
 *   log('something happened: %s', 'it was ok')
 * } catch (err) {
 *   log.error('something bad happened: %o', err)
 * }
 *
 * log('with this peer: %p', {})
 * log('and this base58btc: %b', Uint8Array.from([0, 1, 2, 3]))
 * log('and this base32: %t', Uint8Array.from([4, 5, 6, 7]))
 * ```
 *
 * ```console
 * $ DEBUG=libp2p:* node index.js
 * something happened: it was ok
 * something bad happened: <stack trace>
 * with this peer: 12D3Foo
 * with this base58btc: Qmfoo
 * with this base32: bafyfoo
 * ```
 */
// Add a formatter for converting to a base58 string
weald.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc.baseEncode(v);
};
// Add a formatter for converting to a base32 string
weald.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$2.baseEncode(v);
};
// Add a formatter for converting to a base64 string
weald.formatters.m = (v) => {
    return v == null ? 'undefined' : base64.baseEncode(v);
};
// Add a formatter for stringifying peer ids
weald.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
weald.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
weald.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
weald.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
/**
 * Create a component logger
 *
 * @example
 *
 * ```TypeScript
 * import { defaultLogger } from '@libp2p/logger'
 * import { peerIdFromString } from '@libp2p/peer-id'
 *
 * const logger = defaultLogger()
 *
 * const log = logger.forComponent('my-component')
 * log.info('hello world')
 * // logs "my-component hello world"
 * ```
 */
function defaultLogger() {
    return {
        forComponent(name) {
            return logger$2(name);
        }
    };
}
/**
 * Creates a logger for the passed component name.
 *
 * @example
 *
 * ```TypeScript
 * import { logger } from '@libp2p/logger'
 *
 * const log = logger('my-component')
 * log.info('hello world')
 * // logs "my-component hello world"
 * ```
 */
function logger$2(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (weald.enabled(`${name}:trace`) && weald.names.map((r) => r.toString()).find((n) => n.includes(':trace')) != null) {
        trace = weald(`${name}:trace`);
    }
    return Object.assign(weald(name), {
        error: weald(`${name}:error`),
        trace
    });
}

/**
 * Calls the passed map function on every entry of the passed iterable iterator
 */
function mapIterable(iter, map) {
    const iterator = {
        [Symbol.iterator]: () => {
            return iterator;
        },
        next: () => {
            const next = iter.next();
            const val = next.value;
            if (next.done === true || val == null) {
                const result = {
                    done: true,
                    value: undefined
                };
                return result;
            }
            return {
                done: false,
                value: map(val)
            };
        }
    };
    return iterator;
}

/**
 * We can't use PeerIds as map keys because map keys are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```TypeScript
 * import { peerMap } from '@libp2p/peer-collections'
 *
 * const map = peerMap<string>()
 * map.set(peerId, 'value')
 * ```
 */
class PeerMap {
    map;
    constructor(map) {
        this.map = new Map();
        if (map != null) {
            for (const [key, value] of map.entries()) {
                this.map.set(key.toString(), value);
            }
        }
    }
    [Symbol.iterator]() {
        return this.entries();
    }
    clear() {
        this.map.clear();
    }
    delete(peer) {
        return this.map.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.map.entries(), (val) => {
            return [peerIdFromString(val[0]), val[1]];
        });
    }
    forEach(fn) {
        this.map.forEach((value, key) => {
            fn(value, peerIdFromString(key), this);
        });
    }
    get(peer) {
        return this.map.get(peer.toString());
    }
    has(peer) {
        return this.map.has(peer.toString());
    }
    set(peer, value) {
        this.map.set(peer.toString(), value);
    }
    keys() {
        return mapIterable(this.map.keys(), (val) => {
            return peerIdFromString(val);
        });
    }
    values() {
        return this.map.values();
    }
    get size() {
        return this.map.size;
    }
}

/**
 * We can't use PeerIds as set entries because set entries are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```TypeScript
 * import { peerSet } from '@libp2p/peer-collections'
 *
 * const set = peerSet()
 * set.add(peerId)
 * ```
 */
class PeerSet {
    set;
    constructor(set) {
        this.set = new Set();
        if (set != null) {
            for (const key of set) {
                this.set.add(key.toString());
            }
        }
    }
    get size() {
        return this.set.size;
    }
    [Symbol.iterator]() {
        return this.values();
    }
    add(peer) {
        this.set.add(peer.toString());
    }
    clear() {
        this.set.clear();
    }
    delete(peer) {
        this.set.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.set.entries(), (val) => {
            const peerId = peerIdFromString(val[0]);
            return [peerId, peerId];
        });
    }
    forEach(predicate) {
        this.set.forEach((str) => {
            const id = peerIdFromString(str);
            predicate(id, id, this);
        });
    }
    has(peer) {
        return this.set.has(peer.toString());
    }
    values() {
        return mapIterable(this.set.values(), (val) => {
            return peerIdFromString(val);
        });
    }
    intersection(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            if (this.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    difference(other) {
        const output = new PeerSet();
        for (const peerId of this) {
            if (!other.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    union(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            output.add(peerId);
        }
        for (const peerId of this) {
            output.add(peerId);
        }
        return output;
    }
}

var murmurHash3js = {exports: {}};

/* jshint -W086: true */

(function (module, exports) {
(function (root, undefined$1) {

	    // Create a local object that'll be exported or referenced globally.
	    var library = {
	        'version': '3.0.0',
	        'x86': {},
	        'x64': {},
	        'inputValidation': true
	    };

	    // PRIVATE FUNCTIONS
	    // -----------------

	    function _validBytes(bytes) {
	        // check the input is an array or a typed array
	        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {
	            return false;
	        }

	        // check all bytes are actually bytes
	        for (var i = 0; i < bytes.length; i++) {
	            if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {
	                return false;
	            }
	        }
	        return true;
	    }

	    function _x86Multiply(m, n) {
	        //
	        // Given two 32bit ints, returns the two multiplied together as a
	        // 32bit int.
	        //

	        return ((m & 0xffff) * n) + ((((m >>> 16) * n) & 0xffff) << 16);
	    }

	    function _x86Rotl(m, n) {
	        //
	        // Given a 32bit int and an int representing a number of bit positions,
	        // returns the 32bit int rotated left by that number of positions.
	        //

	        return (m << n) | (m >>> (32 - n));
	    }

	    function _x86Fmix(h) {
	        //
	        // Given a block, returns murmurHash3's final x86 mix of that block.
	        //

	        h ^= h >>> 16;
	        h = _x86Multiply(h, 0x85ebca6b);
	        h ^= h >>> 13;
	        h = _x86Multiply(h, 0xc2b2ae35);
	        h ^= h >>> 16;

	        return h;
	    }

	    function _x64Add(m, n) {
	        //
	        // Given two 64bit ints (as an array of two 32bit ints) returns the two
	        // added together as a 64bit int (as an array of two 32bit ints).
	        //

	        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];
	        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];
	        var o = [0, 0, 0, 0];

	        o[3] += m[3] + n[3];
	        o[2] += o[3] >>> 16;
	        o[3] &= 0xffff;

	        o[2] += m[2] + n[2];
	        o[1] += o[2] >>> 16;
	        o[2] &= 0xffff;

	        o[1] += m[1] + n[1];
	        o[0] += o[1] >>> 16;
	        o[1] &= 0xffff;

	        o[0] += m[0] + n[0];
	        o[0] &= 0xffff;

	        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];
	    }

	    function _x64Multiply(m, n) {
	        //
	        // Given two 64bit ints (as an array of two 32bit ints) returns the two
	        // multiplied together as a 64bit int (as an array of two 32bit ints).
	        //

	        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];
	        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];
	        var o = [0, 0, 0, 0];

	        o[3] += m[3] * n[3];
	        o[2] += o[3] >>> 16;
	        o[3] &= 0xffff;

	        o[2] += m[2] * n[3];
	        o[1] += o[2] >>> 16;
	        o[2] &= 0xffff;

	        o[2] += m[3] * n[2];
	        o[1] += o[2] >>> 16;
	        o[2] &= 0xffff;

	        o[1] += m[1] * n[3];
	        o[0] += o[1] >>> 16;
	        o[1] &= 0xffff;

	        o[1] += m[2] * n[2];
	        o[0] += o[1] >>> 16;
	        o[1] &= 0xffff;

	        o[1] += m[3] * n[1];
	        o[0] += o[1] >>> 16;
	        o[1] &= 0xffff;

	        o[0] += (m[0] * n[3]) + (m[1] * n[2]) + (m[2] * n[1]) + (m[3] * n[0]);
	        o[0] &= 0xffff;

	        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];
	    }

	    function _x64Rotl(m, n) {
	        //
	        // Given a 64bit int (as an array of two 32bit ints) and an int
	        // representing a number of bit positions, returns the 64bit int (as an
	        // array of two 32bit ints) rotated left by that number of positions.
	        //

	        n %= 64;

	        if (n === 32) {
	            return [m[1], m[0]];
	        } else if (n < 32) {
	            return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];
	        } else {
	            n -= 32;
	            return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];
	        }
	    }

	    function _x64LeftShift(m, n) {
	        //
	        // Given a 64bit int (as an array of two 32bit ints) and an int
	        // representing a number of bit positions, returns the 64bit int (as an
	        // array of two 32bit ints) shifted left by that number of positions.
	        //

	        n %= 64;

	        if (n === 0) {
	            return m;
	        } else if (n < 32) {
	            return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];
	        } else {
	            return [m[1] << (n - 32), 0];
	        }
	    }

	    function _x64Xor(m, n) {
	        //
	        // Given two 64bit ints (as an array of two 32bit ints) returns the two
	        // xored together as a 64bit int (as an array of two 32bit ints).
	        //

	        return [m[0] ^ n[0], m[1] ^ n[1]];
	    }

	    function _x64Fmix(h) {
	        //
	        // Given a block, returns murmurHash3's final x64 mix of that block.
	        // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the
	        // only place where we need to right shift 64bit ints.)
	        //

	        h = _x64Xor(h, [0, h[0] >>> 1]);
	        h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);
	        h = _x64Xor(h, [0, h[0] >>> 1]);
	        h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);
	        h = _x64Xor(h, [0, h[0] >>> 1]);

	        return h;
	    }

	    // PUBLIC FUNCTIONS
	    // ----------------

	    library.x86.hash32 = function (bytes, seed) {
	        //
	        // Given a string and an optional seed as an int, returns a 32 bit hash
	        // using the x86 flavor of MurmurHash3, as an unsigned int.
	        //
	        if (library.inputValidation && !_validBytes(bytes)) {
	            return undefined$1;
	        }
	        seed = seed || 0;

	        var remainder = bytes.length % 4;
	        var blocks = bytes.length - remainder;

	        var h1 = seed;

	        var k1 = 0;

	        var c1 = 0xcc9e2d51;
	        var c2 = 0x1b873593;

	        for (var i = 0; i < blocks; i = i + 4) {
	            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);

	            k1 = _x86Multiply(k1, c1);
	            k1 = _x86Rotl(k1, 15);
	            k1 = _x86Multiply(k1, c2);

	            h1 ^= k1;
	            h1 = _x86Rotl(h1, 13);
	            h1 = _x86Multiply(h1, 5) + 0xe6546b64;
	        }

	        k1 = 0;

	        switch (remainder) {
	            case 3:
	                k1 ^= bytes[i + 2] << 16;

	            case 2:
	                k1 ^= bytes[i + 1] << 8;

	            case 1:
	                k1 ^= bytes[i];
	                k1 = _x86Multiply(k1, c1);
	                k1 = _x86Rotl(k1, 15);
	                k1 = _x86Multiply(k1, c2);
	                h1 ^= k1;
	        }

	        h1 ^= bytes.length;
	        h1 = _x86Fmix(h1);

	        return h1 >>> 0;
	    };

	    library.x86.hash128 = function (bytes, seed) {
	        //
	        // Given a string and an optional seed as an int, returns a 128 bit
	        // hash using the x86 flavor of MurmurHash3, as an unsigned hex.
	        //
	        if (library.inputValidation && !_validBytes(bytes)) {
	            return undefined$1;
	        }

	        seed = seed || 0;
	        var remainder = bytes.length % 16;
	        var blocks = bytes.length - remainder;

	        var h1 = seed;
	        var h2 = seed;
	        var h3 = seed;
	        var h4 = seed;

	        var k1 = 0;
	        var k2 = 0;
	        var k3 = 0;
	        var k4 = 0;

	        var c1 = 0x239b961b;
	        var c2 = 0xab0e9789;
	        var c3 = 0x38b34ae5;
	        var c4 = 0xa1e38b93;

	        for (var i = 0; i < blocks; i = i + 16) {
	            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);
	            k2 = (bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24);
	            k3 = (bytes[i + 8]) | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24);
	            k4 = (bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24);

	            k1 = _x86Multiply(k1, c1);
	            k1 = _x86Rotl(k1, 15);
	            k1 = _x86Multiply(k1, c2);
	            h1 ^= k1;

	            h1 = _x86Rotl(h1, 19);
	            h1 += h2;
	            h1 = _x86Multiply(h1, 5) + 0x561ccd1b;

	            k2 = _x86Multiply(k2, c2);
	            k2 = _x86Rotl(k2, 16);
	            k2 = _x86Multiply(k2, c3);
	            h2 ^= k2;

	            h2 = _x86Rotl(h2, 17);
	            h2 += h3;
	            h2 = _x86Multiply(h2, 5) + 0x0bcaa747;

	            k3 = _x86Multiply(k3, c3);
	            k3 = _x86Rotl(k3, 17);
	            k3 = _x86Multiply(k3, c4);
	            h3 ^= k3;

	            h3 = _x86Rotl(h3, 15);
	            h3 += h4;
	            h3 = _x86Multiply(h3, 5) + 0x96cd1c35;

	            k4 = _x86Multiply(k4, c4);
	            k4 = _x86Rotl(k4, 18);
	            k4 = _x86Multiply(k4, c1);
	            h4 ^= k4;

	            h4 = _x86Rotl(h4, 13);
	            h4 += h1;
	            h4 = _x86Multiply(h4, 5) + 0x32ac3b17;
	        }

	        k1 = 0;
	        k2 = 0;
	        k3 = 0;
	        k4 = 0;

	        switch (remainder) {
	            case 15:
	                k4 ^= bytes[i + 14] << 16;

	            case 14:
	                k4 ^= bytes[i + 13] << 8;

	            case 13:
	                k4 ^= bytes[i + 12];
	                k4 = _x86Multiply(k4, c4);
	                k4 = _x86Rotl(k4, 18);
	                k4 = _x86Multiply(k4, c1);
	                h4 ^= k4;

	            case 12:
	                k3 ^= bytes[i + 11] << 24;

	            case 11:
	                k3 ^= bytes[i + 10] << 16;

	            case 10:
	                k3 ^= bytes[i + 9] << 8;

	            case 9:
	                k3 ^= bytes[i + 8];
	                k3 = _x86Multiply(k3, c3);
	                k3 = _x86Rotl(k3, 17);
	                k3 = _x86Multiply(k3, c4);
	                h3 ^= k3;

	            case 8:
	                k2 ^= bytes[i + 7] << 24;

	            case 7:
	                k2 ^= bytes[i + 6] << 16;

	            case 6:
	                k2 ^= bytes[i + 5] << 8;

	            case 5:
	                k2 ^= bytes[i + 4];
	                k2 = _x86Multiply(k2, c2);
	                k2 = _x86Rotl(k2, 16);
	                k2 = _x86Multiply(k2, c3);
	                h2 ^= k2;

	            case 4:
	                k1 ^= bytes[i + 3] << 24;

	            case 3:
	                k1 ^= bytes[i + 2] << 16;

	            case 2:
	                k1 ^= bytes[i + 1] << 8;

	            case 1:
	                k1 ^= bytes[i];
	                k1 = _x86Multiply(k1, c1);
	                k1 = _x86Rotl(k1, 15);
	                k1 = _x86Multiply(k1, c2);
	                h1 ^= k1;
	        }

	        h1 ^= bytes.length;
	        h2 ^= bytes.length;
	        h3 ^= bytes.length;
	        h4 ^= bytes.length;

	        h1 += h2;
	        h1 += h3;
	        h1 += h4;
	        h2 += h1;
	        h3 += h1;
	        h4 += h1;

	        h1 = _x86Fmix(h1);
	        h2 = _x86Fmix(h2);
	        h3 = _x86Fmix(h3);
	        h4 = _x86Fmix(h4);

	        h1 += h2;
	        h1 += h3;
	        h1 += h4;
	        h2 += h1;
	        h3 += h1;
	        h4 += h1;

	        return ("00000000" + (h1 >>> 0).toString(16)).slice(-8) + ("00000000" + (h2 >>> 0).toString(16)).slice(-8) + ("00000000" + (h3 >>> 0).toString(16)).slice(-8) + ("00000000" + (h4 >>> 0).toString(16)).slice(-8);
	    };

	    library.x64.hash128 = function (bytes, seed) {
	        //
	        // Given a string and an optional seed as an int, returns a 128 bit
	        // hash using the x64 flavor of MurmurHash3, as an unsigned hex.
	        //
	        if (library.inputValidation && !_validBytes(bytes)) {
	            return undefined$1;
	        }
	        seed = seed || 0;

	        var remainder = bytes.length % 16;
	        var blocks = bytes.length - remainder;

	        var h1 = [0, seed];
	        var h2 = [0, seed];

	        var k1 = [0, 0];
	        var k2 = [0, 0];

	        var c1 = [0x87c37b91, 0x114253d5];
	        var c2 = [0x4cf5ad43, 0x2745937f];

	        for (var i = 0; i < blocks; i = i + 16) {
	            k1 = [(bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24), (bytes[i]) |
	                (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24)];
	            k2 = [(bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24), (bytes[i + 8]) |
	                (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24)];

	            k1 = _x64Multiply(k1, c1);
	            k1 = _x64Rotl(k1, 31);
	            k1 = _x64Multiply(k1, c2);
	            h1 = _x64Xor(h1, k1);

	            h1 = _x64Rotl(h1, 27);
	            h1 = _x64Add(h1, h2);
	            h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);

	            k2 = _x64Multiply(k2, c2);
	            k2 = _x64Rotl(k2, 33);
	            k2 = _x64Multiply(k2, c1);
	            h2 = _x64Xor(h2, k2);

	            h2 = _x64Rotl(h2, 31);
	            h2 = _x64Add(h2, h1);
	            h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);
	        }

	        k1 = [0, 0];
	        k2 = [0, 0];

	        switch (remainder) {
	            case 15:
	                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));

	            case 14:
	                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));

	            case 13:
	                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));

	            case 12:
	                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));

	            case 11:
	                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));

	            case 10:
	                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));

	            case 9:
	                k2 = _x64Xor(k2, [0, bytes[i + 8]]);
	                k2 = _x64Multiply(k2, c2);
	                k2 = _x64Rotl(k2, 33);
	                k2 = _x64Multiply(k2, c1);
	                h2 = _x64Xor(h2, k2);

	            case 8:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));

	            case 7:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));

	            case 6:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));

	            case 5:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));

	            case 4:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));

	            case 3:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));

	            case 2:
	                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));

	            case 1:
	                k1 = _x64Xor(k1, [0, bytes[i]]);
	                k1 = _x64Multiply(k1, c1);
	                k1 = _x64Rotl(k1, 31);
	                k1 = _x64Multiply(k1, c2);
	                h1 = _x64Xor(h1, k1);
	        }

	        h1 = _x64Xor(h1, [0, bytes.length]);
	        h2 = _x64Xor(h2, [0, bytes.length]);

	        h1 = _x64Add(h1, h2);
	        h2 = _x64Add(h2, h1);

	        h1 = _x64Fmix(h1);
	        h2 = _x64Fmix(h2);

	        h1 = _x64Add(h1, h2);
	        h2 = _x64Add(h2, h1);

	        return ("00000000" + (h1[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h1[1] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[1] >>> 0).toString(16)).slice(-8);
	    };

	    // INITIALIZATION
	    // --------------

	    // Export murmurHash3 for CommonJS, either as an AMD module or just as part
	    // of the global object.
	    {

	        if (module.exports) {
	            exports = module.exports = library;
	        }

	        exports.murmurHash3 = library;

	    }
	})(); 
} (murmurHash3js, murmurHash3js.exports));

const MAX_FINGERPRINT_SIZE = 64;
class Fingerprint {
    fp;
    h;
    seed;
    constructor(buf, hash, seed, fingerprintSize = 2) {
        if (fingerprintSize > MAX_FINGERPRINT_SIZE) {
            throw new TypeError('Invalid Fingerprint Size');
        }
        const fnv = hash.hashV(buf, seed);
        const fp = alloc$2(fingerprintSize);
        for (let i = 0; i < fp.length; i++) {
            fp[i] = fnv[i];
        }
        if (fp.length === 0) {
            fp[0] = 7;
        }
        this.fp = fp;
        this.h = hash;
        this.seed = seed;
    }
    hash() {
        return this.h.hash(this.fp, this.seed);
    }
    equals(other) {
        if (!(other?.fp instanceof Uint8Array)) {
            return false;
        }
        return equals(this.fp, other.fp);
    }
}

function getRandomInt(min, max) {
    return Math.floor(Math.random() * (max - min)) + min;
}

class Bucket {
    contents;
    constructor(size) {
        this.contents = new Array(size).fill(null);
    }
    has(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        return this.contents.some((fp) => {
            return fingerprint.equals(fp);
        });
    }
    add(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        for (let i = 0; i < this.contents.length; i++) {
            if (this.contents[i] == null) {
                this.contents[i] = fingerprint;
                return true;
            }
        }
        return true;
    }
    swap(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        const i = getRandomInt(0, this.contents.length - 1);
        const current = this.contents[i];
        this.contents[i] = fingerprint;
        return current;
    }
    remove(fingerprint) {
        if (!(fingerprint instanceof Fingerprint)) {
            throw new TypeError('Invalid Fingerprint');
        }
        const found = this.contents.findIndex((fp) => {
            return fingerprint.equals(fp);
        });
        if (found > -1) {
            this.contents[found] = null;
            return true;
        }
        else {
            return false;
        }
    }
}

// FNV_PRIMES and FNV_OFFSETS from
// http://www.isthe.com/chongo/tech/comp/fnv/index.html#FNV-param

const FNV_PRIMES = {
	32: 16_777_619n,
	64: 1_099_511_628_211n,
	128: 309_485_009_821_345_068_724_781_371n,
	256: 374_144_419_156_711_147_060_143_317_175_368_453_031_918_731_002_211n,
	512: 35_835_915_874_844_867_368_919_076_489_095_108_449_946_327_955_754_392_558_399_825_615_420_669_938_882_575_126_094_039_892_345_713_852_759n,
	1024: 5_016_456_510_113_118_655_434_598_811_035_278_955_030_765_345_404_790_744_303_017_523_831_112_055_108_147_451_509_157_692_220_295_382_716_162_651_878_526_895_249_385_292_291_816_524_375_083_746_691_371_804_094_271_873_160_484_737_966_720_260_389_217_684_476_157_468_082_573n,
};

const FNV_OFFSETS = {
	32: 2_166_136_261n,
	64: 14_695_981_039_346_656_037n,
	128: 144_066_263_297_769_815_596_495_629_667_062_367_629n,
	256: 100_029_257_958_052_580_907_070_968_620_625_704_837_092_796_014_241_193_945_225_284_501_741_471_925_557n,
	512: 9_659_303_129_496_669_498_009_435_400_716_310_466_090_418_745_672_637_896_108_374_329_434_462_657_994_582_932_197_716_438_449_813_051_892_206_539_805_784_495_328_239_340_083_876_191_928_701_583_869_517_785n,
	1024: 14_197_795_064_947_621_068_722_070_641_403_218_320_880_622_795_441_933_960_878_474_914_617_582_723_252_296_732_303_717_722_150_864_096_521_202_355_549_365_628_174_669_108_571_814_760_471_015_076_148_029_755_969_804_077_320_157_692_458_563_003_215_304_957_150_157_403_644_460_363_550_505_412_711_285_966_361_610_267_868_082_893_823_963_790_439_336_411_086_884_584_107_735_010_676_915n,
};

const cachedEncoder = new globalThis.TextEncoder();

function fnv1aUint8Array(uint8Array, size) {
	const fnvPrime = FNV_PRIMES[size];
	let hash = FNV_OFFSETS[size];

	// eslint-disable-next-line unicorn/no-for-loop -- This is a performance-sensitive loop
	for (let index = 0; index < uint8Array.length; index++) {
		hash ^= BigInt(uint8Array[index]);
		hash = BigInt.asUintN(size, hash * fnvPrime);
	}

	return hash;
}

function fnv1aEncodeInto(string, size, utf8Buffer) {
	if (utf8Buffer.length === 0) {
		throw new Error('The `utf8Buffer` option must have a length greater than zero');
	}

	const fnvPrime = FNV_PRIMES[size];
	let hash = FNV_OFFSETS[size];
	let remaining = string;

	while (remaining.length > 0) {
		const result = cachedEncoder.encodeInto(remaining, utf8Buffer);
		remaining = remaining.slice(result.read);
		for (let index = 0; index < result.written; index++) {
			hash ^= BigInt(utf8Buffer[index]);
			hash = BigInt.asUintN(size, hash * fnvPrime);
		}
	}

	return hash;
}

function fnv1a$1(value, {size = 32, utf8Buffer} = {}) {
	if (!FNV_PRIMES[size]) {
		throw new Error('The `size` option must be one of 32, 64, 128, 256, 512, or 1024');
	}

	if (typeof value === 'string') {
		if (utf8Buffer) {
			return fnv1aEncodeInto(value, size, utf8Buffer);
		}

		value = cachedEncoder.encode(value);
	}

	return fnv1aUint8Array(value, size);
}

const fnv1a = {
    hash: (input) => {
        return Number(fnv1a$1(input, {
            size: 32
        }));
    },
    hashV: (input, seed) => {
        return numberToBuffer(fnv1a.hash(input, seed));
    }
};
function numberToBuffer(num) {
    let hex = num.toString(16);
    if (hex.length % 2 === 1) {
        hex = `0${hex}`;
    }
    return fromString(hex, 'base16');
}

const maxCuckooCount = 500;
class CuckooFilter {
    bucketSize;
    filterSize;
    fingerprintSize;
    buckets;
    count;
    hash;
    seed;
    constructor(init) {
        this.filterSize = init.filterSize;
        this.bucketSize = init.bucketSize ?? 4;
        this.fingerprintSize = init.fingerprintSize ?? 2;
        this.count = 0;
        this.buckets = [];
        this.hash = init.hash ?? fnv1a;
        this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));
    }
    add(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
        const j = this.hash.hash(item, this.seed) % this.filterSize;
        const k = (j ^ fingerprint.hash()) % this.filterSize;
        if (this.buckets[j] == null) {
            this.buckets[j] = new Bucket(this.bucketSize);
        }
        if (this.buckets[k] == null) {
            this.buckets[k] = new Bucket(this.bucketSize);
        }
        if (this.buckets[j].add(fingerprint) || this.buckets[k].add(fingerprint)) {
            this.count++;
            return true;
        }
        const rand = [j, k];
        let i = rand[getRandomInt(0, rand.length - 1)];
        if (this.buckets[i] == null) {
            this.buckets[i] = new Bucket(this.bucketSize);
        }
        for (let n = 0; n < maxCuckooCount; n++) {
            const swapped = this.buckets[i].swap(fingerprint);
            if (swapped == null) {
                continue;
            }
            i = (i ^ swapped.hash()) % this.filterSize;
            if (this.buckets[i] == null) {
                this.buckets[i] = new Bucket(this.bucketSize);
            }
            if (this.buckets[i].add(swapped)) {
                this.count++;
                return true;
            }
            else {
                continue;
            }
        }
        return false;
    }
    has(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
        const j = this.hash.hash(item, this.seed) % this.filterSize;
        const inJ = this.buckets[j]?.has(fingerprint) ?? false;
        if (inJ) {
            return inJ;
        }
        const k = (j ^ fingerprint.hash()) % this.filterSize;
        return this.buckets[k]?.has(fingerprint) ?? false;
    }
    remove(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
        const j = this.hash.hash(item, this.seed) % this.filterSize;
        const inJ = this.buckets[j]?.remove(fingerprint) ?? false;
        if (inJ) {
            this.count--;
            return inJ;
        }
        const k = (j ^ fingerprint.hash()) % this.filterSize;
        const inK = this.buckets[k]?.remove(fingerprint) ?? false;
        if (inK) {
            this.count--;
        }
        return inK;
    }
    get reliable() {
        return Math.floor(100 * (this.count / this.filterSize)) <= 90;
    }
}
// max load constants, defined in the cuckoo paper
const MAX_LOAD = {
    1: 0.5,
    2: 0.84,
    4: 0.95,
    8: 0.98
};
function calculateBucketSize(errorRate = 0.001) {
    if (errorRate > 0.002) {
        return 2;
    }
    if (errorRate > 0.00001) {
        return 4;
    }
    return 8;
}
function optimize(maxItems, errorRate = 0.001) {
    // https://www.eecs.harvard.edu/~michaelm/postscripts/cuckoo-conext2014.pdf
    // Section 5.1 Optimal Bucket Size
    const bucketSize = calculateBucketSize(errorRate);
    const load = MAX_LOAD[bucketSize];
    // https://stackoverflow.com/questions/57555236/how-to-size-a-cuckoo-filter/57617208#57617208
    const filterSize = Math.round(maxItems / load);
    const fingerprintSize = Math.min(Math.ceil(Math.log2(1 / errorRate) + Math.log2(2 * bucketSize)), MAX_FINGERPRINT_SIZE);
    return {
        filterSize,
        bucketSize,
        fingerprintSize
    };
}

class ScalableCuckooFilter {
    filterSize;
    bucketSize;
    fingerprintSize;
    scale;
    filterSeries;
    hash;
    seed;
    constructor(init) {
        this.bucketSize = init.bucketSize ?? 4;
        this.filterSize = init.filterSize ?? (1 << 18) / this.bucketSize;
        this.fingerprintSize = init.fingerprintSize ?? 2;
        this.scale = init.scale ?? 2;
        this.hash = init.hash ?? fnv1a;
        this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));
        this.filterSeries = [
            new CuckooFilter({
                filterSize: this.filterSize,
                bucketSize: this.bucketSize,
                fingerprintSize: this.fingerprintSize,
                hash: this.hash,
                seed: this.seed
            })
        ];
    }
    add(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        if (this.has(item)) {
            return true;
        }
        let current = this.filterSeries.find((cuckoo) => {
            return cuckoo.reliable;
        });
        if (current == null) {
            const curSize = this.filterSize * Math.pow(this.scale, this.filterSeries.length);
            current = new CuckooFilter({
                filterSize: curSize,
                bucketSize: this.bucketSize,
                fingerprintSize: this.fingerprintSize,
                hash: this.hash,
                seed: this.seed
            });
            this.filterSeries.push(current);
        }
        return current.add(item);
    }
    has(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        for (let i = 0; i < this.filterSeries.length; i++) {
            if (this.filterSeries[i].has(item)) {
                return true;
            }
        }
        return false;
    }
    remove(item) {
        if (typeof item === 'string') {
            item = fromString(item);
        }
        for (let i = 0; i < this.filterSeries.length; i++) {
            if (this.filterSeries[i].remove(item)) {
                return true;
            }
        }
        return false;
    }
    get count() {
        return this.filterSeries.reduce((acc, curr) => {
            return acc + curr.count;
        }, 0);
    }
}
function createScalableCuckooFilter(maxItems, errorRate = 0.001, options) {
    return new ScalableCuckooFilter({
        ...optimize(maxItems, errorRate),
        ...({})
    });
}

/**
 * @packageDocumentation
 *
 * Generate, import, and export PeerIDs.
 *
 * A Peer ID is the SHA-256 [multihash](https://github.com/multiformats/multihash) of a public key.
 *
 * The public key is a base64 encoded string of a protobuf containing an RSA DER buffer. This uses a node buffer to pass the base64 encoded public key protobuf to the multihash for ID generation.
 *
 * @example
 *
 * ```TypeScript
 * import { createEd25519PeerId } from '@libp2p/peer-id-factory'
 *
 * const peerId = await createEd25519PeerId()
 * console.log(peerId.toString())
 * ```
 *
 * ```bash
 * 12D3KooWRm8J3iL796zPFi2EtGGtUJn58AG67gcqzMFHZnnsTzqD
 * ```
 */
const createEd25519PeerId = async () => {
    const key = await generateKeyPair('Ed25519');
    const id = await createFromPrivKey(key);
    if (id.type === 'Ed25519') {
        return id;
    }
    throw new Error(`Generated unexpected PeerId type "${id.type}"`);
};
async function createFromPubKey(publicKey) {
    return peerIdFromKeys(marshalPublicKey(publicKey));
}
async function createFromPrivKey(privateKey) {
    return peerIdFromKeys(marshalPublicKey(privateKey.public), marshalPrivateKey(privateKey));
}
async function createFromJSON(obj) {
    return createFromParts(fromString(obj.id, 'base58btc'), obj.privKey != null ? fromString(obj.privKey, 'base64pad') : undefined, obj.pubKey != null ? fromString(obj.pubKey, 'base64pad') : undefined);
}
async function createFromParts(multihash, privKey, pubKey) {
    if (privKey != null) {
        const key = await unmarshalPrivateKey(privKey);
        return createFromPrivKey(key);
    }
    else if (pubKey != null) {
        const key = unmarshalPublicKey(pubKey);
        return createFromPubKey(key);
    }
    const peerId = peerIdFromBytes(multihash);
    if (peerId.type !== 'Ed25519' && peerId.type !== 'secp256k1' && peerId.type !== 'RSA') {
        // should not be possible since `multihash` is derived from keys and these
        // are the cryptographic peer id types
        throw new Error('Supplied PeerID is invalid');
    }
    return peerId;
}

var eventemitter3 = {exports: {}};

(function (module) {

	var has = Object.prototype.hasOwnProperty
	  , prefix = '~';

	/**
	 * Constructor to create a storage for our `EE` objects.
	 * An `Events` instance is a plain object whose properties are event names.
	 *
	 * @constructor
	 * @private
	 */
	function Events() {}

	//
	// We try to not inherit from `Object.prototype`. In some engines creating an
	// instance in this way is faster than calling `Object.create(null)` directly.
	// If `Object.create(null)` is not supported we prefix the event names with a
	// character to make sure that the built-in object properties are not
	// overridden or used as an attack vector.
	//
	if (Object.create) {
	  Events.prototype = Object.create(null);

	  //
	  // This hack is needed because the `__proto__` property is still inherited in
	  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
	  //
	  if (!new Events().__proto__) prefix = false;
	}

	/**
	 * Representation of a single event listener.
	 *
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
	 * @constructor
	 * @private
	 */
	function EE(fn, context, once) {
	  this.fn = fn;
	  this.context = context;
	  this.once = once || false;
	}

	/**
	 * Add a listener for a given event.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} once Specify if the listener is a one-time listener.
	 * @returns {EventEmitter}
	 * @private
	 */
	function addListener(emitter, event, fn, context, once) {
	  if (typeof fn !== 'function') {
	    throw new TypeError('The listener must be a function');
	  }

	  var listener = new EE(fn, context || emitter, once)
	    , evt = prefix ? prefix + event : event;

	  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
	  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
	  else emitter._events[evt] = [emitter._events[evt], listener];

	  return emitter;
	}

	/**
	 * Clear event by name.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} evt The Event name.
	 * @private
	 */
	function clearEvent(emitter, evt) {
	  if (--emitter._eventsCount === 0) emitter._events = new Events();
	  else delete emitter._events[evt];
	}

	/**
	 * Minimal `EventEmitter` interface that is molded against the Node.js
	 * `EventEmitter` interface.
	 *
	 * @constructor
	 * @public
	 */
	function EventEmitter() {
	  this._events = new Events();
	  this._eventsCount = 0;
	}

	/**
	 * Return an array listing the events for which the emitter has registered
	 * listeners.
	 *
	 * @returns {Array}
	 * @public
	 */
	EventEmitter.prototype.eventNames = function eventNames() {
	  var names = []
	    , events
	    , name;

	  if (this._eventsCount === 0) return names;

	  for (name in (events = this._events)) {
	    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
	  }

	  if (Object.getOwnPropertySymbols) {
	    return names.concat(Object.getOwnPropertySymbols(events));
	  }

	  return names;
	};

	/**
	 * Return the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Array} The registered listeners.
	 * @public
	 */
	EventEmitter.prototype.listeners = function listeners(event) {
	  var evt = prefix ? prefix + event : event
	    , handlers = this._events[evt];

	  if (!handlers) return [];
	  if (handlers.fn) return [handlers.fn];

	  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
	    ee[i] = handlers[i].fn;
	  }

	  return ee;
	};

	/**
	 * Return the number of listeners listening to a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Number} The number of listeners.
	 * @public
	 */
	EventEmitter.prototype.listenerCount = function listenerCount(event) {
	  var evt = prefix ? prefix + event : event
	    , listeners = this._events[evt];

	  if (!listeners) return 0;
	  if (listeners.fn) return 1;
	  return listeners.length;
	};

	/**
	 * Calls each of the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Boolean} `true` if the event had listeners, else `false`.
	 * @public
	 */
	EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return false;

	  var listeners = this._events[evt]
	    , len = arguments.length
	    , args
	    , i;

	  if (listeners.fn) {
	    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

	    switch (len) {
	      case 1: return listeners.fn.call(listeners.context), true;
	      case 2: return listeners.fn.call(listeners.context, a1), true;
	      case 3: return listeners.fn.call(listeners.context, a1, a2), true;
	      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;
	      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
	      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
	    }

	    for (i = 1, args = new Array(len -1); i < len; i++) {
	      args[i - 1] = arguments[i];
	    }

	    listeners.fn.apply(listeners.context, args);
	  } else {
	    var length = listeners.length
	      , j;

	    for (i = 0; i < length; i++) {
	      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

	      switch (len) {
	        case 1: listeners[i].fn.call(listeners[i].context); break;
	        case 2: listeners[i].fn.call(listeners[i].context, a1); break;
	        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;
	        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;
	        default:
	          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {
	            args[j - 1] = arguments[j];
	          }

	          listeners[i].fn.apply(listeners[i].context, args);
	      }
	    }
	  }

	  return true;
	};

	/**
	 * Add a listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.on = function on(event, fn, context) {
	  return addListener(this, event, fn, context, false);
	};

	/**
	 * Add a one-time listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.once = function once(event, fn, context) {
	  return addListener(this, event, fn, context, true);
	};

	/**
	 * Remove the listeners of a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn Only remove the listeners that match this function.
	 * @param {*} context Only remove the listeners that have this context.
	 * @param {Boolean} once Only remove one-time listeners.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return this;
	  if (!fn) {
	    clearEvent(this, evt);
	    return this;
	  }

	  var listeners = this._events[evt];

	  if (listeners.fn) {
	    if (
	      listeners.fn === fn &&
	      (!once || listeners.once) &&
	      (!context || listeners.context === context)
	    ) {
	      clearEvent(this, evt);
	    }
	  } else {
	    for (var i = 0, events = [], length = listeners.length; i < length; i++) {
	      if (
	        listeners[i].fn !== fn ||
	        (once && !listeners[i].once) ||
	        (context && listeners[i].context !== context)
	      ) {
	        events.push(listeners[i]);
	      }
	    }

	    //
	    // Reset the array, or remove it completely if we have no more listeners.
	    //
	    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
	    else clearEvent(this, evt);
	  }

	  return this;
	};

	/**
	 * Remove all listeners, or those of the specified event.
	 *
	 * @param {(String|Symbol)} [event] The event name.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
	  var evt;

	  if (event) {
	    evt = prefix ? prefix + event : event;
	    if (this._events[evt]) clearEvent(this, evt);
	  } else {
	    this._events = new Events();
	    this._eventsCount = 0;
	  }

	  return this;
	};

	//
	// Alias methods names because people roll like that.
	//
	EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
	EventEmitter.prototype.addListener = EventEmitter.prototype.on;

	//
	// Expose the prefix.
	//
	EventEmitter.prefixed = prefix;

	//
	// Allow `EventEmitter` to be imported as module namespace.
	//
	EventEmitter.EventEmitter = EventEmitter;

	//
	// Expose the module.
	//
	{
	  module.exports = EventEmitter;
	} 
} (eventemitter3));

var eventemitter3Exports = eventemitter3.exports;
var EventEmitter = /*@__PURE__*/getDefaultExportFromCjs(eventemitter3Exports);

let TimeoutError$1 = class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
};

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
let AbortError$2 = class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
};

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException = errorMessage => globalThis.DOMException === undefined
	? new AbortError$2(errorMessage)
	: new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason = signal => {
	const reason = signal.reason === undefined
		? getDOMException('This operation was aborted.')
		: signal.reason;

	return reason instanceof Error ? reason : getDOMException(reason);
};

function pTimeout(promise, options) {
	const {
		milliseconds,
		fallback,
		message,
		customTimers = {setTimeout, clearTimeout},
	} = options;

	let timer;

	const wrappedPromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason(signal));
			}

			signal.addEventListener('abort', () => {
				reject(getAbortedReason(signal));
			});
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			promise.then(resolve, reject);
			return;
		}

		// We create the error outside of `setTimeout` to preserve the stack trace.
		const timeoutError = new TimeoutError$1();

		timer = customTimers.setTimeout.call(undefined, () => {
			if (fallback) {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			if (message === false) {
				resolve();
			} else if (message instanceof Error) {
				reject(message);
			} else {
				timeoutError.message = message ?? `Promise timed out after ${milliseconds} milliseconds`;
				reject(timeoutError);
			}
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			}
		})();
	});

	const cancelablePromise = wrappedPromise.finally(() => {
		cancelablePromise.clear();
	});

	cancelablePromise.clear = () => {
		customTimers.clearTimeout.call(undefined, timer);
		timer = undefined;
	};

	return cancelablePromise;
}

// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound
// Used to compute insertion index to keep queue sorted after insertion
function lowerBound(array, value, comparator) {
    let first = 0;
    let count = array.length;
    while (count > 0) {
        const step = Math.trunc(count / 2);
        let it = first + step;
        if (comparator(array[it], value) <= 0) {
            first = ++it;
            count -= step + 1;
        }
        else {
            count = step;
        }
    }
    return first;
}

let PriorityQueue$1 = class PriorityQueue {
    #queue = [];
    enqueue(run, options) {
        options = {
            priority: 0,
            ...options,
        };
        const element = {
            priority: options.priority,
            run,
        };
        if (this.size && this.#queue[this.size - 1].priority >= options.priority) {
            this.#queue.push(element);
            return;
        }
        const index = lowerBound(this.#queue, element, (a, b) => b.priority - a.priority);
        this.#queue.splice(index, 0, element);
    }
    dequeue() {
        const item = this.#queue.shift();
        return item?.run;
    }
    filter(options) {
        return this.#queue.filter((element) => element.priority === options.priority).map((element) => element.run);
    }
    get size() {
        return this.#queue.length;
    }
};

/**
Promise queue with concurrency control.
*/
class PQueue extends EventEmitter {
    #carryoverConcurrencyCount;
    #isIntervalIgnored;
    #intervalCount = 0;
    #intervalCap;
    #interval;
    #intervalEnd = 0;
    #intervalId;
    #timeoutId;
    #queue;
    #queueClass;
    #pending = 0;
    // The `!` is needed because of https://github.com/microsoft/TypeScript/issues/32194
    #concurrency;
    #isPaused;
    #throwOnTimeout;
    /**
    Per-operation timeout in milliseconds. Operations fulfill once `timeout` elapses if they haven't already.

    Applies to each future operation.
    */
    timeout;
    // TODO: The `throwOnTimeout` option should affect the return types of `add()` and `addAll()`
    constructor(options) {
        super();
        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
        options = {
            carryoverConcurrencyCount: false,
            intervalCap: Number.POSITIVE_INFINITY,
            interval: 0,
            concurrency: Number.POSITIVE_INFINITY,
            autoStart: true,
            queueClass: PriorityQueue$1,
            ...options,
        };
        if (!(typeof options.intervalCap === 'number' && options.intervalCap >= 1)) {
            throw new TypeError(`Expected \`intervalCap\` to be a number from 1 and up, got \`${options.intervalCap?.toString() ?? ''}\` (${typeof options.intervalCap})`);
        }
        if (options.interval === undefined || !(Number.isFinite(options.interval) && options.interval >= 0)) {
            throw new TypeError(`Expected \`interval\` to be a finite number >= 0, got \`${options.interval?.toString() ?? ''}\` (${typeof options.interval})`);
        }
        this.#carryoverConcurrencyCount = options.carryoverConcurrencyCount;
        this.#isIntervalIgnored = options.intervalCap === Number.POSITIVE_INFINITY || options.interval === 0;
        this.#intervalCap = options.intervalCap;
        this.#interval = options.interval;
        this.#queue = new options.queueClass();
        this.#queueClass = options.queueClass;
        this.concurrency = options.concurrency;
        this.timeout = options.timeout;
        this.#throwOnTimeout = options.throwOnTimeout === true;
        this.#isPaused = options.autoStart === false;
    }
    get #doesIntervalAllowAnother() {
        return this.#isIntervalIgnored || this.#intervalCount < this.#intervalCap;
    }
    get #doesConcurrentAllowAnother() {
        return this.#pending < this.#concurrency;
    }
    #next() {
        this.#pending--;
        this.#tryToStartAnother();
        this.emit('next');
    }
    #onResumeInterval() {
        this.#onInterval();
        this.#initializeIntervalIfNeeded();
        this.#timeoutId = undefined;
    }
    get #isIntervalPaused() {
        const now = Date.now();
        if (this.#intervalId === undefined) {
            const delay = this.#intervalEnd - now;
            if (delay < 0) {
                // Act as the interval was done
                // We don't need to resume it here because it will be resumed on line 160
                this.#intervalCount = (this.#carryoverConcurrencyCount) ? this.#pending : 0;
            }
            else {
                // Act as the interval is pending
                if (this.#timeoutId === undefined) {
                    this.#timeoutId = setTimeout(() => {
                        this.#onResumeInterval();
                    }, delay);
                }
                return true;
            }
        }
        return false;
    }
    #tryToStartAnother() {
        if (this.#queue.size === 0) {
            // We can clear the interval ("pause")
            // Because we can redo it later ("resume")
            if (this.#intervalId) {
                clearInterval(this.#intervalId);
            }
            this.#intervalId = undefined;
            this.emit('empty');
            if (this.#pending === 0) {
                this.emit('idle');
            }
            return false;
        }
        if (!this.#isPaused) {
            const canInitializeInterval = !this.#isIntervalPaused;
            if (this.#doesIntervalAllowAnother && this.#doesConcurrentAllowAnother) {
                const job = this.#queue.dequeue();
                if (!job) {
                    return false;
                }
                this.emit('active');
                job();
                if (canInitializeInterval) {
                    this.#initializeIntervalIfNeeded();
                }
                return true;
            }
        }
        return false;
    }
    #initializeIntervalIfNeeded() {
        if (this.#isIntervalIgnored || this.#intervalId !== undefined) {
            return;
        }
        this.#intervalId = setInterval(() => {
            this.#onInterval();
        }, this.#interval);
        this.#intervalEnd = Date.now() + this.#interval;
    }
    #onInterval() {
        if (this.#intervalCount === 0 && this.#pending === 0 && this.#intervalId) {
            clearInterval(this.#intervalId);
            this.#intervalId = undefined;
        }
        this.#intervalCount = this.#carryoverConcurrencyCount ? this.#pending : 0;
        this.#processQueue();
    }
    /**
    Executes all queued functions until it reaches the limit.
    */
    #processQueue() {
        // eslint-disable-next-line no-empty
        while (this.#tryToStartAnother()) { }
    }
    get concurrency() {
        return this.#concurrency;
    }
    set concurrency(newConcurrency) {
        if (!(typeof newConcurrency === 'number' && newConcurrency >= 1)) {
            throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${newConcurrency}\` (${typeof newConcurrency})`);
        }
        this.#concurrency = newConcurrency;
        this.#processQueue();
    }
    async #throwOnAbort(signal) {
        return new Promise((_resolve, reject) => {
            signal.addEventListener('abort', () => {
                reject(signal.reason);
            }, { once: true });
        });
    }
    async add(function_, options = {}) {
        options = {
            timeout: this.timeout,
            throwOnTimeout: this.#throwOnTimeout,
            ...options,
        };
        return new Promise((resolve, reject) => {
            this.#queue.enqueue(async () => {
                this.#pending++;
                this.#intervalCount++;
                try {
                    options.signal?.throwIfAborted();
                    let operation = function_({ signal: options.signal });
                    if (options.timeout) {
                        operation = pTimeout(Promise.resolve(operation), { milliseconds: options.timeout });
                    }
                    if (options.signal) {
                        operation = Promise.race([operation, this.#throwOnAbort(options.signal)]);
                    }
                    const result = await operation;
                    resolve(result);
                    this.emit('completed', result);
                }
                catch (error) {
                    if (error instanceof TimeoutError$1 && !options.throwOnTimeout) {
                        resolve();
                        return;
                    }
                    reject(error);
                    this.emit('error', error);
                }
                finally {
                    this.#next();
                }
            }, options);
            this.emit('add');
            this.#tryToStartAnother();
        });
    }
    async addAll(functions, options) {
        return Promise.all(functions.map(async (function_) => this.add(function_, options)));
    }
    /**
    Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)
    */
    start() {
        if (!this.#isPaused) {
            return this;
        }
        this.#isPaused = false;
        this.#processQueue();
        return this;
    }
    /**
    Put queue execution on hold.
    */
    pause() {
        this.#isPaused = true;
    }
    /**
    Clear the queue.
    */
    clear() {
        this.#queue = new this.#queueClass();
    }
    /**
    Can be called multiple times. Useful if you for example add additional items at a later time.

    @returns A promise that settles when the queue becomes empty.
    */
    async onEmpty() {
        // Instantly resolve if the queue is empty
        if (this.#queue.size === 0) {
            return;
        }
        await this.#onEvent('empty');
    }
    /**
    @returns A promise that settles when the queue size is less than the given limit: `queue.size < limit`.

    If you want to avoid having the queue grow beyond a certain size you can `await queue.onSizeLessThan()` before adding a new item.

    Note that this only limits the number of items waiting to start. There could still be up to `concurrency` jobs already running that this call does not include in its calculation.
    */
    async onSizeLessThan(limit) {
        // Instantly resolve if the queue is empty.
        if (this.#queue.size < limit) {
            return;
        }
        await this.#onEvent('next', () => this.#queue.size < limit);
    }
    /**
    The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.

    @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.
    */
    async onIdle() {
        // Instantly resolve if none pending and if nothing else is queued
        if (this.#pending === 0 && this.#queue.size === 0) {
            return;
        }
        await this.#onEvent('idle');
    }
    async #onEvent(event, filter) {
        return new Promise(resolve => {
            const listener = () => {
                if (filter && !filter()) {
                    return;
                }
                this.off(event, listener);
                resolve();
            };
            this.on(event, listener);
        });
    }
    /**
    Size of the queue, the number of queued items waiting to run.
    */
    get size() {
        return this.#queue.size;
    }
    /**
    Size of the queue, filtered by the given options.

    For example, this can be used to find the number of items remaining in the queue with a specific priority level.
    */
    sizeBy(options) {
        // eslint-disable-next-line unicorn/no-array-callback-reference
        return this.#queue.filter(options).length;
    }
    /**
    Number of running items (no longer in the queue).
    */
    get pending() {
        return this.#pending;
    }
    /**
    Whether the queue is currently paused.
    */
    get isPaused() {
        return this.#isPaused;
    }
}

const events = {};
const observable = (worker) => {
    worker.addEventListener('message', (event) => {
        observable.dispatchEvent('message', worker, event);
    });
    if (worker.port != null) {
        worker.port.addEventListener('message', (event) => {
            observable.dispatchEvent('message', worker, event);
        });
    }
};
observable.addEventListener = (type, fn) => {
    if (events[type] == null) {
        events[type] = [];
    }
    events[type].push(fn);
};
observable.removeEventListener = (type, fn) => {
    if (events[type] == null) {
        return;
    }
    events[type] = events[type]
        .filter(listener => listener === fn);
};
observable.dispatchEvent = function (type, worker, event) {
    if (events[type] == null) {
        return;
    }
    events[type].forEach(fn => fn(worker, event));
};

const WORKER_REQUEST_READ_LOCK = 'lock:worker:request-read';
const WORKER_RELEASE_READ_LOCK = 'lock:worker:release-read';
const MASTER_GRANT_READ_LOCK = 'lock:master:grant-read';
const WORKER_REQUEST_WRITE_LOCK = 'lock:worker:request-write';
const WORKER_RELEASE_WRITE_LOCK = 'lock:worker:release-write';
const MASTER_GRANT_WRITE_LOCK = 'lock:master:grant-write';

const nanoid = (size = 21) => {
    return Math.random().toString().substring(2);
};

const handleWorkerLockRequest = (emitter, masterEvent, requestType, releaseType, grantType) => {
    return (worker, event) => {
        if (event.data.type !== requestType) {
            return;
        }
        const requestEvent = {
            type: event.data.type,
            name: event.data.name,
            identifier: event.data.identifier
        };
        emitter.dispatchEvent(new MessageEvent(masterEvent, {
            data: {
                name: requestEvent.name,
                handler: async () => {
                    // grant lock to worker
                    worker.postMessage({
                        type: grantType,
                        name: requestEvent.name,
                        identifier: requestEvent.identifier
                    });
                    // wait for worker to finish
                    await new Promise((resolve) => {
                        const releaseEventListener = (event) => {
                            if (event == null || event.data == null) {
                                return;
                            }
                            const releaseEvent = {
                                type: event.data.type,
                                name: event.data.name,
                                identifier: event.data.identifier
                            };
                            if (releaseEvent.type === releaseType && releaseEvent.identifier === requestEvent.identifier) {
                                worker.removeEventListener('message', releaseEventListener);
                                resolve();
                            }
                        };
                        worker.addEventListener('message', releaseEventListener);
                    });
                }
            }
        }));
    };
};
const makeWorkerLockRequest = (name, requestType, grantType, releaseType) => {
    return async () => {
        const id = nanoid();
        globalThis.postMessage({
            type: requestType,
            identifier: id,
            name
        });
        return new Promise((resolve) => {
            const listener = (event) => {
                if (event == null || event.data == null) {
                    return;
                }
                const responseEvent = {
                    type: event.data.type,
                    identifier: event.data.identifier
                };
                if (responseEvent.type === grantType && responseEvent.identifier === id) {
                    globalThis.removeEventListener('message', listener);
                    // grant lock
                    resolve(() => {
                        // release lock
                        globalThis.postMessage({
                            type: releaseType,
                            identifier: id,
                            name
                        });
                    });
                }
            };
            globalThis.addEventListener('message', listener);
        });
    };
};
const defaultOptions$5 = {
    singleProcess: false
};
var impl = (options) => {
    options = Object.assign({}, defaultOptions$5, options);
    const isPrimary = Boolean(globalThis.document) || options.singleProcess;
    if (isPrimary) {
        const emitter = new EventTarget();
        observable.addEventListener('message', handleWorkerLockRequest(emitter, 'requestReadLock', WORKER_REQUEST_READ_LOCK, WORKER_RELEASE_READ_LOCK, MASTER_GRANT_READ_LOCK));
        observable.addEventListener('message', handleWorkerLockRequest(emitter, 'requestWriteLock', WORKER_REQUEST_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK));
        return emitter;
    }
    return {
        isWorker: true,
        readLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_READ_LOCK, MASTER_GRANT_READ_LOCK, WORKER_RELEASE_READ_LOCK),
        writeLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK)
    };
};

/**
 * @packageDocumentation
 *
 * - Reads occur concurrently
 * - Writes occur one at a time
 * - No reads occur while a write operation is in progress
 * - Locks can be created with different names
 * - Reads/writes can time out
 *
 * ## Usage
 *
 * ```javascript
 * import mortice from 'mortice'
 * import delay from 'delay'
 *
 * // the lock name & options objects are both optional
 * const mutex = mortice('my-lock', {
 *
 *   // how long before write locks time out (default: 24 hours)
 *   timeout: 30000,
 *
 *    // control how many read operations are executed concurrently (default: Infinity)
 *   concurrency: 5,
 *
 *   // by default the the lock will be held on the main thread, set this to true if the
 *   // a lock should reside on each worker (default: false)
 *   singleProcess: false
 * })
 *
 * Promise.all([
 *   (async () => {
 *     const release = await mutex.readLock()
 *
 *     try {
 *       console.info('read 1')
 *     } finally {
 *       release()
 *     }
 *   })(),
 *   (async () => {
 *     const release = await mutex.readLock()
 *
 *     try {
 *       console.info('read 2')
 *     } finally {
 *       release()
 *     }
 *   })(),
 *   (async () => {
 *     const release = await mutex.writeLock()
 *
 *     try {
 *       await delay(1000)
 *
 *       console.info('write 1')
 *     } finally {
 *       release()
 *     }
 *   })(),
 *   (async () => {
 *     const release = await mutex.readLock()
 *
 *     try {
 *       console.info('read 3')
 *     } finally {
 *       release()
 *     }
 *   })()
 * ])
 * ```
 *
 *     read 1
 *     read 2
 *     <small pause>
 *     write 1
 *     read 3
 *
 * ## Browser
 *
 * Because there's no global way to evesdrop on messages sent by Web Workers, please pass all created Web Workers to the [`observable-webworkers`](https://npmjs.org/package/observable-webworkers) module:
 *
 * ```javascript
 * // main.js
 * import mortice from 'mortice'
 * import observe from 'observable-webworkers'
 *
 * // create our lock on the main thread, it will be held here
 * const mutex = mortice()
 *
 * const worker = new Worker('worker.js')
 *
 * observe(worker)
 * ```
 *
 * ```javascript
 * // worker.js
 * import mortice from 'mortice'
 * import delay from 'delay'
 *
 * const mutex = mortice()
 *
 * let release = await mutex.readLock()
 * // read something
 * release()
 *
 * release = await mutex.writeLock()
 * // write something
 * release()
 * ```
 */
const mutexes = {};
let implementation;
async function createReleaseable(queue, options) {
    let res;
    const p = new Promise((resolve) => {
        res = resolve;
    });
    void queue.add(async () => pTimeout((async () => {
        await new Promise((resolve) => {
            res(() => {
                resolve();
            });
        });
    })(), {
        milliseconds: options.timeout
    }));
    return p;
}
const createMutex = (name, options) => {
    if (implementation.isWorker === true) {
        return {
            readLock: implementation.readLock(name, options),
            writeLock: implementation.writeLock(name, options)
        };
    }
    const masterQueue = new PQueue({ concurrency: 1 });
    let readQueue;
    return {
        async readLock() {
            // If there's already a read queue, just add the task to it
            if (readQueue != null) {
                return createReleaseable(readQueue, options);
            }
            // Create a new read queue
            readQueue = new PQueue({
                concurrency: options.concurrency,
                autoStart: false
            });
            const localReadQueue = readQueue;
            // Add the task to the read queue
            const readPromise = createReleaseable(readQueue, options);
            void masterQueue.add(async () => {
                // Start the task only once the master queue has completed processing
                // any previous tasks
                localReadQueue.start();
                // Once all the tasks in the read queue have completed, remove it so
                // that the next read lock will occur after any write locks that were
                // started in the interim
                await localReadQueue.onIdle()
                    .then(() => {
                    if (readQueue === localReadQueue) {
                        readQueue = null;
                    }
                });
            });
            return readPromise;
        },
        async writeLock() {
            // Remove the read queue reference, so that any later read locks will be
            // added to a new queue that starts after this write lock has been
            // released
            readQueue = null;
            return createReleaseable(masterQueue, options);
        }
    };
};
const defaultOptions$4 = {
    name: 'lock',
    concurrency: Infinity,
    timeout: 84600000,
    singleProcess: false
};
function createMortice(options) {
    const opts = Object.assign({}, defaultOptions$4, options);
    if (implementation == null) {
        implementation = impl(opts);
        if (implementation.isWorker !== true) {
            // we are master, set up worker requests
            implementation.addEventListener('requestReadLock', (event) => {
                if (mutexes[event.data.name] == null) {
                    return;
                }
                void mutexes[event.data.name].readLock()
                    .then(async (release) => event.data.handler().finally(() => { release(); }));
            });
            implementation.addEventListener('requestWriteLock', async (event) => {
                if (mutexes[event.data.name] == null) {
                    return;
                }
                void mutexes[event.data.name].writeLock()
                    .then(async (release) => event.data.handler().finally(() => { release(); }));
            });
        }
    }
    if (mutexes[opts.name] == null) {
        mutexes[opts.name] = createMutex(opts.name, opts);
    }
    return mutexes[opts.name];
}

const codes$1 = {
    ERR_INVALID_PARAMETERS: 'ERR_INVALID_PARAMETERS'
};

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Peer;
(function (Peer) {
    (function (Peer$metadataEntry) {
        let _codec;
        Peer$metadataEntry.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.key != null && obj.key !== '')) {
                        w.uint32(10);
                        w.string(obj.key);
                    }
                    if ((obj.value != null && obj.value.byteLength > 0)) {
                        w.uint32(18);
                        w.bytes(obj.value);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        key: '',
                        value: new Uint8Array(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.key = reader.string();
                                break;
                            case 2:
                                obj.value = reader.bytes();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer$metadataEntry.encode = (obj) => {
            return encodeMessage(obj, Peer$metadataEntry.codec());
        };
        Peer$metadataEntry.decode = (buf) => {
            return decodeMessage(buf, Peer$metadataEntry.codec());
        };
    })(Peer.Peer$metadataEntry || (Peer.Peer$metadataEntry = {}));
    (function (Peer$tagsEntry) {
        let _codec;
        Peer$tagsEntry.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.key != null && obj.key !== '')) {
                        w.uint32(10);
                        w.string(obj.key);
                    }
                    if (obj.value != null) {
                        w.uint32(18);
                        Tag.codec().encode(obj.value, w);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        key: ''
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.key = reader.string();
                                break;
                            case 2:
                                obj.value = Tag.codec().decode(reader, reader.uint32());
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer$tagsEntry.encode = (obj) => {
            return encodeMessage(obj, Peer$tagsEntry.codec());
        };
        Peer$tagsEntry.decode = (buf) => {
            return decodeMessage(buf, Peer$tagsEntry.codec());
        };
    })(Peer.Peer$tagsEntry || (Peer.Peer$tagsEntry = {}));
    let _codec;
    Peer.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(10);
                        Address.codec().encode(value, w);
                    }
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(18);
                        w.string(value);
                    }
                }
                if (obj.publicKey != null) {
                    w.uint32(34);
                    w.bytes(obj.publicKey);
                }
                if (obj.peerRecordEnvelope != null) {
                    w.uint32(42);
                    w.bytes(obj.peerRecordEnvelope);
                }
                if (obj.metadata != null && obj.metadata.size !== 0) {
                    for (const [key, value] of obj.metadata.entries()) {
                        w.uint32(50);
                        Peer.Peer$metadataEntry.codec().encode({ key, value }, w);
                    }
                }
                if (obj.tags != null && obj.tags.size !== 0) {
                    for (const [key, value] of obj.tags.entries()) {
                        w.uint32(58);
                        Peer.Peer$tagsEntry.codec().encode({ key, value }, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    addresses: [],
                    protocols: [],
                    metadata: new Map(),
                    tags: new Map()
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.addresses.push(Address.codec().decode(reader, reader.uint32()));
                            break;
                        case 2:
                            obj.protocols.push(reader.string());
                            break;
                        case 4:
                            obj.publicKey = reader.bytes();
                            break;
                        case 5:
                            obj.peerRecordEnvelope = reader.bytes();
                            break;
                        case 6: {
                            const entry = Peer.Peer$metadataEntry.codec().decode(reader, reader.uint32());
                            obj.metadata.set(entry.key, entry.value);
                            break;
                        }
                        case 7: {
                            const entry = Peer.Peer$tagsEntry.codec().decode(reader, reader.uint32());
                            obj.tags.set(entry.key, entry.value);
                            break;
                        }
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Peer.encode = (obj) => {
        return encodeMessage(obj, Peer.codec());
    };
    Peer.decode = (buf) => {
        return decodeMessage(buf, Peer.codec());
    };
})(Peer || (Peer = {}));
var Address;
(function (Address) {
    let _codec;
    Address.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.multiaddr);
                }
                if (obj.isCertified != null) {
                    w.uint32(16);
                    w.bool(obj.isCertified);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    multiaddr: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.multiaddr = reader.bytes();
                            break;
                        case 2:
                            obj.isCertified = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Address.encode = (obj) => {
        return encodeMessage(obj, Address.codec());
    };
    Address.decode = (buf) => {
        return decodeMessage(buf, Address.codec());
    };
})(Address || (Address = {}));
var Tag;
(function (Tag) {
    let _codec;
    Tag.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.value != null && obj.value !== 0)) {
                    w.uint32(8);
                    w.uint32(obj.value);
                }
                if (obj.expiry != null) {
                    w.uint32(16);
                    w.uint64(obj.expiry);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    value: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.value = reader.uint32();
                            break;
                        case 2:
                            obj.expiry = reader.uint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Tag.encode = (obj) => {
        return encodeMessage(obj, Tag.codec());
    };
    Tag.decode = (buf) => {
        return decodeMessage(buf, Tag.codec());
    };
})(Tag || (Tag = {}));

function bytesToPeer(peerId, buf) {
    const peer = Peer.decode(buf);
    if (peer.publicKey != null && peerId.publicKey == null) {
        peerId = peerIdFromPeerId({
            ...peerId,
            publicKey: peerId.publicKey
        });
    }
    const tags = new Map();
    // remove any expired tags
    const now = BigInt(Date.now());
    for (const [key, tag] of peer.tags.entries()) {
        if (tag.expiry != null && tag.expiry < now) {
            continue;
        }
        tags.set(key, tag);
    }
    return {
        ...peer,
        id: peerId,
        addresses: peer.addresses.map(({ multiaddr: ma, isCertified }) => {
            return {
                multiaddr: multiaddr(ma),
                isCertified: isCertified ?? false
            };
        }),
        metadata: peer.metadata,
        peerRecordEnvelope: peer.peerRecordEnvelope ?? undefined,
        tags
    };
}

const pathSepS = '/';
const pathSepB = new TextEncoder().encode(pathSepS);
const pathSep = pathSepB[0];
/**
 * A Key represents the unique identifier of an object.
 * Our Key scheme is inspired by file systems and Google App Engine key model.
 * Keys are meant to be unique across a system. Keys are hierarchical,
 * incorporating more and more specific namespaces. Thus keys can be deemed
 * 'children' or 'ancestors' of other keys:
 * - `new Key('/Comedy')`
 * - `new Key('/Comedy/MontyPython')`
 * Also, every namespace can be parametrized to embed relevant object
 * information. For example, the Key `name` (most specific namespace) could
 * include the object type:
 * - `new Key('/Comedy/MontyPython/Actor:JohnCleese')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop/Character:Mousebender')`
 *
 */
class Key {
    _buf;
    /**
     * @param {string | Uint8Array} s
     * @param {boolean} [clean]
     */
    constructor(s, clean) {
        if (typeof s === 'string') {
            this._buf = fromString(s);
        }
        else if (s instanceof Uint8Array) {
            this._buf = s;
        }
        else {
            throw new Error('Invalid key, should be String of Uint8Array');
        }
        if (clean == null) {
            clean = true;
        }
        if (clean) {
            this.clean();
        }
        if (this._buf.byteLength === 0 || this._buf[0] !== pathSep) {
            throw new Error('Invalid key');
        }
    }
    /**
     * Convert to the string representation
     *
     * @param {import('uint8arrays/to-string').SupportedEncodings} [encoding='utf8'] - The encoding to use.
     * @returns {string}
     */
    toString(encoding = 'utf8') {
        return toString$6(this._buf, encoding);
    }
    /**
     * Return the Uint8Array representation of the key
     *
     * @returns {Uint8Array}
     */
    uint8Array() {
        return this._buf;
    }
    /**
     * Return string representation of the key
     *
     * @returns {string}
     */
    get [Symbol.toStringTag]() {
        return `Key(${this.toString()})`;
    }
    /**
     * Constructs a key out of a namespace array.
     *
     * @param {Array<string>} list - The array of namespaces
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.withNamespaces(['one', 'two'])
     * // => Key('/one/two')
     * ```
     */
    static withNamespaces(list) {
        return new Key(list.join(pathSepS));
    }
    /**
     * Returns a randomly (uuid) generated key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.random()
     * // => Key('/344502982398')
     * ```
     */
    static random() {
        return new Key(Math.random().toString().substring(2));
    }
    /**
     * @param {*} other
     */
    static asKey(other) {
        if (other instanceof Uint8Array || typeof other === 'string') {
            // we can create a key from this
            return new Key(other);
        }
        if (typeof other.uint8Array === 'function') {
            // this is an older version or may have crossed the esm/cjs boundary
            return new Key(other.uint8Array());
        }
        return null;
    }
    /**
     * Cleanup the current key
     *
     * @returns {void}
     */
    clean() {
        if (this._buf == null || this._buf.byteLength === 0) {
            this._buf = pathSepB;
        }
        if (this._buf[0] !== pathSep) {
            const bytes = new Uint8Array(this._buf.byteLength + 1);
            bytes.fill(pathSep, 0, 1);
            bytes.set(this._buf, 1);
            this._buf = bytes;
        }
        // normalize does not remove trailing slashes
        while (this._buf.byteLength > 1 && this._buf[this._buf.byteLength - 1] === pathSep) {
            this._buf = this._buf.subarray(0, -1);
        }
    }
    /**
     * Check if the given key is sorted lower than ourself.
     *
     * @param {Key} key - The other Key to check against
     * @returns {boolean}
     */
    less(key) {
        const list1 = this.list();
        const list2 = key.list();
        for (let i = 0; i < list1.length; i++) {
            if (list2.length < i + 1) {
                return false;
            }
            const c1 = list1[i];
            const c2 = list2[i];
            if (c1 < c2) {
                return true;
            }
            else if (c1 > c2) {
                return false;
            }
        }
        return list1.length < list2.length;
    }
    /**
     * Returns the key with all parts in reversed order.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').reverse()
     * // => Key('/Actor:JohnCleese/MontyPython/Comedy')
     * ```
     */
    reverse() {
        return Key.withNamespaces(this.list().slice().reverse());
    }
    /**
     * Returns the `namespaces` making up this Key.
     *
     * @returns {Array<string>}
     */
    namespaces() {
        return this.list();
    }
    /** Returns the "base" namespace of this key.
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').baseNamespace()
     * // => 'Actor:JohnCleese'
     * ```
     */
    baseNamespace() {
        const ns = this.namespaces();
        return ns[ns.length - 1];
    }
    /**
     * Returns the `list` representation of this key.
     *
     * @returns {Array<string>}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').list()
     * // => ['Comedy', 'MontyPythong', 'Actor:JohnCleese']
     * ```
     */
    list() {
        return this.toString().split(pathSepS).slice(1);
    }
    /**
     * Returns the "type" of this key (value of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').type()
     * // => 'Actor'
     * ```
     */
    type() {
        return namespaceType(this.baseNamespace());
    }
    /**
     * Returns the "name" of this key (field of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').name()
     * // => 'JohnCleese'
     * ```
     */
    name() {
        return namespaceValue(this.baseNamespace());
    }
    /**
     * Returns an "instance" of this type key (appends value to namespace).
     *
     * @param {string} s - The string to append.
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor').instance('JohnClesse')
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    instance(s) {
        return new Key(this.toString() + ':' + s);
    }
    /**
     * Returns the "path" of this key (parent + type).
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').path()
     * // => Key('/Comedy/MontyPython/Actor')
     * ```
     */
    path() {
        let p = this.parent().toString();
        if (!p.endsWith(pathSepS)) {
            p += pathSepS;
        }
        p += this.type();
        return new Key(p);
    }
    /**
     * Returns the `parent` Key of this Key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key("/Comedy/MontyPython/Actor:JohnCleese").parent()
     * // => Key("/Comedy/MontyPython")
     * ```
     */
    parent() {
        const list = this.list();
        if (list.length === 1) {
            return new Key(pathSepS);
        }
        return new Key(list.slice(0, -1).join(pathSepS));
    }
    /**
     * Returns the `child` Key of this Key.
     *
     * @param {Key} key - The child Key to add
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').child(new Key('Actor:JohnCleese'))
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    child(key) {
        if (this.toString() === pathSepS) {
            return key;
        }
        else if (key.toString() === pathSepS) {
            return this;
        }
        return new Key(this.toString() + key.toString(), false);
    }
    /**
     * Returns whether this key is a prefix of `other`
     *
     * @param {Key} other - The other key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy').isAncestorOf('/Comedy/MontyPython')
     * // => true
     * ```
     */
    isAncestorOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return other.toString().startsWith(this.toString());
    }
    /**
     * Returns whether this key is a contains another as prefix.
     *
     * @param {Key} other - The other Key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').isDecendantOf('/Comedy')
     * // => true
     * ```
     */
    isDecendantOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return this.toString().startsWith(other.toString());
    }
    /**
     * Checks if this key has only one namespace.
     *
     * @returns {boolean}
     */
    isTopLevel() {
        return this.list().length === 1;
    }
    /**
     * Concats one or more Keys into one new Key.
     *
     * @param {Array<Key>} keys - The array of keys to concatenate
     * @returns {Key}
     */
    concat(...keys) {
        return Key.withNamespaces([...this.namespaces(), ...flatten(keys.map(key => key.namespaces()))]);
    }
}
/**
 * The first component of a namespace. `foo` in `foo:bar`
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceType(ns) {
    const parts = ns.split(':');
    if (parts.length < 2) {
        return '';
    }
    return parts.slice(0, -1).join(':');
}
/**
 * The last component of a namespace, `baz` in `foo:bar:baz`.
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceValue(ns) {
    const parts = ns.split(':');
    return parts[parts.length - 1];
}
/**
 * Flatten array of arrays (only one level)
 *
 * @template T
 * @param {Array<any>} arr
 * @returns {T[]}
 */
function flatten(arr) {
    return ([]).concat(...arr);
}

const NAMESPACE_COMMON = '/peers/';
function peerIdToDatastoreKey(peerId) {
    if (!isPeerId(peerId) || peerId.type == null) {
        throw new CodeError$1('Invalid PeerId', codes$1.ERR_INVALID_PARAMETERS);
    }
    const b32key = peerId.toCID().toString();
    return new Key(`${NAMESPACE_COMMON}${b32key}`);
}

async function dedupeFilterAndSortAddresses(peerId, filter, addresses) {
    const addressMap = new Map();
    for (const addr of addresses) {
        if (addr == null) {
            continue;
        }
        if (addr.multiaddr instanceof Uint8Array) {
            addr.multiaddr = multiaddr(addr.multiaddr);
        }
        if (!isMultiaddr(addr.multiaddr)) {
            throw new CodeError$1('Multiaddr was invalid', codes$1.ERR_INVALID_PARAMETERS);
        }
        if (!(await filter(peerId, addr.multiaddr))) {
            continue;
        }
        const isCertified = addr.isCertified ?? false;
        const maStr = addr.multiaddr.toString();
        const existingAddr = addressMap.get(maStr);
        if (existingAddr != null) {
            addr.isCertified = existingAddr.isCertified || isCertified;
        }
        else {
            addressMap.set(maStr, {
                multiaddr: addr.multiaddr,
                isCertified
            });
        }
    }
    return [...addressMap.values()]
        .sort((a, b) => {
        return a.multiaddr.toString().localeCompare(b.multiaddr.toString());
    })
        .map(({ isCertified, multiaddr }) => ({
        isCertified,
        multiaddr: multiaddr.bytes
    }));
}

async function toPeerPB(peerId, data, strategy, options) {
    if (data == null) {
        throw new CodeError$1('Invalid PeerData', codes$1.ERR_INVALID_PARAMETERS);
    }
    if (data.publicKey != null && peerId.publicKey != null && !equals(data.publicKey, peerId.publicKey)) {
        throw new CodeError$1('publicKey bytes do not match peer id publicKey bytes', codes$1.ERR_INVALID_PARAMETERS);
    }
    const existingPeer = options.existingPeer;
    if (existingPeer != null && !peerId.equals(existingPeer.id)) {
        throw new CodeError$1('peer id did not match existing peer id', codes$1.ERR_INVALID_PARAMETERS);
    }
    let addresses = existingPeer?.addresses ?? [];
    let protocols = new Set(existingPeer?.protocols ?? []);
    let metadata = existingPeer?.metadata ?? new Map();
    let tags = existingPeer?.tags ?? new Map();
    let peerRecordEnvelope = existingPeer?.peerRecordEnvelope;
    // when patching, we replace the original fields with passed values
    if (strategy === 'patch') {
        if (data.multiaddrs != null || data.addresses != null) {
            addresses = [];
            if (data.multiaddrs != null) {
                addresses.push(...data.multiaddrs.map(multiaddr => ({
                    isCertified: false,
                    multiaddr
                })));
            }
            if (data.addresses != null) {
                addresses.push(...data.addresses);
            }
        }
        if (data.protocols != null) {
            protocols = new Set(data.protocols);
        }
        if (data.metadata != null) {
            const metadataEntries = data.metadata instanceof Map ? [...data.metadata.entries()] : Object.entries(data.metadata);
            metadata = createSortedMap(metadataEntries, {
                validate: validateMetadata
            });
        }
        if (data.tags != null) {
            const tagsEntries = data.tags instanceof Map ? [...data.tags.entries()] : Object.entries(data.tags);
            tags = createSortedMap(tagsEntries, {
                validate: validateTag,
                map: mapTag
            });
        }
        if (data.peerRecordEnvelope != null) {
            peerRecordEnvelope = data.peerRecordEnvelope;
        }
    }
    // when merging, we join the original fields with passed values
    if (strategy === 'merge') {
        if (data.multiaddrs != null) {
            addresses.push(...data.multiaddrs.map(multiaddr => ({
                isCertified: false,
                multiaddr
            })));
        }
        if (data.addresses != null) {
            addresses.push(...data.addresses);
        }
        if (data.protocols != null) {
            protocols = new Set([...protocols, ...data.protocols]);
        }
        if (data.metadata != null) {
            const metadataEntries = data.metadata instanceof Map ? [...data.metadata.entries()] : Object.entries(data.metadata);
            for (const [key, value] of metadataEntries) {
                if (value == null) {
                    metadata.delete(key);
                }
                else {
                    metadata.set(key, value);
                }
            }
            metadata = createSortedMap([...metadata.entries()], {
                validate: validateMetadata
            });
        }
        if (data.tags != null) {
            const tagsEntries = data.tags instanceof Map ? [...data.tags.entries()] : Object.entries(data.tags);
            const mergedTags = new Map(tags);
            for (const [key, value] of tagsEntries) {
                if (value == null) {
                    mergedTags.delete(key);
                }
                else {
                    mergedTags.set(key, value);
                }
            }
            tags = createSortedMap([...mergedTags.entries()], {
                validate: validateTag,
                map: mapTag
            });
        }
        if (data.peerRecordEnvelope != null) {
            peerRecordEnvelope = data.peerRecordEnvelope;
        }
    }
    const output = {
        addresses: await dedupeFilterAndSortAddresses(peerId, options.addressFilter ?? (async () => true), addresses),
        protocols: [...protocols.values()].sort((a, b) => {
            return a.localeCompare(b);
        }),
        metadata,
        tags,
        publicKey: existingPeer?.id.publicKey ?? data.publicKey ?? peerId.publicKey,
        peerRecordEnvelope
    };
    // Ed25519 and secp256k1 have their public key embedded in them so no need to duplicate it
    if (peerId.type !== 'RSA') {
        delete output.publicKey;
    }
    return output;
}
/**
 * In JS maps are ordered by insertion order so create a new map with the
 * keys inserted in alphabetical order.
 */
function createSortedMap(entries, options) {
    const output = new Map();
    for (const [key, value] of entries) {
        if (value == null) {
            continue;
        }
        options.validate(key, value);
    }
    for (const [key, value] of entries.sort(([a], [b]) => {
        return a.localeCompare(b);
    })) {
        if (value != null) {
            output.set(key, options.map?.(key, value) ?? value);
        }
    }
    return output;
}
function validateMetadata(key, value) {
    if (typeof key !== 'string') {
        throw new CodeError$1('Metadata key must be a string', codes$1.ERR_INVALID_PARAMETERS);
    }
    if (!(value instanceof Uint8Array)) {
        throw new CodeError$1('Metadata value must be a Uint8Array', codes$1.ERR_INVALID_PARAMETERS);
    }
}
function validateTag(key, tag) {
    if (typeof key !== 'string') {
        throw new CodeError$1('Tag name must be a string', codes$1.ERR_INVALID_PARAMETERS);
    }
    if (tag.value != null) {
        if (parseInt(`${tag.value}`, 10) !== tag.value) {
            throw new CodeError$1('Tag value must be an integer', codes$1.ERR_INVALID_PARAMETERS);
        }
        if (tag.value < 0 || tag.value > 100) {
            throw new CodeError$1('Tag value must be between 0-100', codes$1.ERR_INVALID_PARAMETERS);
        }
    }
    if (tag.ttl != null) {
        if (parseInt(`${tag.ttl}`, 10) !== tag.ttl) {
            throw new CodeError$1('Tag ttl must be an integer', codes$1.ERR_INVALID_PARAMETERS);
        }
        if (tag.ttl < 0) {
            throw new CodeError$1('Tag ttl must be between greater than 0', codes$1.ERR_INVALID_PARAMETERS);
        }
    }
}
function mapTag(key, tag) {
    let expiry;
    if (tag.expiry != null) {
        expiry = tag.expiry;
    }
    if (tag.ttl != null) {
        expiry = BigInt(Date.now() + Number(tag.ttl));
    }
    return {
        value: tag.value ?? 0,
        expiry
    };
}

function decodePeer(key, value, cache) {
    // /peers/${peer-id-as-libp2p-key-cid-string-in-base-32}
    const base32Str = key.toString().split('/')[2];
    const buf = base32$2.decode(base32Str);
    const peerId = peerIdFromBytes(buf);
    const cached = cache.get(peerId);
    if (cached != null) {
        return cached;
    }
    const peer = bytesToPeer(peerId, value);
    cache.set(peerId, peer);
    return peer;
}
function mapQuery(query, cache) {
    if (query == null) {
        return {};
    }
    return {
        prefix: NAMESPACE_COMMON,
        filters: (query.filters ?? []).map(fn => ({ key, value }) => {
            return fn(decodePeer(key, value, cache));
        }),
        orders: (query.orders ?? []).map(fn => (a, b) => {
            return fn(decodePeer(a.key, a.value, cache), decodePeer(b.key, b.value, cache));
        })
    };
}
class PersistentStore {
    peerId;
    datastore;
    lock;
    addressFilter;
    constructor(components, init = {}) {
        this.peerId = components.peerId;
        this.datastore = components.datastore;
        this.addressFilter = init.addressFilter;
        this.lock = createMortice({
            name: 'peer-store',
            singleProcess: true
        });
    }
    async has(peerId) {
        return this.datastore.has(peerIdToDatastoreKey(peerId));
    }
    async delete(peerId) {
        if (this.peerId.equals(peerId)) {
            throw new CodeError$1('Cannot delete self peer', codes$1.ERR_INVALID_PARAMETERS);
        }
        await this.datastore.delete(peerIdToDatastoreKey(peerId));
    }
    async load(peerId) {
        const buf = await this.datastore.get(peerIdToDatastoreKey(peerId));
        return bytesToPeer(peerId, buf);
    }
    async save(peerId, data) {
        const { existingBuf, existingPeer } = await this.#findExistingPeer(peerId);
        const peerPb = await toPeerPB(peerId, data, 'patch', {
            addressFilter: this.addressFilter
        });
        return this.#saveIfDifferent(peerId, peerPb, existingBuf, existingPeer);
    }
    async patch(peerId, data) {
        const { existingBuf, existingPeer } = await this.#findExistingPeer(peerId);
        const peerPb = await toPeerPB(peerId, data, 'patch', {
            addressFilter: this.addressFilter,
            existingPeer
        });
        return this.#saveIfDifferent(peerId, peerPb, existingBuf, existingPeer);
    }
    async merge(peerId, data) {
        const { existingBuf, existingPeer } = await this.#findExistingPeer(peerId);
        const peerPb = await toPeerPB(peerId, data, 'merge', {
            addressFilter: this.addressFilter,
            existingPeer
        });
        return this.#saveIfDifferent(peerId, peerPb, existingBuf, existingPeer);
    }
    async *all(query) {
        const peerCache = new PeerMap();
        for await (const { key, value } of this.datastore.query(mapQuery(query ?? {}, peerCache))) {
            const peer = decodePeer(key, value, peerCache);
            if (peer.id.equals(this.peerId)) {
                // Skip self peer if present
                continue;
            }
            yield peer;
        }
    }
    async #findExistingPeer(peerId) {
        try {
            const existingBuf = await this.datastore.get(peerIdToDatastoreKey(peerId));
            const existingPeer = bytesToPeer(peerId, existingBuf);
            return {
                existingBuf,
                existingPeer
            };
        }
        catch (err) {
            if (err.code !== 'ERR_NOT_FOUND') {
                throw err;
            }
        }
        return {};
    }
    async #saveIfDifferent(peerId, peer, existingBuf, existingPeer) {
        const buf = Peer.encode(peer);
        if (existingBuf != null && equals(buf, existingBuf)) {
            return {
                peer: bytesToPeer(peerId, buf),
                previous: existingPeer,
                updated: false
            };
        }
        await this.datastore.put(peerIdToDatastoreKey(peerId), buf);
        return {
            peer: bytesToPeer(peerId, buf),
            previous: existingPeer,
            updated: true
        };
    }
}

/**
 * @packageDocumentation
 *
 * The peer store is where libp2p stores data about the peers it has encountered on the network.
 */
/**
 * An implementation of PeerStore that stores data in a Datastore
 */
class PersistentPeerStore {
    store;
    events;
    peerId;
    log;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:peer-store');
        this.events = components.events;
        this.peerId = components.peerId;
        this.store = new PersistentStore(components, init);
    }
    [Symbol.toStringTag] = '@libp2p/peer-store';
    async forEach(fn, query) {
        this.log.trace('forEach await read lock');
        const release = await this.store.lock.readLock();
        this.log.trace('forEach got read lock');
        try {
            for await (const peer of this.store.all(query)) {
                fn(peer);
            }
        }
        finally {
            this.log.trace('forEach release read lock');
            release();
        }
    }
    async all(query) {
        this.log.trace('all await read lock');
        const release = await this.store.lock.readLock();
        this.log.trace('all got read lock');
        try {
            return await all$1(this.store.all(query));
        }
        finally {
            this.log.trace('all release read lock');
            release();
        }
    }
    async delete(peerId) {
        this.log.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        this.log.trace('delete got write lock');
        try {
            await this.store.delete(peerId);
        }
        finally {
            this.log.trace('delete release write lock');
            release();
        }
    }
    async has(peerId) {
        this.log.trace('has await read lock');
        const release = await this.store.lock.readLock();
        this.log.trace('has got read lock');
        try {
            return await this.store.has(peerId);
        }
        finally {
            this.log.trace('has release read lock');
            release();
        }
    }
    async get(peerId) {
        this.log.trace('get await read lock');
        const release = await this.store.lock.readLock();
        this.log.trace('get got read lock');
        try {
            return await this.store.load(peerId);
        }
        finally {
            this.log.trace('get release read lock');
            release();
        }
    }
    async save(id, data) {
        this.log.trace('save await write lock');
        const release = await this.store.lock.writeLock();
        this.log.trace('save got write lock');
        try {
            const result = await this.store.save(id, data);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            this.log.trace('save release write lock');
            release();
        }
    }
    async patch(id, data) {
        this.log.trace('patch await write lock');
        const release = await this.store.lock.writeLock();
        this.log.trace('patch got write lock');
        try {
            const result = await this.store.patch(id, data);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            this.log.trace('patch release write lock');
            release();
        }
    }
    async merge(id, data) {
        this.log.trace('merge await write lock');
        const release = await this.store.lock.writeLock();
        this.log.trace('merge got write lock');
        try {
            const result = await this.store.merge(id, data);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            this.log.trace('merge release write lock');
            release();
        }
    }
    async consumePeerRecord(buf, expectedPeer) {
        const envelope = await RecordEnvelope.openAndCertify(buf, PeerRecord.DOMAIN);
        if (expectedPeer?.equals(envelope.peerId) === false) {
            this.log('envelope peer id was not the expected peer id - expected: %p received: %p', expectedPeer, envelope.peerId);
            return false;
        }
        const peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
        let peer;
        try {
            peer = await this.get(envelope.peerId);
        }
        catch (err) {
            if (err.code !== 'ERR_NOT_FOUND') {
                throw err;
            }
        }
        // ensure seq is greater than, or equal to, the last received
        if (peer?.peerRecordEnvelope != null) {
            const storedEnvelope = await RecordEnvelope.createFromProtobuf(peer.peerRecordEnvelope);
            const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
            if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                this.log('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                return false;
            }
        }
        await this.patch(peerRecord.peerId, {
            peerRecordEnvelope: buf,
            addresses: peerRecord.multiaddrs.map(multiaddr => ({
                isCertified: true,
                multiaddr
            }))
        });
        return true;
    }
    #emitIfUpdated(id, result) {
        if (!result.updated) {
            return;
        }
        if (this.peerId.equals(id)) {
            this.events.safeDispatchEvent('self:peer:update', { detail: result });
        }
        else {
            this.events.safeDispatchEvent('peer:update', { detail: result });
        }
    }
}

/**
 * @packageDocumentation
 *
 * Lets you look at the contents of an async iterator and decide what to do
 *
 * @example
 *
 * ```javascript
 * import peekable from 'it-peekable'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const it = peekable(value)
 *
 * const first = it.peek()
 *
 * console.info(first) // 0
 *
 * it.push(first)
 *
 * console.info([...it])
 * // [ 0, 1, 2, 3, 4 ]
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import peekable from 'it-peekable'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const it = peekable(values())
 *
 * const first = await it.peek()
 *
 * console.info(first) // 0
 *
 * it.push(first)
 *
 * console.info(await all(it))
 * // [ 0, 1, 2, 3, 4 ]
 * ```
 */
function peekable(iterable) {
    // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable
    const [iterator, symbol] = iterable[Symbol.asyncIterator] != null
        // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable
        ? [iterable[Symbol.asyncIterator](), Symbol.asyncIterator]
        // @ts-expect-error can't use Symbol.iterator to index iterable since it might be AsyncIterable
        : [iterable[Symbol.iterator](), Symbol.iterator];
    const queue = [];
    // @ts-expect-error can't use symbol to index peekable
    return {
        peek: () => {
            return iterator.next();
        },
        push: (value) => {
            queue.push(value);
        },
        next: () => {
            if (queue.length > 0) {
                return {
                    done: false,
                    value: queue.shift()
                };
            }
            return iterator.next();
        },
        [symbol]() {
            return this;
        }
    };
}

/**
 * @packageDocumentation
 *
 * Filter values out of an (async)iterable
 *
 * @example
 *
 * ```javascript
 * import all from 'it-all'
 * import filter from 'it-filter'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const fn = (val, index) => val > 2 // Return boolean to keep item
 *
 * const arr = all(filter(values, fn))
 *
 * console.info(arr) // 3, 4
 * ```
 *
 * Async sources and filter functions must be awaited:
 *
 * ```javascript
 * import all from 'it-all'
 * import filter from 'it-filter'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const fn = async val => (val, index) > 2 // Return boolean or promise of boolean to keep item
 *
 * const arr = await all(filter(values, fn))
 *
 * console.info(arr) // 3, 4
 * ```
 */
function isAsyncIterable$2(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function filter(source, fn) {
    let index = 0;
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            for await (const entry of source) {
                if (await fn(entry, index++)) {
                    yield entry;
                }
            }
        })();
    }
    // if mapping function returns a promise we have to return an async generator
    const peekable$1 = peekable(source);
    const { value, done } = peekable$1.next();
    if (done === true) {
        return (function* () { }());
    }
    const res = fn(value, index++);
    // @ts-expect-error .then is not present on O
    if (typeof res.then === 'function') {
        return (async function* () {
            if (await res) {
                yield value;
            }
            for await (const entry of peekable$1) {
                if (await fn(entry, index++)) {
                    yield entry;
                }
            }
        })();
    }
    const func = fn;
    return (function* () {
        if (res === true) {
            yield value;
        }
        for (const entry of peekable$1) {
            if (func(entry, index++)) {
                yield entry;
            }
        }
    })();
}

/**
 * @packageDocumentation
 *
 * Consumes all values from an (async)iterable and returns them sorted by the passed sort function.
 *
 * @example
 *
 * ```javascript
 * import sort from 'it-sort'
 * import all from 'it-all'
 *
 * const sorter = (a, b) => {
 *   return a.localeCompare(b)
 * }
 *
 * // This can also be an iterator, generator, etc
 * const values = ['foo', 'bar']
 *
 * const arr = all(sort(values, sorter))
 *
 * console.info(arr) // 'bar', 'foo'
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import sort from 'it-sort'
 * import all from 'it-all'
 *
 * const sorter = (a, b) => {
 *   return a.localeCompare(b)
 * }
 *
 * const values = async function * () {
 *   yield * ['foo', 'bar']
 * }
 *
 * const arr = await all(sort(values, sorter))
 *
 * console.info(arr) // 'bar', 'foo'
 * ```
 */
function isAsyncIterable$1(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function sort(source, sorter) {
    if (isAsyncIterable$1(source)) {
        return (async function* () {
            const arr = await all$1(source);
            yield* arr.sort(sorter);
        })();
    }
    return (function* () {
        const arr = all$1(source);
        yield* arr.sort(sorter);
    })();
}

/**
 * @packageDocumentation
 *
 * For when you only want a few values out of an (async)iterable.
 *
 * @example
 *
 * ```javascript
 * import take from 'it-take'
 * import all from 'it-all'
 *
 * // This can also be an iterator, generator, etc
 * const values = [0, 1, 2, 3, 4]
 *
 * const arr = all(take(values, 2))
 *
 * console.info(arr) // 0, 1
 * ```
 *
 * Async sources must be awaited:
 *
 * ```javascript
 * import take from 'it-take'
 * import all from 'it-all'
 *
 * const values = async function * () {
 *   yield * [0, 1, 2, 3, 4]
 * }
 *
 * const arr = await all(take(values(), 2))
 *
 * console.info(arr) // 0, 1
 * ```
 */
function isAsyncIterable(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function take(source, limit) {
    if (isAsyncIterable(source)) {
        return (async function* () {
            let items = 0;
            if (limit < 1) {
                return;
            }
            for await (const entry of source) {
                yield entry;
                items++;
                if (items === limit) {
                    return;
                }
            }
        })();
    }
    return (function* () {
        let items = 0;
        if (limit < 1) {
            return;
        }
        for (const entry of source) {
            yield entry;
            items++;
            if (items === limit) {
                return;
            }
        }
    })();
}

class BaseDatastore {
    put(key, val, options) {
        return Promise.reject(new Error('.put is not implemented'));
    }
    get(key, options) {
        return Promise.reject(new Error('.get is not implemented'));
    }
    has(key, options) {
        return Promise.reject(new Error('.has is not implemented'));
    }
    delete(key, options) {
        return Promise.reject(new Error('.delete is not implemented'));
    }
    async *putMany(source, options = {}) {
        for await (const { key, value } of source) {
            await this.put(key, value, options);
            yield key;
        }
    }
    async *getMany(source, options = {}) {
        for await (const key of source) {
            yield {
                key,
                value: await this.get(key, options)
            };
        }
    }
    async *deleteMany(source, options = {}) {
        for await (const key of source) {
            await this.delete(key, options);
            yield key;
        }
    }
    batch() {
        let puts = [];
        let dels = [];
        return {
            put(key, value) {
                puts.push({ key, value });
            },
            delete(key) {
                dels.push(key);
            },
            commit: async (options) => {
                await drain(this.putMany(puts, options));
                puts = [];
                await drain(this.deleteMany(dels, options));
                dels = [];
            }
        };
    }
    /**
     * Extending classes should override `query` or implement this method
     */
    // eslint-disable-next-line require-yield
    async *_all(q, options) {
        throw new Error('._all is not implemented');
    }
    /**
     * Extending classes should override `queryKeys` or implement this method
     */
    // eslint-disable-next-line require-yield
    async *_allKeys(q, options) {
        throw new Error('._allKeys is not implemented');
    }
    query(q, options) {
        let it = this._all(q, options);
        if (q.prefix != null) {
            const prefix = q.prefix;
            it = filter(it, (e) => e.key.toString().startsWith(prefix));
        }
        if (Array.isArray(q.filters)) {
            it = q.filters.reduce((it, f) => filter(it, f), it);
        }
        if (Array.isArray(q.orders)) {
            it = q.orders.reduce((it, f) => sort(it, f), it);
        }
        if (q.offset != null) {
            let i = 0;
            const offset = q.offset;
            it = filter(it, () => i++ >= offset);
        }
        if (q.limit != null) {
            it = take(it, q.limit);
        }
        return it;
    }
    queryKeys(q, options) {
        let it = this._allKeys(q, options);
        if (q.prefix != null) {
            const prefix = q.prefix;
            it = filter(it, (key) => key.toString().startsWith(prefix));
        }
        if (Array.isArray(q.filters)) {
            it = q.filters.reduce((it, f) => filter(it, f), it);
        }
        if (Array.isArray(q.orders)) {
            it = q.orders.reduce((it, f) => sort(it, f), it);
        }
        if (q.offset != null) {
            const offset = q.offset;
            let i = 0;
            it = filter(it, () => i++ >= offset);
        }
        if (q.limit != null) {
            it = take(it, q.limit);
        }
        return it;
    }
}

/**
 * @typedef {{ [key: string]: any }} Extensions
 * @typedef {Error} Err
 * @property {string} message
 */

/**
 *
 * @param {Error} obj
 * @param {Extensions} props
 * @returns {Error & Extensions}
 */
function assign(obj, props) {
    for (const key in props) {
        Object.defineProperty(obj, key, {
            value: props[key],
            enumerable: true,
            configurable: true,
        });
    }

    return obj;
}

/**
 *
 * @param {any} err - An Error
 * @param {string|Extensions} code - A string code or props to set on the error
 * @param {Extensions} [props] - Props to set on the error
 * @returns {Error & Extensions}
 */
function createError(err, code, props) {
    if (!err || typeof err === 'string') {
        throw new TypeError('Please pass an Error to err-code');
    }

    if (!props) {
        props = {};
    }

    if (typeof code === 'object') {
        props = code;
        code = '';
    }

    if (code) {
        props.code = code;
    }

    try {
        return assign(err, props);
    } catch (_) {
        props.message = err.message;
        props.stack = err.stack;

        const ErrClass = function () {};

        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));

        // @ts-ignore
        const output = assign(new ErrClass(), props);

        return output;
    }
}

var errCode = createError;

var errCode$1 = /*@__PURE__*/getDefaultExportFromCjs(errCode);

function notFoundError(err) {
    err = err ?? new Error('Not Found');
    return errCode$1(err, 'ERR_NOT_FOUND');
}

class MemoryDatastore extends BaseDatastore {
    data;
    constructor() {
        super();
        this.data = new Map();
    }
    put(key, val) {
        this.data.set(key.toString(), val);
        return key;
    }
    get(key) {
        const result = this.data.get(key.toString());
        if (result == null) {
            throw notFoundError();
        }
        return result;
    }
    has(key) {
        return this.data.has(key.toString());
    }
    delete(key) {
        this.data.delete(key.toString());
    }
    *_all() {
        for (const [key, value] of this.data.entries()) {
            yield { key: new Key(key), value };
        }
    }
    *_allKeys() {
        for (const key of this.data.keys()) {
            yield new Key(key);
        }
    }
}

function debounce(func, wait) {
    let timeout;
    return function () {
        const later = function () {
            timeout = undefined;
            func();
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
}

const defaultAddressFilter = (addrs) => addrs;
/**
 * If the passed multiaddr contains the passed peer id, remove it
 */
function stripPeerId(ma, peerId) {
    const observedPeerIdStr = ma.getPeerId();
    // strip our peer id if it has been passed
    if (observedPeerIdStr != null) {
        const observedPeerId = peerIdFromString(observedPeerIdStr);
        // use same encoding for comparison
        if (observedPeerId.equals(peerId)) {
            ma = ma.decapsulate(multiaddr(`/p2p/${peerId.toString()}`));
        }
    }
    return ma;
}
class DefaultAddressManager {
    log;
    components;
    // this is an array to allow for duplicates, e.g. multiples of `/ip4/0.0.0.0/tcp/0`
    listen;
    announce;
    observed;
    announceFilter;
    /**
     * Responsible for managing the peer addresses.
     * Peers can specify their listen and announce addresses.
     * The listen addresses will be used by the libp2p transports to listen for new connections,
     * while the announce addresses will be used for the peer addresses' to other peers in the network.
     */
    constructor(components, init = {}) {
        const { listen = [], announce = [] } = init;
        this.components = components;
        this.log = components.logger.forComponent('libp2p:address-manager');
        this.listen = listen.map(ma => ma.toString());
        this.announce = new Set(announce.map(ma => ma.toString()));
        this.observed = new Map();
        this.announceFilter = init.announceFilter ?? defaultAddressFilter;
        // this method gets called repeatedly on startup when transports start listening so
        // debounce it so we don't cause multiple self:peer:update events to be emitted
        this._updatePeerStoreAddresses = debounce(this._updatePeerStoreAddresses.bind(this), 1000);
        // update our stored addresses when new transports listen
        components.events.addEventListener('transport:listening', () => {
            this._updatePeerStoreAddresses();
        });
        // update our stored addresses when existing transports stop listening
        components.events.addEventListener('transport:close', () => {
            this._updatePeerStoreAddresses();
        });
    }
    [Symbol.toStringTag] = '@libp2p/address-manager';
    _updatePeerStoreAddresses() {
        // if announce addresses have been configured, ensure they make it into our peer
        // record for things like identify
        const addrs = this.getAnnounceAddrs()
            .concat(this.components.transportManager.getAddrs())
            .concat([...this.observed.entries()]
            .filter(([_, metadata]) => metadata.confident)
            .map(([str]) => multiaddr(str))).map(ma => {
            // strip our peer id if it is present
            if (ma.getPeerId() === this.components.peerId.toString()) {
                return ma.decapsulate(`/p2p/${this.components.peerId.toString()}`);
            }
            return ma;
        });
        this.components.peerStore.patch(this.components.peerId, {
            multiaddrs: addrs
        })
            .catch(err => { this.log.error('error updating addresses', err); });
    }
    /**
     * Get peer listen multiaddrs
     */
    getListenAddrs() {
        return Array.from(this.listen).map((a) => multiaddr(a));
    }
    /**
     * Get peer announcing multiaddrs
     */
    getAnnounceAddrs() {
        return Array.from(this.announce).map((a) => multiaddr(a));
    }
    /**
     * Get observed multiaddrs
     */
    getObservedAddrs() {
        return Array.from(this.observed).map(([a]) => multiaddr(a));
    }
    /**
     * Add peer observed addresses
     */
    addObservedAddr(addr) {
        addr = stripPeerId(addr, this.components.peerId);
        const addrString = addr.toString();
        // do not trigger the change:addresses event if we already know about this address
        if (this.observed.has(addrString)) {
            return;
        }
        this.observed.set(addrString, {
            confident: false
        });
    }
    confirmObservedAddr(addr) {
        addr = stripPeerId(addr, this.components.peerId);
        const addrString = addr.toString();
        const metadata = this.observed.get(addrString) ?? {
            confident: false
        };
        const startingConfidence = metadata.confident;
        this.observed.set(addrString, {
            confident: true
        });
        // only trigger the 'self:peer:update' event if our confidence in an address has changed
        if (!startingConfidence) {
            this._updatePeerStoreAddresses();
        }
    }
    removeObservedAddr(addr) {
        addr = stripPeerId(addr, this.components.peerId);
        const addrString = addr.toString();
        this.observed.delete(addrString);
    }
    getAddresses() {
        let addrs = this.getAnnounceAddrs().map(ma => ma.toString());
        if (addrs.length === 0) {
            // no configured announce addrs, add configured listen addresses
            addrs = this.components.transportManager.getAddrs().map(ma => ma.toString());
        }
        // add observed addresses we are confident in
        addrs = addrs.concat(Array.from(this.observed)
            .filter(([ma, metadata]) => metadata.confident)
            .map(([ma]) => ma));
        // dedupe multiaddrs
        const addrSet = new Set(addrs);
        // Create advertising list
        return this.announceFilter(Array.from(addrSet)
            .map(str => multiaddr(str)))
            .map(ma => {
            // do not append our peer id to a path multiaddr as it will become invalid
            if (ma.protos().pop()?.path === true) {
                return ma;
            }
            if (ma.getPeerId() === this.components.peerId.toString()) {
                return ma;
            }
            return ma.encapsulate(`/p2p/${this.components.peerId.toString()}`);
        });
    }
}

class DefaultComponents {
    components = {};
    _started = false;
    constructor(init = {}) {
        this.components = {};
        for (const [key, value] of Object.entries(init)) {
            this.components[key] = value;
        }
        if (this.components.logger == null) {
            this.components.logger = defaultLogger();
        }
    }
    isStarted() {
        return this._started;
    }
    async _invokeStartableMethod(methodName) {
        await Promise.all(Object.values(this.components)
            .filter(obj => isStartable(obj))
            .map(async (startable) => {
            await startable[methodName]?.();
        }));
    }
    async beforeStart() {
        await this._invokeStartableMethod('beforeStart');
    }
    async start() {
        await this._invokeStartableMethod('start');
        this._started = true;
    }
    async afterStart() {
        await this._invokeStartableMethod('afterStart');
    }
    async beforeStop() {
        await this._invokeStartableMethod('beforeStop');
    }
    async stop() {
        await this._invokeStartableMethod('stop');
        this._started = false;
    }
    async afterStop() {
        await this._invokeStartableMethod('afterStop');
    }
}
const OPTIONAL_SERVICES = [
    'metrics',
    'connectionProtector',
    'dns'
];
const NON_SERVICE_PROPERTIES = [
    'components',
    'isStarted',
    'beforeStart',
    'start',
    'afterStart',
    'beforeStop',
    'stop',
    'afterStop',
    'then',
    '_invokeStartableMethod'
];
function defaultComponents(init = {}) {
    const components = new DefaultComponents(init);
    const proxy = new Proxy(components, {
        get(target, prop, receiver) {
            if (typeof prop === 'string' && !NON_SERVICE_PROPERTIES.includes(prop)) {
                const service = components.components[prop];
                if (service == null && !OPTIONAL_SERVICES.includes(prop)) {
                    throw new CodeError$1(`${prop} not set`, 'ERR_SERVICE_MISSING');
                }
                return service;
            }
            return Reflect.get(target, prop, receiver);
        },
        set(target, prop, value) {
            if (typeof prop === 'string') {
                components.components[prop] = value;
            }
            else {
                Reflect.set(target, prop, value);
            }
            return true;
        }
    });
    // @ts-expect-error component keys are proxied
    return proxy;
}
function checkServiceDependencies(components) {
    const serviceCapabilities = {};
    for (const service of Object.values(components.components)) {
        for (const capability of getServiceCapabilities(service)) {
            serviceCapabilities[capability] = true;
        }
    }
    for (const service of Object.values(components.components)) {
        for (const capability of getServiceDependencies(service)) {
            if (serviceCapabilities[capability] !== true) {
                throw new CodeError$1(`Service "${getServiceName(service)}" required capability "${capability}" but it was not provided by any component, you may need to add additional configuration when creating your node.`, 'ERR_UNMET_SERVICE_DEPENDENCIES');
            }
        }
    }
}
function getServiceCapabilities(service) {
    if (Array.isArray(service?.[serviceCapabilities])) {
        return service[serviceCapabilities];
    }
    return [];
}
function getServiceDependencies(service) {
    if (Array.isArray(service?.[serviceDependencies])) {
        return service[serviceDependencies];
    }
    return [];
}
function getServiceName(service) {
    return service?.[Symbol.toStringTag] ?? service?.toString() ?? 'unknown';
}

var Netmask_1;
// Generated by CoffeeScript 1.12.7
(function() {
  var Netmask, atob, chr, chr0, chrA, chra, ip2long, long2ip;

  long2ip = function(long) {
    var a, b, c, d;
    a = (long & (0xff << 24)) >>> 24;
    b = (long & (0xff << 16)) >>> 16;
    c = (long & (0xff << 8)) >>> 8;
    d = long & 0xff;
    return [a, b, c, d].join('.');
  };

  ip2long = function(ip) {
    var b, c, i, j, n, ref;
    b = [];
    for (i = j = 0; j <= 3; i = ++j) {
      if (ip.length === 0) {
        break;
      }
      if (i > 0) {
        if (ip[0] !== '.') {
          throw new Error('Invalid IP');
        }
        ip = ip.substring(1);
      }
      ref = atob(ip), n = ref[0], c = ref[1];
      ip = ip.substring(c);
      b.push(n);
    }
    if (ip.length !== 0) {
      throw new Error('Invalid IP');
    }
    switch (b.length) {
      case 1:
        if (b[0] > 0xFFFFFFFF) {
          throw new Error('Invalid IP');
        }
        return b[0] >>> 0;
      case 2:
        if (b[0] > 0xFF || b[1] > 0xFFFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1]) >>> 0;
      case 3:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2]) >>> 0;
      case 4:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFF || b[3] > 0xFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3]) >>> 0;
      default:
        throw new Error('Invalid IP');
    }
  };

  chr = function(b) {
    return b.charCodeAt(0);
  };

  chr0 = chr('0');

  chra = chr('a');

  chrA = chr('A');

  atob = function(s) {
    var base, dmax, i, n, start;
    n = 0;
    base = 10;
    dmax = '9';
    i = 0;
    if (s.length > 1 && s[i] === '0') {
      if (s[i + 1] === 'x' || s[i + 1] === 'X') {
        i += 2;
        base = 16;
      } else if ('0' <= s[i + 1] && s[i + 1] <= '9') {
        i++;
        base = 8;
        dmax = '7';
      }
    }
    start = i;
    while (i < s.length) {
      if ('0' <= s[i] && s[i] <= dmax) {
        n = (n * base + (chr(s[i]) - chr0)) >>> 0;
      } else if (base === 16) {
        if ('a' <= s[i] && s[i] <= 'f') {
          n = (n * base + (10 + chr(s[i]) - chra)) >>> 0;
        } else if ('A' <= s[i] && s[i] <= 'F') {
          n = (n * base + (10 + chr(s[i]) - chrA)) >>> 0;
        } else {
          break;
        }
      } else {
        break;
      }
      if (n > 0xFFFFFFFF) {
        throw new Error('too large');
      }
      i++;
    }
    if (i === start) {
      throw new Error('empty octet');
    }
    return [n, i];
  };

  Netmask = (function() {
    function Netmask(net, mask) {
      var i, j, ref;
      if (typeof net !== 'string') {
        throw new Error("Missing `net' parameter");
      }
      if (!mask) {
        ref = net.split('/', 2), net = ref[0], mask = ref[1];
      }
      if (!mask) {
        mask = 32;
      }
      if (typeof mask === 'string' && mask.indexOf('.') > -1) {
        try {
          this.maskLong = ip2long(mask);
        } catch (error1) {
          throw new Error("Invalid mask: " + mask);
        }
        for (i = j = 32; j >= 0; i = --j) {
          if (this.maskLong === (0xffffffff << (32 - i)) >>> 0) {
            this.bitmask = i;
            break;
          }
        }
      } else if (mask || mask === 0) {
        this.bitmask = parseInt(mask, 10);
        this.maskLong = 0;
        if (this.bitmask > 0) {
          this.maskLong = (0xffffffff << (32 - this.bitmask)) >>> 0;
        }
      } else {
        throw new Error("Invalid mask: empty");
      }
      try {
        this.netLong = (ip2long(net) & this.maskLong) >>> 0;
      } catch (error1) {
        throw new Error("Invalid net address: " + net);
      }
      if (!(this.bitmask <= 32)) {
        throw new Error("Invalid mask for ip4: " + mask);
      }
      this.size = Math.pow(2, 32 - this.bitmask);
      this.base = long2ip(this.netLong);
      this.mask = long2ip(this.maskLong);
      this.hostmask = long2ip(~this.maskLong);
      this.first = this.bitmask <= 30 ? long2ip(this.netLong + 1) : this.base;
      this.last = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 2) : long2ip(this.netLong + this.size - 1);
      this.broadcast = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 1) : void 0;
    }

    Netmask.prototype.contains = function(ip) {
      if (typeof ip === 'string' && (ip.indexOf('/') > 0 || ip.split('.').length !== 4)) {
        ip = new Netmask(ip);
      }
      if (ip instanceof Netmask) {
        return this.contains(ip.base) && this.contains(ip.broadcast || ip.last);
      } else {
        return (ip2long(ip) & this.maskLong) >>> 0 === (this.netLong & this.maskLong) >>> 0;
      }
    };

    Netmask.prototype.next = function(count) {
      if (count == null) {
        count = 1;
      }
      return new Netmask(long2ip(this.netLong + (this.size * count)), this.mask);
    };

    Netmask.prototype.forEach = function(fn) {
      var index, lastLong, long;
      long = ip2long(this.first);
      lastLong = ip2long(this.last);
      index = 0;
      while (long <= lastLong) {
        fn(long2ip(long), long, index);
        index++;
        long++;
      }
    };

    Netmask.prototype.toString = function() {
      return this.base + "/" + this.bitmask;
    };

    return Netmask;

  })();

  Netmask_1 = Netmask;

}).call(commonjsGlobal);

const PRIVATE_IP_RANGES = [
    '0.0.0.0/8',
    '10.0.0.0/8',
    '100.64.0.0/10',
    '127.0.0.0/8',
    '169.254.0.0/16',
    '172.16.0.0/12',
    '192.0.0.0/24',
    '192.0.0.0/29',
    '192.0.0.8/32',
    '192.0.0.9/32',
    '192.0.0.10/32',
    '192.0.0.170/32',
    '192.0.0.171/32',
    '192.0.2.0/24',
    '192.31.196.0/24',
    '192.52.193.0/24',
    '192.88.99.0/24',
    '192.168.0.0/16',
    '192.175.48.0/24',
    '198.18.0.0/15',
    '198.51.100.0/24',
    '203.0.113.0/24',
    '240.0.0.0/4',
    '255.255.255.255/32'
];
const NETMASK_RANGES = PRIVATE_IP_RANGES.map(ipRange => new Netmask_1(ipRange));
function ipv4Check(ipAddr) {
    for (const r of NETMASK_RANGES) {
        if (r.contains(ipAddr))
            return true;
    }
    return false;
}
function isIpv4MappedIpv6(ipAddr) {
    return /^::ffff:([0-9a-fA-F]{1,4}):([0-9a-fA-F]{1,4})$/.test(ipAddr);
}
/**
 * @see https://datatracker.ietf.org/doc/html/rfc4291#section-2.5.5.2
 */
function ipv4MappedIpv6Check(ipAddr) {
    const parts = ipAddr.split(':');
    if (parts.length < 2) {
        return false;
    }
    const octet34 = parts[parts.length - 1].padStart(4, '0');
    const octet12 = parts[parts.length - 2].padStart(4, '0');
    const ip4 = `${parseInt(octet12.substring(0, 2), 16)}.${parseInt(octet12.substring(2), 16)}.${parseInt(octet34.substring(0, 2), 16)}.${parseInt(octet34.substring(2), 16)}`;
    return ipv4Check(ip4);
}
/**
 * @see https://datatracker.ietf.org/doc/html/rfc4291#section-2.2 example 3
 */
function isIpv4EmbeddedIpv6(ipAddr) {
    return /^::ffff:([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ipAddr);
}
function ipv4EmbeddedIpv6Check(ipAddr) {
    const parts = ipAddr.split(':');
    const ip4 = parts[parts.length - 1];
    return ipv4Check(ip4);
}
function ipv6Check(ipAddr) {
    return /^::$/.test(ipAddr) ||
        /^::1$/.test(ipAddr) ||
        /^64:ff9b::([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ipAddr) ||
        /^100::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2001::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2001:2[0-9a-fA-F]:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2001:db8:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^2002:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||
        /^f[c-d]([0-9a-fA-F]{2,2}):/i.test(ipAddr) ||
        /^fe[8-9a-bA-B][0-9a-fA-F]:/i.test(ipAddr) ||
        /^ff([0-9a-fA-F]{2,2}):/i.test(ipAddr);
}
function isPrivateIp(ip) {
    if (isIPv4(ip))
        return ipv4Check(ip);
    else if (isIpv4MappedIpv6(ip))
        return ipv4MappedIpv6Check(ip);
    else if (isIpv4EmbeddedIpv6(ip))
        return ipv4EmbeddedIpv6Check(ip);
    else if (isIPv6(ip))
        return ipv6Check(ip);
    else
        return undefined;
}

/**
 * Returns a connection gater that disallows dialling private addresses by
 * default. Browsers are severely limited in their resource usage so don't
 * waste time trying to dial undiallable addresses.
 */
function connectionGater(gater = {}) {
    return {
        denyDialPeer: async () => false,
        denyDialMultiaddr: async (multiaddr) => {
            const tuples = multiaddr.stringTuples();
            if (tuples[0][0] === 4 || tuples[0][0] === 41) {
                return Boolean(isPrivateIp(`${tuples[0][1]}`));
            }
            return false;
        },
        denyInboundConnection: async () => false,
        denyOutboundConnection: async () => false,
        denyInboundEncryptedConnection: async () => false,
        denyOutboundEncryptedConnection: async () => false,
        denyInboundUpgradedConnection: async () => false,
        denyOutboundUpgradedConnection: async () => false,
        filterMultiaddrForPeer: async () => true,
        ...gater
    };
}

/**
 * Check if a given multiaddr has a private address.
 */
function isPrivate(ma) {
    try {
        const { address } = ma.nodeAddress();
        return Boolean(isPrivateIp(address));
    }
    catch {
        return true;
    }
}

/**
 * @packageDocumentation
 *
 * Provides strategies to sort a list of multiaddrs.
 *
 * @example
 *
 * ```typescript
 * import { publicAddressesFirst } from '@libp2p/utils/address-sort'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 *
 * const addresses = [
 *   multiaddr('/ip4/127.0.0.1/tcp/9000'),
 *   multiaddr('/ip4/82.41.53.1/tcp/9000')
 * ].sort(publicAddressesFirst)
 *
 * console.info(addresses)
 * // ['/ip4/82.41.53.1/tcp/9000', '/ip4/127.0.0.1/tcp/9000']
 * ```
 */
/**
 * Compare function for array.sort() that moves public addresses to the start
 * of the array.
 */
function publicAddressesFirst(a, b) {
    const isAPrivate = isPrivate(a.multiaddr);
    const isBPrivate = isPrivate(b.multiaddr);
    if (isAPrivate && !isBPrivate) {
        return 1;
    }
    else if (!isAPrivate && isBPrivate) {
        return -1;
    }
    return 0;
}
/**
 * Compare function for array.sort() that moves certified addresses to the start
 * of the array.
 */
function certifiedAddressesFirst(a, b) {
    if (a.isCertified && !b.isCertified) {
        return -1;
    }
    else if (!a.isCertified && b.isCertified) {
        return 1;
    }
    return 0;
}
/**
 * Compare function for array.sort() that moves circuit relay addresses to the
 * start of the array.
 */
function circuitRelayAddressesLast(a, b) {
    const isACircuit = Circuit.exactMatch(a.multiaddr);
    const isBCircuit = Circuit.exactMatch(b.multiaddr);
    if (isACircuit && !isBCircuit) {
        return 1;
    }
    else if (!isACircuit && isBCircuit) {
        return -1;
    }
    return 0;
}
function defaultAddressSort(a, b) {
    const publicResult = publicAddressesFirst(a, b);
    if (publicResult !== 0) {
        return publicResult;
    }
    const relayResult = circuitRelayAddressesLast(a, b);
    if (relayResult !== 0) {
        return relayResult;
    }
    const certifiedResult = certifiedAddressesFirst(a, b);
    return certifiedResult;
}

function getTypes(types) {
    const DEFAULT_TYPES = [
        RecordType.A
    ];
    if (types == null) {
        return DEFAULT_TYPES;
    }
    if (Array.isArray(types)) {
        if (types.length === 0) {
            return DEFAULT_TYPES;
        }
        return types;
    }
    return [
        types
    ];
}

/**
 * This TTL will be used if the remote service does not return one
 */
const DEFAULT_TTL = 60;
function toDNSResponse(obj) {
    return {
        Status: obj.Status ?? 0,
        TC: obj.TC ?? obj.flag_tc ?? false,
        RD: obj.RD ?? obj.flag_rd ?? false,
        RA: obj.RA ?? obj.flag_ra ?? false,
        AD: obj.AD ?? obj.flag_ad ?? false,
        CD: obj.CD ?? obj.flag_cd ?? false,
        Question: (obj.Question ?? obj.questions ?? []).map((question) => {
            return {
                name: question.name,
                type: RecordType[question.type]
            };
        }),
        Answer: (obj.Answer ?? obj.answers ?? []).map((answer) => {
            return {
                name: answer.name,
                type: RecordType[answer.type],
                TTL: (answer.TTL ?? answer.ttl ?? DEFAULT_TTL),
                data: answer.data instanceof Uint8Array ? toString$6(answer.data) : answer.data
            };
        })
    };
}

/* eslint-env browser */
/**
 * Browsers limit concurrent connections per host (~6), we don't want to exhaust
 * the limit so this value controls how many DNS queries can be in flight at
 * once.
 */
const DEFAULT_QUERY_CONCURRENCY = 4;
/**
 * Uses the RFC 8427 'application/dns-json' content-type to resolve DNS queries.
 *
 * Supports and server that uses the same schema as Google's DNS over HTTPS
 * resolver.
 *
 * This resolver needs fewer dependencies than the regular DNS-over-HTTPS
 * resolver so can result in a smaller bundle size and consequently is preferred
 * for browser use.
 *
 * @see https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-https/make-api-requests/dns-json/
 * @see https://github.com/curl/curl/wiki/DNS-over-HTTPS#publicly-available-servers
 * @see https://dnsprivacy.org/public_resolvers/
 * @see https://datatracker.ietf.org/doc/html/rfc8427
 */
function dnsJsonOverHttps(url, init = {}) {
    const httpQueue = new PQueue({
        concurrency: init.queryConcurrency ?? DEFAULT_QUERY_CONCURRENCY
    });
    return async (fqdn, options = {}) => {
        const searchParams = new URLSearchParams();
        searchParams.set('name', fqdn);
        getTypes(options.types).forEach(type => {
            // We pass record type as a string to the server because cloudflare DNS bug. see https://github.com/ipfs/helia/issues/474
            searchParams.append('type', RecordType[type]);
        });
        options.onProgress?.(new CustomProgressEvent('dns:query', { detail: fqdn }));
        // query DNS-JSON over HTTPS server
        const response = await httpQueue.add(async () => {
            const res = await fetch(`${url}?${searchParams}`, {
                headers: {
                    accept: 'application/dns-json'
                },
                signal: options?.signal
            });
            if (res.status !== 200) {
                throw new Error(`Unexpected HTTP status: ${res.status} - ${res.statusText}`);
            }
            const response = toDNSResponse(await res.json());
            options.onProgress?.(new CustomProgressEvent('dns:response', { detail: response }));
            return response;
        }, {
            signal: options.signal
        });
        if (response == null) {
            throw new Error('No DNS response received');
        }
        return response;
    };
}

function defaultResolver() {
    return [
        dnsJsonOverHttps('https://cloudflare-dns.com/dns-query'),
        dnsJsonOverHttps('https://dns.google/resolve')
    ];
}

var hashlru = function (max) {

  if (!max) throw Error('hashlru must have a max value, of type number, greater than 0')

  var size = 0, cache = Object.create(null), _cache = Object.create(null);

  function update (key, value) {
    cache[key] = value;
    size ++;
    if(size >= max) {
      size = 0;
      _cache = cache;
      cache = Object.create(null);
    }
  }

  return {
    has: function (key) {
      return cache[key] !== undefined || _cache[key] !== undefined
    },
    remove: function (key) {
      if(cache[key] !== undefined)
        cache[key] = undefined;
      if(_cache[key] !== undefined)
        _cache[key] = undefined;
    },
    get: function (key) {
      var v = cache[key];
      if(v !== undefined) return v
      if((v = _cache[key]) !== undefined) {
        update(key, v);
        return v
      }
    },
    set: function (key, value) {
      if(cache[key] !== undefined) cache[key] = value;
      else update(key, value);
    },
    clear: function () {
      cache = Object.create(null);
      _cache = Object.create(null);
    }
  }
};

var hashlru$1 = /*@__PURE__*/getDefaultExportFromCjs(hashlru);

/**
 * Time Aware Least Recent Used Cache
 *
 * @see https://arxiv.org/pdf/1801.00390
 */
class CachedAnswers {
    lru;
    constructor(maxSize) {
        this.lru = hashlru$1(maxSize);
    }
    get(fqdn, types) {
        let foundAllAnswers = true;
        const answers = [];
        for (const type of types) {
            const cached = this.getAnswers(fqdn, type);
            if (cached.length === 0) {
                foundAllAnswers = false;
                break;
            }
            answers.push(...cached);
        }
        if (foundAllAnswers) {
            return toDNSResponse({ answers });
        }
    }
    getAnswers(domain, type) {
        const key = `${domain.toLowerCase()}-${type}`;
        const answers = this.lru.get(key);
        if (answers != null) {
            const cachedAnswers = answers
                .filter((entry) => {
                return entry.expires > Date.now();
            })
                .map(({ expires, value }) => ({
                ...value,
                TTL: Math.round((expires - Date.now()) / 1000),
                type: RecordType[value.type]
            }));
            if (cachedAnswers.length === 0) {
                this.lru.remove(key);
            }
            // @ts-expect-error hashlru stringifies stored types which turns enums
            // into strings, we convert back into enums above but tsc doesn't know
            return cachedAnswers;
        }
        return [];
    }
    add(domain, answer) {
        const key = `${domain.toLowerCase()}-${answer.type}`;
        const answers = this.lru.get(key) ?? [];
        answers.push({
            expires: Date.now() + ((answer.TTL ?? DEFAULT_TTL) * 1000),
            value: answer
        });
        this.lru.set(key, answers);
    }
    remove(domain, type) {
        const key = `${domain.toLowerCase()}-${type}`;
        this.lru.remove(key);
    }
    clear() {
        this.lru.clear();
    }
}
/**
 * Avoid sending multiple queries for the same hostname by caching results
 */
function cache(size) {
    return new CachedAnswers(size);
}

const DEFAULT_ANSWER_CACHE_SIZE = 1000;
class DNS {
    resolvers;
    cache;
    constructor(init) {
        this.resolvers = {};
        this.cache = cache(init.cacheSize ?? DEFAULT_ANSWER_CACHE_SIZE);
        Object.entries(init.resolvers ?? {}).forEach(([tld, resolver]) => {
            if (!Array.isArray(resolver)) {
                resolver = [resolver];
            }
            // convert `com` -> `com.`
            if (!tld.endsWith('.')) {
                tld = `${tld}.`;
            }
            this.resolvers[tld] = resolver;
        });
        // configure default resolver if none specified
        if (this.resolvers['.'] == null) {
            this.resolvers['.'] = defaultResolver();
        }
    }
    /**
     * Queries DNS resolvers for the passed record types for the passed domain.
     *
     * If cached records exist for all desired types they will be returned
     * instead.
     *
     * Any new responses will be added to the cache for subsequent requests.
     */
    async query(domain, options = {}) {
        const types = getTypes(options.types);
        const cached = options.cached !== false ? this.cache.get(domain, types) : undefined;
        if (cached != null) {
            options.onProgress?.(new CustomProgressEvent('dns:cache', { detail: cached }));
            return cached;
        }
        const tld = `${domain.split('.').pop()}.`;
        const resolvers = (this.resolvers[tld] ?? this.resolvers['.']).sort(() => {
            return (Math.random() > 0.5) ? -1 : 1;
        });
        const errors = [];
        for (const resolver of resolvers) {
            // skip further resolutions if the user aborted the signal
            if (options.signal?.aborted === true) {
                break;
            }
            try {
                const result = await resolver(domain, {
                    ...options,
                    types
                });
                for (const answer of result.Answer) {
                    this.cache.add(domain, answer);
                }
                return result;
            }
            catch (err) {
                errors.push(err);
                options.onProgress?.(new CustomProgressEvent('dns:error', { detail: err }));
            }
        }
        if (errors.length === 1) {
            throw errors[0];
        }
        throw new AggregateError(errors, `DNS lookup of ${domain} ${types} failed`);
    }
}

/**
 * @packageDocumentation
 *
 * Query DNS records using `node:dns`, DNS over HTTP and/or DNSJSON over HTTP.
 *
 * A list of publicly accessible servers can be found [here](https://github.com/curl/curl/wiki/DNS-over-HTTPS#publicly-available-servers).
 *
 * @example Using the default resolver
 *
 * ```TypeScript
 * import { dns } from '@multiformats/dns'
 *
 * const resolver = dns()
 *
 * // resolve A records with a 5s timeout
 * const result = await dns.query('google.com', {
 *   signal: AbortSignal.timeout(5000)
 * })
 * ```
 *
 * @example Using per-TLD resolvers
 *
 * ```TypeScript
 * import { dns } from '@multiformats/dns'
 * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'
 *
 * const resolver = dns({
 *   resolvers: {
 *     // will only be used to resolve `.com` addresses
 *     'com.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query'),
 *
 *     // this can also be an array, resolvers will be shuffled and tried in
 *     // series
 *     'net.': [
 *       dnsJsonOverHttps('https://dns.google/resolve'),
 *       dnsJsonOverHttps('https://dns.pub/dns-query')
 *     ],
 *
 *     // will only be used to resolve all other addresses
 *     '.': dnsJsonOverHttps('https://dnsforge.de/dns-query'),
 *   }
 * })
 * ```
 *
 * @example Query for specific record types
 *
 * ```TypeScript
 * import { dns, RecordType } from '@multiformats/dns'
 *
 * const resolver = dns()
 *
 * // resolve only TXT records
 * const result = await dns.query('google.com', {
 *   types: [
 *     RecordType.TXT
 *   ]
 * })
 * ```
 *
 * ## Caching
 *
 * Individual Aanswers are cached so. If you make a request, for which all
 * record types are cached, all values will be pulled from the cache.
 *
 * If any of the record types are not cached, a new request will be resolved as
 * if none of the records were cached, and the cache will be updated to include
 * the new results.
 *
 * @example Ignoring the cache
 *
 * ```TypeScript
 * import { dns, RecordType } from '@multiformats/dns'
 *
 * const resolver = dns()
 *
 * // do not used cached results, always resolve a new query
 * const result = await dns.query('google.com', {
 *   cached: false
 * })
 * ```
 */
/**
 * A subset of DNS Record Types
 *
 * @see https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-4.
 */
var RecordType;
(function (RecordType) {
    RecordType[RecordType["A"] = 1] = "A";
    RecordType[RecordType["CNAME"] = 5] = "CNAME";
    RecordType[RecordType["TXT"] = 16] = "TXT";
    RecordType[RecordType["AAAA"] = 28] = "AAAA";
})(RecordType || (RecordType = {}));
function dns(init = {}) {
    return new DNS(init);
}

const MAX_RECURSIVE_DEPTH = 32;
const { code: dnsaddrCode } = getProtocol('dnsaddr');
class RecursionLimitError extends Error {
    constructor(message = 'Max recursive depth reached') {
        super(message);
        this.name = 'RecursionLimitError';
    }
}
const dnsaddrResolver = async function dnsaddrResolver(ma, options = {}) {
    const recursionLimit = options.maxRecursiveDepth ?? MAX_RECURSIVE_DEPTH;
    if (recursionLimit === 0) {
        throw new RecursionLimitError('Max recursive depth reached');
    }
    const [, hostname] = ma.stringTuples().find(([proto]) => proto === dnsaddrCode) ?? [];
    const resolver = options?.dns ?? dns();
    const result = await resolver.query(`_dnsaddr.${hostname}`, {
        signal: options?.signal,
        types: [
            RecordType.TXT
        ]
    });
    const peerId = ma.getPeerId();
    const output = [];
    for (const answer of result.Answer) {
        const addr = answer.data
            .replace(/["']/g, '')
            .trim()
            .split('=')[1];
        if (addr == null) {
            continue;
        }
        if (peerId != null && !addr.includes(peerId)) {
            continue;
        }
        const ma = multiaddr(addr);
        if (addr.startsWith('/dnsaddr')) {
            const resolved = await ma.resolve({
                ...options,
                maxRecursiveDepth: recursionLimit - 1
            });
            output.push(...resolved.map(ma => ma.toString()));
        }
        else {
            output.push(ma.toString());
        }
    }
    return output;
};

var isPlainObj = value => {
	if (Object.prototype.toString.call(value) !== '[object Object]') {
		return false;
	}

	const prototype = Object.getPrototypeOf(value);
	return prototype === null || prototype === Object.prototype;
};

const isOptionObject = isPlainObj;

const {hasOwnProperty} = Object.prototype;
const {propertyIsEnumerable} = Object;
const defineProperty = (object, name, value) => Object.defineProperty(object, name, {
	value,
	writable: true,
	enumerable: true,
	configurable: true
});

const globalThis$1 = commonjsGlobal;
const defaultMergeOptions = {
	concatArrays: false,
	ignoreUndefined: false
};

const getEnumerableOwnPropertyKeys = value => {
	const keys = [];

	for (const key in value) {
		if (hasOwnProperty.call(value, key)) {
			keys.push(key);
		}
	}

	/* istanbul ignore else  */
	if (Object.getOwnPropertySymbols) {
		const symbols = Object.getOwnPropertySymbols(value);

		for (const symbol of symbols) {
			if (propertyIsEnumerable.call(value, symbol)) {
				keys.push(symbol);
			}
		}
	}

	return keys;
};

function clone(value) {
	if (Array.isArray(value)) {
		return cloneArray(value);
	}

	if (isOptionObject(value)) {
		return cloneOptionObject(value);
	}

	return value;
}

function cloneArray(array) {
	const result = array.slice(0, 0);

	getEnumerableOwnPropertyKeys(array).forEach(key => {
		defineProperty(result, key, clone(array[key]));
	});

	return result;
}

function cloneOptionObject(object) {
	const result = Object.getPrototypeOf(object) === null ? Object.create(null) : {};

	getEnumerableOwnPropertyKeys(object).forEach(key => {
		defineProperty(result, key, clone(object[key]));
	});

	return result;
}

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {string[]} keys keys to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 */
const mergeKeys = (merged, source, keys, config) => {
	keys.forEach(key => {
		if (typeof source[key] === 'undefined' && config.ignoreUndefined) {
			return;
		}

		// Do not recurse into prototype chain of merged
		if (key in merged && merged[key] !== Object.getPrototypeOf(merged)) {
			defineProperty(merged, key, merge(merged[key], source[key], config));
		} else {
			defineProperty(merged, key, clone(source[key]));
		}
	});

	return merged;
};

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 *
 * see [Array.prototype.concat ( ...arguments )](http://www.ecma-international.org/ecma-262/6.0/#sec-array.prototype.concat)
 */
const concatArrays = (merged, source, config) => {
	let result = merged.slice(0, 0);
	let resultIndex = 0;

	[merged, source].forEach(array => {
		const indices = [];

		// `result.concat(array)` with cloning
		for (let k = 0; k < array.length; k++) {
			if (!hasOwnProperty.call(array, k)) {
				continue;
			}

			indices.push(String(k));

			if (array === merged) {
				// Already cloned
				defineProperty(result, resultIndex++, array[k]);
			} else {
				defineProperty(result, resultIndex++, clone(array[k]));
			}
		}

		// Merge non-index keys
		result = mergeKeys(result, array, getEnumerableOwnPropertyKeys(array).filter(key => !indices.includes(key)), config);
	});

	return result;
};

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 */
function merge(merged, source, config) {
	if (config.concatArrays && Array.isArray(merged) && Array.isArray(source)) {
		return concatArrays(merged, source, config);
	}

	if (!isOptionObject(source) || !isOptionObject(merged)) {
		return clone(source);
	}

	return mergeKeys(merged, source, getEnumerableOwnPropertyKeys(source), config);
}

var mergeOptions = function (...options) {
	const config = merge(clone(defaultMergeOptions), (this !== globalThis$1 && this) || {}, defaultMergeOptions);
	let merged = {_: {}};

	for (const option of options) {
		if (option === undefined) {
			continue;
		}

		if (!isOptionObject(option)) {
			throw new TypeError('`' + option + '` is not an Option Object');
		}

		merged = merge(merged, {_: option}, config);
	}

	return merged._;
};

var mergeOptions$1 = /*@__PURE__*/getDefaultExportFromCjs(mergeOptions);

var messages;
(function (messages) {
    messages["NOT_STARTED_YET"] = "The libp2p node is not started yet";
    messages["ERR_PROTECTOR_REQUIRED"] = "Private network is enforced, but no protector was provided";
    messages["NOT_FOUND"] = "Not found";
})(messages || (messages = {}));
var codes;
(function (codes) {
    codes["ERR_PROTECTOR_REQUIRED"] = "ERR_PROTECTOR_REQUIRED";
    codes["ERR_PEER_DIAL_INTERCEPTED"] = "ERR_PEER_DIAL_INTERCEPTED";
    codes["ERR_CONNECTION_INTERCEPTED"] = "ERR_CONNECTION_INTERCEPTED";
    codes["ERR_INVALID_PROTOCOLS_FOR_STREAM"] = "ERR_INVALID_PROTOCOLS_FOR_STREAM";
    codes["ERR_CONNECTION_ENDED"] = "ERR_CONNECTION_ENDED";
    codes["ERR_CONNECTION_FAILED"] = "ERR_CONNECTION_FAILED";
    codes["ERR_NODE_NOT_STARTED"] = "ERR_NODE_NOT_STARTED";
    codes["ERR_ALREADY_ABORTED"] = "ERR_ALREADY_ABORTED";
    codes["ERR_TOO_MANY_ADDRESSES"] = "ERR_TOO_MANY_ADDRESSES";
    codes["ERR_NO_VALID_ADDRESSES"] = "ERR_NO_VALID_ADDRESSES";
    codes["ERR_RELAYED_DIAL"] = "ERR_RELAYED_DIAL";
    codes["ERR_DIALED_SELF"] = "ERR_DIALED_SELF";
    codes["ERR_DISCOVERED_SELF"] = "ERR_DISCOVERED_SELF";
    codes["ERR_DUPLICATE_TRANSPORT"] = "ERR_DUPLICATE_TRANSPORT";
    codes["ERR_ENCRYPTION_FAILED"] = "ERR_ENCRYPTION_FAILED";
    codes["ERR_HOP_REQUEST_FAILED"] = "ERR_HOP_REQUEST_FAILED";
    codes["ERR_INVALID_KEY"] = "ERR_INVALID_KEY";
    codes["ERR_INVALID_MESSAGE"] = "ERR_INVALID_MESSAGE";
    codes["ERR_INVALID_PARAMETERS"] = "ERR_INVALID_PARAMETERS";
    codes["ERR_INVALID_PEER"] = "ERR_INVALID_PEER";
    codes["ERR_MUXER_UNAVAILABLE"] = "ERR_MUXER_UNAVAILABLE";
    codes["ERR_NOT_FOUND"] = "ERR_NOT_FOUND";
    codes["ERR_TRANSPORT_UNAVAILABLE"] = "ERR_TRANSPORT_UNAVAILABLE";
    codes["ERR_TRANSPORT_DIAL_FAILED"] = "ERR_TRANSPORT_DIAL_FAILED";
    codes["ERR_UNSUPPORTED_PROTOCOL"] = "ERR_UNSUPPORTED_PROTOCOL";
    codes["ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED"] = "ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED";
    codes["ERR_INVALID_MULTIADDR"] = "ERR_INVALID_MULTIADDR";
    codes["ERR_SIGNATURE_NOT_VALID"] = "ERR_SIGNATURE_NOT_VALID";
    codes["ERR_FIND_SELF"] = "ERR_FIND_SELF";
    codes["ERR_NO_ROUTERS_AVAILABLE"] = "ERR_NO_ROUTERS_AVAILABLE";
    codes["ERR_CONNECTION_NOT_MULTIPLEXED"] = "ERR_CONNECTION_NOT_MULTIPLEXED";
    codes["ERR_NO_DIAL_TOKENS"] = "ERR_NO_DIAL_TOKENS";
    codes["ERR_INVALID_CMS"] = "ERR_INVALID_CMS";
    codes["ERR_MISSING_KEYS"] = "ERR_MISSING_KEYS";
    codes["ERR_NO_KEY"] = "ERR_NO_KEY";
    codes["ERR_INVALID_KEY_NAME"] = "ERR_INVALID_KEY_NAME";
    codes["ERR_INVALID_KEY_TYPE"] = "ERR_INVALID_KEY_TYPE";
    codes["ERR_KEY_ALREADY_EXISTS"] = "ERR_KEY_ALREADY_EXISTS";
    codes["ERR_INVALID_KEY_SIZE"] = "ERR_INVALID_KEY_SIZE";
    codes["ERR_KEY_NOT_FOUND"] = "ERR_KEY_NOT_FOUND";
    codes["ERR_OLD_KEY_NAME_INVALID"] = "ERR_OLD_KEY_NAME_INVALID";
    codes["ERR_NEW_KEY_NAME_INVALID"] = "ERR_NEW_KEY_NAME_INVALID";
    codes["ERR_PASSWORD_REQUIRED"] = "ERR_PASSWORD_REQUIRED";
    codes["ERR_PEM_REQUIRED"] = "ERR_PEM_REQUIRED";
    codes["ERR_CANNOT_READ_KEY"] = "ERR_CANNOT_READ_KEY";
    codes["ERR_MISSING_PRIVATE_KEY"] = "ERR_MISSING_PRIVATE_KEY";
    codes["ERR_MISSING_PUBLIC_KEY"] = "ERR_MISSING_PUBLIC_KEY";
    codes["ERR_INVALID_OLD_PASS_TYPE"] = "ERR_INVALID_OLD_PASS_TYPE";
    codes["ERR_INVALID_NEW_PASS_TYPE"] = "ERR_INVALID_NEW_PASS_TYPE";
    codes["ERR_INVALID_PASS_LENGTH"] = "ERR_INVALID_PASS_LENGTH";
    codes["ERR_NOT_IMPLEMENTED"] = "ERR_NOT_IMPLEMENTED";
    codes["ERR_WRONG_PING_ACK"] = "ERR_WRONG_PING_ACK";
    codes["ERR_INVALID_RECORD"] = "ERR_INVALID_RECORD";
    codes["ERR_ALREADY_SUCCEEDED"] = "ERR_ALREADY_SUCCEEDED";
    codes["ERR_NO_HANDLER_FOR_PROTOCOL"] = "ERR_NO_HANDLER_FOR_PROTOCOL";
    codes["ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS"] = "ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS";
    codes["ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS"] = "ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS";
    codes["ERR_CONNECTION_DENIED"] = "ERR_CONNECTION_DENIED";
    codes["ERR_TRANSFER_LIMIT_EXCEEDED"] = "ERR_TRANSFER_LIMIT_EXCEEDED";
})(codes || (codes = {}));

const DefaultConfig = {
    addresses: {
        listen: [],
        announce: [],
        noAnnounce: [],
        announceFilter: (multiaddrs) => multiaddrs
    },
    connectionManager: {
        resolvers: {
            dnsaddr: dnsaddrResolver
        },
        addressSorter: defaultAddressSort
    },
    transportManager: {
        faultTolerance: FaultTolerance.FATAL_ALL
    }
};
async function validateConfig(opts) {
    const resultingOptions = mergeOptions$1(DefaultConfig, opts);
    if (resultingOptions.connectionProtector === null && globalThis.process?.env?.LIBP2P_FORCE_PNET != null) { // eslint-disable-line no-undef
        throw new CodeError$1(messages.ERR_PROTECTOR_REQUIRED, codes.ERR_PROTECTOR_REQUIRED);
    }
    if (resultingOptions.privateKey != null && !(await peerIdFromKeys(resultingOptions.privateKey.public.bytes, resultingOptions.privateKey.bytes)).equals(resultingOptions.peerId)) {
        throw new CodeError$1('Private key doesn\'t match peer id', codes.ERR_INVALID_KEY);
    }
    return resultingOptions;
}

/**
 * Extracts a PeerId and/or multiaddr from the passed PeerId or Multiaddr or an array of Multiaddrs
 */
function getPeerAddress(peer) {
    if (isPeerId(peer)) {
        return { peerId: peer, multiaddrs: [] };
    }
    if (!Array.isArray(peer)) {
        peer = [peer];
    }
    let peerId;
    if (peer.length > 0) {
        const peerIdStr = peer[0].getPeerId();
        peerId = peerIdStr == null ? undefined : peerIdFromString(peerIdStr);
        // ensure PeerId is either not set or is consistent
        peer.forEach(ma => {
            if (!isMultiaddr(ma)) {
                throw new CodeError$1('Invalid Multiaddr', codes.ERR_INVALID_MULTIADDR);
            }
            const maPeerIdStr = ma.getPeerId();
            if (maPeerIdStr == null) {
                if (peerId != null) {
                    throw new CodeError$1('Multiaddrs must all have the same peer id or have no peer id', codes.ERR_INVALID_PARAMETERS);
                }
            }
            else {
                const maPeerId = peerIdFromString(maPeerIdStr);
                if (peerId?.equals(maPeerId) !== true) {
                    throw new CodeError$1('Multiaddrs must all have the same peer id or have no peer id', codes.ERR_INVALID_PARAMETERS);
                }
            }
        });
    }
    return {
        peerId,
        multiaddrs: peer
    };
}

/**
 * @packageDocumentation
 *
 * Race an event against an AbortSignal, taking care to remove any event
 * listeners that were added.
 *
 * @example Getting started
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * setTimeout(() => {
 *   controller.abort()
 * }, 500)
 *
 * setTimeout(() => {
 *   // too late
 *   emitter.dispatchEvent(new CustomEvent('event'))
 * }, 1000)
 *
 * // throws an AbortError
 * const resolve = await raceEvent(emitter, 'event', controller.signal)
 * ```
 *
 * @example Aborting the promise with an error event
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const emitter = new EventTarget()
 *
 * setTimeout(() => {
 *   emitter.dispatchEvent(new CustomEvent('failure', {
 *     detail: new Error('Oh no!')
 *   }))
 * }, 1000)
 *
 * // throws 'Oh no!' error
 * const resolve = await raceEvent(emitter, 'success', AbortSignal.timeout(5000), {
 *   errorEvent: 'failure'
 * })
 * ```
 *
 * @example Customising the thrown AbortError
 *
 * The error message and `.code` property of the thrown `AbortError` can be
 * specified by passing options:
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * setTimeout(() => {
 *   controller.abort()
 * }, 500)
 *
 * // throws a Error: Oh no!
 * const resolve = await raceEvent(emitter, 'event', controller.signal, {
 *   errorMessage: 'Oh no!',
 *   errorCode: 'ERR_OH_NO'
 * })
 * ```
 *
 * @example Only resolving on specific events
 *
 * Where multiple events with the same type are emitted, a `filter` function can
 * be passed to only resolve on one of them:
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * // throws a Error: Oh no!
 * const resolve = await raceEvent(emitter, 'event', controller.signal, {
 *   filter: (evt: Event) => {
 *     return evt.detail.foo === 'bar'
 *   }
 * })
 * ```
 *
 * @example Terminating early by throwing from the filter
 *
 * You can cause listening for the event to cease and all event listeners to be
 * removed by throwing from the filter:
 *
 * ```TypeScript
 * import { raceEvent } from 'race-event'
 *
 * const controller = new AbortController()
 * const emitter = new EventTarget()
 *
 * // throws Error: Cannot continue
 * const resolve = await raceEvent(emitter, 'event', controller.signal, {
 *   filter: (evt) => {
 *     if (...reasons) {
 *       throw new Error('Cannot continue')
 *     }
 *
 *     return true
 *   }
 * })
 * ```
 */
/**
 * An abort error class that extends error
 */
let AbortError$1 = class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.name = 'AbortError';
        this.code = code ?? 'ABORT_ERR';
    }
};
/**
 * Race a promise against an abort signal
 */
async function raceEvent(emitter, eventName, signal, opts) {
    // create the error here so we have more context in the stack trace
    const error = new AbortError$1(opts?.errorMessage, opts?.errorCode);
    if (signal?.aborted === true) {
        return Promise.reject(error);
    }
    return new Promise((resolve, reject) => {
        function removeListeners() {
            signal?.removeEventListener('abort', abortListener);
            emitter.removeEventListener(eventName, eventListener);
            if (opts?.errorEvent != null) {
                emitter.removeEventListener(opts.errorEvent, errorEventListener);
            }
        }
        const eventListener = (evt) => {
            try {
                if (opts?.filter?.(evt) === false) {
                    return;
                }
            }
            catch (err) {
                removeListeners();
                reject(err);
                return;
            }
            removeListeners();
            resolve(evt);
        };
        const errorEventListener = (evt) => {
            removeListeners();
            reject(evt.detail);
        };
        const abortListener = () => {
            removeListeners();
            reject(error);
        };
        signal?.addEventListener('abort', abortListener);
        emitter.addEventListener(eventName, eventListener);
        if (opts?.errorEvent != null) {
            emitter.addEventListener(opts.errorEvent, errorEventListener);
        }
    });
}

class JobRecipient {
    deferred;
    signal;
    constructor(signal) {
        this.signal = signal;
        this.deferred = pDefer();
        this.onAbort = this.onAbort.bind(this);
        this.signal?.addEventListener('abort', this.onAbort);
    }
    onAbort() {
        this.deferred.reject(this.signal?.reason ?? new AbortError$5());
    }
    cleanup() {
        this.signal?.removeEventListener('abort', this.onAbort);
    }
}

/**
 * Returns a random string
 */
function randomId() {
    return `${(parseInt(String(Math.random() * 1e9), 10)).toString()}${Date.now()}`;
}
class Job {
    id;
    fn;
    options;
    recipients;
    status;
    timeline;
    controller;
    constructor(fn, options) {
        this.id = randomId();
        this.status = 'queued';
        this.fn = fn;
        this.options = options;
        this.recipients = [];
        this.timeline = {
            created: Date.now()
        };
        this.controller = new AbortController();
        setMaxListeners(Infinity, this.controller.signal);
        this.onAbort = this.onAbort.bind(this);
    }
    abort(err) {
        this.controller.abort(err);
    }
    onAbort() {
        const allAborted = this.recipients.reduce((acc, curr) => {
            return acc && (curr.signal?.aborted === true);
        }, true);
        // if all recipients have aborted the job, actually abort the job
        if (allAborted) {
            this.controller.abort(new AbortError$5());
            this.cleanup();
        }
    }
    async join(options = {}) {
        const recipient = new JobRecipient(options.signal);
        this.recipients.push(recipient);
        options.signal?.addEventListener('abort', this.onAbort);
        return recipient.deferred.promise;
    }
    async run() {
        this.status = 'running';
        this.timeline.started = Date.now();
        try {
            this.controller.signal.throwIfAborted();
            const result = await raceSignal(this.fn({
                ...(this.options ?? {}),
                signal: this.controller.signal
            }), this.controller.signal);
            this.recipients.forEach(recipient => {
                recipient.deferred.resolve(result);
            });
            this.status = 'complete';
        }
        catch (err) {
            this.recipients.forEach(recipient => {
                recipient.deferred.reject(err);
            });
            this.status = 'errored';
        }
        finally {
            this.timeline.finished = Date.now();
            this.cleanup();
        }
    }
    cleanup() {
        this.recipients.forEach(recipient => {
            recipient.cleanup();
            recipient.signal?.removeEventListener('abort', this.onAbort);
        });
    }
}

/**
 * Heavily influence by `p-queue` with the following differences:
 *
 * 1. Items remain at the head of the queue while they are running so `queue.size` includes `queue.pending` items - this is so interested parties can join the results of a queue item while it is running
 * 2. The options for a job are stored separately to the job in order for them to be modified while they are still in the queue
 */
class Queue extends TypedEventEmitter {
    concurrency;
    queue;
    pending;
    sort;
    constructor(init = {}) {
        super();
        this.concurrency = init.concurrency ?? Number.POSITIVE_INFINITY;
        this.pending = 0;
        if (init.metricName != null) {
            init.metrics?.registerMetricGroup(init.metricName, {
                calculate: () => {
                    return {
                        size: this.queue.length,
                        running: this.pending,
                        queued: this.queue.length - this.pending
                    };
                }
            });
        }
        this.sort = init.sort;
        this.queue = [];
    }
    tryToStartAnother() {
        if (this.size === 0) {
            // do this in the microtask queue so all job recipients receive the
            // result before the "empty" event fires
            queueMicrotask(() => {
                this.safeDispatchEvent('empty');
            });
            if (this.running === 0) {
                // do this in the microtask queue so all job recipients receive the
                // result before the "idle" event fires
                queueMicrotask(() => {
                    this.safeDispatchEvent('idle');
                });
            }
            return false;
        }
        if (this.pending < this.concurrency) {
            let job;
            for (const j of this.queue) {
                if (j.status === 'queued') {
                    job = j;
                    break;
                }
            }
            if (job == null) {
                return false;
            }
            this.safeDispatchEvent('active');
            this.pending++;
            void job.run()
                .finally(() => {
                // remove the job from the queue
                for (let i = 0; i < this.queue.length; i++) {
                    if (this.queue[i] === job) {
                        this.queue.splice(i, 1);
                        break;
                    }
                }
                this.pending--;
                this.tryToStartAnother();
                this.safeDispatchEvent('next');
            });
            return true;
        }
        return false;
    }
    enqueue(job) {
        this.queue.push(job);
        if (this.sort != null) {
            this.queue.sort(this.sort);
        }
    }
    /**
     * Adds a sync or async task to the queue. Always returns a promise.
     */
    async add(fn, options) {
        options?.signal?.throwIfAborted();
        const job = new Job(fn, options);
        this.enqueue(job);
        this.safeDispatchEvent('add');
        this.tryToStartAnother();
        return job.join(options)
            .then(result => {
            this.safeDispatchEvent('completed', { detail: result });
            this.safeDispatchEvent('success', { detail: { job, result } });
            return result;
        })
            .catch(err => {
            if (job.status === 'queued') {
                // job was aborted before it started - remove the job from the queue
                for (let i = 0; i < this.queue.length; i++) {
                    if (this.queue[i] === job) {
                        this.queue.splice(i, 1);
                        break;
                    }
                }
            }
            this.safeDispatchEvent('error', { detail: err });
            this.safeDispatchEvent('failure', { detail: { job, error: err } });
            throw err;
        });
    }
    /**
     * Clear the queue
     */
    clear() {
        this.queue.splice(0, this.queue.length);
    }
    /**
     * Abort all jobs in the queue and clear it
     */
    abort() {
        this.queue.forEach(job => {
            job.abort(new AbortError$5());
        });
        this.clear();
    }
    /**
     * Can be called multiple times. Useful if you for example add additional items at a later time.
     *
     * @returns A promise that settles when the queue becomes empty.
     */
    async onEmpty(options) {
        // Instantly resolve if the queue is empty
        if (this.size === 0) {
            return;
        }
        await raceEvent(this, 'empty', options?.signal);
    }
    /**
     * @returns A promise that settles when the queue size is less than the given
     * limit: `queue.size < limit`.
     *
     * If you want to avoid having the queue grow beyond a certain size you can
     * `await queue.onSizeLessThan()` before adding a new item.
     *
     * Note that this only limits the number of items waiting to start. There
     * could still be up to `concurrency` jobs already running that this call does
     * not include in its calculation.
     */
    async onSizeLessThan(limit, options) {
        // Instantly resolve if the queue is empty.
        if (this.size < limit) {
            return;
        }
        await raceEvent(this, 'next', options?.signal, {
            filter: () => this.size < limit
        });
    }
    /**
     * The difference with `.onEmpty` is that `.onIdle` guarantees that all work
     * from the queue has finished. `.onEmpty` merely signals that the queue is
     * empty, but it could mean that some promises haven't completed yet.
     *
     * @returns A promise that settles when the queue becomes empty, and all
     * promises have completed; `queue.size === 0 && queue.pending === 0`.
     */
    async onIdle(options) {
        // Instantly resolve if none pending and if nothing else is queued
        if (this.pending === 0 && this.size === 0) {
            return;
        }
        await raceEvent(this, 'idle', options?.signal);
    }
    /**
     * Size of the queue including running items
     */
    get size() {
        return this.queue.length;
    }
    /**
     * The number of queued items waiting to run.
     */
    get queued() {
        return this.queue.length - this.pending;
    }
    /**
     * The number of items currently running.
     */
    get running() {
        return this.pending;
    }
    /**
     * Returns an async generator that makes it easy to iterate over the results
     * of jobs added to the queue.
     *
     * The generator will end when the queue becomes idle, that is there are no
     * jobs running and no jobs that have yet to run.
     *
     * If you need to keep the queue open indefinitely, consider using it-pushable
     * instead.
     */
    async *toGenerator(options) {
        options?.signal?.throwIfAborted();
        const stream = pushable({
            objectMode: true
        });
        const cleanup = (err) => {
            if (err != null) {
                this.abort();
            }
            else {
                this.clear();
            }
            stream.end(err);
        };
        const onQueueJobComplete = (evt) => {
            if (evt.detail != null) {
                stream.push(evt.detail);
            }
        };
        const onQueueError = (evt) => {
            cleanup(evt.detail);
        };
        const onQueueIdle = () => {
            cleanup();
        };
        // clear the queue and throw if the query is aborted
        const onSignalAbort = () => {
            cleanup(new CodeError$1('Queue aborted', 'ERR_QUEUE_ABORTED'));
        };
        // add listeners
        this.addEventListener('completed', onQueueJobComplete);
        this.addEventListener('error', onQueueError);
        this.addEventListener('idle', onQueueIdle);
        options?.signal?.addEventListener('abort', onSignalAbort);
        try {
            yield* stream;
        }
        finally {
            // remove listeners
            this.removeEventListener('completed', onQueueJobComplete);
            this.removeEventListener('error', onQueueError);
            this.removeEventListener('idle', onQueueIdle);
            options?.signal?.removeEventListener('abort', onSignalAbort);
            // empty the queue for when the user has broken out of a loop early
            cleanup();
        }
    }
}

/**
 * Extends Queue to add support for querying queued jobs by peer id
 */
class PeerQueue extends Queue {
    has(peerId) {
        return this.find(peerId) != null;
    }
    find(peerId) {
        return this.queue.find(job => {
            return peerId.equals(job.options.peerId);
        });
    }
}

/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#dialTimeout
 */
const DIAL_TIMEOUT = 5e3;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#inboundUpgradeTimeout
 */
const INBOUND_UPGRADE_TIMEOUT = 2e3;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxPeerAddrsToDial
 */
const MAX_PEER_ADDRS_TO_DIAL = 25;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialInterval
 */
const AUTO_DIAL_INTERVAL = 5000;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialConcurrency
 */
const AUTO_DIAL_CONCURRENCY = 25;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialPriority
 */
const AUTO_DIAL_PRIORITY = 0;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialMaxQueueLength
 */
const AUTO_DIAL_MAX_QUEUE_LENGTH = 100;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/libp2p.index.unknown.ConnectionManagerInit.html#autoDialDiscoveredPeersDebounce
 */
const AUTO_DIAL_DISCOVERED_PEERS_DEBOUNCE = 10;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#inboundConnectionThreshold
 */
const INBOUND_CONNECTION_THRESHOLD = 5;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxIncomingPendingConnections
 */
const MAX_INCOMING_PENDING_CONNECTIONS = 10;
/**
 * Store as part of the peer store metadata for a given peer, the value for this
 * key is a timestamp of the last time a dial attempted failed with the relevant
 * peer stored as a string.
 *
 * Used to insure we do not endlessly try to auto dial peers we have recently
 * failed to dial.
 */
const LAST_DIAL_FAILURE_KEY = 'last-dial-failure';
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxDialQueueLength
 */
const MAX_DIAL_QUEUE_LENGTH = 500;

/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#minConnections
 */
const MIN_CONNECTIONS = 5;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxConnections
 */
const MAX_CONNECTIONS = 100;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxParallelDials
 */
const MAX_PARALLEL_DIALS = 50;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/libp2p.index.unknown.ConnectionManagerInit.html#autoDialPeerRetryThreshold
 */
const AUTO_DIAL_PEER_RETRY_THRESHOLD = 1000 * 60 * 7;

const defaultOptions$3 = {
    minConnections: MIN_CONNECTIONS,
    maxQueueLength: AUTO_DIAL_MAX_QUEUE_LENGTH,
    autoDialConcurrency: AUTO_DIAL_CONCURRENCY,
    autoDialPriority: AUTO_DIAL_PRIORITY,
    autoDialInterval: AUTO_DIAL_INTERVAL,
    autoDialPeerRetryThreshold: AUTO_DIAL_PEER_RETRY_THRESHOLD,
    autoDialDiscoveredPeersDebounce: AUTO_DIAL_DISCOVERED_PEERS_DEBOUNCE
};
class AutoDial {
    connectionManager;
    peerStore;
    queue;
    minConnections;
    autoDialPriority;
    autoDialIntervalMs;
    autoDialMaxQueueLength;
    autoDialPeerRetryThresholdMs;
    autoDialDiscoveredPeersDebounce;
    autoDialInterval;
    started;
    running;
    log;
    /**
     * Proactively tries to connect to known peers stored in the PeerStore.
     * It will keep the number of connections below the upper limit and sort
     * the peers to connect based on whether we know their keys and protocols.
     */
    constructor(components, init) {
        this.connectionManager = components.connectionManager;
        this.peerStore = components.peerStore;
        this.minConnections = init.minConnections ?? defaultOptions$3.minConnections;
        this.autoDialPriority = init.autoDialPriority ?? defaultOptions$3.autoDialPriority;
        this.autoDialIntervalMs = init.autoDialInterval ?? defaultOptions$3.autoDialInterval;
        this.autoDialMaxQueueLength = init.maxQueueLength ?? defaultOptions$3.maxQueueLength;
        this.autoDialPeerRetryThresholdMs = init.autoDialPeerRetryThreshold ?? defaultOptions$3.autoDialPeerRetryThreshold;
        this.autoDialDiscoveredPeersDebounce = init.autoDialDiscoveredPeersDebounce ?? defaultOptions$3.autoDialDiscoveredPeersDebounce;
        this.log = components.logger.forComponent('libp2p:connection-manager:auto-dial');
        this.started = false;
        this.running = false;
        this.queue = new PeerQueue({
            concurrency: init.autoDialConcurrency ?? defaultOptions$3.autoDialConcurrency,
            metricName: 'libp2p_autodial_queue',
            metrics: components.metrics
        });
        this.queue.addEventListener('error', (evt) => {
            this.log.error('error during auto-dial', evt.detail);
        });
        // check the min connection limit whenever a peer disconnects
        components.events.addEventListener('connection:close', () => {
            this.autoDial()
                .catch(err => {
                this.log.error(err);
            });
        });
        // sometimes peers are discovered in quick succession so add a small
        // debounce to ensure all eligible peers are autodialed
        let debounce;
        // when new peers are discovered, dial them if we don't have
        // enough connections
        components.events.addEventListener('peer:discovery', () => {
            clearTimeout(debounce);
            debounce = setTimeout(() => {
                this.autoDial()
                    .catch(err => {
                    this.log.error(err);
                });
            }, this.autoDialDiscoveredPeersDebounce);
        });
    }
    isStarted() {
        return this.started;
    }
    start() {
        this.started = true;
    }
    afterStart() {
        this.autoDial()
            .catch(err => {
            this.log.error('error while autodialing', err);
        });
    }
    stop() {
        // clear the queue
        this.queue.clear();
        clearTimeout(this.autoDialInterval);
        this.started = false;
        this.running = false;
    }
    async autoDial() {
        if (!this.started || this.running) {
            return;
        }
        const connections = this.connectionManager.getConnectionsMap();
        const numConnections = connections.size;
        // already have enough connections
        if (numConnections >= this.minConnections) {
            if (this.minConnections > 0) {
                this.log.trace('have enough connections %d/%d', numConnections, this.minConnections);
            }
            // no need to schedule next autodial as it will be run when on
            // connection:close event
            return;
        }
        if (this.queue.size > this.autoDialMaxQueueLength) {
            this.log('not enough connections %d/%d but auto dial queue is full', numConnections, this.minConnections);
            this.sheduleNextAutodial();
            return;
        }
        this.running = true;
        this.log('not enough connections %d/%d - will dial peers to increase the number of connections', numConnections, this.minConnections);
        const dialQueue = new PeerSet(
        // @ts-expect-error boolean filter removes falsy peer IDs
        this.connectionManager.getDialQueue()
            .map(queue => queue.peerId)
            .filter(Boolean));
        // sort peers on whether we know protocols or public keys for them
        const peers = await this.peerStore.all({
            filters: [
                // remove some peers
                (peer) => {
                    // remove peers without addresses
                    if (peer.addresses.length === 0) {
                        this.log.trace('not autodialing %p because they have no addresses', peer.id);
                        return false;
                    }
                    // remove peers we are already connected to
                    if (connections.has(peer.id)) {
                        this.log.trace('not autodialing %p because they are already connected', peer.id);
                        return false;
                    }
                    // remove peers we are already dialling
                    if (dialQueue.has(peer.id)) {
                        this.log.trace('not autodialing %p because they are already being dialed', peer.id);
                        return false;
                    }
                    // remove peers already in the autodial queue
                    if (this.queue.has(peer.id)) {
                        this.log.trace('not autodialing %p because they are already being autodialed', peer.id);
                        return false;
                    }
                    return true;
                }
            ]
        });
        // shuffle the peers - this is so peers with the same tag values will be
        // dialled in a different order each time
        const shuffledPeers = peers.sort(() => Math.random() > 0.5 ? 1 : -1);
        // sort shuffled peers by tag value
        const peerValues = new PeerMap();
        for (const peer of shuffledPeers) {
            if (peerValues.has(peer.id)) {
                continue;
            }
            // sum all tag values
            peerValues.set(peer.id, [...peer.tags.values()].reduce((acc, curr) => {
                return acc + curr.value;
            }, 0));
        }
        // sort by value, highest to lowest
        const sortedPeers = shuffledPeers.sort((a, b) => {
            const peerAValue = peerValues.get(a.id) ?? 0;
            const peerBValue = peerValues.get(b.id) ?? 0;
            if (peerAValue > peerBValue) {
                return -1;
            }
            if (peerAValue < peerBValue) {
                return 1;
            }
            return 0;
        });
        const peersThatHaveNotFailed = sortedPeers.filter(peer => {
            const lastDialFailure = peer.metadata.get(LAST_DIAL_FAILURE_KEY);
            if (lastDialFailure == null) {
                return true;
            }
            const lastDialFailureTimestamp = parseInt(toString$6(lastDialFailure));
            if (isNaN(lastDialFailureTimestamp)) {
                return true;
            }
            // only dial if the time since the last failure is above the retry threshold
            return Date.now() - lastDialFailureTimestamp > this.autoDialPeerRetryThresholdMs;
        });
        this.log('selected %d/%d peers to dial', peersThatHaveNotFailed.length, peers.length);
        for (const peer of peersThatHaveNotFailed) {
            this.queue.add(async () => {
                const numConnections = this.connectionManager.getConnectionsMap().size;
                // Check to see if we still need to auto dial
                if (numConnections >= this.minConnections) {
                    this.log('got enough connections now %d/%d', numConnections, this.minConnections);
                    this.queue.clear();
                    return;
                }
                this.log('connecting to a peerStore stored peer %p', peer.id);
                await this.connectionManager.openConnection(peer.id, {
                    priority: this.autoDialPriority
                });
            }, {
                peerId: peer.id
            }).catch(err => {
                this.log.error('could not connect to peerStore stored peer', err);
            });
        }
        this.running = false;
        this.sheduleNextAutodial();
    }
    sheduleNextAutodial() {
        if (!this.started) {
            return;
        }
        this.autoDialInterval = setTimeout(() => {
            this.autoDial()
                .catch(err => {
                this.log.error('error while autodialing', err);
            });
        }, this.autoDialIntervalMs);
    }
}

/**
 * Close the passed stream, falling back to aborting the stream if closing
 * cleanly fails.
 */
/**
 * These are speculative protocols that are run automatically on connection open
 * so are usually not the reason the connection was opened.
 *
 * Consequently when requested it should be safe to close connections that only
 * have these protocol streams open.
 */
const DEFAULT_CLOSABLE_PROTOCOLS = [
    // identify
    '/ipfs/id/1.0.0',
    // identify-push
    '/ipfs/id/push/1.0.0',
    // autonat
    '/libp2p/autonat/1.0.0',
    // dcutr
    '/libp2p/dcutr'
];
/**
 * Close the passed connection if it has no streams, or only closable protocol
 * streams, falling back to aborting the connection if closing it cleanly fails.
 */
async function safelyCloseConnectionIfUnused(connection, options) {
    const streamProtocols = connection?.streams?.map(stream => stream.protocol) ?? [];
    const closableProtocols = options?.closableProtocols ?? DEFAULT_CLOSABLE_PROTOCOLS;
    // if the connection has protocols not in the closable protocols list, do not
    // close the connection
    if (streamProtocols.filter(proto => proto != null && !closableProtocols.includes(proto)).length > 0) {
        return;
    }
    try {
        await connection?.close(options);
    }
    catch (err) {
        connection?.abort(err);
    }
}

const defaultOptions$2 = {
    maxConnections: MAX_CONNECTIONS,
    allow: []
};
/**
 * If we go over the max connections limit, choose some connections to close
 */
class ConnectionPruner {
    maxConnections;
    connectionManager;
    peerStore;
    allow;
    events;
    log;
    constructor(components, init = {}) {
        this.maxConnections = init.maxConnections ?? defaultOptions$2.maxConnections;
        this.allow = init.allow ?? defaultOptions$2.allow;
        this.connectionManager = components.connectionManager;
        this.peerStore = components.peerStore;
        this.events = components.events;
        this.log = components.logger.forComponent('libp2p:connection-manager:connection-pruner');
        // check the max connection limit whenever a peer connects
        components.events.addEventListener('connection:open', () => {
            this.maybePruneConnections()
                .catch(err => {
                this.log.error(err);
            });
        });
    }
    /**
     * If we have more connections than our maximum, select some excess connections
     * to prune based on peer value
     */
    async maybePruneConnections() {
        const connections = this.connectionManager.getConnections();
        const numConnections = connections.length;
        this.log('checking max connections limit %d/%d', numConnections, this.maxConnections);
        if (numConnections <= this.maxConnections) {
            return;
        }
        const peerValues = new PeerMap();
        // work out peer values
        for (const connection of connections) {
            const remotePeer = connection.remotePeer;
            if (peerValues.has(remotePeer)) {
                continue;
            }
            peerValues.set(remotePeer, 0);
            try {
                const peer = await this.peerStore.get(remotePeer);
                // sum all tag values
                peerValues.set(remotePeer, [...peer.tags.values()].reduce((acc, curr) => {
                    return acc + curr.value;
                }, 0));
            }
            catch (err) {
                if (err.code !== 'ERR_NOT_FOUND') {
                    this.log.error('error loading peer tags', err);
                }
            }
        }
        const sortedConnections = this.sortConnections(connections, peerValues);
        // close some connections
        const toPrune = Math.max(numConnections - this.maxConnections, 0);
        const toClose = [];
        for (const connection of sortedConnections) {
            this.log('too many connections open - closing a connection to %p', connection.remotePeer);
            // check allow list
            const connectionInAllowList = this.allow.some((ma) => {
                return connection.remoteAddr.toString().startsWith(ma.toString());
            });
            // Connections in the allow list should be excluded from pruning
            if (!connectionInAllowList) {
                toClose.push(connection);
            }
            if (toClose.length === toPrune) {
                break;
            }
        }
        // close connections
        await Promise.all(toClose.map(async (connection) => {
            await safelyCloseConnectionIfUnused(connection, {
                signal: AbortSignal.timeout(1000)
            });
        }));
        // despatch prune event
        this.events.safeDispatchEvent('connection:prune', { detail: toClose });
    }
    sortConnections(connections, peerValues) {
        return connections
            // sort by connection age, newest to oldest
            .sort((a, b) => {
            const connectionALifespan = a.timeline.open;
            const connectionBLifespan = b.timeline.open;
            if (connectionALifespan < connectionBLifespan) {
                return 1;
            }
            if (connectionALifespan > connectionBLifespan) {
                return -1;
            }
            return 0;
        })
            // sort by direction, incoming first then outgoing
            .sort((a, b) => {
            if (a.direction === 'outbound' && b.direction === 'inbound') {
                return 1;
            }
            if (a.direction === 'inbound' && b.direction === 'outbound') {
                return -1;
            }
            return 0;
        })
            // sort by number of streams, lowest to highest
            .sort((a, b) => {
            if (a.streams.length > b.streams.length) {
                return 1;
            }
            if (a.streams.length < b.streams.length) {
                return -1;
            }
            return 0;
        })
            // sort by tag value, lowest to highest
            .sort((a, b) => {
            const peerAValue = peerValues.get(a.remotePeer) ?? 0;
            const peerBValue = peerValues.get(b.remotePeer) ?? 0;
            if (peerAValue > peerBValue) {
                return 1;
            }
            if (peerAValue < peerBValue) {
                return -1;
            }
            return 0;
        });
    }
}

class PriorityQueue extends Queue {
    constructor(init = {}) {
        super({
            ...init,
            sort: (a, b) => {
                if (a.options.priority > b.options.priority) {
                    return -1;
                }
                if (a.options.priority < b.options.priority) {
                    return 1;
                }
                return 0;
            }
        });
    }
}

/**
 * Takes an array of AbortSignals and returns a single signal.
 * If any signals are aborted, the returned signal will be aborted.
 */
function anySignal(signals) {
    const controller = new globalThis.AbortController();
    function onAbort() {
        controller.abort();
        for (const signal of signals) {
            if (signal?.removeEventListener != null) {
                signal.removeEventListener('abort', onAbort);
            }
        }
    }
    for (const signal of signals) {
        if (signal?.aborted === true) {
            onAbort();
            break;
        }
        if (signal?.addEventListener != null) {
            signal.addEventListener('abort', onAbort);
        }
    }
    function clear() {
        for (const signal of signals) {
            if (signal?.removeEventListener != null) {
                signal.removeEventListener('abort', onAbort);
            }
        }
    }
    const signal = controller.signal;
    signal.clear = clear;
    return signal;
}

/**
 * Recursively resolve DNSADDR multiaddrs
 */
async function resolveMultiaddrs(ma, options) {
    // check multiaddr resolvers
    let resolvable = false;
    for (const key of resolvers$1.keys()) {
        resolvable = ma.protoNames().includes(key);
        if (resolvable) {
            break;
        }
    }
    // return multiaddr if it is not resolvable
    if (!resolvable) {
        return [ma];
    }
    const output = await ma.resolve(options);
    options.log('resolved %s to', ma, output.map(ma => ma.toString()));
    return output;
}

/* eslint-disable max-depth */
const defaultOptions$1 = {
    addressSorter: defaultAddressSort,
    maxParallelDials: MAX_PARALLEL_DIALS,
    maxDialQueueLength: MAX_DIAL_QUEUE_LENGTH,
    maxPeerAddrsToDial: MAX_PEER_ADDRS_TO_DIAL,
    dialTimeout: DIAL_TIMEOUT,
    resolvers: {
        dnsaddr: dnsaddrResolver
    }
};
class DialQueue {
    queue;
    components;
    addressSorter;
    maxPeerAddrsToDial;
    maxDialQueueLength;
    dialTimeout;
    shutDownController;
    connections;
    log;
    constructor(components, init = {}) {
        this.addressSorter = init.addressSorter ?? defaultOptions$1.addressSorter;
        this.maxPeerAddrsToDial = init.maxPeerAddrsToDial ?? defaultOptions$1.maxPeerAddrsToDial;
        this.maxDialQueueLength = init.maxDialQueueLength ?? defaultOptions$1.maxDialQueueLength;
        this.dialTimeout = init.dialTimeout ?? defaultOptions$1.dialTimeout;
        this.connections = init.connections ?? new PeerMap();
        this.log = components.logger.forComponent('libp2p:connection-manager:dial-queue');
        this.components = components;
        this.shutDownController = new AbortController();
        setMaxListeners(Infinity, this.shutDownController.signal);
        for (const [key, value] of Object.entries(init.resolvers ?? {})) {
            resolvers$1.set(key, value);
        }
        // controls dial concurrency
        this.queue = new PriorityQueue({
            concurrency: init.maxParallelDials ?? defaultOptions$1.maxParallelDials,
            metricName: 'libp2p_dial_queue',
            metrics: components.metrics
        });
        // a started job errored
        this.queue.addEventListener('error', (event) => {
            this.log.error('error in dial queue', event.detail);
        });
    }
    start() {
        this.shutDownController = new AbortController();
        setMaxListeners(Infinity, this.shutDownController.signal);
    }
    /**
     * Clears any pending dials
     */
    stop() {
        this.shutDownController.abort();
        this.queue.abort();
    }
    /**
     * Connects to a given peer, multiaddr or list of multiaddrs.
     *
     * If a peer is passed, all known multiaddrs will be tried. If a multiaddr or
     * multiaddrs are passed only those will be dialled.
     *
     * Where a list of multiaddrs is passed, if any contain a peer id then all
     * multiaddrs in the list must contain the same peer id.
     *
     * The dial to the first address that is successfully able to upgrade a
     * connection will be used, all other dials will be aborted when that happens.
     */
    async dial(peerIdOrMultiaddr, options = {}) {
        const { peerId, multiaddrs } = getPeerAddress(peerIdOrMultiaddr);
        // make sure we don't have an existing connection to any of the addresses we
        // are about to dial
        const existingConnection = Array.from(this.connections.values()).flat().find(conn => {
            if (options.force === true) {
                return false;
            }
            if (conn.remotePeer.equals(peerId)) {
                return true;
            }
            return multiaddrs.find(addr => {
                return addr.equals(conn.remoteAddr);
            });
        });
        if (existingConnection != null) {
            this.log('already connected to %a', existingConnection.remoteAddr);
            options.onProgress?.(new CustomProgressEvent('dial-queue:already-connected'));
            return existingConnection;
        }
        // ready to dial, all async work finished - make sure we don't have any
        // pending dials in progress for this peer or set of multiaddrs
        const existingDial = this.queue.queue.find(job => {
            if (peerId?.equals(job.options.peerId) === true) {
                return true;
            }
            // does the dial contain any of the target multiaddrs?
            const addresses = job.options.multiaddrs;
            if (addresses == null) {
                return false;
            }
            for (const multiaddr of multiaddrs) {
                if (addresses.has(multiaddr.toString())) {
                    return true;
                }
            }
            return false;
        });
        if (existingDial != null) {
            this.log('joining existing dial target for %p', peerId);
            // add all multiaddrs to the dial target
            for (const multiaddr of multiaddrs) {
                existingDial.options.multiaddrs.add(multiaddr.toString());
            }
            options.onProgress?.(new CustomProgressEvent('dial-queue:already-in-dial-queue'));
            return existingDial.join(options);
        }
        if (this.queue.size >= this.maxDialQueueLength) {
            throw new CodeError$1('Dial queue is full', 'ERR_DIAL_QUEUE_FULL');
        }
        this.log('creating dial target for %p', peerId, multiaddrs.map(ma => ma.toString()));
        options.onProgress?.(new CustomProgressEvent('dial-queue:add-to-dial-queue'));
        return this.queue.add(async (options) => {
            options?.onProgress?.(new CustomProgressEvent('dial-queue:start-dial'));
            // create abort conditions - need to do this before `calculateMultiaddrs` as
            // we may be about to resolve a dns addr which can time out
            const signal = this.createDialAbortController(options?.signal);
            let addrsToDial;
            try {
                // load addresses from address book, resolve and dnsaddrs, filter
                // undiallables, add peer IDs, etc
                addrsToDial = await this.calculateMultiaddrs(peerId, options?.multiaddrs, {
                    ...options,
                    signal
                });
                options?.onProgress?.(new CustomProgressEvent('dial-queue:calculated-addresses', addrsToDial));
                addrsToDial.map(({ multiaddr }) => multiaddr.toString()).forEach(addr => {
                    options?.multiaddrs.add(addr);
                });
            }
            catch (err) {
                signal.clear();
                throw err;
            }
            try {
                let dialed = 0;
                const errors = [];
                for (const address of addrsToDial) {
                    if (dialed === this.maxPeerAddrsToDial) {
                        this.log('dialed maxPeerAddrsToDial (%d) addresses for %p, not trying any others', dialed, peerId);
                        throw new CodeError$1('Peer had more than maxPeerAddrsToDial', codes.ERR_TOO_MANY_ADDRESSES);
                    }
                    dialed++;
                    try {
                        const conn = await this.components.transportManager.dial(address.multiaddr, {
                            ...options,
                            signal
                        });
                        this.log('dial to %a succeeded', address.multiaddr);
                        return conn;
                    }
                    catch (err) {
                        this.log.error('dial failed to %a', address.multiaddr, err);
                        if (peerId != null) {
                            // record the failed dial
                            try {
                                await this.components.peerStore.patch(peerId, {
                                    metadata: {
                                        [LAST_DIAL_FAILURE_KEY]: fromString(Date.now().toString())
                                    }
                                });
                            }
                            catch (err) {
                                this.log.error('could not update last dial failure key for %p', peerId, err);
                            }
                        }
                        // the user/dial timeout/shutdown controller signal aborted
                        if (signal.aborted) {
                            throw new CodeError$1(err.message, ERR_TIMEOUT);
                        }
                        errors.push(err);
                    }
                }
                if (errors.length === 1) {
                    throw errors[0];
                }
                throw new AggregateCodeError(errors, 'All multiaddr dials failed', codes.ERR_TRANSPORT_DIAL_FAILED);
            }
            finally {
                // clean up abort signals/controllers
                signal.clear();
            }
        }, {
            peerId,
            priority: options.priority ?? DEFAULT_DIAL_PRIORITY,
            multiaddrs: new Set(multiaddrs.map(ma => ma.toString())),
            signal: options.signal,
            onProgress: options.onProgress
        });
    }
    createDialAbortController(userSignal) {
        // let any signal abort the dial
        const signal = anySignal([
            AbortSignal.timeout(this.dialTimeout),
            this.shutDownController.signal,
            userSignal
        ]);
        // This emitter gets listened to a lot
        setMaxListeners(Infinity, signal);
        return signal;
    }
    // eslint-disable-next-line complexity
    async calculateMultiaddrs(peerId, multiaddrs = new Set(), options = {}) {
        const addrs = [...multiaddrs].map(ma => ({
            multiaddr: multiaddr(ma),
            isCertified: false
        }));
        // if a peer id or multiaddr(s) with a peer id, make sure it isn't our peer id and that we are allowed to dial it
        if (peerId != null) {
            if (this.components.peerId.equals(peerId)) {
                throw new CodeError$1('Tried to dial self', codes.ERR_DIALED_SELF);
            }
            if ((await this.components.connectionGater.denyDialPeer?.(peerId)) === true) {
                throw new CodeError$1('The dial request is blocked by gater.allowDialPeer', codes.ERR_PEER_DIAL_INTERCEPTED);
            }
            // if just a peer id was passed, load available multiaddrs for this peer
            // from the peer store
            if (addrs.length === 0) {
                this.log('loading multiaddrs for %p', peerId);
                try {
                    const peer = await this.components.peerStore.get(peerId);
                    addrs.push(...peer.addresses);
                    this.log('loaded multiaddrs for %p', peerId, addrs.map(({ multiaddr }) => multiaddr.toString()));
                }
                catch (err) {
                    if (err.code !== codes.ERR_NOT_FOUND) {
                        throw err;
                    }
                }
            }
            // if we still don't have any addresses for this peer, try a lookup
            // using the peer routing
            if (addrs.length === 0) {
                this.log('looking up multiaddrs for %p in the peer routing', peerId);
                try {
                    const peerInfo = await this.components.peerRouting.findPeer(peerId);
                    this.log('found multiaddrs for %p in the peer routing', peerId, addrs.map(({ multiaddr }) => multiaddr.toString()));
                    addrs.push(...peerInfo.multiaddrs.map(multiaddr => ({
                        multiaddr,
                        isCertified: false
                    })));
                }
                catch (err) {
                    if (err.code !== codes.ERR_NO_ROUTERS_AVAILABLE) {
                        this.log.error('looking up multiaddrs for %p in the peer routing failed', peerId, err);
                    }
                }
            }
        }
        // resolve addresses - this can result in a one-to-many translation when
        // dnsaddrs are resolved
        let resolvedAddresses = (await Promise.all(addrs.map(async (addr) => {
            const result = await resolveMultiaddrs(addr.multiaddr, {
                dns: this.components.dns,
                ...options,
                log: this.log
            });
            if (result.length === 1 && result[0].equals(addr.multiaddr)) {
                return addr;
            }
            return result.map(multiaddr => ({
                multiaddr,
                isCertified: false
            }));
        })))
            .flat();
        // ensure the peer id is appended to the multiaddr
        if (peerId != null) {
            const peerIdMultiaddr = `/p2p/${peerId.toString()}`;
            resolvedAddresses = resolvedAddresses.map(addr => {
                const lastProto = addr.multiaddr.protos().pop();
                // do not append peer id to path multiaddrs
                if (lastProto?.path === true) {
                    return addr;
                }
                // append peer id to multiaddr if it is not already present
                if (addr.multiaddr.getPeerId() == null) {
                    return {
                        multiaddr: addr.multiaddr.encapsulate(peerIdMultiaddr),
                        isCertified: addr.isCertified
                    };
                }
                return addr;
            });
        }
        const filteredAddrs = resolvedAddresses.filter(addr => {
            // filter out any multiaddrs that we do not have transports for
            if (this.components.transportManager.dialTransportForMultiaddr(addr.multiaddr) == null) {
                return false;
            }
            // if the resolved multiaddr has a PeerID but it's the wrong one, ignore it
            // - this can happen with addresses like bootstrap.libp2p.io that resolve
            // to multiple different peers
            const addrPeerId = addr.multiaddr.getPeerId();
            if (peerId != null && addrPeerId != null) {
                return peerId.equals(addrPeerId);
            }
            return true;
        });
        // deduplicate addresses
        const dedupedAddrs = new Map();
        for (const addr of filteredAddrs) {
            const maStr = addr.multiaddr.toString();
            const existing = dedupedAddrs.get(maStr);
            if (existing != null) {
                existing.isCertified = existing.isCertified || addr.isCertified || false;
                continue;
            }
            dedupedAddrs.set(maStr, addr);
        }
        const dedupedMultiaddrs = [...dedupedAddrs.values()];
        // make sure we actually have some addresses to dial
        if (dedupedMultiaddrs.length === 0) {
            throw new CodeError$1('The dial request has no valid addresses', codes.ERR_NO_VALID_ADDRESSES);
        }
        const gatedAdrs = [];
        for (const addr of dedupedMultiaddrs) {
            if (this.components.connectionGater.denyDialMultiaddr != null && await this.components.connectionGater.denyDialMultiaddr(addr.multiaddr)) {
                continue;
            }
            gatedAdrs.push(addr);
        }
        const sortedGatedAddrs = gatedAdrs.sort(this.addressSorter);
        // make sure we actually have some addresses to dial
        if (sortedGatedAddrs.length === 0) {
            throw new CodeError$1('The connection gater denied all addresses in the dial request', codes.ERR_NO_VALID_ADDRESSES);
        }
        this.log.trace('addresses for %p before filtering', peerId ?? 'unknown peer', resolvedAddresses.map(({ multiaddr }) => multiaddr.toString()));
        this.log.trace('addresses for %p after filtering', peerId ?? 'unknown peer', sortedGatedAddrs.map(({ multiaddr }) => multiaddr.toString()));
        return sortedGatedAddrs;
    }
    async isDialable(multiaddr, options = {}) {
        if (!Array.isArray(multiaddr)) {
            multiaddr = [multiaddr];
        }
        try {
            const addresses = await this.calculateMultiaddrs(undefined, new Set(multiaddr.map(ma => ma.toString())), options);
            if (options.runOnTransientConnection === false) {
                // return true if any resolved multiaddrs are not relay addresses
                return addresses.find(addr => {
                    return !Circuit.matches(addr.multiaddr);
                }) != null;
            }
            return true;
        }
        catch (err) {
            this.log.trace('error calculating if multiaddr(s) were dialable', err);
        }
        return false;
    }
}

const DEFAULT_DIAL_PRIORITY = 50;
const defaultOptions = {
    minConnections: MIN_CONNECTIONS,
    maxConnections: MAX_CONNECTIONS,
    inboundConnectionThreshold: INBOUND_CONNECTION_THRESHOLD,
    maxIncomingPendingConnections: MAX_INCOMING_PENDING_CONNECTIONS,
    autoDialConcurrency: AUTO_DIAL_CONCURRENCY,
    autoDialPriority: AUTO_DIAL_PRIORITY,
    autoDialMaxQueueLength: AUTO_DIAL_MAX_QUEUE_LENGTH,
    autoDialPeerRetryThreshold: AUTO_DIAL_PEER_RETRY_THRESHOLD,
    autoDialDiscoveredPeersDebounce: AUTO_DIAL_DISCOVERED_PEERS_DEBOUNCE
};
/**
 * Responsible for managing known connections.
 */
class DefaultConnectionManager {
    started;
    connections;
    allow;
    deny;
    maxIncomingPendingConnections;
    incomingPendingConnections;
    maxConnections;
    dialQueue;
    autoDial;
    connectionPruner;
    inboundConnectionRateLimiter;
    peerStore;
    metrics;
    events;
    log;
    constructor(components, init = {}) {
        this.maxConnections = init.maxConnections ?? defaultOptions.maxConnections;
        const minConnections = init.minConnections ?? defaultOptions.minConnections;
        if (this.maxConnections < minConnections) {
            throw new CodeError$1('Connection Manager maxConnections must be greater than minConnections', codes.ERR_INVALID_PARAMETERS);
        }
        /**
         * Map of connections per peer
         */
        this.connections = new PeerMap();
        this.started = false;
        this.peerStore = components.peerStore;
        this.metrics = components.metrics;
        this.events = components.events;
        this.log = components.logger.forComponent('libp2p:connection-manager');
        this.onConnect = this.onConnect.bind(this);
        this.onDisconnect = this.onDisconnect.bind(this);
        this.events.addEventListener('connection:open', this.onConnect);
        this.events.addEventListener('connection:close', this.onDisconnect);
        // allow/deny lists
        this.allow = (init.allow ?? []).map(ma => multiaddr(ma));
        this.deny = (init.deny ?? []).map(ma => multiaddr(ma));
        this.incomingPendingConnections = 0;
        this.maxIncomingPendingConnections = init.maxIncomingPendingConnections ?? defaultOptions.maxIncomingPendingConnections;
        // controls individual peers trying to dial us too quickly
        this.inboundConnectionRateLimiter = new RateLimiter({
            points: init.inboundConnectionThreshold ?? defaultOptions.inboundConnectionThreshold,
            duration: 1
        });
        // controls what happens when we don't have enough connections
        this.autoDial = new AutoDial({
            connectionManager: this,
            peerStore: components.peerStore,
            events: components.events,
            logger: components.logger
        }, {
            minConnections,
            autoDialConcurrency: init.autoDialConcurrency ?? defaultOptions.autoDialConcurrency,
            autoDialPriority: init.autoDialPriority ?? defaultOptions.autoDialPriority,
            autoDialPeerRetryThreshold: init.autoDialPeerRetryThreshold ?? defaultOptions.autoDialPeerRetryThreshold,
            autoDialDiscoveredPeersDebounce: init.autoDialDiscoveredPeersDebounce ?? defaultOptions.autoDialDiscoveredPeersDebounce,
            maxQueueLength: init.autoDialMaxQueueLength ?? defaultOptions.autoDialMaxQueueLength
        });
        // controls what happens when we have too many connections
        this.connectionPruner = new ConnectionPruner({
            connectionManager: this,
            peerStore: components.peerStore,
            events: components.events,
            logger: components.logger
        }, {
            maxConnections: this.maxConnections,
            allow: this.allow
        });
        this.dialQueue = new DialQueue(components, {
            addressSorter: init.addressSorter ?? defaultAddressSort,
            maxParallelDials: init.maxParallelDials ?? MAX_PARALLEL_DIALS,
            maxDialQueueLength: init.maxDialQueueLength ?? MAX_DIAL_QUEUE_LENGTH,
            maxPeerAddrsToDial: init.maxPeerAddrsToDial ?? MAX_PEER_ADDRS_TO_DIAL,
            dialTimeout: init.dialTimeout ?? DIAL_TIMEOUT,
            resolvers: init.resolvers ?? {
                dnsaddr: dnsaddrResolver
            },
            connections: this.connections
        });
    }
    [Symbol.toStringTag] = '@libp2p/connection-manager';
    isStarted() {
        return this.started;
    }
    /**
     * Starts the Connection Manager. If Metrics are not enabled on libp2p
     * only event loop and connection limits will be monitored.
     */
    async start() {
        // track inbound/outbound connections
        this.metrics?.registerMetricGroup('libp2p_connection_manager_connections', {
            calculate: () => {
                const metric = {
                    inbound: 0,
                    outbound: 0
                };
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        if (conn.direction === 'inbound') {
                            metric.inbound++;
                        }
                        else {
                            metric.outbound++;
                        }
                    }
                }
                return metric;
            }
        });
        // track total number of streams per protocol
        this.metrics?.registerMetricGroup('libp2p_protocol_streams_total', {
            label: 'protocol',
            calculate: () => {
                const metric = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        for (const stream of conn.streams) {
                            const key = `${stream.direction} ${stream.protocol ?? 'unnegotiated'}`;
                            metric[key] = (metric[key] ?? 0) + 1;
                        }
                    }
                }
                return metric;
            }
        });
        // track 90th percentile of streams per protocol
        this.metrics?.registerMetricGroup('libp2p_connection_manager_protocol_streams_per_connection_90th_percentile', {
            label: 'protocol',
            calculate: () => {
                const allStreams = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        const streams = {};
                        for (const stream of conn.streams) {
                            const key = `${stream.direction} ${stream.protocol ?? 'unnegotiated'}`;
                            streams[key] = (streams[key] ?? 0) + 1;
                        }
                        for (const [protocol, count] of Object.entries(streams)) {
                            allStreams[protocol] = allStreams[protocol] ?? [];
                            allStreams[protocol].push(count);
                        }
                    }
                }
                const metric = {};
                for (let [protocol, counts] of Object.entries(allStreams)) {
                    counts = counts.sort((a, b) => a - b);
                    const index = Math.floor(counts.length * 0.9);
                    metric[protocol] = counts[index];
                }
                return metric;
            }
        });
        this.dialQueue.start();
        this.autoDial.start();
        this.started = true;
        this.log('started');
    }
    async afterStart() {
        // re-connect to any peers with the KEEP_ALIVE tag
        void Promise.resolve()
            .then(async () => {
            const keepAlivePeers = await this.peerStore.all({
                filters: [(peer) => {
                        return peer.tags.has(KEEP_ALIVE);
                    }]
            });
            await Promise.all(keepAlivePeers.map(async (peer) => {
                await this.openConnection(peer.id)
                    .catch(err => {
                    this.log.error(err);
                });
            }));
        })
            .catch(err => {
            this.log.error(err);
        });
        this.autoDial.afterStart();
    }
    /**
     * Stops the Connection Manager
     */
    async stop() {
        this.dialQueue.stop();
        this.autoDial.stop();
        // Close all connections we're tracking
        const tasks = [];
        for (const connectionList of this.connections.values()) {
            for (const connection of connectionList) {
                tasks.push((async () => {
                    try {
                        await connection.close();
                    }
                    catch (err) {
                        this.log.error(err);
                    }
                })());
            }
        }
        this.log('closing %d connections', tasks.length);
        await Promise.all(tasks);
        this.connections.clear();
        this.log('stopped');
    }
    onConnect(evt) {
        void this._onConnect(evt).catch(err => {
            this.log.error(err);
        });
    }
    /**
     * Tracks the incoming connection and check the connection limit
     */
    async _onConnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            await connection.close();
            return;
        }
        const peerId = connection.remotePeer;
        const storedConns = this.connections.get(peerId);
        let isNewPeer = false;
        if (storedConns != null) {
            storedConns.push(connection);
        }
        else {
            isNewPeer = true;
            this.connections.set(peerId, [connection]);
        }
        // only need to store RSA public keys, all other types are embedded in the peer id
        if (peerId.publicKey != null && peerId.type === 'RSA') {
            await this.peerStore.patch(peerId, {
                publicKey: peerId.publicKey
            });
        }
        if (isNewPeer) {
            this.events.safeDispatchEvent('peer:connect', { detail: connection.remotePeer });
        }
    }
    /**
     * Removes the connection from tracking
     */
    onDisconnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            return;
        }
        const peerId = connection.remotePeer;
        let storedConn = this.connections.get(peerId);
        if (storedConn != null && storedConn.length > 1) {
            storedConn = storedConn.filter((conn) => conn.id !== connection.id);
            this.connections.set(peerId, storedConn);
        }
        else if (storedConn != null) {
            this.connections.delete(peerId);
            this.events.safeDispatchEvent('peer:disconnect', { detail: connection.remotePeer });
        }
    }
    getConnections(peerId) {
        if (peerId != null) {
            return this.connections.get(peerId) ?? [];
        }
        let conns = [];
        for (const c of this.connections.values()) {
            conns = conns.concat(c);
        }
        return conns;
    }
    getConnectionsMap() {
        return this.connections;
    }
    async openConnection(peerIdOrMultiaddr, options = {}) {
        if (!this.isStarted()) {
            throw new CodeError$1('Not started', codes.ERR_NODE_NOT_STARTED);
        }
        options.signal?.throwIfAborted();
        const { peerId } = getPeerAddress(peerIdOrMultiaddr);
        if (peerId != null && options.force !== true) {
            this.log('dial %p', peerId);
            const existingConnection = this.getConnections(peerId)
                .find(conn => !conn.transient);
            if (existingConnection != null) {
                this.log('had an existing non-transient connection to %p', peerId);
                options.onProgress?.(new CustomProgressEvent('dial-queue:already-connected'));
                return existingConnection;
            }
        }
        const connection = await this.dialQueue.dial(peerIdOrMultiaddr, {
            ...options,
            priority: options.priority ?? DEFAULT_DIAL_PRIORITY
        });
        let peerConnections = this.connections.get(connection.remotePeer);
        if (peerConnections == null) {
            peerConnections = [];
            this.connections.set(connection.remotePeer, peerConnections);
        }
        // we get notified of connections via the Upgrader emitting "connection"
        // events, double check we aren't already tracking this connection before
        // storing it
        let trackedConnection = false;
        for (const conn of peerConnections) {
            if (conn.id === connection.id) {
                trackedConnection = true;
            }
        }
        if (!trackedConnection) {
            peerConnections.push(connection);
        }
        return connection;
    }
    async closeConnections(peerId, options = {}) {
        const connections = this.connections.get(peerId) ?? [];
        await Promise.all(connections.map(async (connection) => {
            try {
                await connection.close(options);
            }
            catch (err) {
                connection.abort(err);
            }
        }));
    }
    async acceptIncomingConnection(maConn) {
        // check deny list
        const denyConnection = this.deny.some(ma => {
            return maConn.remoteAddr.toString().startsWith(ma.toString());
        });
        if (denyConnection) {
            this.log('connection from %a refused - connection remote address was in deny list', maConn.remoteAddr);
            return false;
        }
        // check allow list
        const allowConnection = this.allow.some(ma => {
            return maConn.remoteAddr.toString().startsWith(ma.toString());
        });
        if (allowConnection) {
            this.incomingPendingConnections++;
            return true;
        }
        // check pending connections
        if (this.incomingPendingConnections === this.maxIncomingPendingConnections) {
            this.log('connection from %a refused - incomingPendingConnections exceeded by host', maConn.remoteAddr);
            return false;
        }
        if (maConn.remoteAddr.isThinWaistAddress()) {
            const host = maConn.remoteAddr.nodeAddress().address;
            try {
                await this.inboundConnectionRateLimiter.consume(host, 1);
            }
            catch {
                this.log('connection from %a refused - inboundConnectionThreshold exceeded by host %s', maConn.remoteAddr, host);
                return false;
            }
        }
        if (this.getConnections().length < this.maxConnections) {
            this.incomingPendingConnections++;
            return true;
        }
        this.log('connection from %a refused - maxConnections exceeded', maConn.remoteAddr);
        return false;
    }
    afterUpgradeInbound() {
        this.incomingPendingConnections--;
    }
    getDialQueue() {
        const statusMap = {
            queued: 'queued',
            running: 'active',
            errored: 'error',
            complete: 'success'
        };
        return this.dialQueue.queue.queue.map(job => {
            return {
                id: job.id,
                status: statusMap[job.status],
                peerId: job.options.peerId,
                multiaddrs: [...job.options.multiaddrs].map(ma => multiaddr(ma))
            };
        });
    }
    async isDialable(multiaddr, options = {}) {
        return this.dialQueue.isDialable(multiaddr, options);
    }
}

/**
 * Implements exponential moving average. Ported from `moving-average`.
 *
 * @see https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
 * @see https://www.npmjs.com/package/moving-average
 */
class MovingAverage {
    movingAverage;
    variance;
    deviation;
    forecast;
    timespan;
    previousTime;
    constructor(timespan) {
        this.timespan = timespan;
        this.movingAverage = 0;
        this.variance = 0;
        this.deviation = 0;
        this.forecast = 0;
    }
    alpha(t, pt) {
        return 1 - (Math.exp(-(t - pt) / this.timespan));
    }
    push(value, time = Date.now()) {
        if (this.previousTime != null) {
            // calculate moving average
            const a = this.alpha(time, this.previousTime);
            const diff = value - this.movingAverage;
            const incr = a * diff;
            this.movingAverage = a * value + (1 - a) * this.movingAverage;
            // calculate variance & deviation
            this.variance = (1 - a) * (this.variance + diff * incr);
            this.deviation = Math.sqrt(this.variance);
            // calculate forecast
            this.forecast = this.movingAverage + a * diff;
        }
        else {
            this.movingAverage = value;
        }
        this.previousTime = time;
    }
}

const DEFAULT_TIMEOUT_MULTIPLIER = 1.2;
const DEFAULT_FAILURE_MULTIPLIER = 2;
const DEFAULT_MIN_TIMEOUT = 2000;
class AdaptiveTimeout {
    success;
    failure;
    next;
    metric;
    timeoutMultiplier;
    failureMultiplier;
    minTimeout;
    constructor(init = {}) {
        this.success = new MovingAverage(init.interval ?? 5000);
        this.failure = new MovingAverage(init.interval ?? 5000);
        this.next = new MovingAverage(init.interval ?? 5000);
        this.failureMultiplier = init.failureMultiplier ?? DEFAULT_FAILURE_MULTIPLIER;
        this.timeoutMultiplier = init.timeoutMultiplier ?? DEFAULT_TIMEOUT_MULTIPLIER;
        this.minTimeout = init.minTimeout ?? DEFAULT_MIN_TIMEOUT;
        if (init.metricName != null) {
            this.metric = init.metrics?.registerMetricGroup(init.metricName);
        }
    }
    getTimeoutSignal(options = {}) {
        // calculate timeout for individual peers based on moving average of
        // previous successful requests
        const timeout = Math.max(Math.round(this.next.movingAverage * (options.timeoutFactor ?? this.timeoutMultiplier)), this.minTimeout);
        const sendTimeout = AbortSignal.timeout(timeout);
        const timeoutSignal = anySignal([options.signal, sendTimeout]);
        setMaxListeners(Infinity, timeoutSignal, sendTimeout);
        timeoutSignal.start = Date.now();
        timeoutSignal.timeout = timeout;
        return timeoutSignal;
    }
    cleanUp(signal) {
        const time = Date.now() - signal.start;
        if (signal.aborted) {
            this.failure.push(time);
            this.next.push(time * this.failureMultiplier);
            this.metric?.update({
                failureMovingAverage: this.failure.movingAverage,
                failureDeviation: this.failure.deviation,
                failureForecast: this.failure.forecast,
                failureVariance: this.failure.variance,
                failure: time
            });
        }
        else {
            this.success.push(time);
            this.next.push(time);
            this.metric?.update({
                successMovingAverage: this.success.movingAverage,
                successDeviation: this.success.deviation,
                successForecast: this.success.forecast,
                successVariance: this.success.variance,
                success: time
            });
        }
    }
}

const DEFAULT_PING_INTERVAL_MS = 10000;
const PROTOCOL_VERSION = '1.0.0';
const PROTOCOL_NAME = 'ping';
const PROTOCOL_PREFIX = 'ipfs';
const PING_LENGTH = 32;
class ConnectionMonitor {
    protocol;
    components;
    log;
    heartbeatInterval;
    pingIntervalMs;
    abortController;
    timeout;
    constructor(components, init = {}) {
        this.components = components;
        this.protocol = `/${init.protocolPrefix ?? PROTOCOL_PREFIX}/${PROTOCOL_NAME}/${PROTOCOL_VERSION}`;
        this.log = components.logger.forComponent('libp2p:connection-monitor');
        this.pingIntervalMs = init.pingInterval ?? DEFAULT_PING_INTERVAL_MS;
        this.timeout = new AdaptiveTimeout({
            ...(init.pingTimeout ?? {}),
            metrics: components.metrics,
            metricName: 'libp2p_connection_monitor_ping_time_milliseconds'
        });
    }
    [Symbol.toStringTag] = '@libp2p/connection-monitor';
    [serviceCapabilities] = [
        '@libp2p/connection-monitor'
    ];
    start() {
        this.abortController = new AbortController();
        this.heartbeatInterval = setInterval(() => {
            this.components.connectionManager.getConnections().forEach(conn => {
                Promise.resolve().then(async () => {
                    let start = Date.now();
                    try {
                        const signal = this.timeout.getTimeoutSignal({
                            signal: this.abortController?.signal
                        });
                        const stream = await conn.newStream(this.protocol, {
                            signal,
                            runOnTransientConnection: true
                        });
                        const bs = byteStream(stream);
                        start = Date.now();
                        await Promise.all([
                            bs.write(randomBytes(PING_LENGTH), {
                                signal
                            }),
                            bs.read(PING_LENGTH, {
                                signal
                            })
                        ]);
                        conn.rtt = Date.now() - start;
                        await bs.unwrap().close({
                            signal
                        });
                    }
                    catch (err) {
                        if (err.code !== 'ERR_UNSUPPORTED_PROTOCOL') {
                            throw err;
                        }
                        // protocol was unsupported, but that's ok as it means the remote
                        // peer was still alive. We ran multistream-select which means two
                        // round trips (e.g. 1x for the mss header, then another for the
                        // protocol) so divide the time it took by two
                        conn.rtt = (Date.now() - start) / 2;
                    }
                })
                    .catch(err => {
                    this.log.error('error during heartbeat, aborting connection', err);
                    conn.abort(err);
                });
            });
        }, this.pingIntervalMs);
    }
    stop() {
        this.abortController?.abort();
        if (this.heartbeatInterval != null) {
            clearInterval(this.heartbeatInterval);
        }
    }
}

class CompoundContentRouting {
    routers;
    started;
    components;
    constructor(components, init) {
        this.routers = init.routers ?? [];
        this.started = false;
        this.components = components;
    }
    [Symbol.toStringTag] = '@libp2p/content-routing';
    isStarted() {
        return this.started;
    }
    async start() {
        this.started = true;
    }
    async stop() {
        this.started = false;
    }
    /**
     * Iterates over all content routers in parallel to find providers of the given key
     */
    async *findProviders(key, options = {}) {
        if (this.routers.length === 0) {
            throw new CodeError$1('No content routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        const self = this;
        const seen = new PeerSet();
        for await (const peer of merge$1(...self.routers.map(router => router.findProviders(key, options)))) {
            // the peer was yielded by a content router without multiaddrs and we
            // failed to load them
            if (peer == null) {
                continue;
            }
            // store the addresses for the peer if found
            if (peer.multiaddrs.length > 0) {
                await this.components.peerStore.merge(peer.id, {
                    multiaddrs: peer.multiaddrs
                });
            }
            // deduplicate peers
            if (seen.has(peer.id)) {
                continue;
            }
            seen.add(peer.id);
            yield peer;
        }
    }
    /**
     * Iterates over all content routers in parallel to notify it is
     * a provider of the given key
     */
    async provide(key, options = {}) {
        if (this.routers.length === 0) {
            throw new CodeError$1('No content routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        await Promise.all(this.routers.map(async (router) => {
            await router.provide(key, options);
        }));
    }
    /**
     * Store the given key/value pair in the available content routings
     */
    async put(key, value, options) {
        if (!this.isStarted()) {
            throw new CodeError$1(messages.NOT_STARTED_YET, codes.ERR_NODE_NOT_STARTED);
        }
        await Promise.all(this.routers.map(async (router) => {
            await router.put(key, value, options);
        }));
    }
    /**
     * Get the value to the given key.
     * Times out after 1 minute by default.
     */
    async get(key, options) {
        if (!this.isStarted()) {
            throw new CodeError$1(messages.NOT_STARTED_YET, codes.ERR_NODE_NOT_STARTED);
        }
        return Promise.any(this.routers.map(async (router) => {
            return router.get(key, options);
        }));
    }
}

class DefaultPeerRouting {
    log;
    peerId;
    peerStore;
    routers;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:peer-routing');
        this.peerId = components.peerId;
        this.peerStore = components.peerStore;
        this.routers = init.routers ?? [];
    }
    [Symbol.toStringTag] = '@libp2p/peer-routing';
    /**
     * Iterates over all peer routers in parallel to find the given peer
     */
    async findPeer(id, options) {
        if (this.routers.length === 0) {
            throw new CodeError$1('No peer routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        if (id.toString() === this.peerId.toString()) {
            throw new CodeError$1('Should not try to find self', codes.ERR_FIND_SELF);
        }
        const self = this;
        const source = merge$1(...this.routers.map(router => (async function* () {
            try {
                yield await router.findPeer(id, options);
            }
            catch (err) {
                self.log.error(err);
            }
        })()));
        for await (const peer of source) {
            if (peer == null) {
                continue;
            }
            // store the addresses for the peer if found
            if (peer.multiaddrs.length > 0) {
                await this.peerStore.merge(peer.id, {
                    multiaddrs: peer.multiaddrs
                });
            }
            return peer;
        }
        throw new CodeError$1(messages.NOT_FOUND, codes.ERR_NOT_FOUND);
    }
    /**
     * Attempt to find the closest peers on the network to the given key
     */
    async *getClosestPeers(key, options = {}) {
        if (this.routers.length === 0) {
            throw new CodeError$1('No peer routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        const self = this;
        const seen = createScalableCuckooFilter(1024);
        for await (const peer of parallel(async function* () {
            const source = merge$1(...self.routers.map(router => router.getClosestPeers(key, options)));
            for await (let peer of source) {
                yield async () => {
                    // find multiaddrs if they are missing
                    if (peer.multiaddrs.length === 0) {
                        try {
                            peer = await self.findPeer(peer.id, {
                                ...options,
                                useCache: false
                            });
                        }
                        catch (err) {
                            self.log.error('could not find peer multiaddrs', err);
                            return;
                        }
                    }
                    return peer;
                };
            }
        }())) {
            if (peer == null) {
                continue;
            }
            // store the addresses for the peer if found
            if (peer.multiaddrs.length > 0) {
                await this.peerStore.merge(peer.id, {
                    multiaddrs: peer.multiaddrs
                });
            }
            // deduplicate peers
            if (seen.has(peer.id.toBytes())) {
                continue;
            }
            seen.add(peer.id.toBytes());
            yield peer;
        }
    }
}

class RandomWalk extends TypedEventEmitter {
    peerRouting;
    log;
    walking;
    walkers;
    shutdownController;
    walkController;
    needNext;
    constructor(components) {
        super();
        this.log = components.logger.forComponent('libp2p:random-walk');
        this.peerRouting = components.peerRouting;
        this.walkers = 0;
        this.walking = false;
        // stops any in-progress walks when the node is shut down
        this.shutdownController = new AbortController();
        setMaxListeners(Infinity, this.shutdownController.signal);
    }
    [Symbol.toStringTag] = '@libp2p/random-walk';
    start() {
        this.shutdownController = new AbortController();
        setMaxListeners(Infinity, this.shutdownController.signal);
    }
    stop() {
        this.shutdownController.abort();
    }
    async *walk(options) {
        if (!this.walking) {
            // start the query that causes walk:peer events to be emitted
            this.startWalk();
        }
        this.walkers++;
        const signal = anySignal([this.shutdownController.signal, options?.signal]);
        setMaxListeners(Infinity, signal);
        try {
            while (true) {
                // if another consumer has paused the query, start it again
                this.needNext?.resolve();
                this.needNext = pDefer();
                // wait for a walk:peer or walk:error event
                const event = await raceEvent(this, 'walk:peer', signal, {
                    errorEvent: 'walk:error'
                });
                yield event.detail;
            }
        }
        finally {
            signal.clear();
            this.walkers--;
            // stop the walk if no more consumers are interested
            if (this.walkers === 0) {
                this.walkController?.abort();
                this.walkController = undefined;
            }
        }
    }
    startWalk() {
        this.walking = true;
        // the signal for this controller will be aborted if no more random peers
        // are required
        this.walkController = new AbortController();
        setMaxListeners(Infinity, this.walkController.signal);
        const signal = anySignal([this.walkController.signal, this.shutdownController.signal]);
        setMaxListeners(Infinity, signal);
        const start = Date.now();
        let found = 0;
        Promise.resolve().then(async () => {
            this.log('start walk');
            // find peers until no more consumers are interested
            while (this.walkers > 0) {
                try {
                    const data = randomBytes(32);
                    let s = Date.now();
                    for await (const peer of this.peerRouting.getClosestPeers(data, { signal })) {
                        if (signal.aborted) {
                            this.log('aborting walk');
                        }
                        signal.throwIfAborted();
                        this.log('found peer %p after %dms for %d walkers', peer.id, Date.now() - s, this.walkers);
                        found++;
                        this.safeDispatchEvent('walk:peer', {
                            detail: peer
                        });
                        // if we only have one consumer, pause the query until they request
                        // another random peer or they signal they are no longer interested
                        if (this.walkers === 1 && this.needNext != null) {
                            this.log('wait for need next');
                            await raceSignal(this.needNext.promise, signal);
                        }
                        s = Date.now();
                    }
                    this.log('walk iteration for %b and %d walkers finished, found %d peers', data, this.walkers, found);
                }
                catch (err) {
                    this.log.error('randomwalk errored', err);
                    this.safeDispatchEvent('walk:error', {
                        detail: err
                    });
                }
            }
            this.log('no walkers left, ended walk');
        })
            .catch(err => {
            this.log.error('randomwalk errored', err);
        })
            .finally(() => {
            this.log('finished walk, found %d peers after %dms', found, Date.now() - start);
            this.walking = false;
        });
    }
}

const DEFAULT_MAX_INBOUND_STREAMS = 32;
const DEFAULT_MAX_OUTBOUND_STREAMS = 64;
/**
 * Responsible for notifying registered protocols of events in the network.
 */
class DefaultRegistrar {
    log;
    topologies;
    handlers;
    components;
    constructor(components) {
        this.log = components.logger.forComponent('libp2p:registrar');
        this.topologies = new Map();
        this.handlers = new Map();
        this.components = components;
        this._onDisconnect = this._onDisconnect.bind(this);
        this._onPeerUpdate = this._onPeerUpdate.bind(this);
        this._onPeerIdentify = this._onPeerIdentify.bind(this);
        this.components.events.addEventListener('peer:disconnect', this._onDisconnect);
        this.components.events.addEventListener('peer:update', this._onPeerUpdate);
        this.components.events.addEventListener('peer:identify', this._onPeerIdentify);
    }
    [Symbol.toStringTag] = '@libp2p/registrar';
    getProtocols() {
        return Array.from(new Set([
            ...this.handlers.keys()
        ])).sort();
    }
    getHandler(protocol) {
        const handler = this.handlers.get(protocol);
        if (handler == null) {
            throw new CodeError$1(`No handler registered for protocol ${protocol}`, codes.ERR_NO_HANDLER_FOR_PROTOCOL);
        }
        return handler;
    }
    getTopologies(protocol) {
        const topologies = this.topologies.get(protocol);
        if (topologies == null) {
            return [];
        }
        return [
            ...topologies.values()
        ];
    }
    /**
     * Registers the `handler` for each protocol
     */
    async handle(protocol, handler, opts) {
        if (this.handlers.has(protocol)) {
            throw new CodeError$1(`Handler already registered for protocol ${protocol}`, codes.ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED);
        }
        const options = mergeOptions$1.bind({ ignoreUndefined: true })({
            maxInboundStreams: DEFAULT_MAX_INBOUND_STREAMS,
            maxOutboundStreams: DEFAULT_MAX_OUTBOUND_STREAMS
        }, opts);
        this.handlers.set(protocol, {
            handler,
            options
        });
        // Add new protocol to self protocols in the peer store
        await this.components.peerStore.merge(this.components.peerId, {
            protocols: [protocol]
        });
    }
    /**
     * Removes the handler for each protocol. The protocol
     * will no longer be supported on streams.
     */
    async unhandle(protocols) {
        const protocolList = Array.isArray(protocols) ? protocols : [protocols];
        protocolList.forEach(protocol => {
            this.handlers.delete(protocol);
        });
        // Update self protocols in the peer store
        await this.components.peerStore.patch(this.components.peerId, {
            protocols: this.getProtocols()
        });
    }
    /**
     * Register handlers for a set of multicodecs given
     */
    async register(protocol, topology) {
        if (topology == null) {
            throw new CodeError$1('invalid topology', codes.ERR_INVALID_PARAMETERS);
        }
        // Create topology
        const id = `${(Math.random() * 1e9).toString(36)}${Date.now()}`;
        let topologies = this.topologies.get(protocol);
        if (topologies == null) {
            topologies = new Map();
            this.topologies.set(protocol, topologies);
        }
        topologies.set(id, topology);
        return id;
    }
    /**
     * Unregister topology
     */
    unregister(id) {
        for (const [protocol, topologies] of this.topologies.entries()) {
            if (topologies.has(id)) {
                topologies.delete(id);
                if (topologies.size === 0) {
                    this.topologies.delete(protocol);
                }
            }
        }
    }
    /**
     * Remove a disconnected peer from the record
     */
    _onDisconnect(evt) {
        const remotePeer = evt.detail;
        void this.components.peerStore.get(remotePeer)
            .then(peer => {
            for (const protocol of peer.protocols) {
                const topologies = this.topologies.get(protocol);
                if (topologies == null) {
                    // no topologies are interested in this protocol
                    continue;
                }
                for (const topology of topologies.values()) {
                    if (topology.filter?.has(remotePeer) === false) {
                        continue;
                    }
                    topology.filter?.remove(remotePeer);
                    topology.onDisconnect?.(remotePeer);
                }
            }
        })
            .catch(err => {
            if (err.code === codes.ERR_NOT_FOUND) {
                // peer has not completed identify so they are not in the peer store
                return;
            }
            this.log.error('could not inform topologies of disconnecting peer %p', remotePeer, err);
        });
    }
    /**
     * When a peer is updated, if they have removed supported protocols notify any
     * topologies interested in the removed protocols.
     */
    _onPeerUpdate(evt) {
        const { peer, previous } = evt.detail;
        const removed = (previous?.protocols ?? []).filter(protocol => !peer.protocols.includes(protocol));
        for (const protocol of removed) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                if (topology.filter?.has(peer.id) === false) {
                    continue;
                }
                topology.filter?.remove(peer.id);
                topology.onDisconnect?.(peer.id);
            }
        }
    }
    /**
     * After identify has completed and we have received the list of supported
     * protocols, notify any topologies interested in those protocols.
     */
    _onPeerIdentify(evt) {
        const protocols = evt.detail.protocols;
        const connection = evt.detail.connection;
        const peerId = evt.detail.peerId;
        for (const protocol of protocols) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                if (connection.transient && topology.notifyOnTransient !== true) {
                    continue;
                }
                if (topology.filter?.has(peerId) === true) {
                    continue;
                }
                topology.filter?.add(peerId);
                topology.onConnect?.(peerId, connection);
            }
        }
    }
}

class TrackedMap extends Map {
    metric;
    constructor(init) {
        super();
        const { name, metrics } = init;
        this.metric = metrics.registerMetric(name);
        this.updateComponentMetric();
    }
    set(key, value) {
        super.set(key, value);
        this.updateComponentMetric();
        return this;
    }
    delete(key) {
        const deleted = super.delete(key);
        this.updateComponentMetric();
        return deleted;
    }
    clear() {
        super.clear();
        this.updateComponentMetric();
    }
    updateComponentMetric() {
        this.metric.update(this.size);
    }
}
function trackedMap(config) {
    const { name, metrics } = config;
    let map;
    if (metrics != null) {
        map = new TrackedMap({ name, metrics });
    }
    else {
        map = new Map();
    }
    return map;
}

class DefaultTransportManager {
    log;
    components;
    transports;
    listeners;
    faultTolerance;
    started;
    constructor(components, init = {}) {
        this.log = components.logger.forComponent('libp2p:transports');
        this.components = components;
        this.started = false;
        this.transports = new Map();
        this.listeners = trackedMap({
            name: 'libp2p_transport_manager_listeners',
            metrics: this.components.metrics
        });
        this.faultTolerance = init.faultTolerance ?? FaultTolerance.FATAL_ALL;
    }
    [Symbol.toStringTag] = '@libp2p/transport-manager';
    /**
     * Adds a `Transport` to the manager
     */
    add(transport) {
        const tag = transport[Symbol.toStringTag];
        if (tag == null) {
            throw new CodeError$1('Transport must have a valid tag', codes.ERR_INVALID_KEY);
        }
        if (this.transports.has(tag)) {
            throw new CodeError$1(`There is already a transport with the tag ${tag}`, codes.ERR_DUPLICATE_TRANSPORT);
        }
        this.log('adding transport %s', tag);
        this.transports.set(tag, transport);
        if (!this.listeners.has(tag)) {
            this.listeners.set(tag, []);
        }
    }
    isStarted() {
        return this.started;
    }
    start() {
        this.started = true;
    }
    async afterStart() {
        // Listen on the provided transports for the provided addresses
        const addrs = this.components.addressManager.getListenAddrs();
        await this.listen(addrs);
    }
    /**
     * Stops all listeners
     */
    async stop() {
        const tasks = [];
        for (const [key, listeners] of this.listeners) {
            this.log('closing listeners for %s', key);
            while (listeners.length > 0) {
                const listener = listeners.pop();
                if (listener == null) {
                    continue;
                }
                tasks.push(listener.close());
            }
        }
        await Promise.all(tasks);
        this.log('all listeners closed');
        for (const key of this.listeners.keys()) {
            this.listeners.set(key, []);
        }
        this.started = false;
    }
    /**
     * Dials the given Multiaddr over it's supported transport
     */
    async dial(ma, options) {
        const transport = this.dialTransportForMultiaddr(ma);
        if (transport == null) {
            throw new CodeError$1(`No transport available for address ${String(ma)}`, codes.ERR_TRANSPORT_UNAVAILABLE);
        }
        options?.onProgress?.(new CustomProgressEvent('transport-manager:selected-transport', transport[Symbol.toStringTag]));
        try {
            // @ts-expect-error the transport has a typed onProgress option but we
            // can't predict what transport implementation we selected so all we can
            // do is pass the onProgress handler in and hope for the best
            return await transport.dial(ma, {
                ...options,
                upgrader: this.components.upgrader
            });
        }
        catch (err) {
            if (err.code == null) {
                err.code = codes.ERR_TRANSPORT_DIAL_FAILED;
            }
            throw err;
        }
    }
    /**
     * Returns all Multiaddr's the listeners are using
     */
    getAddrs() {
        let addrs = [];
        for (const listeners of this.listeners.values()) {
            for (const listener of listeners) {
                addrs = [...addrs, ...listener.getAddrs()];
            }
        }
        return addrs;
    }
    /**
     * Returns all the transports instances
     */
    getTransports() {
        return Array.of(...this.transports.values());
    }
    /**
     * Returns all the listener instances
     */
    getListeners() {
        return Array.of(...this.listeners.values()).flat();
    }
    /**
     * Finds a transport that matches the given Multiaddr
     */
    dialTransportForMultiaddr(ma) {
        for (const transport of this.transports.values()) {
            const addrs = transport.dialFilter([ma]);
            if (addrs.length > 0) {
                return transport;
            }
        }
    }
    /**
     * Finds a transport that matches the given Multiaddr
     */
    listenTransportForMultiaddr(ma) {
        for (const transport of this.transports.values()) {
            const addrs = transport.listenFilter([ma]);
            if (addrs.length > 0) {
                return transport;
            }
        }
    }
    /**
     * Starts listeners for each listen Multiaddr
     */
    async listen(addrs) {
        if (!this.isStarted()) {
            throw new CodeError$1('Not started', codes.ERR_NODE_NOT_STARTED);
        }
        if (addrs == null || addrs.length === 0) {
            this.log('no addresses were provided for listening, this node is dial only');
            return;
        }
        const couldNotListen = [];
        for (const [key, transport] of this.transports.entries()) {
            const supportedAddrs = transport.listenFilter(addrs);
            const tasks = [];
            // For each supported multiaddr, create a listener
            for (const addr of supportedAddrs) {
                this.log('creating listener for %s on %a', key, addr);
                const listener = transport.createListener({
                    upgrader: this.components.upgrader
                });
                let listeners = this.listeners.get(key) ?? [];
                if (listeners == null) {
                    listeners = [];
                    this.listeners.set(key, listeners);
                }
                listeners.push(listener);
                // Track listen/close events
                listener.addEventListener('listening', () => {
                    this.components.events.safeDispatchEvent('transport:listening', {
                        detail: listener
                    });
                });
                listener.addEventListener('close', () => {
                    const index = listeners.findIndex(l => l === listener);
                    // remove the listener
                    listeners.splice(index, 1);
                    this.components.events.safeDispatchEvent('transport:close', {
                        detail: listener
                    });
                });
                // We need to attempt to listen on everything
                tasks.push(listener.listen(addr));
            }
            // Keep track of transports we had no addresses for
            if (tasks.length === 0) {
                couldNotListen.push(key);
                continue;
            }
            const results = await Promise.allSettled(tasks);
            // If we are listening on at least 1 address, succeed.
            // TODO: we should look at adding a retry (`p-retry`) here to better support
            // listening on remote addresses as they may be offline. We could then potentially
            // just wait for any (`p-any`) listener to succeed on each transport before returning
            const isListening = results.find(r => r.status === 'fulfilled');
            if ((isListening == null) && this.faultTolerance !== FaultTolerance.NO_FATAL) {
                throw new CodeError$1(`Transport (${key}) could not listen on any available address`, codes.ERR_NO_VALID_ADDRESSES);
            }
        }
        // If no transports were able to listen, throw an error. This likely
        // means we were given addresses we do not have transports for
        if (couldNotListen.length === this.transports.size) {
            const message = `no valid addresses were provided for transports [${couldNotListen.join(', ')}]`;
            if (this.faultTolerance === FaultTolerance.FATAL_ALL) {
                throw new CodeError$1(message, codes.ERR_NO_VALID_ADDRESSES);
            }
            this.log(`libp2p in dial mode only: ${message}`);
        }
    }
    /**
     * Removes the given transport from the manager.
     * If a transport has any running listeners, they will be closed.
     */
    async remove(key) {
        const listeners = this.listeners.get(key) ?? [];
        this.log.trace('removing transport %s', key);
        // Close any running listeners
        const tasks = [];
        this.log.trace('closing listeners for %s', key);
        while (listeners.length > 0) {
            const listener = listeners.pop();
            if (listener == null) {
                continue;
            }
            tasks.push(listener.close());
        }
        await Promise.all(tasks);
        this.transports.delete(key);
        this.listeners.delete(key);
    }
    /**
     * Removes all transports from the manager.
     * If any listeners are running, they will be closed.
     *
     * @async
     */
    async removeAll() {
        const tasks = [];
        for (const key of this.transports.keys()) {
            tasks.push(this.remove(key));
        }
        await Promise.all(tasks);
    }
}

const PROTOCOL_ID = '/multistream/1.0.0';
// Conforming to go-libp2p
// See https://github.com/multiformats/go-multistream/blob/master/multistream.go#L297
const MAX_PROTOCOL_LENGTH = 1024;

const NewLine = fromString('\n');
/**
 * `write` encodes and writes a single buffer
 */
async function write$1(writer, buffer, options) {
    await writer.write(buffer, options);
}
/**
 * `writeAll` behaves like `write`, except it encodes an array of items as a single write
 */
async function writeAll(writer, buffers, options) {
    await writer.writeV(buffers, options);
}
/**
 * Read a length-prefixed buffer from the passed stream, stripping the final newline character
 */
async function read(reader, options) {
    const buf = await reader.read(options);
    if (buf.byteLength === 0 || buf.get(buf.byteLength - 1) !== NewLine[0]) {
        options.log.error('Invalid mss message - missing newline', buf);
        throw new CodeError$1('missing newline', 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE');
    }
    return buf.sublist(0, -1); // Remove newline
}
/**
 * Read a length-prefixed string from the passed stream, stripping the final newline character
 */
async function readString(reader, options) {
    const buf = await read(reader, options);
    return toString$6(buf.subarray());
}

/**
 * Negotiate a protocol to use from a list of protocols.
 *
 * @param stream - A duplex iterable stream to dial on
 * @param protocols - A list of protocols (or single protocol) to negotiate with. Protocols are attempted in order until a match is made.
 * @param options - An options object containing an AbortSignal and an optional boolean `writeBytes` - if this is true, `Uint8Array`s will be written into `duplex`, otherwise `Uint8ArrayList`s will
 * @returns A stream for the selected protocol and the protocol that was selected from the list of protocols provided to `select`.
 * @example
 *
 * ```TypeScript
 * import { pipe } from 'it-pipe'
 * import * as mss from '@libp2p/multistream-select'
 * import { Mplex } from '@libp2p/mplex'
 *
 * const muxer = new Mplex()
 * const muxedStream = muxer.newStream()
 *
 * // mss.select(protocol(s))
 * // Select from one of the passed protocols (in priority order)
 * // Returns selected stream and protocol
 * const { stream: dhtStream, protocol } = await mss.select(muxedStream, [
 *   // This might just be different versions of DHT, but could be different impls
 *   '/ipfs-dht/2.0.0', // Most of the time this will probably just be one item.
 *   '/ipfs-dht/1.0.0'
 * ])
 *
 * // Typically this stream will be passed back to the caller of libp2p.dialProtocol
 * //
 * // ...it might then do something like this:
 * // try {
 * //   await pipe(
 * //     [uint8ArrayFromString('Some DHT data')]
 * //     dhtStream,
 * //     async source => {
 * //       for await (const chunk of source)
 * //         // DHT response data
 * //     }
 * //   )
 * // } catch (err) {
 * //   // Error in stream
 * // }
 * ```
 */
async function select(stream, protocols, options) {
    protocols = Array.isArray(protocols) ? [...protocols] : [protocols];
    if (protocols.length === 1 && options.negotiateFully === false) {
        return optimisticSelect(stream, protocols[0], options);
    }
    const lp = lpStream(stream, {
        ...options,
        maxDataLength: MAX_PROTOCOL_LENGTH
    });
    const protocol = protocols.shift();
    if (protocol == null) {
        throw new Error('At least one protocol must be specified');
    }
    options.log.trace('select: write ["%s", "%s"]', PROTOCOL_ID, protocol);
    const p1 = fromString(`${PROTOCOL_ID}\n`);
    const p2 = fromString(`${protocol}\n`);
    await writeAll(lp, [p1, p2], options);
    options.log.trace('select: reading multistream-select header');
    let response = await readString(lp, options);
    options.log.trace('select: read "%s"', response);
    // Read the protocol response if we got the protocolId in return
    if (response === PROTOCOL_ID) {
        options.log.trace('select: reading protocol response');
        response = await readString(lp, options);
        options.log.trace('select: read "%s"', response);
    }
    // We're done
    if (response === protocol) {
        return { stream: lp.unwrap(), protocol };
    }
    // We haven't gotten a valid ack, try the other protocols
    for (const protocol of protocols) {
        options.log.trace('select: write "%s"', protocol);
        await write$1(lp, fromString(`${protocol}\n`), options);
        options.log.trace('select: reading protocol response');
        const response = await readString(lp, options);
        options.log.trace('select: read "%s" for "%s"', response, protocol);
        if (response === protocol) {
            return { stream: lp.unwrap(), protocol };
        }
    }
    throw new CodeError$1('protocol selection failed', 'ERR_UNSUPPORTED_PROTOCOL');
}
/**
 * Optimistically negotiates a protocol.
 *
 * It *does not* block writes waiting for the other end to respond. Instead, it
 * simply assumes the negotiation went successfully and starts writing data.
 *
 * Use when it is known that the receiver supports the desired protocol.
 */
function optimisticSelect(stream, protocol, options) {
    const originalSink = stream.sink.bind(stream);
    const originalSource = stream.source;
    let negotiated = false;
    let negotiating = false;
    const doneNegotiating = pDefer();
    let sentProtocol = false;
    let sendingProtocol = false;
    const doneSendingProtocol = pDefer();
    let readProtocol = false;
    let readingProtocol = false;
    const doneReadingProtocol = pDefer();
    const lp = lpStream({
        sink: originalSink,
        source: originalSource
    }, {
        ...options,
        maxDataLength: MAX_PROTOCOL_LENGTH
    });
    stream.sink = async (source) => {
        const { sink } = lp.unwrap();
        await sink(async function* () {
            let sentData = false;
            for await (const buf of source) {
                // started reading before the source yielded, wait for protocol send
                if (sendingProtocol) {
                    await doneSendingProtocol.promise;
                }
                // writing before reading, send the protocol and the first chunk of data
                if (!sentProtocol) {
                    sendingProtocol = true;
                    options.log.trace('optimistic: write ["%s", "%s", data(%d)] in sink', PROTOCOL_ID, protocol, buf.byteLength);
                    const protocolString = `${protocol}\n`;
                    // send protocols in first chunk of data written to transport
                    yield new Uint8ArrayList(Uint8Array.from([19]), // length of PROTOCOL_ID plus newline
                    fromString(`${PROTOCOL_ID}\n`), encode$a(protocolString.length), fromString(protocolString), buf).subarray();
                    options.log.trace('optimistic: wrote ["%s", "%s", data(%d)] in sink', PROTOCOL_ID, protocol, buf.byteLength);
                    sentProtocol = true;
                    sendingProtocol = false;
                    doneSendingProtocol.resolve();
                    // read the negotiation response but don't block more sending
                    negotiate()
                        .catch(err => {
                        options.log.error('could not finish optimistic protocol negotiation of %s', protocol, err);
                    });
                }
                else {
                    yield buf;
                }
                sentData = true;
            }
            // special case - the source passed to the sink has ended but we didn't
            // negotiated the protocol yet so do it now
            if (!sentData) {
                await negotiate();
            }
        }());
    };
    async function negotiate() {
        if (negotiating) {
            options.log.trace('optimistic: already negotiating %s stream', protocol);
            await doneNegotiating.promise;
            return;
        }
        negotiating = true;
        try {
            // we haven't sent the protocol yet, send it now
            if (!sentProtocol) {
                options.log.trace('optimistic: doing send protocol for %s stream', protocol);
                await doSendProtocol();
            }
            // if we haven't read the protocol response yet, do it now
            if (!readProtocol) {
                options.log.trace('optimistic: doing read protocol for %s stream', protocol);
                await doReadProtocol();
            }
        }
        finally {
            negotiating = false;
            negotiated = true;
            doneNegotiating.resolve();
        }
    }
    async function doSendProtocol() {
        if (sendingProtocol) {
            await doneSendingProtocol.promise;
            return;
        }
        sendingProtocol = true;
        try {
            options.log.trace('optimistic: write ["%s", "%s", data] in source', PROTOCOL_ID, protocol);
            await lp.writeV([
                fromString(`${PROTOCOL_ID}\n`),
                fromString(`${protocol}\n`)
            ]);
            options.log.trace('optimistic: wrote ["%s", "%s", data] in source', PROTOCOL_ID, protocol);
        }
        finally {
            sentProtocol = true;
            sendingProtocol = false;
            doneSendingProtocol.resolve();
        }
    }
    async function doReadProtocol() {
        if (readingProtocol) {
            await doneReadingProtocol.promise;
            return;
        }
        readingProtocol = true;
        try {
            options.log.trace('optimistic: reading multistream select header');
            let response = await readString(lp, options);
            options.log.trace('optimistic: read multistream select header "%s"', response);
            if (response === PROTOCOL_ID) {
                response = await readString(lp, options);
            }
            options.log.trace('optimistic: read protocol "%s", expecting "%s"', response, protocol);
            if (response !== protocol) {
                throw new CodeError$1('protocol selection failed', 'ERR_UNSUPPORTED_PROTOCOL');
            }
        }
        finally {
            readProtocol = true;
            readingProtocol = false;
            doneReadingProtocol.resolve();
        }
    }
    stream.source = (async function* () {
        // make sure we've done protocol negotiation before we read stream data
        await negotiate();
        options.log.trace('optimistic: reading data from "%s" stream', protocol);
        yield* lp.unwrap().source;
    })();
    if (stream.closeRead != null) {
        const originalCloseRead = stream.closeRead.bind(stream);
        stream.closeRead = async (opts) => {
            // we need to read & write to negotiate the protocol so ensure we've done
            // this before closing the readable end of the stream
            if (!negotiated) {
                await negotiate().catch(err => {
                    options.log.error('could not negotiate protocol before close read', err);
                });
            }
            // protocol has been negotiated, ok to close the readable end
            await originalCloseRead(opts);
        };
    }
    if (stream.closeWrite != null) {
        const originalCloseWrite = stream.closeWrite.bind(stream);
        stream.closeWrite = async (opts) => {
            // we need to read & write to negotiate the protocol so ensure we've done
            // this before closing the writable end of the stream
            if (!negotiated) {
                await negotiate().catch(err => {
                    options.log.error('could not negotiate protocol before close write', err);
                });
            }
            // protocol has been negotiated, ok to close the writable end
            await originalCloseWrite(opts);
        };
    }
    if (stream.close != null) {
        const originalClose = stream.close.bind(stream);
        stream.close = async (opts) => {
            // if we are in the process of negotiation, let it finish before closing
            // because we may have unsent early data
            const tasks = [];
            if (sendingProtocol) {
                tasks.push(doneSendingProtocol.promise);
            }
            if (readingProtocol) {
                tasks.push(doneReadingProtocol.promise);
            }
            if (tasks.length > 0) {
                // let the in-flight protocol negotiation finish gracefully
                await raceSignal(Promise.all(tasks), opts?.signal);
            }
            else {
                // no protocol negotiation attempt has occurred so don't start one
                negotiated = true;
                negotiating = false;
                doneNegotiating.resolve();
            }
            // protocol has been negotiated, ok to close the writable end
            await originalClose(opts);
        };
    }
    return {
        stream,
        protocol
    };
}

/**
 * Handle multistream protocol selections for the given list of protocols.
 *
 * Note that after a protocol is handled `listener` can no longer be used.
 *
 * @param stream - A duplex iterable stream to listen on
 * @param protocols - A list of protocols (or single protocol) that this listener is able to speak.
 * @param options - an options object containing an AbortSignal and an optional boolean `writeBytes` - if this is true, `Uint8Array`s will be written into `duplex`, otherwise `Uint8ArrayList`s will
 * @returns A stream for the selected protocol and the protocol that was selected from the list of protocols provided to `select`
 * @example
 *
 * ```TypeScript
 * import { pipe } from 'it-pipe'
 * import * as mss from '@libp2p/multistream-select'
 * import { Mplex } from '@libp2p/mplex'
 *
 * const muxer = new Mplex({
 *   async onStream (muxedStream) {
 *   // mss.handle(handledProtocols)
 *   // Returns selected stream and protocol
 *   const { stream, protocol } = await mss.handle(muxedStream, [
 *     '/ipfs-dht/1.0.0',
 *     '/ipfs-bitswap/1.0.0'
 *   ])
 *
 *   // Typically here we'd call the handler function that was registered in
 *   // libp2p for the given protocol:
 *   // e.g. handlers[protocol].handler(stream)
 *   //
 *   // If protocol was /ipfs-dht/1.0.0 it might do something like this:
 *   // try {
 *   //   await pipe(
 *   //     dhtStream,
 *   //     source => (async function * () {
 *   //       for await (const chunk of source)
 *   //         // Incoming DHT data -> process and yield to respond
 *   //     })(),
 *   //     dhtStream
 *   //   )
 *   // } catch (err) {
 *   //   // Error in stream
 *   // }
 *   }
 * })
 * ```
 */
async function handle(stream, protocols, options) {
    protocols = Array.isArray(protocols) ? protocols : [protocols];
    options.log.trace('handle: available protocols %s', protocols);
    const lp = lpStream(stream, {
        ...options,
        maxDataLength: MAX_PROTOCOL_LENGTH,
        maxLengthLength: 2 // 2 bytes is enough to length-prefix MAX_PROTOCOL_LENGTH
    });
    while (true) {
        options.log.trace('handle: reading incoming string');
        const protocol = await readString(lp, options);
        options.log.trace('handle: read "%s"', protocol);
        if (protocol === PROTOCOL_ID) {
            options.log.trace('handle: respond with "%s" for "%s"', PROTOCOL_ID, protocol);
            await write$1(lp, fromString(`${PROTOCOL_ID}\n`), options);
            options.log.trace('handle: responded with "%s" for "%s"', PROTOCOL_ID, protocol);
            continue;
        }
        if (protocols.includes(protocol)) {
            options.log.trace('handle: respond with "%s" for "%s"', protocol, protocol);
            await write$1(lp, fromString(`${protocol}\n`), options);
            options.log.trace('handle: responded with "%s" for "%s"', protocol, protocol);
            return { stream: lp.unwrap(), protocol };
        }
        if (protocol === 'ls') {
            // <varint-msg-len><varint-proto-name-len><proto-name>\n<varint-proto-name-len><proto-name>\n\n
            const protos = new Uint8ArrayList(...protocols.map(p => encode$5.single(fromString(`${p}\n`))), fromString('\n'));
            options.log.trace('handle: respond with "%s" for %s', protocols, protocol);
            await write$1(lp, protos, options);
            options.log.trace('handle: responded with "%s" for %s', protocols, protocol);
            continue;
        }
        options.log('handle: respond with "na" for "%s"', protocol);
        await write$1(lp, fromString('na\n'), options);
        options.log('handle: responded with "na" for "%s"', protocol);
    }
}

const CLOSE_TIMEOUT = 500;
/**
 * An implementation of the js-libp2p connection.
 * Any libp2p transport should use an upgrader to return this connection.
 */
class ConnectionImpl {
    /**
     * Connection identifier.
     */
    id;
    /**
     * Observed multiaddr of the remote peer
     */
    remoteAddr;
    /**
     * Remote peer id
     */
    remotePeer;
    direction;
    timeline;
    multiplexer;
    encryption;
    status;
    transient;
    log;
    /**
     * User provided tags
     *
     */
    tags;
    /**
     * Reference to the new stream function of the multiplexer
     */
    _newStream;
    /**
     * Reference to the close function of the raw connection
     */
    _close;
    _abort;
    /**
     * Reference to the getStreams function of the muxer
     */
    _getStreams;
    /**
     * An implementation of the js-libp2p connection.
     * Any libp2p transport should use an upgrader to return this connection.
     */
    constructor(init) {
        const { remoteAddr, remotePeer, newStream, close, abort, getStreams } = init;
        this.id = `${(parseInt(String(Math.random() * 1e9))).toString(36)}${Date.now()}`;
        this.remoteAddr = remoteAddr;
        this.remotePeer = remotePeer;
        this.direction = init.direction;
        this.status = 'open';
        this.timeline = init.timeline;
        this.multiplexer = init.multiplexer;
        this.encryption = init.encryption;
        this.transient = init.transient ?? false;
        this.log = init.logger.forComponent(`libp2p:connection:${this.direction}:${this.id}`);
        if (this.remoteAddr.getPeerId() == null) {
            this.remoteAddr = this.remoteAddr.encapsulate(`/p2p/${this.remotePeer}`);
        }
        this._newStream = newStream;
        this._close = close;
        this._abort = abort;
        this._getStreams = getStreams;
        this.tags = [];
    }
    [Symbol.toStringTag] = 'Connection';
    [connectionSymbol] = true;
    /**
     * Get all the streams of the muxer
     */
    get streams() {
        return this._getStreams();
    }
    /**
     * Create a new stream from this connection
     */
    async newStream(protocols, options) {
        if (this.status === 'closing') {
            throw new CodeError$1('the connection is being closed', 'ERR_CONNECTION_BEING_CLOSED');
        }
        if (this.status === 'closed') {
            throw new CodeError$1('the connection is closed', 'ERR_CONNECTION_CLOSED');
        }
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        if (this.transient && options?.runOnTransientConnection !== true) {
            throw new CodeError$1('Cannot open protocol stream on transient connection', 'ERR_TRANSIENT_CONNECTION');
        }
        const stream = await this._newStream(protocols, options);
        stream.direction = 'outbound';
        return stream;
    }
    /**
     * Close the connection
     */
    async close(options = {}) {
        if (this.status === 'closed' || this.status === 'closing') {
            return;
        }
        this.log('closing connection to %a', this.remoteAddr);
        this.status = 'closing';
        if (options.signal == null) {
            const signal = AbortSignal.timeout(CLOSE_TIMEOUT);
            setMaxListeners(Infinity, signal);
            options = {
                ...options,
                signal
            };
        }
        try {
            this.log.trace('closing all streams');
            // close all streams gracefully - this can throw if we're not multiplexed
            await Promise.all(this.streams.map(async (s) => s.close(options)));
            this.log.trace('closing underlying transport');
            // close raw connection
            await this._close(options);
            this.log.trace('updating timeline with close time');
            this.status = 'closed';
            this.timeline.close = Date.now();
        }
        catch (err) {
            this.log.error('error encountered during graceful close of connection to %a', this.remoteAddr, err);
            this.abort(err);
        }
    }
    abort(err) {
        this.log.error('aborting connection to %a due to error', this.remoteAddr, err);
        this.status = 'closing';
        this.streams.forEach(s => { s.abort(err); });
        this.log.error('all streams aborted', this.streams.length);
        // Abort raw connection
        this._abort(err);
        this.timeline.close = Date.now();
        this.status = 'closed';
    }
}
function createConnection(init) {
    return new ConnectionImpl(init);
}

const DEFAULT_PROTOCOL_SELECT_TIMEOUT = 30000;
function findIncomingStreamLimit(protocol, registrar) {
    try {
        const { options } = registrar.getHandler(protocol);
        return options.maxInboundStreams;
    }
    catch (err) {
        if (err.code !== codes.ERR_NO_HANDLER_FOR_PROTOCOL) {
            throw err;
        }
    }
    return DEFAULT_MAX_INBOUND_STREAMS;
}
function findOutgoingStreamLimit(protocol, registrar, options = {}) {
    try {
        const { options } = registrar.getHandler(protocol);
        if (options.maxOutboundStreams != null) {
            return options.maxOutboundStreams;
        }
    }
    catch (err) {
        if (err.code !== codes.ERR_NO_HANDLER_FOR_PROTOCOL) {
            throw err;
        }
    }
    return options.maxOutboundStreams ?? DEFAULT_MAX_OUTBOUND_STREAMS;
}
function countStreams(protocol, direction, connection) {
    let streamCount = 0;
    connection.streams.forEach(stream => {
        if (stream.direction === direction && stream.protocol === protocol) {
            streamCount++;
        }
    });
    return streamCount;
}
class DefaultUpgrader {
    components;
    connectionEncryption;
    muxers;
    inboundUpgradeTimeout;
    events;
    constructor(components, init) {
        this.components = components;
        this.connectionEncryption = new Map();
        init.connectionEncryption.forEach(encrypter => {
            this.connectionEncryption.set(encrypter.protocol, encrypter);
        });
        this.muxers = new Map();
        init.muxers.forEach(muxer => {
            this.muxers.set(muxer.protocol, muxer);
        });
        this.inboundUpgradeTimeout = init.inboundUpgradeTimeout ?? INBOUND_UPGRADE_TIMEOUT;
        this.events = components.events;
    }
    [Symbol.toStringTag] = '@libp2p/upgrader';
    async shouldBlockConnection(remotePeer, maConn, connectionType) {
        const connectionGater = this.components.connectionGater[connectionType];
        if (connectionGater !== undefined) {
            if (await connectionGater(remotePeer, maConn)) {
                throw new CodeError$1(`The multiaddr connection is blocked by gater.${connectionType}`, codes.ERR_CONNECTION_INTERCEPTED);
            }
        }
    }
    /**
     * Upgrades an inbound connection
     */
    async upgradeInbound(maConn, opts) {
        const accept = await this.components.connectionManager.acceptIncomingConnection(maConn);
        if (!accept) {
            throw new CodeError$1('connection denied', codes.ERR_CONNECTION_DENIED);
        }
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let muxerFactory;
        let cryptoProtocol;
        const signal = AbortSignal.timeout(this.inboundUpgradeTimeout);
        const onAbort = () => {
            maConn.abort(new CodeError$1('inbound upgrade timeout', ERR_TIMEOUT));
        };
        signal.addEventListener('abort', onAbort, { once: true });
        setMaxListeners(Infinity, signal);
        try {
            if ((await this.components.connectionGater.denyInboundConnection?.(maConn)) === true) {
                throw new CodeError$1('The multiaddr connection is blocked by gater.acceptConnection', codes.ERR_CONNECTION_INTERCEPTED);
            }
            this.components.metrics?.trackMultiaddrConnection(maConn);
            maConn.log('starting the inbound connection upgrade');
            // Protect
            let protectedConn = maConn;
            if (opts?.skipProtection !== true) {
                const protector = this.components.connectionProtector;
                if (protector != null) {
                    maConn.log('protecting the inbound connection');
                    protectedConn = await protector.protect(maConn);
                }
            }
            try {
                // Encrypt the connection
                encryptedConn = protectedConn;
                if (opts?.skipEncryption !== true) {
                    opts?.onProgress?.(new CustomProgressEvent('upgrader:encrypt-inbound-connection'));
                    ({
                        conn: encryptedConn,
                        remotePeer,
                        protocol: cryptoProtocol
                    } = await this._encryptInbound(protectedConn));
                    const maConn = {
                        ...protectedConn,
                        ...encryptedConn
                    };
                    await this.shouldBlockConnection(remotePeer, maConn, 'denyInboundEncryptedConnection');
                }
                else {
                    const idStr = maConn.remoteAddr.getPeerId();
                    if (idStr == null) {
                        throw new CodeError$1('inbound connection that skipped encryption must have a peer id', codes.ERR_INVALID_MULTIADDR);
                    }
                    const remotePeerId = peerIdFromString(idStr);
                    cryptoProtocol = 'native';
                    remotePeer = remotePeerId;
                }
                upgradedConn = encryptedConn;
                if (opts?.muxerFactory != null) {
                    muxerFactory = opts.muxerFactory;
                }
                else if (this.muxers.size > 0) {
                    opts?.onProgress?.(new CustomProgressEvent('upgrader:multiplex-inbound-connection'));
                    // Multiplex the connection
                    const multiplexed = await this._multiplexInbound({
                        ...protectedConn,
                        ...encryptedConn
                    }, this.muxers);
                    muxerFactory = multiplexed.muxerFactory;
                    upgradedConn = multiplexed.stream;
                }
            }
            catch (err) {
                maConn.log.error('failed to upgrade inbound connection', err);
                throw err;
            }
            await this.shouldBlockConnection(remotePeer, maConn, 'denyInboundUpgradedConnection');
            maConn.log('successfully upgraded inbound connection');
            return this._createConnection({
                cryptoProtocol,
                direction: 'inbound',
                maConn,
                upgradedConn,
                muxerFactory,
                remotePeer,
                transient: opts?.transient
            });
        }
        finally {
            signal.removeEventListener('abort', onAbort);
            this.components.connectionManager.afterUpgradeInbound();
        }
    }
    /**
     * Upgrades an outbound connection
     */
    async upgradeOutbound(maConn, opts) {
        const idStr = maConn.remoteAddr.getPeerId();
        let remotePeerId;
        if (idStr != null) {
            remotePeerId = peerIdFromString(idStr);
            await this.shouldBlockConnection(remotePeerId, maConn, 'denyOutboundConnection');
        }
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let cryptoProtocol;
        let muxerFactory;
        this.components.metrics?.trackMultiaddrConnection(maConn);
        maConn.log('starting the outbound connection upgrade');
        // If the transport natively supports encryption, skip connection
        // protector and encryption
        // Protect
        let protectedConn = maConn;
        if (opts?.skipProtection !== true) {
            const protector = this.components.connectionProtector;
            if (protector != null) {
                protectedConn = await protector.protect(maConn);
            }
        }
        try {
            // Encrypt the connection
            encryptedConn = protectedConn;
            if (opts?.skipEncryption !== true) {
                ({
                    conn: encryptedConn,
                    remotePeer,
                    protocol: cryptoProtocol
                } = await this._encryptOutbound(protectedConn, remotePeerId));
                const maConn = {
                    ...protectedConn,
                    ...encryptedConn
                };
                await this.shouldBlockConnection(remotePeer, maConn, 'denyOutboundEncryptedConnection');
            }
            else {
                if (remotePeerId == null) {
                    throw new CodeError$1('Encryption was skipped but no peer id was passed', codes.ERR_INVALID_PEER);
                }
                cryptoProtocol = 'native';
                remotePeer = remotePeerId;
            }
            upgradedConn = encryptedConn;
            if (opts?.muxerFactory != null) {
                muxerFactory = opts.muxerFactory;
            }
            else if (this.muxers.size > 0) {
                // Multiplex the connection
                const multiplexed = await this._multiplexOutbound({
                    ...protectedConn,
                    ...encryptedConn
                }, this.muxers);
                muxerFactory = multiplexed.muxerFactory;
                upgradedConn = multiplexed.stream;
            }
        }
        catch (err) {
            maConn.log.error('failed to upgrade outbound connection', err);
            await maConn.close(err);
            throw err;
        }
        await this.shouldBlockConnection(remotePeer, maConn, 'denyOutboundUpgradedConnection');
        maConn.log('successfully upgraded outbound connection');
        return this._createConnection({
            cryptoProtocol,
            direction: 'outbound',
            maConn,
            upgradedConn,
            muxerFactory,
            remotePeer,
            transient: opts?.transient
        });
    }
    /**
     * A convenience method for generating a new `Connection`
     */
    _createConnection(opts) {
        const { cryptoProtocol, direction, maConn, upgradedConn, remotePeer, muxerFactory, transient } = opts;
        let muxer;
        let newStream;
        let connection; // eslint-disable-line prefer-const
        if (muxerFactory != null) {
            // Create the muxer
            muxer = muxerFactory.createStreamMuxer({
                direction,
                // Run anytime a remote stream is created
                onIncomingStream: muxedStream => {
                    if (connection == null) {
                        return;
                    }
                    void Promise.resolve()
                        .then(async () => {
                        const protocols = this.components.registrar.getProtocols();
                        const { stream, protocol } = await handle(muxedStream, protocols, {
                            log: muxedStream.log,
                            yieldBytes: false
                        });
                        if (connection == null) {
                            return;
                        }
                        connection.log('incoming stream opened on %s', protocol);
                        const incomingLimit = findIncomingStreamLimit(protocol, this.components.registrar);
                        const streamCount = countStreams(protocol, 'inbound', connection);
                        if (streamCount === incomingLimit) {
                            const err = new CodeError$1(`Too many inbound protocol streams for protocol "${protocol}" - limit ${incomingLimit}`, codes.ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS);
                            muxedStream.abort(err);
                            throw err;
                        }
                        // after the handshake the returned stream can have early data so override
                        // the souce/sink
                        muxedStream.source = stream.source;
                        muxedStream.sink = stream.sink;
                        muxedStream.protocol = protocol;
                        // allow closing the write end of a not-yet-negotiated stream
                        if (stream.closeWrite != null) {
                            muxedStream.closeWrite = stream.closeWrite;
                        }
                        // allow closing the read end of a not-yet-negotiated stream
                        if (stream.closeRead != null) {
                            muxedStream.closeRead = stream.closeRead;
                        }
                        // make sure we don't try to negotiate a stream we are closing
                        if (stream.close != null) {
                            muxedStream.close = stream.close;
                        }
                        // If a protocol stream has been successfully negotiated and is to be passed to the application,
                        // the peerstore should ensure that the peer is registered with that protocol
                        await this.components.peerStore.merge(remotePeer, {
                            protocols: [protocol]
                        });
                        this.components.metrics?.trackProtocolStream(muxedStream, connection);
                        this._onStream({ connection, stream: muxedStream, protocol });
                    })
                        .catch(async (err) => {
                        connection.log.error('error handling incoming stream id %s', muxedStream.id, err.message, err.code, err.stack);
                        if (muxedStream.timeline.close == null) {
                            await muxedStream.close();
                        }
                    });
                }
            });
            newStream = async (protocols, options = {}) => {
                if (muxer == null) {
                    throw new CodeError$1('Stream is not multiplexed', codes.ERR_MUXER_UNAVAILABLE);
                }
                connection.log('starting new stream for protocols %s', protocols);
                const muxedStream = await muxer.newStream();
                connection.log.trace('started new stream %s for protocols %s', muxedStream.id, protocols);
                try {
                    if (options.signal == null) {
                        muxedStream.log('no abort signal was passed while trying to negotiate protocols %s falling back to default timeout', protocols);
                        const signal = AbortSignal.timeout(DEFAULT_PROTOCOL_SELECT_TIMEOUT);
                        setMaxListeners(Infinity, signal);
                        options = {
                            ...options,
                            signal
                        };
                    }
                    muxedStream.log.trace('selecting protocol from protocols %s', protocols);
                    const { stream, protocol } = await select(muxedStream, protocols, {
                        ...options,
                        log: muxedStream.log,
                        yieldBytes: true
                    });
                    muxedStream.log('selected protocol %s', protocol);
                    const outgoingLimit = findOutgoingStreamLimit(protocol, this.components.registrar, options);
                    const streamCount = countStreams(protocol, 'outbound', connection);
                    if (streamCount >= outgoingLimit) {
                        const err = new CodeError$1(`Too many outbound protocol streams for protocol "${protocol}" - ${streamCount}/${outgoingLimit}`, codes.ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS);
                        muxedStream.abort(err);
                        throw err;
                    }
                    // If a protocol stream has been successfully negotiated and is to be passed to the application,
                    // the peerstore should ensure that the peer is registered with that protocol
                    await this.components.peerStore.merge(remotePeer, {
                        protocols: [protocol]
                    });
                    // after the handshake the returned stream can have early data so override
                    // the souce/sink
                    muxedStream.source = stream.source;
                    muxedStream.sink = stream.sink;
                    muxedStream.protocol = protocol;
                    // allow closing the write end of a not-yet-negotiated stream
                    if (stream.closeWrite != null) {
                        muxedStream.closeWrite = stream.closeWrite;
                    }
                    // allow closing the read end of a not-yet-negotiated stream
                    if (stream.closeRead != null) {
                        muxedStream.closeRead = stream.closeRead;
                    }
                    // make sure we don't try to negotiate a stream we are closing
                    if (stream.close != null) {
                        muxedStream.close = stream.close;
                    }
                    this.components.metrics?.trackProtocolStream(muxedStream, connection);
                    return muxedStream;
                }
                catch (err) {
                    connection.log.error('could not create new stream for protocols %s', protocols, err);
                    if (muxedStream.timeline.close == null) {
                        muxedStream.abort(err);
                    }
                    if (err.code != null) {
                        throw err;
                    }
                    throw new CodeError$1(String(err), codes.ERR_UNSUPPORTED_PROTOCOL);
                }
            };
            // Pipe all data through the muxer
            void Promise.all([
                muxer.sink(upgradedConn.source),
                upgradedConn.sink(muxer.source)
            ]).catch(err => {
                connection.log.error('error piping data through muxer', err);
            });
        }
        const _timeline = maConn.timeline;
        maConn.timeline = new Proxy(_timeline, {
            set: (...args) => {
                if (connection != null && args[1] === 'close' && args[2] != null && _timeline.close == null) {
                    // Wait for close to finish before notifying of the closure
                    (async () => {
                        try {
                            if (connection.status === 'open') {
                                await connection.close();
                            }
                        }
                        catch (err) {
                            connection.log.error('error closing connection after timeline close', err);
                        }
                        finally {
                            this.events.safeDispatchEvent('connection:close', {
                                detail: connection
                            });
                        }
                    })().catch(err => {
                        connection.log.error('error thrown while dispatching connection:close event', err);
                    });
                }
                return Reflect.set(...args);
            }
        });
        maConn.timeline.upgraded = Date.now();
        const errConnectionNotMultiplexed = () => {
            throw new CodeError$1('connection is not multiplexed', codes.ERR_CONNECTION_NOT_MULTIPLEXED);
        };
        // Create the connection
        connection = createConnection({
            remoteAddr: maConn.remoteAddr,
            remotePeer,
            status: 'open',
            direction,
            timeline: maConn.timeline,
            multiplexer: muxer?.protocol,
            encryption: cryptoProtocol,
            transient,
            logger: this.components.logger,
            newStream: newStream ?? errConnectionNotMultiplexed,
            getStreams: () => { if (muxer != null) {
                return muxer.streams;
            }
            else {
                return [];
            } },
            close: async (options) => {
                // Ensure remaining streams are closed gracefully
                if (muxer != null) {
                    connection.log.trace('close muxer');
                    await muxer.close(options);
                }
                connection.log.trace('close maconn');
                // close the underlying transport
                await maConn.close(options);
                connection.log.trace('closed maconn');
            },
            abort: (err) => {
                maConn.abort(err);
                // Ensure remaining streams are aborted
                if (muxer != null) {
                    muxer.abort(err);
                }
            }
        });
        this.events.safeDispatchEvent('connection:open', {
            detail: connection
        });
        return connection;
    }
    /**
     * Routes incoming streams to the correct handler
     */
    _onStream(opts) {
        const { connection, stream, protocol } = opts;
        const { handler, options } = this.components.registrar.getHandler(protocol);
        if (connection.transient && options.runOnTransientConnection !== true) {
            throw new CodeError$1('Cannot open protocol stream on transient connection', 'ERR_TRANSIENT_CONNECTION');
        }
        handler({ connection, stream });
    }
    /**
     * Attempts to encrypt the incoming `connection` with the provided `cryptos`
     */
    async _encryptInbound(connection) {
        const protocols = Array.from(this.connectionEncryption.keys());
        connection.log('handling inbound crypto protocol selection', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                log: connection.log
            });
            const encrypter = this.connectionEncryption.get(protocol);
            if (encrypter == null) {
                throw new Error(`no crypto module found for ${protocol}`);
            }
            connection.log('encrypting inbound connection using', protocol);
            return {
                ...await encrypter.secureInbound(this.components.peerId, stream),
                protocol
            };
        }
        catch (err) {
            connection.log.error('encrypting inbound connection failed', err);
            throw new CodeError$1(err.message, codes.ERR_ENCRYPTION_FAILED);
        }
    }
    /**
     * Attempts to encrypt the given `connection` with the provided connection encrypters.
     * The first `ConnectionEncrypter` module to succeed will be used
     */
    async _encryptOutbound(connection, remotePeerId) {
        const protocols = Array.from(this.connectionEncryption.keys());
        connection.log('selecting outbound crypto protocol', protocols);
        try {
            connection.log.trace('selecting encrypter from %s', protocols);
            const { stream, protocol } = await select(connection, protocols, {
                log: connection.log,
                yieldBytes: true
            });
            const encrypter = this.connectionEncryption.get(protocol);
            if (encrypter == null) {
                throw new Error(`no crypto module found for ${protocol}`);
            }
            connection.log('encrypting outbound connection to %p using %s', remotePeerId, encrypter);
            return {
                ...await encrypter.secureOutbound(this.components.peerId, stream, remotePeerId),
                protocol
            };
        }
        catch (err) {
            connection.log.error('encrypting outbound connection to %p failed', remotePeerId, err);
            throw new CodeError$1(err.message, codes.ERR_ENCRYPTION_FAILED);
        }
    }
    /**
     * Selects one of the given muxers via multistream-select. That
     * muxer will be used for all future streams on the connection.
     */
    async _multiplexOutbound(connection, muxers) {
        const protocols = Array.from(muxers.keys());
        connection.log('outbound selecting muxer %s', protocols);
        try {
            connection.log.trace('selecting stream muxer from %s', protocols);
            const { stream, protocol } = await select(connection, protocols, {
                log: connection.log,
                yieldBytes: true
            });
            connection.log('selected %s as muxer protocol', protocol);
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            connection.log.error('error multiplexing outbound connection', err);
            throw new CodeError$1(String(err), codes.ERR_MUXER_UNAVAILABLE);
        }
    }
    /**
     * Registers support for one of the given muxers via multistream-select. The
     * selected muxer will be used for all future streams on the connection.
     */
    async _multiplexInbound(connection, muxers) {
        const protocols = Array.from(muxers.keys());
        connection.log('inbound handling muxers %s', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                log: connection.log
            });
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            connection.log.error('error multiplexing inbound connection', err);
            throw new CodeError$1(String(err), codes.ERR_MUXER_UNAVAILABLE);
        }
    }
}

const version$3 = '1.9.4';
const name$1 = 'libp2p';

class Libp2pNode extends TypedEventEmitter {
    peerId;
    peerStore;
    contentRouting;
    peerRouting;
    metrics;
    services;
    logger;
    status;
    components;
    log;
    constructor(init) {
        super();
        this.status = 'stopped';
        // event bus - components can listen to this emitter to be notified of system events
        // and also cause them to be emitted
        const events = new TypedEventEmitter();
        const originalDispatch = events.dispatchEvent.bind(events);
        events.dispatchEvent = (evt) => {
            const internalResult = originalDispatch(evt);
            const externalResult = this.dispatchEvent(new CustomEvent$1(evt.type, { detail: evt.detail }));
            return internalResult || externalResult;
        };
        // This emitter gets listened to a lot
        setMaxListeners(Infinity, events);
        this.peerId = init.peerId;
        this.logger = init.logger ?? defaultLogger();
        this.log = this.logger.forComponent('libp2p');
        // @ts-expect-error {} may not be of type T
        this.services = {};
        // @ts-expect-error defaultComponents is missing component types added later
        const components = this.components = defaultComponents({
            peerId: init.peerId,
            privateKey: init.privateKey,
            nodeInfo: init.nodeInfo ?? {
                name: name$1,
                version: version$3
            },
            logger: this.logger,
            events,
            datastore: init.datastore ?? new MemoryDatastore(),
            connectionGater: connectionGater(init.connectionGater),
            dns: init.dns
        });
        this.peerStore = this.configureComponent('peerStore', new PersistentPeerStore(components, {
            addressFilter: this.components.connectionGater.filterMultiaddrForPeer,
            ...init.peerStore
        }));
        // Create Metrics
        if (init.metrics != null) {
            this.metrics = this.configureComponent('metrics', init.metrics(this.components));
        }
        components.events.addEventListener('peer:update', evt => {
            // if there was no peer previously in the peer store this is a new peer
            if (evt.detail.previous == null) {
                const peerInfo = {
                    id: evt.detail.peer.id,
                    multiaddrs: evt.detail.peer.addresses.map(a => a.multiaddr)
                };
                components.events.safeDispatchEvent('peer:discovery', { detail: peerInfo });
            }
        });
        // Set up connection protector if configured
        if (init.connectionProtector != null) {
            this.configureComponent('connectionProtector', init.connectionProtector(components));
        }
        // Set up the Upgrader
        this.components.upgrader = new DefaultUpgrader(this.components, {
            connectionEncryption: (init.connectionEncryption ?? []).map((fn, index) => this.configureComponent(`connection-encryption-${index}`, fn(this.components))),
            muxers: (init.streamMuxers ?? []).map((fn, index) => this.configureComponent(`stream-muxers-${index}`, fn(this.components))),
            inboundUpgradeTimeout: init.connectionManager?.inboundUpgradeTimeout
        });
        // Setup the transport manager
        this.configureComponent('transportManager', new DefaultTransportManager(this.components, init.transportManager));
        // Create the Connection Manager
        this.configureComponent('connectionManager', new DefaultConnectionManager(this.components, init.connectionManager));
        if (init.connectionMonitor?.enabled !== false) {
            // Create the Connection Monitor if not disabled
            this.configureComponent('connectionMonitor', new ConnectionMonitor(this.components, init.connectionMonitor));
        }
        // Create the Registrar
        this.configureComponent('registrar', new DefaultRegistrar(this.components));
        // Addresses {listen, announce, noAnnounce}
        this.configureComponent('addressManager', new DefaultAddressManager(this.components, init.addresses));
        // Peer routers
        const peerRouters = (init.peerRouters ?? []).map((fn, index) => this.configureComponent(`peer-router-${index}`, fn(this.components)));
        this.peerRouting = this.components.peerRouting = this.configureComponent('peerRouting', new DefaultPeerRouting(this.components, {
            routers: peerRouters
        }));
        // Content routers
        const contentRouters = (init.contentRouters ?? []).map((fn, index) => this.configureComponent(`content-router-${index}`, fn(this.components)));
        this.contentRouting = this.components.contentRouting = this.configureComponent('contentRouting', new CompoundContentRouting(this.components, {
            routers: contentRouters
        }));
        // Random walk
        this.configureComponent('randomWalk', new RandomWalk(this.components));
        (init.peerDiscovery ?? []).forEach((fn, index) => {
            const service = this.configureComponent(`peer-discovery-${index}`, fn(this.components));
            service.addEventListener('peer', (evt) => {
                this.#onDiscoveryPeer(evt);
            });
        });
        // Transport modules
        init.transports?.forEach((fn, index) => {
            this.components.transportManager.add(this.configureComponent(`transport-${index}`, fn(this.components)));
        });
        // User defined modules
        if (init.services != null) {
            for (const name of Object.keys(init.services)) {
                const createService = init.services[name];
                const service = createService(this.components);
                if (service == null) {
                    this.log.error('service factory %s returned null or undefined instance', name);
                    continue;
                }
                this.services[name] = service;
                this.configureComponent(name, service);
                if (service[contentRoutingSymbol] != null) {
                    this.log('registering service %s for content routing', name);
                    contentRouters.push(service[contentRoutingSymbol]);
                }
                if (service[peerRoutingSymbol] != null) {
                    this.log('registering service %s for peer routing', name);
                    peerRouters.push(service[peerRoutingSymbol]);
                }
                if (service[peerDiscoverySymbol] != null) {
                    this.log('registering service %s for peer discovery', name);
                    service[peerDiscoverySymbol].addEventListener?.('peer', (evt) => {
                        this.#onDiscoveryPeer(evt);
                    });
                }
            }
        }
        // Ensure all services have their required dependencies
        checkServiceDependencies(components);
    }
    configureComponent(name, component) {
        if (component == null) {
            this.log.error('component %s was null or undefined', name);
        }
        // @ts-expect-error cannot assign props
        this.components[name] = component;
        return component;
    }
    /**
     * Starts the libp2p node and all its subsystems
     */
    async start() {
        if (this.status !== 'stopped') {
            return;
        }
        this.status = 'starting';
        this.log('libp2p is starting');
        try {
            await this.components.beforeStart?.();
            await this.components.start();
            await this.components.afterStart?.();
            this.status = 'started';
            this.safeDispatchEvent('start', { detail: this });
            this.log('libp2p has started');
        }
        catch (err) {
            this.log.error('An error occurred starting libp2p', err);
            // set status to 'started' so this.stop() will stop any running components
            this.status = 'started';
            await this.stop();
            throw err;
        }
    }
    /**
     * Stop the libp2p node by closing its listeners and open connections
     */
    async stop() {
        if (this.status !== 'started') {
            return;
        }
        this.log('libp2p is stopping');
        this.status = 'stopping';
        await this.components.beforeStop?.();
        await this.components.stop();
        await this.components.afterStop?.();
        this.status = 'stopped';
        this.safeDispatchEvent('stop', { detail: this });
        this.log('libp2p has stopped');
    }
    getConnections(peerId) {
        return this.components.connectionManager.getConnections(peerId);
    }
    getDialQueue() {
        return this.components.connectionManager.getDialQueue();
    }
    getPeers() {
        const peerSet = new PeerSet();
        for (const conn of this.components.connectionManager.getConnections()) {
            peerSet.add(conn.remotePeer);
        }
        return Array.from(peerSet);
    }
    async dial(peer, options = {}) {
        return this.components.connectionManager.openConnection(peer, {
            // ensure any userland dials take top priority in the queue
            priority: 75,
            ...options
        });
    }
    async dialProtocol(peer, protocols, options = {}) {
        if (protocols == null) {
            throw new CodeError$1('no protocols were provided to open a stream', codes.ERR_INVALID_PROTOCOLS_FOR_STREAM);
        }
        protocols = Array.isArray(protocols) ? protocols : [protocols];
        if (protocols.length === 0) {
            throw new CodeError$1('no protocols were provided to open a stream', codes.ERR_INVALID_PROTOCOLS_FOR_STREAM);
        }
        const connection = await this.dial(peer, options);
        return connection.newStream(protocols, options);
    }
    getMultiaddrs() {
        return this.components.addressManager.getAddresses();
    }
    getProtocols() {
        return this.components.registrar.getProtocols();
    }
    async hangUp(peer, options = {}) {
        if (isMultiaddr(peer)) {
            peer = peerIdFromString(peer.getPeerId() ?? '');
        }
        await this.components.connectionManager.closeConnections(peer, options);
    }
    /**
     * Get the public key for the given peer id
     */
    async getPublicKey(peer, options = {}) {
        this.log('getPublicKey %p', peer);
        if (peer.publicKey != null) {
            return peer.publicKey;
        }
        try {
            const peerInfo = await this.peerStore.get(peer);
            if (peerInfo.id.publicKey != null) {
                return peerInfo.id.publicKey;
            }
        }
        catch (err) {
            if (err.code !== codes.ERR_NOT_FOUND) {
                throw err;
            }
        }
        const peerKey = concat$1([
            fromString('/pk/'),
            peer.multihash.digest
        ]);
        // search any available content routing methods
        const bytes = await this.contentRouting.get(peerKey, options);
        // ensure the returned key is valid
        unmarshalPublicKey(bytes);
        await this.peerStore.patch(peer, {
            publicKey: bytes
        });
        return bytes;
    }
    async handle(protocols, handler, options) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.handle(protocol, handler, options);
        }));
    }
    async unhandle(protocols) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.unhandle(protocol);
        }));
    }
    async register(protocol, topology) {
        return this.components.registrar.register(protocol, topology);
    }
    unregister(id) {
        this.components.registrar.unregister(id);
    }
    async isDialable(multiaddr, options = {}) {
        return this.components.connectionManager.isDialable(multiaddr, options);
    }
    /**
     * Called whenever peer discovery services emit `peer` events and adds peers
     * to the peer store.
     */
    #onDiscoveryPeer(evt) {
        const { detail: peer } = evt;
        if (peer.id.toString() === this.peerId.toString()) {
            this.log.error(new Error(codes.ERR_DISCOVERED_SELF));
            return;
        }
        void this.components.peerStore.merge(peer.id, {
            multiaddrs: peer.multiaddrs
        })
            .catch(err => { this.log.error(err); });
    }
}
/**
 * Returns a new Libp2pNode instance - this exposes more of the internals than the
 * libp2p interface and is useful for testing and debugging.
 */
async function createLibp2pNode(options = {}) {
    const peerId = options.peerId ??= await createEd25519PeerId();
    if (peerId.privateKey == null) {
        throw new CodeError$1('peer id was missing private key', 'ERR_MISSING_PRIVATE_KEY');
    }
    options.privateKey ??= await unmarshalPrivateKey(peerId.privateKey);
    return new Libp2pNode(await validateConfig(options));
}

/**
 * @packageDocumentation
 *
 * Use the `createLibp2p` function to create a libp2p node.
 *
 * @example
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 *
 * const node = await createLibp2p({
 *   // ...other options
 * })
 * ```
 */
/**
 * Returns a new instance of the Libp2p interface, generating a new PeerId
 * if one is not passed as part of the options.
 *
 * The node will be started unless `start: false` is passed as an option.
 *
 * @example
 *
 * ```TypeScript
 * import { createLibp2p } from 'libp2p'
 * import { tcp } from '@libp2p/tcp'
 * import { mplex } from '@libp2p/mplex'
 * import { noise } from '@chainsafe/libp2p-noise'
 * import { yamux } from '@chainsafe/libp2p-yamux'
 *
 * // specify options
 * const options = {
 *   transports: [tcp()],
 *   streamMuxers: [yamux(), mplex()],
 *   connectionEncryption: [noise()]
 * }
 *
 * // create libp2p
 * const libp2p = await createLibp2p(options)
 * ```
 */
async function createLibp2p(options = {}) {
    const node = await createLibp2pNode(options);
    if (options.start !== false) {
        await node.start();
    }
    return node;
}

/**
 * The ENR tree for the different fleets.
 * SANDBOX and TEST fleets are for The Waku Network.
 */
const enrTree = {
    SANDBOX: "enrtree://AIRVQ5DDA4FFWLRBCHJWUWOO6X6S4ZTZ5B667LQ6AJU6PEYDLRD5O@sandbox.waku.nodes.status.im",
    TEST: "enrtree://AOGYWMBYOUIMOENHXCHILPKY3ZRFEULMFI4DOM442QSZ73TT2A7VI@test.waku.nodes.status.im"
};
const DEFAULT_BOOTSTRAP_TAG_NAME = "bootstrap";
const DEFAULT_BOOTSTRAP_TAG_VALUE = 50;
const DEFAULT_BOOTSTRAP_TAG_TTL = 100_000_000;
const DEFAULT_NODE_REQUIREMENTS = {
    store: 1,
    filter: 2,
    lightPush: 2
};

// Maximum encoded size of an ENR
const ERR_INVALID_ID = "Invalid record id";
// The maximum length of byte size of a multiaddr to encode in the `multiaddr` field
// The size is a big endian 16-bit unsigned integer
const MULTIADDR_LENGTH_SIZE = 2;

var _nodeResolve_empty = {};

var nodeCrypto = /*#__PURE__*/Object.freeze({
    __proto__: null,
    default: _nodeResolve_empty
});

/*! noble-secp256k1 - MIT License (c) 2019 Paul Miller (paulmillr.com) */
const _0n = BigInt(0);
const _1n = BigInt(1);
const _2n = BigInt(2);
const _3n = BigInt(3);
const _8n = BigInt(8);
const CURVE = Object.freeze({
    a: _0n,
    b: BigInt(7),
    P: BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f'),
    n: BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141'),
    h: _1n,
    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),
    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
});
const divNearest = (a, b) => (a + b / _2n) / b;
const endo = {
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
    splitScalar(k) {
        const { n } = CURVE;
        const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
        const b1 = -_1n * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
        const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
        const b2 = a1;
        const POW_2_128 = BigInt('0x100000000000000000000000000000000');
        const c1 = divNearest(b2 * k, n);
        const c2 = divNearest(-b1 * k, n);
        let k1 = mod(k - c1 * a1 - c2 * a2, n);
        let k2 = mod(-c1 * b1 - c2 * b2, n);
        const k1neg = k1 > POW_2_128;
        const k2neg = k2 > POW_2_128;
        if (k1neg)
            k1 = n - k1;
        if (k2neg)
            k2 = n - k2;
        if (k1 > POW_2_128 || k2 > POW_2_128) {
            throw new Error('splitScalarEndo: Endomorphism failed, k=' + k);
        }
        return { k1neg, k1, k2neg, k2 };
    },
};
const fieldLen = 32;
const groupLen = 32;
const hashLen = 32;
const compressedLen = fieldLen + 1;
const uncompressedLen = 2 * fieldLen + 1;
function weierstrass(x) {
    const { a, b } = CURVE;
    const x2 = mod(x * x);
    const x3 = mod(x2 * x);
    return mod(x3 + a * x + b);
}
const USE_ENDOMORPHISM = CURVE.a === _0n;
class ShaError extends Error {
    constructor(message) {
        super(message);
    }
}
function assertJacPoint(other) {
    if (!(other instanceof JacobianPoint))
        throw new TypeError('JacobianPoint expected');
}
class JacobianPoint {
    constructor(x, y, z) {
        this.x = x;
        this.y = y;
        this.z = z;
    }
    static fromAffine(p) {
        if (!(p instanceof Point)) {
            throw new TypeError('JacobianPoint#fromAffine: expected Point');
        }
        if (p.equals(Point.ZERO))
            return JacobianPoint.ZERO;
        return new JacobianPoint(p.x, p.y, _1n);
    }
    static toAffineBatch(points) {
        const toInv = invertBatch(points.map((p) => p.z));
        return points.map((p, i) => p.toAffine(toInv[i]));
    }
    static normalizeZ(points) {
        return JacobianPoint.toAffineBatch(points).map(JacobianPoint.fromAffine);
    }
    equals(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        const Z1Z1 = mod(Z1 * Z1);
        const Z2Z2 = mod(Z2 * Z2);
        const U1 = mod(X1 * Z2Z2);
        const U2 = mod(X2 * Z1Z1);
        const S1 = mod(mod(Y1 * Z2) * Z2Z2);
        const S2 = mod(mod(Y2 * Z1) * Z1Z1);
        return U1 === U2 && S1 === S2;
    }
    negate() {
        return new JacobianPoint(this.x, mod(-this.y), this.z);
    }
    double() {
        const { x: X1, y: Y1, z: Z1 } = this;
        const A = mod(X1 * X1);
        const B = mod(Y1 * Y1);
        const C = mod(B * B);
        const x1b = X1 + B;
        const D = mod(_2n * (mod(x1b * x1b) - A - C));
        const E = mod(_3n * A);
        const F = mod(E * E);
        const X3 = mod(F - _2n * D);
        const Y3 = mod(E * (D - X3) - _8n * C);
        const Z3 = mod(_2n * Y1 * Z1);
        return new JacobianPoint(X3, Y3, Z3);
    }
    add(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        if (X2 === _0n || Y2 === _0n)
            return this;
        if (X1 === _0n || Y1 === _0n)
            return other;
        const Z1Z1 = mod(Z1 * Z1);
        const Z2Z2 = mod(Z2 * Z2);
        const U1 = mod(X1 * Z2Z2);
        const U2 = mod(X2 * Z1Z1);
        const S1 = mod(mod(Y1 * Z2) * Z2Z2);
        const S2 = mod(mod(Y2 * Z1) * Z1Z1);
        const H = mod(U2 - U1);
        const r = mod(S2 - S1);
        if (H === _0n) {
            if (r === _0n) {
                return this.double();
            }
            else {
                return JacobianPoint.ZERO;
            }
        }
        const HH = mod(H * H);
        const HHH = mod(H * HH);
        const V = mod(U1 * HH);
        const X3 = mod(r * r - HHH - _2n * V);
        const Y3 = mod(r * (V - X3) - S1 * HHH);
        const Z3 = mod(Z1 * Z2 * H);
        return new JacobianPoint(X3, Y3, Z3);
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiplyUnsafe(scalar) {
        const P0 = JacobianPoint.ZERO;
        if (typeof scalar === 'bigint' && scalar === _0n)
            return P0;
        let n = normalizeScalar(scalar);
        if (n === _1n)
            return this;
        if (!USE_ENDOMORPHISM) {
            let p = P0;
            let d = this;
            while (n > _0n) {
                if (n & _1n)
                    p = p.add(d);
                d = d.double();
                n >>= _1n;
            }
            return p;
        }
        let { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
        let k1p = P0;
        let k2p = P0;
        let d = this;
        while (k1 > _0n || k2 > _0n) {
            if (k1 & _1n)
                k1p = k1p.add(d);
            if (k2 & _1n)
                k2p = k2p.add(d);
            d = d.double();
            k1 >>= _1n;
            k2 >>= _1n;
        }
        if (k1neg)
            k1p = k1p.negate();
        if (k2neg)
            k2p = k2p.negate();
        k2p = new JacobianPoint(mod(k2p.x * endo.beta), k2p.y, k2p.z);
        return k1p.add(k2p);
    }
    precomputeWindow(W) {
        const windows = USE_ENDOMORPHISM ? 128 / W + 1 : 256 / W + 1;
        const points = [];
        let p = this;
        let base = p;
        for (let window = 0; window < windows; window++) {
            base = p;
            points.push(base);
            for (let i = 1; i < 2 ** (W - 1); i++) {
                base = base.add(p);
                points.push(base);
            }
            p = base.double();
        }
        return points;
    }
    wNAF(n, affinePoint) {
        if (!affinePoint && this.equals(JacobianPoint.BASE))
            affinePoint = Point.BASE;
        const W = (affinePoint && affinePoint._WINDOW_SIZE) || 1;
        if (256 % W) {
            throw new Error('Point#wNAF: Invalid precomputation window, must be power of 2');
        }
        let precomputes = affinePoint && pointPrecomputes.get(affinePoint);
        if (!precomputes) {
            precomputes = this.precomputeWindow(W);
            if (affinePoint && W !== 1) {
                precomputes = JacobianPoint.normalizeZ(precomputes);
                pointPrecomputes.set(affinePoint, precomputes);
            }
        }
        let p = JacobianPoint.ZERO;
        let f = JacobianPoint.BASE;
        const windows = 1 + (USE_ENDOMORPHISM ? 128 / W : 256 / W);
        const windowSize = 2 ** (W - 1);
        const mask = BigInt(2 ** W - 1);
        const maxNumber = 2 ** W;
        const shiftBy = BigInt(W);
        for (let window = 0; window < windows; window++) {
            const offset = window * windowSize;
            let wbits = Number(n & mask);
            n >>= shiftBy;
            if (wbits > windowSize) {
                wbits -= maxNumber;
                n += _1n;
            }
            const offset1 = offset;
            const offset2 = offset + Math.abs(wbits) - 1;
            const cond1 = window % 2 !== 0;
            const cond2 = wbits < 0;
            if (wbits === 0) {
                f = f.add(constTimeNegate(cond1, precomputes[offset1]));
            }
            else {
                p = p.add(constTimeNegate(cond2, precomputes[offset2]));
            }
        }
        return { p, f };
    }
    multiply(scalar, affinePoint) {
        let n = normalizeScalar(scalar);
        let point;
        let fake;
        if (USE_ENDOMORPHISM) {
            const { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
            let { p: k1p, f: f1p } = this.wNAF(k1, affinePoint);
            let { p: k2p, f: f2p } = this.wNAF(k2, affinePoint);
            k1p = constTimeNegate(k1neg, k1p);
            k2p = constTimeNegate(k2neg, k2p);
            k2p = new JacobianPoint(mod(k2p.x * endo.beta), k2p.y, k2p.z);
            point = k1p.add(k2p);
            fake = f1p.add(f2p);
        }
        else {
            const { p, f } = this.wNAF(n, affinePoint);
            point = p;
            fake = f;
        }
        return JacobianPoint.normalizeZ([point, fake])[0];
    }
    toAffine(invZ) {
        const { x, y, z } = this;
        const is0 = this.equals(JacobianPoint.ZERO);
        if (invZ == null)
            invZ = is0 ? _8n : invert(z);
        const iz1 = invZ;
        const iz2 = mod(iz1 * iz1);
        const iz3 = mod(iz2 * iz1);
        const ax = mod(x * iz2);
        const ay = mod(y * iz3);
        const zz = mod(z * iz1);
        if (is0)
            return Point.ZERO;
        if (zz !== _1n)
            throw new Error('invZ was invalid');
        return new Point(ax, ay);
    }
}
JacobianPoint.BASE = new JacobianPoint(CURVE.Gx, CURVE.Gy, _1n);
JacobianPoint.ZERO = new JacobianPoint(_0n, _1n, _0n);
function constTimeNegate(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
const pointPrecomputes = new WeakMap();
class Point {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    _setWindowSize(windowSize) {
        this._WINDOW_SIZE = windowSize;
        pointPrecomputes.delete(this);
    }
    hasEvenY() {
        return this.y % _2n === _0n;
    }
    static fromCompressedHex(bytes) {
        const isShort = bytes.length === 32;
        const x = bytesToNumber(isShort ? bytes : bytes.subarray(1));
        if (!isValidFieldElement(x))
            throw new Error('Point is not on curve');
        const y2 = weierstrass(x);
        let y = sqrtMod(y2);
        const isYOdd = (y & _1n) === _1n;
        if (isShort) {
            if (isYOdd)
                y = mod(-y);
        }
        else {
            const isFirstByteOdd = (bytes[0] & 1) === 1;
            if (isFirstByteOdd !== isYOdd)
                y = mod(-y);
        }
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromUncompressedHex(bytes) {
        const x = bytesToNumber(bytes.subarray(1, fieldLen + 1));
        const y = bytesToNumber(bytes.subarray(fieldLen + 1, fieldLen * 2 + 1));
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromHex(hex) {
        const bytes = ensureBytes(hex);
        const len = bytes.length;
        const header = bytes[0];
        if (len === fieldLen)
            return this.fromCompressedHex(bytes);
        if (len === compressedLen && (header === 0x02 || header === 0x03)) {
            return this.fromCompressedHex(bytes);
        }
        if (len === uncompressedLen && header === 0x04)
            return this.fromUncompressedHex(bytes);
        throw new Error(`Point.fromHex: received invalid point. Expected 32-${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes, not ${len}`);
    }
    static fromPrivateKey(privateKey) {
        return Point.BASE.multiply(normalizePrivateKey(privateKey));
    }
    static fromSignature(msgHash, signature, recovery) {
        const { r, s } = normalizeSignature(signature);
        if (![0, 1, 2, 3].includes(recovery))
            throw new Error('Cannot recover: invalid recovery bit');
        const h = truncateHash(ensureBytes(msgHash));
        const { n } = CURVE;
        const radj = recovery === 2 || recovery === 3 ? r + n : r;
        const rinv = invert(radj, n);
        const u1 = mod(-h * rinv, n);
        const u2 = mod(s * rinv, n);
        const prefix = recovery & 1 ? '03' : '02';
        const R = Point.fromHex(prefix + numTo32bStr(radj));
        const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2);
        if (!Q)
            throw new Error('Cannot recover signature: point at infinify');
        Q.assertValidity();
        return Q;
    }
    toRawBytes(isCompressed = false) {
        return hexToBytes(this.toHex(isCompressed));
    }
    toHex(isCompressed = false) {
        const x = numTo32bStr(this.x);
        if (isCompressed) {
            const prefix = this.hasEvenY() ? '02' : '03';
            return `${prefix}${x}`;
        }
        else {
            return `04${x}${numTo32bStr(this.y)}`;
        }
    }
    toHexX() {
        return this.toHex(true).slice(2);
    }
    toRawX() {
        return this.toRawBytes(true).slice(1);
    }
    assertValidity() {
        const msg = 'Point is not on elliptic curve';
        const { x, y } = this;
        if (!isValidFieldElement(x) || !isValidFieldElement(y))
            throw new Error(msg);
        const left = mod(y * y);
        const right = weierstrass(x);
        if (mod(left - right) !== _0n)
            throw new Error(msg);
    }
    equals(other) {
        return this.x === other.x && this.y === other.y;
    }
    negate() {
        return new Point(this.x, mod(-this.y));
    }
    double() {
        return JacobianPoint.fromAffine(this).double().toAffine();
    }
    add(other) {
        return JacobianPoint.fromAffine(this).add(JacobianPoint.fromAffine(other)).toAffine();
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiply(scalar) {
        return JacobianPoint.fromAffine(this).multiply(scalar, this).toAffine();
    }
    multiplyAndAddUnsafe(Q, a, b) {
        const P = JacobianPoint.fromAffine(this);
        const aP = a === _0n || a === _1n || this !== Point.BASE ? P.multiplyUnsafe(a) : P.multiply(a);
        const bQ = JacobianPoint.fromAffine(Q).multiplyUnsafe(b);
        const sum = aP.add(bQ);
        return sum.equals(JacobianPoint.ZERO) ? undefined : sum.toAffine();
    }
}
Point.BASE = new Point(CURVE.Gx, CURVE.Gy);
Point.ZERO = new Point(_0n, _0n);
function sliceDER(s) {
    return Number.parseInt(s[0], 16) >= 8 ? '00' + s : s;
}
function parseDERInt(data) {
    if (data.length < 2 || data[0] !== 0x02) {
        throw new Error(`Invalid signature integer tag: ${bytesToHex(data)}`);
    }
    const len = data[1];
    const res = data.subarray(2, len + 2);
    if (!len || res.length !== len) {
        throw new Error(`Invalid signature integer: wrong length`);
    }
    if (res[0] === 0x00 && res[1] <= 0x7f) {
        throw new Error('Invalid signature integer: trailing length');
    }
    return { data: bytesToNumber(res), left: data.subarray(len + 2) };
}
function parseDERSignature(data) {
    if (data.length < 2 || data[0] != 0x30) {
        throw new Error(`Invalid signature tag: ${bytesToHex(data)}`);
    }
    if (data[1] !== data.length - 2) {
        throw new Error('Invalid signature: incorrect length');
    }
    const { data: r, left: sBytes } = parseDERInt(data.subarray(2));
    const { data: s, left: rBytesLeft } = parseDERInt(sBytes);
    if (rBytesLeft.length) {
        throw new Error(`Invalid signature: left bytes after parsing: ${bytesToHex(rBytesLeft)}`);
    }
    return { r, s };
}
class Signature {
    constructor(r, s) {
        this.r = r;
        this.s = s;
        this.assertValidity();
    }
    static fromCompact(hex) {
        const arr = hex instanceof Uint8Array;
        const name = 'Signature.fromCompact';
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`${name}: Expected string or Uint8Array`);
        const str = arr ? bytesToHex(hex) : hex;
        if (str.length !== 128)
            throw new Error(`${name}: Expected 64-byte hex`);
        return new Signature(hexToNumber(str.slice(0, 64)), hexToNumber(str.slice(64, 128)));
    }
    static fromDER(hex) {
        const arr = hex instanceof Uint8Array;
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`Signature.fromDER: Expected string or Uint8Array`);
        const { r, s } = parseDERSignature(arr ? hex : hexToBytes(hex));
        return new Signature(r, s);
    }
    static fromHex(hex) {
        return this.fromDER(hex);
    }
    assertValidity() {
        const { r, s } = this;
        if (!isWithinCurveOrder(r))
            throw new Error('Invalid Signature: r must be 0 < r < n');
        if (!isWithinCurveOrder(s))
            throw new Error('Invalid Signature: s must be 0 < s < n');
    }
    hasHighS() {
        const HALF = CURVE.n >> _1n;
        return this.s > HALF;
    }
    normalizeS() {
        return this.hasHighS() ? new Signature(this.r, mod(-this.s, CURVE.n)) : this;
    }
    toDERRawBytes() {
        return hexToBytes(this.toDERHex());
    }
    toDERHex() {
        const sHex = sliceDER(numberToHexUnpadded(this.s));
        const rHex = sliceDER(numberToHexUnpadded(this.r));
        const sHexL = sHex.length / 2;
        const rHexL = rHex.length / 2;
        const sLen = numberToHexUnpadded(sHexL);
        const rLen = numberToHexUnpadded(rHexL);
        const length = numberToHexUnpadded(rHexL + sHexL + 4);
        return `30${length}02${rLen}${rHex}02${sLen}${sHex}`;
    }
    toRawBytes() {
        return this.toDERRawBytes();
    }
    toHex() {
        return this.toDERHex();
    }
    toCompactRawBytes() {
        return hexToBytes(this.toCompactHex());
    }
    toCompactHex() {
        return numTo32bStr(this.r) + numTo32bStr(this.s);
    }
}
function concatBytes(...arrays) {
    if (!arrays.every((b) => b instanceof Uint8Array))
        throw new Error('Uint8Array list expected');
    if (arrays.length === 1)
        return arrays[0];
    const length = arrays.reduce((a, arr) => a + arr.length, 0);
    const result = new Uint8Array(length);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const arr = arrays[i];
        result.set(arr, pad);
        pad += arr.length;
    }
    return result;
}
const hexes = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
function bytesToHex(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    let hex = '';
    for (let i = 0; i < uint8a.length; i++) {
        hex += hexes[uint8a[i]];
    }
    return hex;
}
const POW_2_256 = BigInt('0x10000000000000000000000000000000000000000000000000000000000000000');
function numTo32bStr(num) {
    if (typeof num !== 'bigint')
        throw new Error('Expected bigint');
    if (!(_0n <= num && num < POW_2_256))
        throw new Error('Expected number 0 <= n < 2^256');
    return num.toString(16).padStart(64, '0');
}
function numTo32b(num) {
    const b = hexToBytes(numTo32bStr(num));
    if (b.length !== 32)
        throw new Error('Error: expected 32 bytes');
    return b;
}
function numberToHexUnpadded(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? `0${hex}` : hex;
}
function hexToNumber(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToNumber: expected string, got ' + typeof hex);
    }
    return BigInt(`0x${hex}`);
}
function hexToBytes(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToBytes: expected string, got ' + typeof hex);
    }
    if (hex.length % 2)
        throw new Error('hexToBytes: received invalid unpadded hex' + hex.length);
    const array = new Uint8Array(hex.length / 2);
    for (let i = 0; i < array.length; i++) {
        const j = i * 2;
        const hexByte = hex.slice(j, j + 2);
        const byte = Number.parseInt(hexByte, 16);
        if (Number.isNaN(byte) || byte < 0)
            throw new Error('Invalid byte sequence');
        array[i] = byte;
    }
    return array;
}
function bytesToNumber(bytes) {
    return hexToNumber(bytesToHex(bytes));
}
function ensureBytes(hex) {
    return hex instanceof Uint8Array ? Uint8Array.from(hex) : hexToBytes(hex);
}
function normalizeScalar(num) {
    if (typeof num === 'number' && Number.isSafeInteger(num) && num > 0)
        return BigInt(num);
    if (typeof num === 'bigint' && isWithinCurveOrder(num))
        return num;
    throw new TypeError('Expected valid private scalar: 0 < scalar < curve.n');
}
function mod(a, b = CURVE.P) {
    const result = a % b;
    return result >= _0n ? result : b + result;
}
function pow2(x, power) {
    const { P } = CURVE;
    let res = x;
    while (power-- > _0n) {
        res *= res;
        res %= P;
    }
    return res;
}
function sqrtMod(x) {
    const { P } = CURVE;
    const _6n = BigInt(6);
    const _11n = BigInt(11);
    const _22n = BigInt(22);
    const _23n = BigInt(23);
    const _44n = BigInt(44);
    const _88n = BigInt(88);
    const b2 = (x * x * x) % P;
    const b3 = (b2 * b2 * x) % P;
    const b6 = (pow2(b3, _3n) * b3) % P;
    const b9 = (pow2(b6, _3n) * b3) % P;
    const b11 = (pow2(b9, _2n) * b2) % P;
    const b22 = (pow2(b11, _11n) * b11) % P;
    const b44 = (pow2(b22, _22n) * b22) % P;
    const b88 = (pow2(b44, _44n) * b44) % P;
    const b176 = (pow2(b88, _88n) * b88) % P;
    const b220 = (pow2(b176, _44n) * b44) % P;
    const b223 = (pow2(b220, _3n) * b3) % P;
    const t1 = (pow2(b223, _23n) * b22) % P;
    const t2 = (pow2(t1, _6n) * b2) % P;
    const rt = pow2(t2, _2n);
    const xc = (rt * rt) % P;
    if (xc !== x)
        throw new Error('Cannot find square root');
    return rt;
}
function invert(number, modulo = CURVE.P) {
    if (number === _0n || modulo <= _0n) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    let a = mod(number, modulo);
    let b = modulo;
    let x = _0n, u = _1n;
    while (a !== _0n) {
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n)
        throw new Error('invert: does not exist');
    return mod(x, modulo);
}
function invertBatch(nums, p = CURVE.P) {
    const scratch = new Array(nums.length);
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (num === _0n)
            return acc;
        scratch[i] = acc;
        return mod(acc * num, p);
    }, _1n);
    const inverted = invert(lastMultiplied, p);
    nums.reduceRight((acc, num, i) => {
        if (num === _0n)
            return acc;
        scratch[i] = mod(acc * scratch[i], p);
        return mod(acc * num, p);
    }, inverted);
    return scratch;
}
function bits2int_2(bytes) {
    const delta = bytes.length * 8 - groupLen * 8;
    const num = bytesToNumber(bytes);
    return delta > 0 ? num >> BigInt(delta) : num;
}
function truncateHash(hash, truncateOnly = false) {
    const h = bits2int_2(hash);
    if (truncateOnly)
        return h;
    const { n } = CURVE;
    return h >= n ? h - n : h;
}
let _sha256Sync;
let _hmacSha256Sync;
class HmacDrbg {
    constructor(hashLen, qByteLen) {
        this.hashLen = hashLen;
        this.qByteLen = qByteLen;
        if (typeof hashLen !== 'number' || hashLen < 2)
            throw new Error('hashLen must be a number');
        if (typeof qByteLen !== 'number' || qByteLen < 2)
            throw new Error('qByteLen must be a number');
        this.v = new Uint8Array(hashLen).fill(1);
        this.k = new Uint8Array(hashLen).fill(0);
        this.counter = 0;
    }
    hmac(...values) {
        return utils.hmacSha256(this.k, ...values);
    }
    hmacSync(...values) {
        return _hmacSha256Sync(this.k, ...values);
    }
    checkSync() {
        if (typeof _hmacSha256Sync !== 'function')
            throw new ShaError('hmacSha256Sync needs to be set');
    }
    incr() {
        if (this.counter >= 1000)
            throw new Error('Tried 1,000 k values for sign(), all were invalid');
        this.counter += 1;
    }
    async reseed(seed = new Uint8Array()) {
        this.k = await this.hmac(this.v, Uint8Array.from([0x00]), seed);
        this.v = await this.hmac(this.v);
        if (seed.length === 0)
            return;
        this.k = await this.hmac(this.v, Uint8Array.from([0x01]), seed);
        this.v = await this.hmac(this.v);
    }
    reseedSync(seed = new Uint8Array()) {
        this.checkSync();
        this.k = this.hmacSync(this.v, Uint8Array.from([0x00]), seed);
        this.v = this.hmacSync(this.v);
        if (seed.length === 0)
            return;
        this.k = this.hmacSync(this.v, Uint8Array.from([0x01]), seed);
        this.v = this.hmacSync(this.v);
    }
    async generate() {
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = await this.hmac(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes(...out);
    }
    generateSync() {
        this.checkSync();
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = this.hmacSync(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes(...out);
    }
}
function isWithinCurveOrder(num) {
    return _0n < num && num < CURVE.n;
}
function isValidFieldElement(num) {
    return _0n < num && num < CURVE.P;
}
function kmdToSig(kBytes, m, d, lowS = true) {
    const { n } = CURVE;
    const k = truncateHash(kBytes, true);
    if (!isWithinCurveOrder(k))
        return;
    const kinv = invert(k, n);
    const q = Point.BASE.multiply(k);
    const r = mod(q.x, n);
    if (r === _0n)
        return;
    const s = mod(kinv * mod(m + d * r, n), n);
    if (s === _0n)
        return;
    let sig = new Signature(r, s);
    let recovery = (q.x === sig.r ? 0 : 2) | Number(q.y & _1n);
    if (lowS && sig.hasHighS()) {
        sig = sig.normalizeS();
        recovery ^= 1;
    }
    return { sig, recovery };
}
function normalizePrivateKey(key) {
    let num;
    if (typeof key === 'bigint') {
        num = key;
    }
    else if (typeof key === 'number' && Number.isSafeInteger(key) && key > 0) {
        num = BigInt(key);
    }
    else if (typeof key === 'string') {
        if (key.length !== 2 * groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = hexToNumber(key);
    }
    else if (key instanceof Uint8Array) {
        if (key.length !== groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = bytesToNumber(key);
    }
    else {
        throw new TypeError('Expected valid private key');
    }
    if (!isWithinCurveOrder(num))
        throw new Error('Expected private key: 0 < key < n');
    return num;
}
function normalizePublicKey(publicKey) {
    if (publicKey instanceof Point) {
        publicKey.assertValidity();
        return publicKey;
    }
    else {
        return Point.fromHex(publicKey);
    }
}
function normalizeSignature(signature) {
    if (signature instanceof Signature) {
        signature.assertValidity();
        return signature;
    }
    try {
        return Signature.fromDER(signature);
    }
    catch (error) {
        return Signature.fromCompact(signature);
    }
}
function bits2int(bytes) {
    const slice = bytes.length > fieldLen ? bytes.slice(0, fieldLen) : bytes;
    return bytesToNumber(slice);
}
function bits2octets(bytes) {
    const z1 = bits2int(bytes);
    const z2 = mod(z1, CURVE.n);
    return int2octets(z2 < _0n ? z1 : z2);
}
function int2octets(num) {
    return numTo32b(num);
}
function initSigArgs(msgHash, privateKey, extraEntropy) {
    if (msgHash == null)
        throw new Error(`sign: expected valid message hash, not "${msgHash}"`);
    const h1 = ensureBytes(msgHash);
    const d = normalizePrivateKey(privateKey);
    const seedArgs = [int2octets(d), bits2octets(h1)];
    if (extraEntropy != null) {
        if (extraEntropy === true)
            extraEntropy = utils.randomBytes(fieldLen);
        const e = ensureBytes(extraEntropy);
        if (e.length !== fieldLen)
            throw new Error(`sign: Expected ${fieldLen} bytes of extra data`);
        seedArgs.push(e);
    }
    const seed = concatBytes(...seedArgs);
    const m = bits2int(h1);
    return { seed, m, d };
}
function finalizeSig(recSig, opts) {
    const { sig, recovery } = recSig;
    const { der, recovered } = Object.assign({ canonical: true, der: true }, opts);
    const hashed = der ? sig.toDERRawBytes() : sig.toCompactRawBytes();
    return recovered ? [hashed, recovery] : hashed;
}
async function sign$1(msgHash, privKey, opts = {}) {
    const { seed, m, d } = initSigArgs(msgHash, privKey, opts.extraEntropy);
    const drbg = new HmacDrbg(hashLen, groupLen);
    await drbg.reseed(seed);
    let sig;
    while (!(sig = kmdToSig(await drbg.generate(), m, d, opts.canonical)))
        await drbg.reseed();
    return finalizeSig(sig, opts);
}
const vopts = { strict: true };
function verify(signature, msgHash, publicKey, opts = vopts) {
    let sig;
    try {
        sig = normalizeSignature(signature);
        msgHash = ensureBytes(msgHash);
    }
    catch (error) {
        return false;
    }
    const { r, s } = sig;
    if (opts.strict && sig.hasHighS())
        return false;
    const h = truncateHash(msgHash);
    let P;
    try {
        P = normalizePublicKey(publicKey);
    }
    catch (error) {
        return false;
    }
    const { n } = CURVE;
    const sinv = invert(s, n);
    const u1 = mod(h * sinv, n);
    const u2 = mod(r * sinv, n);
    const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2);
    if (!R)
        return false;
    const v = mod(R.x, n);
    return v === r;
}
Point.BASE._setWindowSize(8);
const crypto$1 = {
    node: nodeCrypto,
    web: typeof self === 'object' && 'crypto' in self ? self.crypto : undefined,
};
const TAGGED_HASH_PREFIXES = {};
const utils = {
    bytesToHex,
    hexToBytes,
    concatBytes,
    mod,
    invert,
    isValidPrivateKey(privateKey) {
        try {
            normalizePrivateKey(privateKey);
            return true;
        }
        catch (error) {
            return false;
        }
    },
    _bigintTo32Bytes: numTo32b,
    _normalizePrivateKey: normalizePrivateKey,
    hashToPrivateKey: (hash) => {
        hash = ensureBytes(hash);
        const minLen = groupLen + 8;
        if (hash.length < minLen || hash.length > 1024) {
            throw new Error(`Expected valid bytes of private key as per FIPS 186`);
        }
        const num = mod(bytesToNumber(hash), CURVE.n - _1n) + _1n;
        return numTo32b(num);
    },
    randomBytes: (bytesLength = 32) => {
        if (crypto$1.web) {
            return crypto$1.web.getRandomValues(new Uint8Array(bytesLength));
        }
        else if (crypto$1.node) {
            const { randomBytes } = crypto$1.node;
            return Uint8Array.from(randomBytes(bytesLength));
        }
        else {
            throw new Error("The environment doesn't have randomBytes function");
        }
    },
    randomPrivateKey: () => utils.hashToPrivateKey(utils.randomBytes(groupLen + 8)),
    precompute(windowSize = 8, point = Point.BASE) {
        const cached = point === Point.BASE ? point : new Point(point.x, point.y);
        cached._setWindowSize(windowSize);
        cached.multiply(_3n);
        return cached;
    },
    sha256: async (...messages) => {
        if (crypto$1.web) {
            const buffer = await crypto$1.web.subtle.digest('SHA-256', concatBytes(...messages));
            return new Uint8Array(buffer);
        }
        else if (crypto$1.node) {
            const { createHash } = crypto$1.node;
            const hash = createHash('sha256');
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have sha256 function");
        }
    },
    hmacSha256: async (key, ...messages) => {
        if (crypto$1.web) {
            const ckey = await crypto$1.web.subtle.importKey('raw', key, { name: 'HMAC', hash: { name: 'SHA-256' } }, false, ['sign']);
            const message = concatBytes(...messages);
            const buffer = await crypto$1.web.subtle.sign('HMAC', ckey, message);
            return new Uint8Array(buffer);
        }
        else if (crypto$1.node) {
            const { createHmac } = crypto$1.node;
            const hash = createHmac('sha256', key);
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have hmac-sha256 function");
        }
    },
    sha256Sync: undefined,
    hmacSha256Sync: undefined,
    taggedHash: async (tag, ...messages) => {
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = await utils.sha256(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return utils.sha256(tagP, ...messages);
    },
    taggedHashSync: (tag, ...messages) => {
        if (typeof _sha256Sync !== 'function')
            throw new ShaError('sha256Sync is undefined, you need to set it');
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = _sha256Sync(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return _sha256Sync(tagP, ...messages);
    },
    _JacobianPoint: JacobianPoint,
};
Object.defineProperties(utils, {
    sha256Sync: {
        configurable: false,
        get() {
            return _sha256Sync;
        },
        set(val) {
            if (!_sha256Sync)
                _sha256Sync = val;
        },
    },
    hmacSha256Sync: {
        configurable: false,
        get() {
            return _hmacSha256Sync;
        },
        set(val) {
            if (!_hmacSha256Sync)
                _hmacSha256Sync = val;
        },
    },
});

var sha3$1 = {exports: {}};

/**
 * [js-sha3]{@link https://github.com/emn178/js-sha3}
 *
 * @version 0.9.3
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2023
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var INPUT_ERROR = 'input is invalid type';
	  var FINALIZE_ERROR = 'finalize already called';
	  var WINDOW = typeof window === 'object';
	  var root = WINDOW ? window : {};
	  if (root.JS_SHA3_NO_WINDOW) {
	    WINDOW = false;
	  }
	  var WEB_WORKER = !WINDOW && typeof self === 'object';
	  var NODE_JS = !root.JS_SHA3_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  } else if (WEB_WORKER) {
	    root = self;
	  }
	  var COMMON_JS = !root.JS_SHA3_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var ARRAY_BUFFER = !root.JS_SHA3_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
	  var HEX_CHARS = '0123456789abcdef'.split('');
	  var SHAKE_PADDING = [31, 7936, 2031616, 520093696];
	  var CSHAKE_PADDING = [4, 1024, 262144, 67108864];
	  var KECCAK_PADDING = [1, 256, 65536, 16777216];
	  var PADDING = [6, 1536, 393216, 100663296];
	  var SHIFT = [0, 8, 16, 24];
	  var RC = [1, 0, 32898, 0, 32906, 2147483648, 2147516416, 2147483648, 32907, 0, 2147483649,
	    0, 2147516545, 2147483648, 32777, 2147483648, 138, 0, 136, 0, 2147516425, 0,
	    2147483658, 0, 2147516555, 0, 139, 2147483648, 32905, 2147483648, 32771,
	    2147483648, 32770, 2147483648, 128, 2147483648, 32778, 0, 2147483658, 2147483648,
	    2147516545, 2147483648, 32896, 2147483648, 2147483649, 0, 2147516424, 2147483648];
	  var BITS = [224, 256, 384, 512];
	  var SHAKE_BITS = [128, 256];
	  var OUTPUT_TYPES = ['hex', 'buffer', 'arrayBuffer', 'array', 'digest'];
	  var CSHAKE_BYTEPAD = {
	    '128': 168,
	    '256': 136
	  };


	  var isArray = root.JS_SHA3_NO_NODE_JS || !Array.isArray
	    ? function (obj) {
	        return Object.prototype.toString.call(obj) === '[object Array]';
	      }
	    : Array.isArray;

	  var isView = (ARRAY_BUFFER && (root.JS_SHA3_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView))
	    ? function (obj) {
	        return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
	      }
	    : ArrayBuffer.isView;

	  // [message: string, isString: bool]
	  var formatMessage = function (message) {
	    var type = typeof message;
	    if (type === 'string') {
	      return [message, true];
	    }
	    if (type !== 'object' || message === null) {
	      throw new Error(INPUT_ERROR);
	    }
	    if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
	      return [new Uint8Array(message), false];
	    }
	    if (!isArray(message) && !isView(message)) {
	      throw new Error(INPUT_ERROR);
	    }
	    return [message, false];
	  };

	  var empty = function (message) {
	    return formatMessage(message)[0].length === 0;
	  };

	  var cloneArray = function (array) {
	    var newArray = [];
	    for (var i = 0; i < array.length; ++i) {
	      newArray[i] = array[i];
	    }
	    return newArray;
	  };

	  var createOutputMethod = function (bits, padding, outputType) {
	    return function (message) {
	      return new Keccak(bits, padding, bits).update(message)[outputType]();
	    };
	  };

	  var createShakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits) {
	      return new Keccak(bits, padding, outputBits).update(message)[outputType]();
	    };
	  };

	  var createCshakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits, n, s) {
	      return methods['cshake' + bits].update(message, outputBits, n, s)[outputType]();
	    };
	  };

	  var createKmacOutputMethod = function (bits, padding, outputType) {
	    return function (key, message, outputBits, s) {
	      return methods['kmac' + bits].update(key, message, outputBits, s)[outputType]();
	    };
	  };

	  var createOutputMethods = function (method, createMethod, bits, padding) {
	    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
	      var type = OUTPUT_TYPES[i];
	      method[type] = createMethod(bits, padding, type);
	    }
	    return method;
	  };

	  var createMethod = function (bits, padding) {
	    var method = createOutputMethod(bits, padding, 'hex');
	    method.create = function () {
	      return new Keccak(bits, padding, bits);
	    };
	    method.update = function (message) {
	      return method.create().update(message);
	    };
	    return createOutputMethods(method, createOutputMethod, bits, padding);
	  };

	  var createShakeMethod = function (bits, padding) {
	    var method = createShakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits) {
	      return new Keccak(bits, padding, outputBits);
	    };
	    method.update = function (message, outputBits) {
	      return method.create(outputBits).update(message);
	    };
	    return createOutputMethods(method, createShakeOutputMethod, bits, padding);
	  };

	  var createCshakeMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createCshakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits, n, s) {
	      if (empty(n) && empty(s)) {
	        return methods['shake' + bits].create(outputBits);
	      } else {
	        return new Keccak(bits, padding, outputBits).bytepad([n, s], w);
	      }
	    };
	    method.update = function (message, outputBits, n, s) {
	      return method.create(outputBits, n, s).update(message);
	    };
	    return createOutputMethods(method, createCshakeOutputMethod, bits, padding);
	  };

	  var createKmacMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createKmacOutputMethod(bits, padding, 'hex');
	    method.create = function (key, outputBits, s) {
	      return new Kmac(bits, padding, outputBits).bytepad(['KMAC', s], w).bytepad([key], w);
	    };
	    method.update = function (key, message, outputBits, s) {
	      return method.create(key, outputBits, s).update(message);
	    };
	    return createOutputMethods(method, createKmacOutputMethod, bits, padding);
	  };

	  var algorithms = [
	    { name: 'keccak', padding: KECCAK_PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'sha3', padding: PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'shake', padding: SHAKE_PADDING, bits: SHAKE_BITS, createMethod: createShakeMethod },
	    { name: 'cshake', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createCshakeMethod },
	    { name: 'kmac', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createKmacMethod }
	  ];

	  var methods = {}, methodNames = [];

	  for (var i = 0; i < algorithms.length; ++i) {
	    var algorithm = algorithms[i];
	    var bits = algorithm.bits;
	    for (var j = 0; j < bits.length; ++j) {
	      var methodName = algorithm.name + '_' + bits[j];
	      methodNames.push(methodName);
	      methods[methodName] = algorithm.createMethod(bits[j], algorithm.padding);
	      if (algorithm.name !== 'sha3') {
	        var newMethodName = algorithm.name + bits[j];
	        methodNames.push(newMethodName);
	        methods[newMethodName] = methods[methodName];
	      }
	    }
	  }

	  function Keccak(bits, padding, outputBits) {
	    this.blocks = [];
	    this.s = [];
	    this.padding = padding;
	    this.outputBits = outputBits;
	    this.reset = true;
	    this.finalized = false;
	    this.block = 0;
	    this.start = 0;
	    this.blockCount = (1600 - (bits << 1)) >> 5;
	    this.byteCount = this.blockCount << 2;
	    this.outputBlocks = outputBits >> 5;
	    this.extraBytes = (outputBits & 31) >> 3;

	    for (var i = 0; i < 50; ++i) {
	      this.s[i] = 0;
	    }
	  }

	  Keccak.prototype.update = function (message) {
	    if (this.finalized) {
	      throw new Error(FINALIZE_ERROR);
	    }
	    var result = formatMessage(message);
	    message = result[0];
	    var isString = result[1];
	    var blocks = this.blocks, byteCount = this.byteCount, length = message.length,
	      blockCount = this.blockCount, index = 0, s = this.s, i, code;

	    while (index < length) {
	      if (this.reset) {
	        this.reset = false;
	        blocks[0] = this.block;
	        for (i = 1; i < blockCount + 1; ++i) {
	          blocks[i] = 0;
	        }
	      }
	      if (isString) {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          code = message.charCodeAt(index);
	          if (code < 0x80) {
	            blocks[i >> 2] |= code << SHIFT[i++ & 3];
	          } else if (code < 0x800) {
	            blocks[i >> 2] |= (0xc0 | (code >> 6)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else if (code < 0xd800 || code >= 0xe000) {
	            blocks[i >> 2] |= (0xe0 | (code >> 12)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else {
	            code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
	            blocks[i >> 2] |= (0xf0 | (code >> 18)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 12) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          }
	        }
	      } else {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
	        }
	      }
	      this.lastByteIndex = i;
	      if (i >= byteCount) {
	        this.start = i - byteCount;
	        this.block = blocks[blockCount];
	        for (i = 0; i < blockCount; ++i) {
	          s[i] ^= blocks[i];
	        }
	        f(s);
	        this.reset = true;
	      } else {
	        this.start = i;
	      }
	    }
	    return this;
	  };

	  Keccak.prototype.encode = function (x, right) {
	    var o = x & 255, n = 1;
	    var bytes = [o];
	    x = x >> 8;
	    o = x & 255;
	    while (o > 0) {
	      bytes.unshift(o);
	      x = x >> 8;
	      o = x & 255;
	      ++n;
	    }
	    if (right) {
	      bytes.push(n);
	    } else {
	      bytes.unshift(n);
	    }
	    this.update(bytes);
	    return bytes.length;
	  };

	  Keccak.prototype.encodeString = function (str) {
	    var result = formatMessage(str);
	    str = result[0];
	    var isString = result[1];
	    var bytes = 0, length = str.length;
	    if (isString) {
	      for (var i = 0; i < str.length; ++i) {
	        var code = str.charCodeAt(i);
	        if (code < 0x80) {
	          bytes += 1;
	        } else if (code < 0x800) {
	          bytes += 2;
	        } else if (code < 0xd800 || code >= 0xe000) {
	          bytes += 3;
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++i) & 0x3ff));
	          bytes += 4;
	        }
	      }
	    } else {
	      bytes = length;
	    }
	    bytes += this.encode(bytes * 8);
	    this.update(str);
	    return bytes;
	  };

	  Keccak.prototype.bytepad = function (strs, w) {
	    var bytes = this.encode(w);
	    for (var i = 0; i < strs.length; ++i) {
	      bytes += this.encodeString(strs[i]);
	    }
	    var paddingBytes = (w - bytes % w) % w;
	    var zeros = [];
	    zeros.length = paddingBytes;
	    this.update(zeros);
	    return this;
	  };

	  Keccak.prototype.finalize = function () {
	    if (this.finalized) {
	      return;
	    }
	    this.finalized = true;
	    var blocks = this.blocks, i = this.lastByteIndex, blockCount = this.blockCount, s = this.s;
	    blocks[i >> 2] |= this.padding[i & 3];
	    if (this.lastByteIndex === this.byteCount) {
	      blocks[0] = blocks[blockCount];
	      for (i = 1; i < blockCount + 1; ++i) {
	        blocks[i] = 0;
	      }
	    }
	    blocks[blockCount - 1] |= 0x80000000;
	    for (i = 0; i < blockCount; ++i) {
	      s[i] ^= blocks[i];
	    }
	    f(s);
	  };

	  Keccak.prototype.toString = Keccak.prototype.hex = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var hex = '', block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        block = s[i];
	        hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F] +
	          HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F] +
	          HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F] +
	          HEX_CHARS[(block >> 28) & 0x0F] + HEX_CHARS[(block >> 24) & 0x0F];
	      }
	      if (j % blockCount === 0) {
	        s = cloneArray(s);
	        f(s);
	        i = 0;
	      }
	    }
	    if (extraBytes) {
	      block = s[i];
	      hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F];
	      if (extraBytes > 1) {
	        hex += HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F];
	      }
	      if (extraBytes > 2) {
	        hex += HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F];
	      }
	    }
	    return hex;
	  };

	  Keccak.prototype.arrayBuffer = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var bytes = this.outputBits >> 3;
	    var buffer;
	    if (extraBytes) {
	      buffer = new ArrayBuffer((outputBlocks + 1) << 2);
	    } else {
	      buffer = new ArrayBuffer(bytes);
	    }
	    var array = new Uint32Array(buffer);
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        array[j] = s[i];
	      }
	      if (j % blockCount === 0) {
	        s = cloneArray(s);
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      array[j] = s[i];
	      buffer = buffer.slice(0, bytes);
	    }
	    return buffer;
	  };

	  Keccak.prototype.buffer = Keccak.prototype.arrayBuffer;

	  Keccak.prototype.digest = Keccak.prototype.array = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var array = [], offset, block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        offset = j << 2;
	        block = s[i];
	        array[offset] = block & 0xFF;
	        array[offset + 1] = (block >> 8) & 0xFF;
	        array[offset + 2] = (block >> 16) & 0xFF;
	        array[offset + 3] = (block >> 24) & 0xFF;
	      }
	      if (j % blockCount === 0) {
	        s = cloneArray(s);
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      offset = j << 2;
	      block = s[i];
	      array[offset] = block & 0xFF;
	      if (extraBytes > 1) {
	        array[offset + 1] = (block >> 8) & 0xFF;
	      }
	      if (extraBytes > 2) {
	        array[offset + 2] = (block >> 16) & 0xFF;
	      }
	    }
	    return array;
	  };

	  function Kmac(bits, padding, outputBits) {
	    Keccak.call(this, bits, padding, outputBits);
	  }

	  Kmac.prototype = new Keccak();

	  Kmac.prototype.finalize = function () {
	    this.encode(this.outputBits, true);
	    return Keccak.prototype.finalize.call(this);
	  };

	  var f = function (s) {
	    var h, l, n, c0, c1, c2, c3, c4, c5, c6, c7, c8, c9,
	      b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, b11, b12, b13, b14, b15, b16, b17,
	      b18, b19, b20, b21, b22, b23, b24, b25, b26, b27, b28, b29, b30, b31, b32, b33,
	      b34, b35, b36, b37, b38, b39, b40, b41, b42, b43, b44, b45, b46, b47, b48, b49;
	    for (n = 0; n < 48; n += 2) {
	      c0 = s[0] ^ s[10] ^ s[20] ^ s[30] ^ s[40];
	      c1 = s[1] ^ s[11] ^ s[21] ^ s[31] ^ s[41];
	      c2 = s[2] ^ s[12] ^ s[22] ^ s[32] ^ s[42];
	      c3 = s[3] ^ s[13] ^ s[23] ^ s[33] ^ s[43];
	      c4 = s[4] ^ s[14] ^ s[24] ^ s[34] ^ s[44];
	      c5 = s[5] ^ s[15] ^ s[25] ^ s[35] ^ s[45];
	      c6 = s[6] ^ s[16] ^ s[26] ^ s[36] ^ s[46];
	      c7 = s[7] ^ s[17] ^ s[27] ^ s[37] ^ s[47];
	      c8 = s[8] ^ s[18] ^ s[28] ^ s[38] ^ s[48];
	      c9 = s[9] ^ s[19] ^ s[29] ^ s[39] ^ s[49];

	      h = c8 ^ ((c2 << 1) | (c3 >>> 31));
	      l = c9 ^ ((c3 << 1) | (c2 >>> 31));
	      s[0] ^= h;
	      s[1] ^= l;
	      s[10] ^= h;
	      s[11] ^= l;
	      s[20] ^= h;
	      s[21] ^= l;
	      s[30] ^= h;
	      s[31] ^= l;
	      s[40] ^= h;
	      s[41] ^= l;
	      h = c0 ^ ((c4 << 1) | (c5 >>> 31));
	      l = c1 ^ ((c5 << 1) | (c4 >>> 31));
	      s[2] ^= h;
	      s[3] ^= l;
	      s[12] ^= h;
	      s[13] ^= l;
	      s[22] ^= h;
	      s[23] ^= l;
	      s[32] ^= h;
	      s[33] ^= l;
	      s[42] ^= h;
	      s[43] ^= l;
	      h = c2 ^ ((c6 << 1) | (c7 >>> 31));
	      l = c3 ^ ((c7 << 1) | (c6 >>> 31));
	      s[4] ^= h;
	      s[5] ^= l;
	      s[14] ^= h;
	      s[15] ^= l;
	      s[24] ^= h;
	      s[25] ^= l;
	      s[34] ^= h;
	      s[35] ^= l;
	      s[44] ^= h;
	      s[45] ^= l;
	      h = c4 ^ ((c8 << 1) | (c9 >>> 31));
	      l = c5 ^ ((c9 << 1) | (c8 >>> 31));
	      s[6] ^= h;
	      s[7] ^= l;
	      s[16] ^= h;
	      s[17] ^= l;
	      s[26] ^= h;
	      s[27] ^= l;
	      s[36] ^= h;
	      s[37] ^= l;
	      s[46] ^= h;
	      s[47] ^= l;
	      h = c6 ^ ((c0 << 1) | (c1 >>> 31));
	      l = c7 ^ ((c1 << 1) | (c0 >>> 31));
	      s[8] ^= h;
	      s[9] ^= l;
	      s[18] ^= h;
	      s[19] ^= l;
	      s[28] ^= h;
	      s[29] ^= l;
	      s[38] ^= h;
	      s[39] ^= l;
	      s[48] ^= h;
	      s[49] ^= l;

	      b0 = s[0];
	      b1 = s[1];
	      b32 = (s[11] << 4) | (s[10] >>> 28);
	      b33 = (s[10] << 4) | (s[11] >>> 28);
	      b14 = (s[20] << 3) | (s[21] >>> 29);
	      b15 = (s[21] << 3) | (s[20] >>> 29);
	      b46 = (s[31] << 9) | (s[30] >>> 23);
	      b47 = (s[30] << 9) | (s[31] >>> 23);
	      b28 = (s[40] << 18) | (s[41] >>> 14);
	      b29 = (s[41] << 18) | (s[40] >>> 14);
	      b20 = (s[2] << 1) | (s[3] >>> 31);
	      b21 = (s[3] << 1) | (s[2] >>> 31);
	      b2 = (s[13] << 12) | (s[12] >>> 20);
	      b3 = (s[12] << 12) | (s[13] >>> 20);
	      b34 = (s[22] << 10) | (s[23] >>> 22);
	      b35 = (s[23] << 10) | (s[22] >>> 22);
	      b16 = (s[33] << 13) | (s[32] >>> 19);
	      b17 = (s[32] << 13) | (s[33] >>> 19);
	      b48 = (s[42] << 2) | (s[43] >>> 30);
	      b49 = (s[43] << 2) | (s[42] >>> 30);
	      b40 = (s[5] << 30) | (s[4] >>> 2);
	      b41 = (s[4] << 30) | (s[5] >>> 2);
	      b22 = (s[14] << 6) | (s[15] >>> 26);
	      b23 = (s[15] << 6) | (s[14] >>> 26);
	      b4 = (s[25] << 11) | (s[24] >>> 21);
	      b5 = (s[24] << 11) | (s[25] >>> 21);
	      b36 = (s[34] << 15) | (s[35] >>> 17);
	      b37 = (s[35] << 15) | (s[34] >>> 17);
	      b18 = (s[45] << 29) | (s[44] >>> 3);
	      b19 = (s[44] << 29) | (s[45] >>> 3);
	      b10 = (s[6] << 28) | (s[7] >>> 4);
	      b11 = (s[7] << 28) | (s[6] >>> 4);
	      b42 = (s[17] << 23) | (s[16] >>> 9);
	      b43 = (s[16] << 23) | (s[17] >>> 9);
	      b24 = (s[26] << 25) | (s[27] >>> 7);
	      b25 = (s[27] << 25) | (s[26] >>> 7);
	      b6 = (s[36] << 21) | (s[37] >>> 11);
	      b7 = (s[37] << 21) | (s[36] >>> 11);
	      b38 = (s[47] << 24) | (s[46] >>> 8);
	      b39 = (s[46] << 24) | (s[47] >>> 8);
	      b30 = (s[8] << 27) | (s[9] >>> 5);
	      b31 = (s[9] << 27) | (s[8] >>> 5);
	      b12 = (s[18] << 20) | (s[19] >>> 12);
	      b13 = (s[19] << 20) | (s[18] >>> 12);
	      b44 = (s[29] << 7) | (s[28] >>> 25);
	      b45 = (s[28] << 7) | (s[29] >>> 25);
	      b26 = (s[38] << 8) | (s[39] >>> 24);
	      b27 = (s[39] << 8) | (s[38] >>> 24);
	      b8 = (s[48] << 14) | (s[49] >>> 18);
	      b9 = (s[49] << 14) | (s[48] >>> 18);

	      s[0] = b0 ^ (~b2 & b4);
	      s[1] = b1 ^ (~b3 & b5);
	      s[10] = b10 ^ (~b12 & b14);
	      s[11] = b11 ^ (~b13 & b15);
	      s[20] = b20 ^ (~b22 & b24);
	      s[21] = b21 ^ (~b23 & b25);
	      s[30] = b30 ^ (~b32 & b34);
	      s[31] = b31 ^ (~b33 & b35);
	      s[40] = b40 ^ (~b42 & b44);
	      s[41] = b41 ^ (~b43 & b45);
	      s[2] = b2 ^ (~b4 & b6);
	      s[3] = b3 ^ (~b5 & b7);
	      s[12] = b12 ^ (~b14 & b16);
	      s[13] = b13 ^ (~b15 & b17);
	      s[22] = b22 ^ (~b24 & b26);
	      s[23] = b23 ^ (~b25 & b27);
	      s[32] = b32 ^ (~b34 & b36);
	      s[33] = b33 ^ (~b35 & b37);
	      s[42] = b42 ^ (~b44 & b46);
	      s[43] = b43 ^ (~b45 & b47);
	      s[4] = b4 ^ (~b6 & b8);
	      s[5] = b5 ^ (~b7 & b9);
	      s[14] = b14 ^ (~b16 & b18);
	      s[15] = b15 ^ (~b17 & b19);
	      s[24] = b24 ^ (~b26 & b28);
	      s[25] = b25 ^ (~b27 & b29);
	      s[34] = b34 ^ (~b36 & b38);
	      s[35] = b35 ^ (~b37 & b39);
	      s[44] = b44 ^ (~b46 & b48);
	      s[45] = b45 ^ (~b47 & b49);
	      s[6] = b6 ^ (~b8 & b0);
	      s[7] = b7 ^ (~b9 & b1);
	      s[16] = b16 ^ (~b18 & b10);
	      s[17] = b17 ^ (~b19 & b11);
	      s[26] = b26 ^ (~b28 & b20);
	      s[27] = b27 ^ (~b29 & b21);
	      s[36] = b36 ^ (~b38 & b30);
	      s[37] = b37 ^ (~b39 & b31);
	      s[46] = b46 ^ (~b48 & b40);
	      s[47] = b47 ^ (~b49 & b41);
	      s[8] = b8 ^ (~b0 & b2);
	      s[9] = b9 ^ (~b1 & b3);
	      s[18] = b18 ^ (~b10 & b12);
	      s[19] = b19 ^ (~b11 & b13);
	      s[28] = b28 ^ (~b20 & b22);
	      s[29] = b29 ^ (~b21 & b23);
	      s[38] = b38 ^ (~b30 & b32);
	      s[39] = b39 ^ (~b31 & b33);
	      s[48] = b48 ^ (~b40 & b42);
	      s[49] = b49 ^ (~b41 & b43);

	      s[0] ^= RC[n];
	      s[1] ^= RC[n + 1];
	    }
	  };

	  if (COMMON_JS) {
	    module.exports = methods;
	  } else {
	    for (i = 0; i < methodNames.length; ++i) {
	      root[methodNames[i]] = methods[methodNames[i]];
	    }
	  }
	})(); 
} (sha3$1));

var sha3Exports = sha3$1.exports;
var sha3 = /*@__PURE__*/getDefaultExportFromCjs(sha3Exports);

function keccak256(input) {
    return new Uint8Array(sha3.keccak256.arrayBuffer(input));
}
/**
 * Verify an ECDSA signature.
 */
function verifySignature(signature, message, publicKey) {
    try {
        const _signature = Signature.fromCompact(signature.slice(0, 64));
        return verify(_signature, message, publicKey);
    }
    catch {
        return false;
    }
}

function multiaddrFromFields(ipFamily, protocol, ipBytes, protocolBytes) {
    let ma = multiaddr("/" + ipFamily + "/" + convertToString(ipFamily, ipBytes));
    ma = ma.encapsulate(multiaddr("/" + protocol + "/" + convertToString(protocol, protocolBytes)));
    return ma;
}

function locationMultiaddrFromEnrFields(enr, protocol) {
    switch (protocol) {
        case "udp":
            return (locationMultiaddrFromEnrFields(enr, "udp4") ||
                locationMultiaddrFromEnrFields(enr, "udp6"));
        case "tcp":
            return (locationMultiaddrFromEnrFields(enr, "tcp4") ||
                locationMultiaddrFromEnrFields(enr, "tcp6"));
    }
    const isIpv6 = protocol.endsWith("6");
    const ipVal = enr.get(isIpv6 ? "ip6" : "ip");
    if (!ipVal)
        return;
    const protoName = protocol.slice(0, 3);
    let protoVal;
    switch (protoName) {
        case "udp":
            protoVal = isIpv6 ? enr.get("udp6") : enr.get("udp");
            break;
        case "tcp":
            protoVal = isIpv6 ? enr.get("tcp6") : enr.get("tcp");
            break;
        default:
            return;
    }
    if (!protoVal)
        return;
    return multiaddrFromFields(isIpv6 ? "ip6" : "ip4", protoName, ipVal, protoVal);
}

function createPeerIdFromPublicKey(publicKey) {
    const _publicKey = new supportedKeys.secp256k1.Secp256k1PublicKey(publicKey);
    return peerIdFromKeys(_publicKey.bytes, undefined);
}

function decodeMultiaddrs(bytes) {
    const multiaddrs = [];
    let index = 0;
    while (index < bytes.length) {
        const sizeDataView = new DataView(bytes.buffer, index, MULTIADDR_LENGTH_SIZE);
        const size = sizeDataView.getUint16(0);
        index += MULTIADDR_LENGTH_SIZE;
        const multiaddrBytes = bytes.slice(index, index + size);
        index += size;
        multiaddrs.push(multiaddr(multiaddrBytes));
    }
    return multiaddrs;
}
function encodeMultiaddrs(multiaddrs) {
    const totalLength = multiaddrs.reduce((acc, ma) => acc + MULTIADDR_LENGTH_SIZE + ma.bytes.length, 0);
    const bytes = new Uint8Array(totalLength);
    const dataView = new DataView(bytes.buffer);
    let index = 0;
    multiaddrs.forEach((multiaddr) => {
        if (multiaddr.getPeerId())
            throw new Error("`multiaddr` field MUST not contain peer id");
        // Prepend the size of the next entry
        dataView.setUint16(index, multiaddr.bytes.length);
        index += MULTIADDR_LENGTH_SIZE;
        bytes.set(multiaddr.bytes, index);
        index += multiaddr.bytes.length;
    });
    return bytes;
}

function encodeWaku2(protocols) {
    let byte = 0;
    if (protocols.lightPush)
        byte += 1;
    byte = byte << 1;
    if (protocols.filter)
        byte += 1;
    byte = byte << 1;
    if (protocols.store)
        byte += 1;
    byte = byte << 1;
    if (protocols.relay)
        byte += 1;
    return byte;
}
function decodeWaku2(byte) {
    const waku2 = {
        relay: false,
        store: false,
        filter: false,
        lightPush: false
    };
    if (byte % 2)
        waku2.relay = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.store = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.filter = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.lightPush = true;
    return waku2;
}

class RawEnr extends Map {
    seq;
    signature;
    constructor(kvs = {}, seq = BigInt(1), signature) {
        super(Object.entries(kvs));
        this.seq = seq;
        this.signature = signature;
    }
    set(k, v) {
        this.signature = undefined;
        this.seq++;
        return super.set(k, v);
    }
    get id() {
        const id = this.get("id");
        if (!id)
            throw new Error("id not found.");
        return bytesToUtf8(id);
    }
    get publicKey() {
        switch (this.id) {
            case "v4":
                return this.get("secp256k1");
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    get rs() {
        const rs = this.get("rs");
        if (!rs)
            return undefined;
        return decodeRelayShard(rs);
    }
    get rsv() {
        const rsv = this.get("rsv");
        if (!rsv)
            return undefined;
        return decodeRelayShard(rsv);
    }
    get ip() {
        return getStringValue(this, "ip", "ip4");
    }
    set ip(ip) {
        setStringValue(this, "ip", "ip4", ip);
    }
    get tcp() {
        return getNumberAsStringValue(this, "tcp", "tcp");
    }
    set tcp(port) {
        setNumberAsStringValue(this, "tcp", "tcp", port);
    }
    get udp() {
        return getNumberAsStringValue(this, "udp", "udp");
    }
    set udp(port) {
        setNumberAsStringValue(this, "udp", "udp", port);
    }
    get ip6() {
        return getStringValue(this, "ip6", "ip6");
    }
    set ip6(ip) {
        setStringValue(this, "ip6", "ip6", ip);
    }
    get tcp6() {
        return getNumberAsStringValue(this, "tcp6", "tcp");
    }
    set tcp6(port) {
        setNumberAsStringValue(this, "tcp6", "tcp", port);
    }
    get udp6() {
        return getNumberAsStringValue(this, "udp6", "udp");
    }
    set udp6(port) {
        setNumberAsStringValue(this, "udp6", "udp", port);
    }
    /**
     * Get the `multiaddrs` field from ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.getLocationMultiaddr } should be preferred.
     *
     * The multiaddresses stored in this field are expected to be location multiaddresses, ie, peer id less.
     */
    get multiaddrs() {
        const raw = this.get("multiaddrs");
        if (raw)
            return decodeMultiaddrs(raw);
        return;
    }
    /**
     * Set the `multiaddrs` field on the ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.setLocationMultiaddr } should be preferred.
     * The multiaddresses stored in this field must be location multiaddresses,
     * ie, without a peer id.
     */
    set multiaddrs(multiaddrs) {
        deleteUndefined(this, "multiaddrs", multiaddrs, encodeMultiaddrs);
    }
    /**
     * Get the `waku2` field from ENR.
     */
    get waku2() {
        const raw = this.get("waku2");
        if (raw)
            return decodeWaku2(raw[0]);
        return;
    }
    /**
     * Set the `waku2` field on the ENR.
     */
    set waku2(waku2) {
        deleteUndefined(this, "waku2", waku2, (w) => new Uint8Array([encodeWaku2(w)]));
    }
}
function getStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return convertToString(proto, raw);
}
function getNumberAsStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return Number(convertToString(proto, raw));
}
function setStringValue(map, key, proto, value) {
    deleteUndefined(map, key, value, convertToBytes.bind({}, proto));
}
function setNumberAsStringValue(map, key, proto, value) {
    setStringValue(map, key, proto, value?.toString(10));
}
function deleteUndefined(map, key, value, transform) {
    if (value !== undefined) {
        map.set(key, transform(value));
    }
    else {
        map.delete(key);
    }
}

async function sign(privKey, msg) {
    return sign$1(keccak256(msg), privKey, {
        der: false
    });
}
function nodeId(pubKey) {
    const publicKey = Point.fromHex(pubKey);
    const uncompressedPubkey = publicKey.toRawBytes(false);
    return bytesToHex$2(keccak256(uncompressedPubkey.slice(1)));
}

const log$9 = new Logger$1("enr");
var TransportProtocol;
(function (TransportProtocol) {
    TransportProtocol["TCP"] = "tcp";
    TransportProtocol["UDP"] = "udp";
})(TransportProtocol || (TransportProtocol = {}));
var TransportProtocolPerIpVersion;
(function (TransportProtocolPerIpVersion) {
    TransportProtocolPerIpVersion["TCP4"] = "tcp4";
    TransportProtocolPerIpVersion["UDP4"] = "udp4";
    TransportProtocolPerIpVersion["TCP6"] = "tcp6";
    TransportProtocolPerIpVersion["UDP6"] = "udp6";
})(TransportProtocolPerIpVersion || (TransportProtocolPerIpVersion = {}));
class ENR extends RawEnr {
    static RECORD_PREFIX = "enr:";
    peerId;
    static async create(kvs = {}, seq = BigInt(1), signature) {
        const enr = new ENR(kvs, seq, signature);
        try {
            const publicKey = enr.publicKey;
            if (publicKey) {
                enr.peerId = await createPeerIdFromPublicKey(publicKey);
            }
        }
        catch (e) {
            log$9.error("Could not calculate peer id for ENR", e);
        }
        return enr;
    }
    get nodeId() {
        switch (this.id) {
            case "v4":
                return this.publicKey ? nodeId(this.publicKey) : undefined;
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    getLocationMultiaddr = locationMultiaddrFromEnrFields.bind({}, this);
    get shardInfo() {
        if (this.rs && this.rsv) {
            log$9.warn("ENR contains both `rs` and `rsv` fields.");
        }
        return this.rs || this.rsv;
    }
    setLocationMultiaddr(multiaddr) {
        const protoNames = multiaddr.protoNames();
        if (protoNames.length !== 2 &&
            protoNames[1] !== "udp" &&
            protoNames[1] !== "tcp") {
            throw new Error("Invalid multiaddr");
        }
        const tuples = multiaddr.tuples();
        if (!tuples[0][1] || !tuples[1][1]) {
            throw new Error("Invalid multiaddr");
        }
        // IPv4
        if (tuples[0][0] === 4) {
            this.set("ip", tuples[0][1]);
            this.set(protoNames[1], tuples[1][1]);
        }
        else {
            this.set("ip6", tuples[0][1]);
            this.set(protoNames[1] + "6", tuples[1][1]);
        }
    }
    getAllLocationMultiaddrs() {
        const multiaddrs = [];
        for (const protocol of Object.values(TransportProtocolPerIpVersion)) {
            const ma = this.getLocationMultiaddr(protocol);
            if (ma)
                multiaddrs.push(ma);
        }
        const _multiaddrs = this.multiaddrs ?? [];
        return multiaddrs.concat(_multiaddrs).map((ma) => {
            if (this.peerId) {
                return ma.encapsulate(`/p2p/${this.peerId.toString()}`);
            }
            return ma;
        });
    }
    get peerInfo() {
        const id = this.peerId;
        if (!id)
            return;
        return {
            id,
            multiaddrs: this.getAllLocationMultiaddrs()
        };
    }
    /**
     * Returns the full multiaddr from the ENR fields matching the provided
     * `protocol` parameter.
     * To return full multiaddrs from the `multiaddrs` ENR field,
     * use { @link ENR.getFullMultiaddrs }.
     *
     * @param protocol
     */
    getFullMultiaddr(protocol) {
        if (this.peerId) {
            const locationMultiaddr = this.getLocationMultiaddr(protocol);
            if (locationMultiaddr) {
                return locationMultiaddr.encapsulate(`/p2p/${this.peerId.toString()}`);
            }
        }
        return;
    }
    /**
     * Returns the full multiaddrs from the `multiaddrs` ENR field.
     */
    getFullMultiaddrs() {
        if (this.peerId && this.multiaddrs) {
            const peerId = this.peerId;
            return this.multiaddrs.map((ma) => {
                return ma.encapsulate(`/p2p/${peerId.toString()}`);
            });
        }
        return [];
    }
    verify(data, signature) {
        if (!this.get("id") || this.id !== "v4") {
            throw new Error(ERR_INVALID_ID);
        }
        if (!this.publicKey) {
            throw new Error("Failed to verify ENR: No public key");
        }
        return verifySignature(signature, keccak256(data), this.publicKey);
    }
    async sign(data, privateKey) {
        switch (this.id) {
            case "v4":
                this.signature = await sign(privateKey, data);
                break;
            default:
                throw new Error(ERR_INVALID_ID);
        }
        return this.signature;
    }
}

const version$2 = "logger/5.7.0";

let _permanentCensorErrors = false;
let _censorErrors = false;
const LogLevels = { debug: 1, "default": 2, info: 2, warning: 3, error: 4, off: 5 };
let _logLevel = LogLevels["default"];
let _globalLogger = null;
function _checkNormalize() {
    try {
        const missing = [];
        // Make sure all forms of normalization are supported
        ["NFD", "NFC", "NFKD", "NFKC"].forEach((form) => {
            try {
                if ("test".normalize(form) !== "test") {
                    throw new Error("bad normalize");
                }
                ;
            }
            catch (error) {
                missing.push(form);
            }
        });
        if (missing.length) {
            throw new Error("missing " + missing.join(", "));
        }
        if (String.fromCharCode(0xe9).normalize("NFD") !== String.fromCharCode(0x65, 0x0301)) {
            throw new Error("broken implementation");
        }
    }
    catch (error) {
        return error.message;
    }
    return null;
}
const _normalizeError = _checkNormalize();
var LogLevel;
(function (LogLevel) {
    LogLevel["DEBUG"] = "DEBUG";
    LogLevel["INFO"] = "INFO";
    LogLevel["WARNING"] = "WARNING";
    LogLevel["ERROR"] = "ERROR";
    LogLevel["OFF"] = "OFF";
})(LogLevel || (LogLevel = {}));
var ErrorCode;
(function (ErrorCode) {
    ///////////////////
    // Generic Errors
    // Unknown Error
    ErrorCode["UNKNOWN_ERROR"] = "UNKNOWN_ERROR";
    // Not Implemented
    ErrorCode["NOT_IMPLEMENTED"] = "NOT_IMPLEMENTED";
    // Unsupported Operation
    //   - operation
    ErrorCode["UNSUPPORTED_OPERATION"] = "UNSUPPORTED_OPERATION";
    // Network Error (i.e. Ethereum Network, such as an invalid chain ID)
    //   - event ("noNetwork" is not re-thrown in provider.ready; otherwise thrown)
    ErrorCode["NETWORK_ERROR"] = "NETWORK_ERROR";
    // Some sort of bad response from the server
    ErrorCode["SERVER_ERROR"] = "SERVER_ERROR";
    // Timeout
    ErrorCode["TIMEOUT"] = "TIMEOUT";
    ///////////////////
    // Operational  Errors
    // Buffer Overrun
    ErrorCode["BUFFER_OVERRUN"] = "BUFFER_OVERRUN";
    // Numeric Fault
    //   - operation: the operation being executed
    //   - fault: the reason this faulted
    ErrorCode["NUMERIC_FAULT"] = "NUMERIC_FAULT";
    ///////////////////
    // Argument Errors
    // Missing new operator to an object
    //  - name: The name of the class
    ErrorCode["MISSING_NEW"] = "MISSING_NEW";
    // Invalid argument (e.g. value is incompatible with type) to a function:
    //   - argument: The argument name that was invalid
    //   - value: The value of the argument
    ErrorCode["INVALID_ARGUMENT"] = "INVALID_ARGUMENT";
    // Missing argument to a function:
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["MISSING_ARGUMENT"] = "MISSING_ARGUMENT";
    // Too many arguments
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["UNEXPECTED_ARGUMENT"] = "UNEXPECTED_ARGUMENT";
    ///////////////////
    // Blockchain Errors
    // Call exception
    //  - transaction: the transaction
    //  - address?: the contract address
    //  - args?: The arguments passed into the function
    //  - method?: The Solidity method signature
    //  - errorSignature?: The EIP848 error signature
    //  - errorArgs?: The EIP848 error parameters
    //  - reason: The reason (only for EIP848 "Error(string)")
    ErrorCode["CALL_EXCEPTION"] = "CALL_EXCEPTION";
    // Insufficient funds (< value + gasLimit * gasPrice)
    //   - transaction: the transaction attempted
    ErrorCode["INSUFFICIENT_FUNDS"] = "INSUFFICIENT_FUNDS";
    // Nonce has already been used
    //   - transaction: the transaction attempted
    ErrorCode["NONCE_EXPIRED"] = "NONCE_EXPIRED";
    // The replacement fee for the transaction is too low
    //   - transaction: the transaction attempted
    ErrorCode["REPLACEMENT_UNDERPRICED"] = "REPLACEMENT_UNDERPRICED";
    // The gas limit could not be estimated
    //   - transaction: the transaction passed to estimateGas
    ErrorCode["UNPREDICTABLE_GAS_LIMIT"] = "UNPREDICTABLE_GAS_LIMIT";
    // The transaction was replaced by one with a higher gas price
    //   - reason: "cancelled", "replaced" or "repriced"
    //   - cancelled: true if reason == "cancelled" or reason == "replaced")
    //   - hash: original transaction hash
    //   - replacement: the full TransactionsResponse for the replacement
    //   - receipt: the receipt of the replacement
    ErrorCode["TRANSACTION_REPLACED"] = "TRANSACTION_REPLACED";
    ///////////////////
    // Interaction Errors
    // The user rejected the action, such as signing a message or sending
    // a transaction
    ErrorCode["ACTION_REJECTED"] = "ACTION_REJECTED";
})(ErrorCode || (ErrorCode = {}));
const HEX = "0123456789abcdef";
class Logger {
    constructor(version) {
        Object.defineProperty(this, "version", {
            enumerable: true,
            value: version,
            writable: false
        });
    }
    _log(logLevel, args) {
        const level = logLevel.toLowerCase();
        if (LogLevels[level] == null) {
            this.throwArgumentError("invalid log level name", "logLevel", logLevel);
        }
        if (_logLevel > LogLevels[level]) {
            return;
        }
        console.log.apply(console, args);
    }
    debug(...args) {
        this._log(Logger.levels.DEBUG, args);
    }
    info(...args) {
        this._log(Logger.levels.INFO, args);
    }
    warn(...args) {
        this._log(Logger.levels.WARNING, args);
    }
    makeError(message, code, params) {
        // Errors are being censored
        if (_censorErrors) {
            return this.makeError("censored error", code, {});
        }
        if (!code) {
            code = Logger.errors.UNKNOWN_ERROR;
        }
        if (!params) {
            params = {};
        }
        const messageDetails = [];
        Object.keys(params).forEach((key) => {
            const value = params[key];
            try {
                if (value instanceof Uint8Array) {
                    let hex = "";
                    for (let i = 0; i < value.length; i++) {
                        hex += HEX[value[i] >> 4];
                        hex += HEX[value[i] & 0x0f];
                    }
                    messageDetails.push(key + "=Uint8Array(0x" + hex + ")");
                }
                else {
                    messageDetails.push(key + "=" + JSON.stringify(value));
                }
            }
            catch (error) {
                messageDetails.push(key + "=" + JSON.stringify(params[key].toString()));
            }
        });
        messageDetails.push(`code=${code}`);
        messageDetails.push(`version=${this.version}`);
        const reason = message;
        let url = "";
        switch (code) {
            case ErrorCode.NUMERIC_FAULT: {
                url = "NUMERIC_FAULT";
                const fault = message;
                switch (fault) {
                    case "overflow":
                    case "underflow":
                    case "division-by-zero":
                        url += "-" + fault;
                        break;
                    case "negative-power":
                    case "negative-width":
                        url += "-unsupported";
                        break;
                    case "unbound-bitwise-result":
                        url += "-unbound-result";
                        break;
                }
                break;
            }
            case ErrorCode.CALL_EXCEPTION:
            case ErrorCode.INSUFFICIENT_FUNDS:
            case ErrorCode.MISSING_NEW:
            case ErrorCode.NONCE_EXPIRED:
            case ErrorCode.REPLACEMENT_UNDERPRICED:
            case ErrorCode.TRANSACTION_REPLACED:
            case ErrorCode.UNPREDICTABLE_GAS_LIMIT:
                url = code;
                break;
        }
        if (url) {
            message += " [ See: https:/\/links.ethers.org/v5-errors-" + url + " ]";
        }
        if (messageDetails.length) {
            message += " (" + messageDetails.join(", ") + ")";
        }
        // @TODO: Any??
        const error = new Error(message);
        error.reason = reason;
        error.code = code;
        Object.keys(params).forEach(function (key) {
            error[key] = params[key];
        });
        return error;
    }
    throwError(message, code, params) {
        throw this.makeError(message, code, params);
    }
    throwArgumentError(message, name, value) {
        return this.throwError(message, Logger.errors.INVALID_ARGUMENT, {
            argument: name,
            value: value
        });
    }
    assert(condition, message, code, params) {
        if (!!condition) {
            return;
        }
        this.throwError(message, code, params);
    }
    assertArgument(condition, message, name, value) {
        if (!!condition) {
            return;
        }
        this.throwArgumentError(message, name, value);
    }
    checkNormalize(message) {
        if (_normalizeError) {
            this.throwError("platform missing String.prototype.normalize", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "String.prototype.normalize", form: _normalizeError
            });
        }
    }
    checkSafeUint53(value, message) {
        if (typeof (value) !== "number") {
            return;
        }
        if (message == null) {
            message = "value not safe";
        }
        if (value < 0 || value >= 0x1fffffffffffff) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "out-of-safe-range",
                value: value
            });
        }
        if (value % 1) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "non-integer",
                value: value
            });
        }
    }
    checkArgumentCount(count, expectedCount, message) {
        if (message) {
            message = ": " + message;
        }
        else {
            message = "";
        }
        if (count < expectedCount) {
            this.throwError("missing argument" + message, Logger.errors.MISSING_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
        if (count > expectedCount) {
            this.throwError("too many arguments" + message, Logger.errors.UNEXPECTED_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
    }
    checkNew(target, kind) {
        if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    checkAbstract(target, kind) {
        if (target === kind) {
            this.throwError("cannot instantiate abstract class " + JSON.stringify(kind.name) + " directly; use a sub-class", Logger.errors.UNSUPPORTED_OPERATION, { name: target.name, operation: "new" });
        }
        else if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    static globalLogger() {
        if (!_globalLogger) {
            _globalLogger = new Logger(version$2);
        }
        return _globalLogger;
    }
    static setCensorship(censorship, permanent) {
        if (!censorship && permanent) {
            this.globalLogger().throwError("cannot permanently disable censorship", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        if (_permanentCensorErrors) {
            if (!censorship) {
                return;
            }
            this.globalLogger().throwError("error censorship permanent", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        _censorErrors = !!censorship;
        _permanentCensorErrors = !!permanent;
    }
    static setLogLevel(logLevel) {
        const level = LogLevels[logLevel.toLowerCase()];
        if (level == null) {
            Logger.globalLogger().warn("invalid log level - " + logLevel);
            return;
        }
        _logLevel = level;
    }
    static from(version) {
        return new Logger(version);
    }
}
Logger.errors = ErrorCode;
Logger.levels = LogLevel;

const version$1 = "bytes/5.7.0";

const logger$1 = new Logger(version$1);
///////////////////////////////
function isHexable(value) {
    return !!(value.toHexString);
}
function addSlice(array) {
    if (array.slice) {
        return array;
    }
    array.slice = function () {
        const args = Array.prototype.slice.call(arguments);
        return addSlice(new Uint8Array(Array.prototype.slice.apply(array, args)));
    };
    return array;
}
function isBytesLike(value) {
    return ((isHexString(value) && !(value.length % 2)) || isBytes(value));
}
function isInteger(value) {
    return (typeof (value) === "number" && value == value && (value % 1) === 0);
}
function isBytes(value) {
    if (value == null) {
        return false;
    }
    if (value.constructor === Uint8Array) {
        return true;
    }
    if (typeof (value) === "string") {
        return false;
    }
    if (!isInteger(value.length) || value.length < 0) {
        return false;
    }
    for (let i = 0; i < value.length; i++) {
        const v = value[i];
        if (!isInteger(v) || v < 0 || v >= 256) {
            return false;
        }
    }
    return true;
}
function arrayify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$1.checkSafeUint53(value, "invalid arrayify value");
        const result = [];
        while (value) {
            result.unshift(value & 0xff);
            value = parseInt(String(value / 256));
        }
        if (result.length === 0) {
            result.push(0);
        }
        return addSlice(new Uint8Array(result));
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        value = value.toHexString();
    }
    if (isHexString(value)) {
        let hex = value.substring(2);
        if (hex.length % 2) {
            if (options.hexPad === "left") {
                hex = "0" + hex;
            }
            else if (options.hexPad === "right") {
                hex += "0";
            }
            else {
                logger$1.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        const result = [];
        for (let i = 0; i < hex.length; i += 2) {
            result.push(parseInt(hex.substring(i, i + 2), 16));
        }
        return addSlice(new Uint8Array(result));
    }
    if (isBytes(value)) {
        return addSlice(new Uint8Array(value));
    }
    return logger$1.throwArgumentError("invalid arrayify value", "value", value);
}
function isHexString(value, length) {
    if (typeof (value) !== "string" || !value.match(/^0x[0-9A-Fa-f]*$/)) {
        return false;
    }
    return true;
}
const HexCharacters = "0123456789abcdef";
function hexlify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$1.checkSafeUint53(value, "invalid hexlify value");
        let hex = "";
        while (value) {
            hex = HexCharacters[value & 0xf] + hex;
            value = Math.floor(value / 16);
        }
        if (hex.length) {
            if (hex.length % 2) {
                hex = "0" + hex;
            }
            return "0x" + hex;
        }
        return "0x00";
    }
    if (typeof (value) === "bigint") {
        value = value.toString(16);
        if (value.length % 2) {
            return ("0x0" + value);
        }
        return "0x" + value;
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        return value.toHexString();
    }
    if (isHexString(value)) {
        if (value.length % 2) {
            if (options.hexPad === "left") {
                value = "0x0" + value.substring(2);
            }
            else if (options.hexPad === "right") {
                value += "0";
            }
            else {
                logger$1.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        return value.toLowerCase();
    }
    if (isBytes(value)) {
        let result = "0x";
        for (let i = 0; i < value.length; i++) {
            let v = value[i];
            result += HexCharacters[(v & 0xf0) >> 4] + HexCharacters[v & 0x0f];
        }
        return result;
    }
    return logger$1.throwArgumentError("invalid hexlify value", "value", value);
}

const version = "rlp/5.7.0";

const logger = new Logger(version);
function arrayifyInteger(value) {
    const result = [];
    while (value) {
        result.unshift(value & 0xff);
        value >>= 8;
    }
    return result;
}
function unarrayifyInteger(data, offset, length) {
    let result = 0;
    for (let i = 0; i < length; i++) {
        result = (result * 256) + data[offset + i];
    }
    return result;
}
function _encode(object) {
    if (Array.isArray(object)) {
        let payload = [];
        object.forEach(function (child) {
            payload = payload.concat(_encode(child));
        });
        if (payload.length <= 55) {
            payload.unshift(0xc0 + payload.length);
            return payload;
        }
        const length = arrayifyInteger(payload.length);
        length.unshift(0xf7 + length.length);
        return length.concat(payload);
    }
    if (!isBytesLike(object)) {
        logger.throwArgumentError("RLP object must be BytesLike", "object", object);
    }
    const data = Array.prototype.slice.call(arrayify(object));
    if (data.length === 1 && data[0] <= 0x7f) {
        return data;
    }
    else if (data.length <= 55) {
        data.unshift(0x80 + data.length);
        return data;
    }
    const length = arrayifyInteger(data.length);
    length.unshift(0xb7 + length.length);
    return length.concat(data);
}
function encode$3(object) {
    return hexlify(_encode(object));
}
function _decodeChildren(data, offset, childOffset, length) {
    const result = [];
    while (childOffset < offset + 1 + length) {
        const decoded = _decode(data, childOffset);
        result.push(decoded.result);
        childOffset += decoded.consumed;
        if (childOffset > offset + 1 + length) {
            logger.throwError("child data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
    }
    return { consumed: (1 + length), result: result };
}
// returns { consumed: number, result: Object }
function _decode(data, offset) {
    if (data.length === 0) {
        logger.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
    }
    // Array with extra length prefix
    if (data[offset] >= 0xf8) {
        const lengthLength = data[offset] - 0xf7;
        if (offset + 1 + lengthLength > data.length) {
            logger.throwError("data short segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger.throwError("data long segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1 + lengthLength, lengthLength + length);
    }
    else if (data[offset] >= 0xc0) {
        const length = data[offset] - 0xc0;
        if (offset + 1 + length > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1, length);
    }
    else if (data[offset] >= 0xb8) {
        const lengthLength = data[offset] - 0xb7;
        if (offset + 1 + lengthLength > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1 + lengthLength, offset + 1 + lengthLength + length));
        return { consumed: (1 + lengthLength + length), result: result };
    }
    else if (data[offset] >= 0x80) {
        const length = data[offset] - 0x80;
        if (offset + 1 + length > data.length) {
            logger.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1, offset + 1 + length));
        return { consumed: (1 + length), result: result };
    }
    return { consumed: 1, result: hexlify(data[offset]) };
}
function decode$3(data) {
    const bytes = arrayify(data);
    const decoded = _decode(bytes, 0);
    if (decoded.consumed !== bytes.length) {
        logger.throwArgumentError("invalid rlp data", "data", data);
    }
    return decoded.result;
}

const log$8 = new Logger$1("enr:decoder");
class EnrDecoder {
    static fromString(encoded) {
        if (!encoded.startsWith(ENR.RECORD_PREFIX)) {
            throw new Error(`"string encoded ENR must start with '${ENR.RECORD_PREFIX}'`);
        }
        return EnrDecoder.fromRLP(fromString(encoded.slice(4), "base64url"));
    }
    static fromRLP(encoded) {
        const decoded = decode$3(encoded).map(hexToBytes$2);
        return fromValues(decoded);
    }
}
async function fromValues(values) {
    const { signature, seq, kvs } = checkValues(values);
    const obj = {};
    for (let i = 0; i < kvs.length; i += 2) {
        try {
            obj[bytesToUtf8(kvs[i])] = kvs[i + 1];
        }
        catch (e) {
            log$8.error("Failed to decode ENR key to UTF-8, skipping it", kvs[i], e);
        }
    }
    const _seq = decodeSeq(seq);
    const enr = await ENR.create(obj, _seq, signature);
    checkSignature(seq, kvs, enr, signature);
    return enr;
}
function decodeSeq(seq) {
    // If seq is an empty array, translate as value 0
    if (!seq.length)
        return BigInt(0);
    return BigInt("0x" + bytesToHex$2(seq));
}
function checkValues(values) {
    if (!Array.isArray(values)) {
        throw new Error("Decoded ENR must be an array");
    }
    if (values.length % 2 !== 0) {
        throw new Error("Decoded ENR must have an even number of elements");
    }
    const [signature, seq, ...kvs] = values;
    if (!signature || Array.isArray(signature)) {
        throw new Error("Decoded ENR invalid signature: must be a byte array");
    }
    if (!seq || Array.isArray(seq)) {
        throw new Error("Decoded ENR invalid sequence number: must be a byte array");
    }
    return { signature, seq, kvs };
}
function checkSignature(seq, kvs, enr, signature) {
    const rlpEncodedBytes = hexToBytes$2(encode$3([seq, ...kvs]));
    if (!enr.verify(rlpEncodedBytes, signature)) {
        throw new Error("Unable to verify ENR signature");
    }
}

const v4Regex$1 = /^(\d{1,3}\.){3,3}\d{1,3}$/;
const v4Size = 4;
const v6Regex$1 = /^(::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?$/i;
const v6Size = 16;

const v4 = {
  name: 'v4',
  size: v4Size,
  isFormat: ip => v4Regex$1.test(ip),
  encode (ip, buff, offset) {
    offset = ~~offset;
    buff = buff || new Uint8Array(offset + v4Size);
    const max = ip.length;
    let n = 0;
    for (let i = 0; i < max;) {
      const c = ip.charCodeAt(i++);
      if (c === 46) { // "."
        buff[offset++] = n;
        n = 0;
      } else {
        n = n * 10 + (c - 48);
      }
    }
    buff[offset] = n;
    return buff
  },
  decode (buff, offset) {
    offset = ~~offset;
    return `${buff[offset++]}.${buff[offset++]}.${buff[offset++]}.${buff[offset]}`
  }
};

const v6 = {
  name: 'v6',
  size: v6Size,
  isFormat: ip => ip.length > 0 && v6Regex$1.test(ip),
  encode (ip, buff, offset) {
    offset = ~~offset;
    let end = offset + v6Size;
    let fill = -1;
    let hexN = 0;
    let decN = 0;
    let prevColon = true;
    let useDec = false;
    buff = buff || new Uint8Array(offset + v6Size);
    // Note: This algorithm needs to check if the offset
    // could exceed the buffer boundaries as it supports
    // non-standard compliant encodings that may go beyond
    // the boundary limits. if (offset < end) checks should
    // not be necessary...
    for (let i = 0; i < ip.length; i++) {
      let c = ip.charCodeAt(i);
      if (c === 58) { // :
        if (prevColon) {
          if (fill !== -1) {
            // Not Standard! (standard doesn't allow multiple ::)
            // We need to treat
            if (offset < end) buff[offset] = 0;
            if (offset < end - 1) buff[offset + 1] = 0;
            offset += 2;
          } else if (offset < end) {
            // :: in the middle
            fill = offset;
          }
        } else {
          // : ends the previous number
          if (useDec === true) {
            // Non-standard! (ipv4 should be at end only)
            // A ipv4 address should not be found anywhere else but at
            // the end. This codec also support putting characters
            // after the ipv4 address..
            if (offset < end) buff[offset] = decN;
            offset++;
          } else {
            if (offset < end) buff[offset] = hexN >> 8;
            if (offset < end - 1) buff[offset + 1] = hexN & 0xff;
            offset += 2;
          }
          hexN = 0;
          decN = 0;
        }
        prevColon = true;
        useDec = false;
      } else if (c === 46) { // . indicates IPV4 notation
        if (offset < end) buff[offset] = decN;
        offset++;
        decN = 0;
        hexN = 0;
        prevColon = false;
        useDec = true;
      } else {
        prevColon = false;
        if (c >= 97) {
          c -= 87; // a-f ... 97~102 -87 => 10~15
        } else if (c >= 65) {
          c -= 55; // A-F ... 65~70 -55 => 10~15
        } else {
          c -= 48; // 0-9 ... starting from charCode 48
          decN = decN * 10 + c;
        }
        // We don't know yet if its a dec or hex number
        hexN = (hexN << 4) + c;
      }
    }
    if (prevColon === false) {
      // Commiting last number
      if (useDec === true) {
        if (offset < end) buff[offset] = decN;
        offset++;
      } else {
        if (offset < end) buff[offset] = hexN >> 8;
        if (offset < end - 1) buff[offset + 1] = hexN & 0xff;
        offset += 2;
      }
    } else if (fill === 0) {
      // Not Standard! (standard doesn't allow multiple ::)
      // This means that a : was found at the start AND end which means the
      // end needs to be treated as 0 entry...
      if (offset < end) buff[offset] = 0;
      if (offset < end - 1) buff[offset + 1] = 0;
      offset += 2;
    } else if (fill !== -1) {
      // Non-standard! (standard doens't allow multiple ::)
      // Here we find that there has been a :: somewhere in the middle
      // and the end. To treat the end with priority we need to move all
      // written data two bytes to the right.
      offset += 2;
      for (let i = Math.min(offset - 1, end - 1); i >= fill + 2; i--) {
        buff[i] = buff[i - 2];
      }
      buff[fill] = 0;
      buff[fill + 1] = 0;
      fill = offset;
    }
    if (fill !== offset && fill !== -1) {
      // Move the written numbers to the end while filling the everything
      // "fill" to the bytes with zeros.
      if (offset > end - 2) {
        // Non Standard support, when the cursor exceeds bounds.
        offset = end - 2;
      }
      while (end > fill) {
        buff[--end] = offset < end && offset > fill ? buff[--offset] : 0;
      }
    } else {
      // Fill the rest with zeros
      while (offset < end) {
        buff[offset++] = 0;
      }
    }
    return buff
  },
  decode (buff, offset) {
    offset = ~~offset;
    let result = '';
    for (let i = 0; i < v6Size; i += 2) {
      if (i !== 0) {
        result += ':';
      }
      result += (buff[offset + i] << 8 | buff[offset + i + 1]).toString(16);
    }
    return result
      .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
      .replace(/:{3,4}/, '::')
  }
};
function sizeOf (ip) {
  if (v4.isFormat(ip)) return v4.size
  if (v6.isFormat(ip)) return v6.size
  throw Error(`Invalid ip address: ${ip}`)
}

function familyOf (string) {
  return sizeOf(string) === v4.size ? 1 : 2
}

function encode$2 (ip, buff, offset) {
  offset = ~~offset;
  const size = sizeOf(ip);
  if (typeof buff === 'function') {
    buff = buff(offset + size);
  }
  if (size === v4.size) {
    return v4.encode(ip, buff, offset)
  }
  return v6.encode(ip, buff, offset)
}

function decode$2 (buff, offset, length) {
  offset = ~~offset;
  length = length || (buff.length - offset);
  if (length === v4.size) {
    return v4.decode(buff, offset, length)
  }
  if (length === v6.size) {
    return v6.decode(buff, offset, length)
  }
  throw Error(`Invalid buffer size needs to be ${v4.size} for v4 or ${v6.size} for v6.`)
}

function toString$4 (type) {
  switch (type) {
    case 1: return 'A'
    case 10: return 'NULL'
    case 28: return 'AAAA'
    case 18: return 'AFSDB'
    case 42: return 'APL'
    case 257: return 'CAA'
    case 60: return 'CDNSKEY'
    case 59: return 'CDS'
    case 37: return 'CERT'
    case 5: return 'CNAME'
    case 49: return 'DHCID'
    case 32769: return 'DLV'
    case 39: return 'DNAME'
    case 48: return 'DNSKEY'
    case 43: return 'DS'
    case 55: return 'HIP'
    case 13: return 'HINFO'
    case 45: return 'IPSECKEY'
    case 25: return 'KEY'
    case 36: return 'KX'
    case 29: return 'LOC'
    case 15: return 'MX'
    case 35: return 'NAPTR'
    case 2: return 'NS'
    case 47: return 'NSEC'
    case 50: return 'NSEC3'
    case 51: return 'NSEC3PARAM'
    case 12: return 'PTR'
    case 46: return 'RRSIG'
    case 17: return 'RP'
    case 24: return 'SIG'
    case 6: return 'SOA'
    case 99: return 'SPF'
    case 33: return 'SRV'
    case 44: return 'SSHFP'
    case 32768: return 'TA'
    case 249: return 'TKEY'
    case 52: return 'TLSA'
    case 250: return 'TSIG'
    case 16: return 'TXT'
    case 252: return 'AXFR'
    case 251: return 'IXFR'
    case 41: return 'OPT'
    case 255: return 'ANY'
  }
  return 'UNKNOWN_' + type
}

function toType (name) {
  switch (name.toUpperCase()) {
    case 'A': return 1
    case 'NULL': return 10
    case 'AAAA': return 28
    case 'AFSDB': return 18
    case 'APL': return 42
    case 'CAA': return 257
    case 'CDNSKEY': return 60
    case 'CDS': return 59
    case 'CERT': return 37
    case 'CNAME': return 5
    case 'DHCID': return 49
    case 'DLV': return 32769
    case 'DNAME': return 39
    case 'DNSKEY': return 48
    case 'DS': return 43
    case 'HIP': return 55
    case 'HINFO': return 13
    case 'IPSECKEY': return 45
    case 'KEY': return 25
    case 'KX': return 36
    case 'LOC': return 29
    case 'MX': return 15
    case 'NAPTR': return 35
    case 'NS': return 2
    case 'NSEC': return 47
    case 'NSEC3': return 50
    case 'NSEC3PARAM': return 51
    case 'PTR': return 12
    case 'RRSIG': return 46
    case 'RP': return 17
    case 'SIG': return 24
    case 'SOA': return 6
    case 'SPF': return 99
    case 'SRV': return 33
    case 'SSHFP': return 44
    case 'TA': return 32768
    case 'TKEY': return 249
    case 'TLSA': return 52
    case 'TSIG': return 250
    case 'TXT': return 16
    case 'AXFR': return 252
    case 'IXFR': return 251
    case 'OPT': return 41
    case 'ANY': return 255
    case '*': return 255
  }
  if (name.toUpperCase().startsWith('UNKNOWN_')) return parseInt(name.slice(8))
  return 0
}

/*
 * Traditional DNS header RCODEs (4-bits) defined by IANA in
 * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml
 */

function toString$3 (rcode) {
  switch (rcode) {
    case 0: return 'NOERROR'
    case 1: return 'FORMERR'
    case 2: return 'SERVFAIL'
    case 3: return 'NXDOMAIN'
    case 4: return 'NOTIMP'
    case 5: return 'REFUSED'
    case 6: return 'YXDOMAIN'
    case 7: return 'YXRRSET'
    case 8: return 'NXRRSET'
    case 9: return 'NOTAUTH'
    case 10: return 'NOTZONE'
    case 11: return 'RCODE_11'
    case 12: return 'RCODE_12'
    case 13: return 'RCODE_13'
    case 14: return 'RCODE_14'
    case 15: return 'RCODE_15'
  }
  return 'RCODE_' + rcode
}

/*
 * Traditional DNS header OPCODEs (4-bits) defined by IANA in
 * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-5
 */

function toString$2 (opcode) {
  switch (opcode) {
    case 0: return 'QUERY'
    case 1: return 'IQUERY'
    case 2: return 'STATUS'
    case 3: return 'OPCODE_3'
    case 4: return 'NOTIFY'
    case 5: return 'UPDATE'
    case 6: return 'OPCODE_6'
    case 7: return 'OPCODE_7'
    case 8: return 'OPCODE_8'
    case 9: return 'OPCODE_9'
    case 10: return 'OPCODE_10'
    case 11: return 'OPCODE_11'
    case 12: return 'OPCODE_12'
    case 13: return 'OPCODE_13'
    case 14: return 'OPCODE_14'
    case 15: return 'OPCODE_15'
  }
  return 'OPCODE_' + opcode
}

function toString$1 (klass) {
  switch (klass) {
    case 1: return 'IN'
    case 2: return 'CS'
    case 3: return 'CH'
    case 4: return 'HS'
    case 255: return 'ANY'
  }
  return 'UNKNOWN_' + klass
}

function toClass (name) {
  switch (name.toUpperCase()) {
    case 'IN': return 1
    case 'CS': return 2
    case 'CH': return 3
    case 'HS': return 4
    case 'ANY': return 255
  }
  return 0
}

function toString (type) {
  switch (type) {
    // list at
    // https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-11
    case 1: return 'LLQ'
    case 2: return 'UL'
    case 3: return 'NSID'
    case 5: return 'DAU'
    case 6: return 'DHU'
    case 7: return 'N3U'
    case 8: return 'CLIENT_SUBNET'
    case 9: return 'EXPIRE'
    case 10: return 'COOKIE'
    case 11: return 'TCP_KEEPALIVE'
    case 12: return 'PADDING'
    case 13: return 'CHAIN'
    case 14: return 'KEY_TAG'
    case 26946: return 'DEVICEID'
  }
  if (type < 0) {
    return null
  }
  return `OPTION_${type}`
}

function toCode (name) {
  if (typeof name === 'number') {
    return name
  }
  if (!name) {
    return -1
  }
  switch (name.toUpperCase()) {
    case 'OPTION_0': return 0
    case 'LLQ': return 1
    case 'UL': return 2
    case 'NSID': return 3
    case 'OPTION_4': return 4
    case 'DAU': return 5
    case 'DHU': return 6
    case 'N3U': return 7
    case 'CLIENT_SUBNET': return 8
    case 'EXPIRE': return 9
    case 'COOKIE': return 10
    case 'TCP_KEEPALIVE': return 11
    case 'PADDING': return 12
    case 'CHAIN': return 13
    case 'KEY_TAG': return 14
    case 'DEVICEID': return 26946
    case 'OPTION_65535': return 65535
  }
  const m = name.match(/_(\d+)$/);
  if (m) {
    return parseInt(m[1], 10)
  }
  return -1
}

const SURROGATE_A = 0b1101100000000000;
const SURROGATE_B = 0b1101110000000000;

function encodingLength$1 (str) {
  let len = 0;
  const strLen = str.length;
  for (let i = 0; i < strLen; i += 1) {
    const code = str.charCodeAt(i);
    if (code <= 0x7F) {
      len += 1;
    } else if (code <= 0x07FF) {
      len += 2;
    } else if ((code & 0xF800) !== SURROGATE_A) {
      len += 3;
    } else {
      const next = i + 1;
      if (next === strLen || code >= SURROGATE_B) {
        len += 3;
      } else {
        const nextCode = str.charCodeAt(next);
        if ((nextCode & 0xFC00) !== SURROGATE_B) {
          len += 3;
        } else {
          i = next;
          len += 4;
        }
      }
    }
  }
  return len
}

function encode$1 (str, buf, offset) {
  const strLen = str.length;
  if (offset === undefined || offset === null) {
    offset = 0;
  }
  if (buf === undefined) {
    buf = new Uint8Array(encodingLength$1(str) + offset);
  }
  let off = offset;
  for (let i = 0; i < strLen; i += 1) {
    let code = str.charCodeAt(i);
    if (code <= 0x7F) {
      buf[off++] = code;
    } else if (code <= 0x07FF) {
      buf[off++] = 0b11000000 | ((code & 0b11111000000) >> 6);
      buf[off++] = 0b10000000 | (code & 0b00000111111);
    } else if ((code & 0xF800) !== SURROGATE_A) {
      buf[off++] = 0b11100000 | ((code & 0b1111000000000000) >> 12);
      buf[off++] = 0b10000000 | ((code & 0b0000111111000000) >> 6);
      buf[off++] = 0b10000000 | (code & 0b0000000000111111);
    } else {
      const next = i + 1;
      if (next === strLen || code >= SURROGATE_B) {
        // Incorrectly started surrogate pair
        buf[off++] = 0xef;
        buf[off++] = 0xbf;
        buf[off++] = 0xbd;
      } else {
        const nextCode = str.charCodeAt(next);
        if ((nextCode & 0xFC00) !== SURROGATE_B) {
          // Incorrect surrogate pair
          buf[off++] = 0xef;
          buf[off++] = 0xbf;
          buf[off++] = 0xbd;
        } else {
          i = next;
          code = 0b000010000000000000000 |
            ((code & 0b1111111111) << 10) |
            (nextCode & 0b1111111111);
          buf[off++] = 0b11110000 | ((code & 0b111000000000000000000) >> 18);
          buf[off++] = 0b10000000 | ((code & 0b000111111000000000000) >> 12);
          buf[off++] = 0b10000000 | ((code & 0b000000000111111000000) >> 6);
          buf[off++] = 0b10000000 | (code & 0b000000000000000111111);
        }
      }
    }
  }
  encode$1.bytes = off - offset;
  return buf
}
encode$1.bytes = 0;

function decode$1 (buf, start, end) {
  let result = '';
  if (start === undefined || start === null) {
    start = 0;
  }
  if (end === undefined || end === null) {
    end = buf.length;
  }
  for (let offset = start; offset < end;) {
    const code = buf[offset++];
    let num;
    if (code <= 128) {
      num = code;
    } else if (code > 191 && code < 224) {
      num = ((code & 0b11111) << 6) | (buf[offset++] & 0b111111);
    } else if (code > 239 && code < 365) {
      num = (
        ((code & 0b111) << 18) |
        ((buf[offset++] & 0b111111) << 12) |
        ((buf[offset++] & 0b111111) << 6) |
        (buf[offset++] & 0b111111)
      ) - 0x10000;
      const numA = SURROGATE_A | ((num >> 10) & 0b1111111111);
      result += String.fromCharCode(numA);
      num = SURROGATE_B | (num & 0b1111111111);
    } else {
      num = ((code & 0b1111) << 12) |
        ((buf[offset++] & 0b111111) << 6) |
        (buf[offset++] & 0b111111);
    }
    result += String.fromCharCode(num);
  }
  decode$1.bytes = end - start;
  return result
}
decode$1.bytes = 0;

const isU8Arr = input => input instanceof Uint8Array;

function bytelength (input) {
  return typeof input === 'string' ? encodingLength$1(input) : input.byteLength
}

function from (input) {
  if (input instanceof Uint8Array) {
    return input
  }
  if (Array.isArray(input)) {
    return new Uint8Array(input)
  }
  return encode$1(input)
}

function write (arr, str, start) {
  if (typeof str !== 'string') {
    throw new Error('unknown input type')
  }
  encode$1(str, arr, start);
  return encode$1.bytes
}

const P_24 = Math.pow(2, 24);
const P_16 = Math.pow(2, 16);
const P_8 = Math.pow(2, 8);
const readUInt32BE = (buf, offset) => buf[offset] * P_24 +
  buf[offset + 1] * P_16 +
  buf[offset + 2] * P_8 +
  buf[offset + 3];

const readUInt16BE = (buf, offset) => (buf[offset] << 8) | buf[offset + 1];
const writeUInt32BE = (buf, value, offset) => {
  value = +value;
  buf[offset + 3] = value;
  value = value >>> 8;
  buf[offset + 2] = value;
  value = value >>> 8;
  buf[offset + 1] = value;
  value = value >>> 8;
  buf[offset] = value;
  return offset + 4
};
const writeUInt16BE = (buf, value, offset) => {
  buf[offset] = value >> 8;
  buf[offset + 1] = value & 0xFF;
  return offset + 2
};

function copy (source, target, targetStart, sourceStart, sourceEnd) {
  if (targetStart < 0) {
    sourceStart -= targetStart;
    targetStart = 0;
  }

  if (sourceStart < 0) {
    sourceStart = 0;
  }

  if (sourceEnd < 0) {
    return new Uint8Array(0)
  }

  if (targetStart >= target.length || sourceStart >= sourceEnd) {
    return 0
  }

  return _copyActual(source, target, targetStart, sourceStart, sourceEnd)
}

function _copyActual (source, target, targetStart, sourceStart, sourceEnd) {
  if (sourceEnd - sourceStart > target.length - targetStart) {
    sourceEnd = sourceStart + target.length - targetStart;
  }

  let nb = sourceEnd - sourceStart;
  const sourceLen = source.length - sourceStart;
  if (nb > sourceLen) {
    nb = sourceLen;
  }

  if (sourceStart !== 0 || sourceEnd < source.length) {
    source = new Uint8Array(source.buffer, source.byteOffset + sourceStart, nb);
  }

  target.set(source, targetStart);

  return nb
}

const QUERY_FLAG = 0;
const RESPONSE_FLAG = 1 << 15;
const FLUSH_MASK = 1 << 15;
const NOT_FLUSH_MASK = ~FLUSH_MASK;
const QU_MASK = 1 << 15;
const NOT_QU_MASK = ~QU_MASK;

function codec ({ bytes = 0, encode, decode, encodingLength }) {
  encode.bytes = bytes;
  decode.bytes = bytes;
  return {
    encode,
    decode,
    encodingLength: encodingLength || (() => bytes)
  }
}

const name = codec({
  encode (str, buf, offset) {
    if (!buf) buf = new Uint8Array(name.encodingLength(str));
    if (!offset) offset = 0;
    const oldOffset = offset;

    // strip leading and trailing .
    const n = str.replace(/^\.|\.$/gm, '');
    if (n.length) {
      const list = n.split('.');

      for (let i = 0; i < list.length; i++) {
        const len = write(buf, list[i], offset + 1);
        buf[offset] = len;
        offset += len + 1;
      }
    }

    buf[offset++] = 0;

    name.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const list = [];
    let oldOffset = offset;
    let totalLength = 0;
    let consumedBytes = 0;
    let jumped = false;

    while (true) {
      if (offset >= buf.length) {
        throw new Error('Cannot decode name (buffer overflow)')
      }
      const len = buf[offset++];
      consumedBytes += jumped ? 0 : 1;

      if (len === 0) {
        break
      } else if ((len & 0xc0) === 0) {
        if (offset + len > buf.length) {
          throw new Error('Cannot decode name (buffer overflow)')
        }
        totalLength += len + 1;
        if (totalLength > 254) {
          throw new Error('Cannot decode name (name too long)')
        }
        list.push(decode$1(buf, offset, offset + len));
        offset += len;
        consumedBytes += jumped ? 0 : len;
      } else if ((len & 0xc0) === 0xc0) {
        if (offset + 1 > buf.length) {
          throw new Error('Cannot decode name (buffer overflow)')
        }
        const jumpOffset = readUInt16BE(buf, offset - 1) - 0xc000;
        if (jumpOffset >= oldOffset) {
          // Allow only pointers to prior data. RFC 1035, section 4.1.4 states:
          // "[...] an entire domain name or a list of labels at the end of a domain name
          // is replaced with a pointer to a prior occurance (sic) of the same name."
          throw new Error('Cannot decode name (bad pointer)')
        }
        offset = jumpOffset;
        oldOffset = jumpOffset;
        consumedBytes += jumped ? 0 : 1;
        jumped = true;
      } else {
        throw new Error('Cannot decode name (bad label)')
      }
    }

    name.decode.bytes = consumedBytes;
    return list.length === 0 ? '.' : list.join('.')
  },
  encodingLength (n) {
    if (n === '.' || n === '..') return 1
    return bytelength(n.replace(/^\.|\.$/gm, '')) + 2
  }
});

const string = codec({
  encode (s, buf, offset) {
    if (!buf) buf = new Uint8Array(string.encodingLength(s));
    if (!offset) offset = 0;

    const len = write(buf, s, offset + 1);
    buf[offset] = len;
    string.encode.bytes = len + 1;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = buf[offset];
    const s = decode$1(buf, offset + 1, offset + 1 + len);
    string.decode.bytes = len + 1;
    return s
  },
  encodingLength (s) {
    return bytelength(s) + 1
  }
});

const header = codec({
  bytes: 12,
  encode (h, buf, offset) {
    if (!buf) buf = new Uint8Array(header.encodingLength(h));
    if (!offset) offset = 0;

    const flags = (h.flags || 0) & 32767;
    const type = h.type === 'response' ? RESPONSE_FLAG : QUERY_FLAG;

    writeUInt16BE(buf, h.id || 0, offset);
    writeUInt16BE(buf, flags | type, offset + 2);
    writeUInt16BE(buf, h.questions.length, offset + 4);
    writeUInt16BE(buf, h.answers.length, offset + 6);
    writeUInt16BE(buf, h.authorities.length, offset + 8);
    writeUInt16BE(buf, h.additionals.length, offset + 10);

    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    if (buf.length < 12) throw new Error('Header must be 12 bytes')
    const flags = readUInt16BE(buf, offset + 2);

    return {
      id: readUInt16BE(buf, offset),
      type: flags & RESPONSE_FLAG ? 'response' : 'query',
      flags: flags & 32767,
      flag_qr: ((flags >> 15) & 0x1) === 1,
      opcode: toString$2((flags >> 11) & 0xf),
      flag_aa: ((flags >> 10) & 0x1) === 1,
      flag_tc: ((flags >> 9) & 0x1) === 1,
      flag_rd: ((flags >> 8) & 0x1) === 1,
      flag_ra: ((flags >> 7) & 0x1) === 1,
      flag_z: ((flags >> 6) & 0x1) === 1,
      flag_ad: ((flags >> 5) & 0x1) === 1,
      flag_cd: ((flags >> 4) & 0x1) === 1,
      rcode: toString$3(flags & 0xf),
      questions: new Array(readUInt16BE(buf, offset + 4)),
      answers: new Array(readUInt16BE(buf, offset + 6)),
      authorities: new Array(readUInt16BE(buf, offset + 8)),
      additionals: new Array(readUInt16BE(buf, offset + 10))
    }
  },
  encodingLength () {
    return 12
  }
});

const runknown = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(runknown.encodingLength(data));
    if (!offset) offset = 0;

    const dLen = data.length;
    writeUInt16BE(buf, dLen, offset);
    copy(data, buf, offset + 2, 0, dLen);

    runknown.encode.bytes = dLen + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    const data = buf.slice(offset + 2, offset + 2 + len);
    runknown.decode.bytes = len + 2;
    return data
  },
  encodingLength (data) {
    return data.length + 2
  }
});

const rns = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rns.encodingLength(data));
    if (!offset) offset = 0;

    name.encode(data, buf, offset + 2);
    writeUInt16BE(buf, name.encode.bytes, offset);
    rns.encode.bytes = name.encode.bytes + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    const dd = name.decode(buf, offset + 2);

    rns.decode.bytes = len + 2;
    return dd
  },
  encodingLength (data) {
    return name.encodingLength(data) + 2
  }
});

const rsoa = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rsoa.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    name.encode(data.mname, buf, offset);
    offset += name.encode.bytes;
    name.encode(data.rname, buf, offset);
    offset += name.encode.bytes;
    writeUInt32BE(buf, data.serial || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.refresh || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.retry || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.expire || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.minimum || 0, offset);
    offset += 4;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rsoa.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.mname = name.decode(buf, offset);
    offset += name.decode.bytes;
    data.rname = name.decode(buf, offset);
    offset += name.decode.bytes;
    data.serial = readUInt32BE(buf, offset);
    offset += 4;
    data.refresh = readUInt32BE(buf, offset);
    offset += 4;
    data.retry = readUInt32BE(buf, offset);
    offset += 4;
    data.expire = readUInt32BE(buf, offset);
    offset += 4;
    data.minimum = readUInt32BE(buf, offset);
    offset += 4;

    rsoa.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 22 + name.encodingLength(data.mname) + name.encodingLength(data.rname)
  }
});

const rtxt = codec({
  encode (data, buf, offset) {
    if (!Array.isArray(data)) data = [data];
    for (let i = 0; i < data.length; i++) {
      if (typeof data[i] === 'string') {
        data[i] = from(data[i]);
      }
      if (!isU8Arr(data[i])) {
        throw new Error('Must be a Buffer')
      }
    }

    if (!buf) buf = new Uint8Array(rtxt.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;

    data.forEach(function (d) {
      buf[offset++] = d.length;
      copy(d, buf, offset, 0, d.length);
      offset += d.length;
    });

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rtxt.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;
    let remaining = readUInt16BE(buf, offset);
    offset += 2;

    const data = [];
    while (remaining > 0) {
      const len = buf[offset++];
      --remaining;
      if (remaining < len) {
        throw new Error('Buffer overflow')
      }
      data.push(buf.slice(offset, offset + len));
      offset += len;
      remaining -= len;
    }

    rtxt.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    if (!Array.isArray(data)) data = [data];
    let length = 2;
    data.forEach(function (buf) {
      if (typeof buf === 'string') {
        length += bytelength(buf) + 1;
      } else {
        length += buf.length + 1;
      }
    });
    return length
  }
});

const rnull = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rnull.encodingLength(data));
    if (!offset) offset = 0;

    if (typeof data === 'string') data = from(data);
    if (!data) data = new Uint8Array(0);

    const oldOffset = offset;
    offset += 2;

    const len = data.length;
    copy(data, buf, offset, 0, len);
    offset += len;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rnull.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;
    const len = readUInt16BE(buf, offset);

    offset += 2;

    const data = buf.slice(offset, offset + len);
    offset += len;

    rnull.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    if (!data) return 2
    return (isU8Arr(data) ? data.length : bytelength(data)) + 2
  }
});

const rhinfo = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rhinfo.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    string.encode(data.cpu, buf, offset);
    offset += string.encode.bytes;
    string.encode(data.os, buf, offset);
    offset += string.encode.bytes;
    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rhinfo.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.cpu = string.decode(buf, offset);
    offset += string.decode.bytes;
    data.os = string.decode(buf, offset);
    offset += string.decode.bytes;
    rhinfo.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return string.encodingLength(data.cpu) + string.encodingLength(data.os) + 2
  }
});

const rptr = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rptr.encodingLength(data));
    if (!offset) offset = 0;

    name.encode(data, buf, offset + 2);
    writeUInt16BE(buf, name.encode.bytes, offset);
    rptr.encode.bytes = name.encode.bytes + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const data = name.decode(buf, offset + 2);
    rptr.decode.bytes = name.decode.bytes + 2;
    return data
  },
  encodingLength (data) {
    return name.encodingLength(data) + 2
  }
});

const rsrv = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rsrv.encodingLength(data));
    if (!offset) offset = 0;

    writeUInt16BE(buf, data.priority || 0, offset + 2);
    writeUInt16BE(buf, data.weight || 0, offset + 4);
    writeUInt16BE(buf, data.port || 0, offset + 6);
    name.encode(data.target, buf, offset + 8);

    const len = name.encode.bytes + 6;
    writeUInt16BE(buf, len, offset);

    rsrv.encode.bytes = len + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);

    const data = {};
    data.priority = readUInt16BE(buf, offset + 2);
    data.weight = readUInt16BE(buf, offset + 4);
    data.port = readUInt16BE(buf, offset + 6);
    data.target = name.decode(buf, offset + 8);

    rsrv.decode.bytes = len + 2;
    return data
  },
  encodingLength (data) {
    return 8 + name.encodingLength(data.target)
  }
});

const rcaa = codec({
  encode (data, buf, offset) {
    const len = rcaa.encodingLength(data);

    if (!buf) buf = new Uint8Array(rcaa.encodingLength(data));
    if (!offset) offset = 0;

    if (data.issuerCritical) {
      data.flags = rcaa.ISSUER_CRITICAL;
    }

    writeUInt16BE(buf, len - 2, offset);
    offset += 2;
    buf[offset] = data.flags || 0;
    offset += 1;
    string.encode(data.tag, buf, offset);
    offset += string.encode.bytes;
    write(buf, data.value, offset);
    offset += bytelength(data.value);

    rcaa.encode.bytes = len;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    offset += 2;

    const oldOffset = offset;
    const data = {};
    data.flags = buf[offset];
    offset += 1;
    data.tag = string.decode(buf, offset);
    offset += string.decode.bytes;
    data.value = decode$1(buf, offset, oldOffset + len);

    data.issuerCritical = !!(data.flags & rcaa.ISSUER_CRITICAL);

    rcaa.decode.bytes = len + 2;

    return data
  },
  encodingLength (data) {
    return string.encodingLength(data.tag) + string.encodingLength(data.value) + 2
  }
});

rcaa.ISSUER_CRITICAL = 1 << 7;

const rmx = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rmx.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    writeUInt16BE(buf, data.preference || 0, offset);
    offset += 2;
    name.encode(data.exchange, buf, offset);
    offset += name.encode.bytes;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rmx.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.preference = readUInt16BE(buf, offset);
    offset += 2;
    data.exchange = name.decode(buf, offset);
    offset += name.decode.bytes;

    rmx.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 4 + name.encodingLength(data.exchange)
  }
});

const ra = codec({
  encode (host, buf, offset) {
    if (!buf) buf = new Uint8Array(ra.encodingLength(host));
    if (!offset) offset = 0;

    writeUInt16BE(buf, 4, offset);
    offset += 2;
    v4.encode(host, buf, offset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    offset += 2;
    const host = v4.decode(buf, offset);
    return host
  },
  bytes: 6
});

const raaaa = codec({
  encode (host, buf, offset) {
    if (!buf) buf = new Uint8Array(raaaa.encodingLength(host));
    if (!offset) offset = 0;

    writeUInt16BE(buf, 16, offset);
    offset += 2;
    v6.encode(host, buf, offset);
    raaaa.encode.bytes = 18;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    offset += 2;
    const host = v6.decode(buf, offset);
    raaaa.decode.bytes = 18;
    return host
  },
  bytes: 18
});

const alloc = size => new Uint8Array(size);

const roption = codec({
  encode (option, buf, offset) {
    if (!buf) buf = new Uint8Array(roption.encodingLength(option));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const code = toCode(option.code);
    writeUInt16BE(buf, code, offset);
    offset += 2;
    if (option.data) {
      writeUInt16BE(buf, option.data.length, offset);
      offset += 2;
      copy(option.data, buf, offset);
      offset += option.data.length;
    } else {
      switch (code) {
        // case 3: NSID.  No encode makes sense.
        // case 5,6,7: Not implementable
        case 8: // ECS
          {
            // note: do IP math before calling
            const spl = option.sourcePrefixLength || 0;
            const fam = option.family || familyOf(option.ip);
            const ipBuf = encode$2(option.ip, alloc);
            const ipLen = Math.ceil(spl / 8);
            writeUInt16BE(buf, ipLen + 4, offset);
            offset += 2;
            writeUInt16BE(buf, fam, offset);
            offset += 2;
            buf[offset++] = spl;
            buf[offset++] = option.scopePrefixLength || 0;

            copy(ipBuf, buf, offset, 0, ipLen);
            offset += ipLen;
          }
          break
        // case 9: EXPIRE (experimental)
        // case 10: COOKIE.  No encode makes sense.
        case 11: // KEEP-ALIVE
          if (option.timeout) {
            writeUInt16BE(buf, 2, offset);
            offset += 2;
            writeUInt16BE(buf, option.timeout, offset);
            offset += 2;
          } else {
            writeUInt16BE(buf, 0, offset);
            offset += 2;
          }
          break
        case 12: // PADDING
          {
            const len = option.length || 0;
            writeUInt16BE(buf, len, offset);
            offset += 2;
            buf.fill(0, offset, offset + len);
            offset += len;
          }
          break
        // case 13:  CHAIN.  Experimental.
        case 14: // KEY-TAG
          {
            const tagsLen = option.tags.length * 2;
            writeUInt16BE(buf, tagsLen, offset);
            offset += 2;
            for (const tag of option.tags) {
              writeUInt16BE(buf, tag, offset);
              offset += 2;
            }
          }
          break
        default:
          throw new Error(`Unknown roption code: ${option.code}`)
      }
    }

    roption.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const option = {};
    option.code = readUInt16BE(buf, offset);
    option.type = toString(option.code);
    offset += 2;
    const len = readUInt16BE(buf, offset);
    offset += 2;
    option.data = buf.slice(offset, offset + len);
    switch (option.code) {
      // case 3: NSID.  No decode makes sense.
      case 8: // ECS
        option.family = readUInt16BE(buf, offset);
        offset += 2;
        option.sourcePrefixLength = buf[offset++];
        option.scopePrefixLength = buf[offset++];
        {
          const padded = new Uint8Array((option.family === 1) ? 4 : 16);
          copy(buf, padded, 0, offset, offset + len - 4);
          option.ip = decode$2(padded);
        }
        break
      // case 12: Padding.  No decode makes sense.
      case 11: // KEEP-ALIVE
        if (len > 0) {
          option.timeout = readUInt16BE(buf, offset);
          offset += 2;
        }
        break
      case 14:
        option.tags = [];
        for (let i = 0; i < len; i += 2) {
          option.tags.push(readUInt16BE(buf, offset));
          offset += 2;
        }
      // don't worry about default.  caller will use data if desired
    }

    roption.decode.bytes = len + 4;
    return option
  },
  encodingLength (option) {
    if (option.data) {
      return option.data.length + 4
    }
    const code = toCode(option.code);
    switch (code) {
      case 8: // ECS
      {
        const spl = option.sourcePrefixLength || 0;
        return Math.ceil(spl / 8) + 8
      }
      case 11: // KEEP-ALIVE
        return (typeof option.timeout === 'number') ? 6 : 4
      case 12: // PADDING
        return option.length + 4
      case 14: // KEY-TAG
        return 4 + (option.tags.length * 2)
    }
    throw new Error(`Unknown roption code: ${option.code}`)
  }
});

const ropt = codec({
  encode (options, buf, offset) {
    if (!buf) buf = new Uint8Array(ropt.encodingLength(options));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const rdlen = encodingLengthList(options, roption);
    writeUInt16BE(buf, rdlen, offset);
    offset = encodeList(options, roption, buf, offset + 2);

    ropt.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const options = [];
    let rdlen = readUInt16BE(buf, offset);
    offset += 2;
    let o = 0;
    while (rdlen > 0) {
      options[o++] = roption.decode(buf, offset);
      offset += roption.decode.bytes;
      rdlen -= roption.decode.bytes;
    }
    ropt.decode.bytes = offset - oldOffset;
    return options
  },
  encodingLength (options) {
    return 2 + encodingLengthList(options || [], roption)
  }
});

const rdnskey = codec({
  encode (key, buf, offset) {
    if (!buf) buf = new Uint8Array(rdnskey.encodingLength(key));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const keydata = key.key;
    if (!isU8Arr(keydata)) {
      throw new Error('Key must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, key.flags, offset);
    offset += 2;
    buf[offset] = rdnskey.PROTOCOL_DNSSEC;
    offset += 1;
    buf[offset] = key.algorithm;
    offset += 1;
    copy(keydata, buf, offset, 0, keydata.length);
    offset += keydata.length;

    rdnskey.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rdnskey.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const key = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    key.flags = readUInt16BE(buf, offset);
    offset += 2;
    if (buf[offset] !== rdnskey.PROTOCOL_DNSSEC) {
      throw new Error('Protocol must be 3')
    }
    offset += 1;
    key.algorithm = buf[offset];
    offset += 1;
    key.key = buf.slice(offset, oldOffset + length + 2);
    offset += key.key.length;
    rdnskey.decode.bytes = offset - oldOffset;
    return key
  },
  encodingLength (key) {
    return 6 + bytelength(key.key)
  }
});

rdnskey.PROTOCOL_DNSSEC = 3;
rdnskey.ZONE_KEY = 0x80;
rdnskey.SECURE_ENTRYPOINT = 0x8000;

const rrrsig = codec({
  encode (sig, buf, offset) {
    if (!buf) buf = new Uint8Array(rrrsig.encodingLength(sig));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const signature = sig.signature;
    if (!isU8Arr(signature)) {
      throw new Error('Signature must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, toType(sig.typeCovered), offset);
    offset += 2;
    buf[offset] = sig.algorithm;
    offset += 1;
    buf[offset] = sig.labels;
    offset += 1;
    writeUInt32BE(buf, sig.originalTTL, offset);
    offset += 4;
    writeUInt32BE(buf, sig.expiration, offset);
    offset += 4;
    writeUInt32BE(buf, sig.inception, offset);
    offset += 4;
    writeUInt16BE(buf, sig.keyTag, offset);
    offset += 2;
    name.encode(sig.signersName, buf, offset);
    offset += name.encode.bytes;
    copy(signature, buf, offset, 0, signature.length);
    offset += signature.length;

    rrrsig.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rrrsig.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const sig = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    sig.typeCovered = toString$4(readUInt16BE(buf, offset));
    offset += 2;
    sig.algorithm = buf[offset];
    offset += 1;
    sig.labels = buf[offset];
    offset += 1;
    sig.originalTTL = readUInt32BE(buf, offset);
    offset += 4;
    sig.expiration = readUInt32BE(buf, offset);
    offset += 4;
    sig.inception = readUInt32BE(buf, offset);
    offset += 4;
    sig.keyTag = readUInt16BE(buf, offset);
    offset += 2;
    sig.signersName = name.decode(buf, offset);
    offset += name.decode.bytes;
    sig.signature = buf.slice(offset, oldOffset + length + 2);
    offset += sig.signature.length;
    rrrsig.decode.bytes = offset - oldOffset;
    return sig
  },
  encodingLength (sig) {
    return 20 +
      name.encodingLength(sig.signersName) +
      bytelength(sig.signature)
  }
});
const rrp = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rrp.encodingLength(data));
    if (!offset) offset = 0;
    const oldOffset = offset;

    offset += 2; // Leave space for length
    name.encode(data.mbox || '.', buf, offset);
    offset += name.encode.bytes;
    name.encode(data.txt || '.', buf, offset);
    offset += name.encode.bytes;
    rrp.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rrp.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.mbox = name.decode(buf, offset) || '.';
    offset += name.decode.bytes;
    data.txt = name.decode(buf, offset) || '.';
    offset += name.decode.bytes;
    rrp.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 2 + name.encodingLength(data.mbox || '.') + name.encodingLength(data.txt || '.')
  }
});

const typebitmap = codec({
  encode (typelist, buf, offset) {
    if (!buf) buf = new Uint8Array(typebitmap.encodingLength(typelist));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const typesByWindow = [];
    for (let i = 0; i < typelist.length; i++) {
      const typeid = toType(typelist[i]);
      if (typesByWindow[typeid >> 8] === undefined) {
        typesByWindow[typeid >> 8] = [];
      }
      typesByWindow[typeid >> 8][(typeid >> 3) & 0x1F] |= 1 << (7 - (typeid & 0x7));
    }

    for (let i = 0; i < typesByWindow.length; i++) {
      if (typesByWindow[i] !== undefined) {
        const windowBuf = from(typesByWindow[i]);
        buf[offset] = i;
        offset += 1;
        buf[offset] = windowBuf.length;
        offset += 1;
        copy(windowBuf, buf, offset, 0, windowBuf.length);
        offset += windowBuf.length;
      }
    }

    typebitmap.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset, length) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const typelist = [];
    while (offset - oldOffset < length) {
      const window = buf[offset];
      offset += 1;
      const windowLength = buf[offset];
      offset += 1;
      for (let i = 0; i < windowLength; i++) {
        const b = buf[offset + i];
        for (let j = 0; j < 8; j++) {
          if (b & (1 << (7 - j))) {
            const typeid = toString$4((window << 8) | (i << 3) | j);
            typelist.push(typeid);
          }
        }
      }
      offset += windowLength;
    }

    typebitmap.decode.bytes = offset - oldOffset;
    return typelist
  },
  encodingLength (typelist) {
    const extents = [];
    for (let i = 0; i < typelist.length; i++) {
      const typeid = toType(typelist[i]);
      extents[typeid >> 8] = Math.max(extents[typeid >> 8] || 0, typeid & 0xFF);
    }

    let len = 0;
    for (let i = 0; i < extents.length; i++) {
      if (extents[i] !== undefined) {
        len += 2 + Math.ceil((extents[i] + 1) / 8);
      }
    }

    return len
  }
});

const rnsec = codec({
  encode (record, buf, offset) {
    if (!buf) buf = new Uint8Array(rnsec.encodingLength(record));
    if (!offset) offset = 0;
    const oldOffset = offset;

    offset += 2; // Leave space for length
    name.encode(record.nextDomain, buf, offset);
    offset += name.encode.bytes;
    typebitmap.encode(record.rrtypes, buf, offset);
    offset += typebitmap.encode.bytes;

    rnsec.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rnsec.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const record = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    record.nextDomain = name.decode(buf, offset);
    offset += name.decode.bytes;
    record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset));
    offset += typebitmap.decode.bytes;

    rnsec.decode.bytes = offset - oldOffset;
    return record
  },
  encodingLength (record) {
    return 2 +
      name.encodingLength(record.nextDomain) +
      typebitmap.encodingLength(record.rrtypes)
  }
});

const rnsec3 = codec({
  encode (record, buf, offset) {
    if (!buf) buf = new Uint8Array(rnsec3.encodingLength(record));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const salt = record.salt;
    if (!isU8Arr(salt)) {
      throw new Error('salt must be a Buffer')
    }

    const nextDomain = record.nextDomain;
    if (!isU8Arr(nextDomain)) {
      throw new Error('nextDomain must be a Buffer')
    }

    offset += 2; // Leave space for length
    buf[offset] = record.algorithm;
    offset += 1;
    buf[offset] = record.flags;
    offset += 1;
    writeUInt16BE(buf, record.iterations, offset);
    offset += 2;
    buf[offset] = salt.length;
    offset += 1;
    copy(salt, buf, offset, 0, salt.length);
    offset += salt.length;
    buf[offset] = nextDomain.length;
    offset += 1;
    copy(nextDomain, buf, offset, 0, nextDomain.length);
    offset += nextDomain.length;
    typebitmap.encode(record.rrtypes, buf, offset);
    offset += typebitmap.encode.bytes;

    rnsec3.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rnsec3.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const record = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    record.algorithm = buf[offset];
    offset += 1;
    record.flags = buf[offset];
    offset += 1;
    record.iterations = readUInt16BE(buf, offset);
    offset += 2;
    const saltLength = buf[offset];
    offset += 1;
    record.salt = buf.slice(offset, offset + saltLength);
    offset += saltLength;
    const hashLength = buf[offset];
    offset += 1;
    record.nextDomain = buf.slice(offset, offset + hashLength);
    offset += hashLength;
    record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset));
    offset += typebitmap.decode.bytes;

    rnsec3.decode.bytes = offset - oldOffset;
    return record
  },
  encodingLength (record) {
    return 8 +
      record.salt.length +
      record.nextDomain.length +
      typebitmap.encodingLength(record.rrtypes)
  }
});

const rds = codec({
  encode (digest, buf, offset) {
    if (!buf) buf = new Uint8Array(rds.encodingLength(digest));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const digestdata = digest.digest;
    if (!isU8Arr(digestdata)) {
      throw new Error('Digest must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, digest.keyTag, offset);
    offset += 2;
    buf[offset] = digest.algorithm;
    offset += 1;
    buf[offset] = digest.digestType;
    offset += 1;
    copy(digestdata, buf, offset, 0, digestdata.length);
    offset += digestdata.length;

    rds.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rds.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const digest = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    digest.keyTag = readUInt16BE(buf, offset);
    offset += 2;
    digest.algorithm = buf[offset];
    offset += 1;
    digest.digestType = buf[offset];
    offset += 1;
    digest.digest = buf.slice(offset, oldOffset + length + 2);
    offset += digest.digest.length;
    rds.decode.bytes = offset - oldOffset;
    return digest
  },
  encodingLength (digest) {
    return 6 + bytelength(digest.digest)
  }
});

function renc (type) {
  switch (type.toUpperCase()) {
    case 'A': return ra
    case 'PTR': return rptr
    case 'CNAME': return rptr
    case 'DNAME': return rptr
    case 'TXT': return rtxt
    case 'NULL': return rnull
    case 'AAAA': return raaaa
    case 'SRV': return rsrv
    case 'HINFO': return rhinfo
    case 'CAA': return rcaa
    case 'NS': return rns
    case 'SOA': return rsoa
    case 'MX': return rmx
    case 'OPT': return ropt
    case 'DNSKEY': return rdnskey
    case 'RRSIG': return rrrsig
    case 'RP': return rrp
    case 'NSEC': return rnsec
    case 'NSEC3': return rnsec3
    case 'DS': return rds
  }
  return runknown
}

const answer = codec({
  encode (a, buf, offset) {
    if (!buf) buf = new Uint8Array(answer.encodingLength(a));
    if (!offset) offset = 0;

    const oldOffset = offset;

    name.encode(a.name, buf, offset);
    offset += name.encode.bytes;

    writeUInt16BE(buf, toType(a.type), offset);

    if (a.type.toUpperCase() === 'OPT') {
      if (a.name !== '.') {
        throw new Error('OPT name must be root.')
      }
      writeUInt16BE(buf, a.udpPayloadSize || 4096, offset + 2);
      buf[offset + 4] = a.extendedRcode || 0;
      buf[offset + 5] = a.ednsVersion || 0;
      writeUInt16BE(buf, a.flags || 0, offset + 6);

      offset += 8;
      ropt.encode(a.options || [], buf, offset);
      offset += ropt.encode.bytes;
    } else {
      let klass = toClass(a.class === undefined ? 'IN' : a.class);
      if (a.flush) klass |= FLUSH_MASK; // the 1st bit of the class is the flush bit
      writeUInt16BE(buf, klass, offset + 2);
      writeUInt32BE(buf, a.ttl || 0, offset + 4);

      offset += 8;
      const enc = renc(a.type);
      enc.encode(a.data, buf, offset);
      offset += enc.encode.bytes;
    }

    answer.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const a = {};
    const oldOffset = offset;

    a.name = name.decode(buf, offset);
    offset += name.decode.bytes;
    a.type = toString$4(readUInt16BE(buf, offset));
    if (a.type === 'OPT') {
      a.udpPayloadSize = readUInt16BE(buf, offset + 2);
      a.extendedRcode = buf[offset + 4];
      a.ednsVersion = buf[offset + 5];
      a.flags = readUInt16BE(buf, offset + 6);
      a.flag_do = ((a.flags >> 15) & 0x1) === 1;
      a.options = ropt.decode(buf, offset + 8);
      offset += 8 + ropt.decode.bytes;
    } else {
      const klass = readUInt16BE(buf, offset + 2);
      a.ttl = readUInt32BE(buf, offset + 4);

      a.class = toString$1(klass & NOT_FLUSH_MASK);
      a.flush = !!(klass & FLUSH_MASK);

      const enc = renc(a.type);
      a.data = enc.decode(buf, offset + 8);
      offset += 8 + enc.decode.bytes;
    }

    answer.decode.bytes = offset - oldOffset;
    return a
  },
  encodingLength (a) {
    const data = (a.data !== null && a.data !== undefined) ? a.data : a.options;
    return name.encodingLength(a.name) + 8 + renc(a.type).encodingLength(data)
  }
});

const question = codec({
  encode (q, buf, offset) {
    if (!buf) buf = new Uint8Array(question.encodingLength(q));
    if (!offset) offset = 0;

    const oldOffset = offset;

    name.encode(q.name, buf, offset);
    offset += name.encode.bytes;

    writeUInt16BE(buf, toType(q.type), offset);
    offset += 2;

    writeUInt16BE(buf, toClass(q.class === undefined ? 'IN' : q.class), offset);
    offset += 2;

    question.encode.bytes = offset - oldOffset;
    return q
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;
    const q = {};

    q.name = name.decode(buf, offset);
    offset += name.decode.bytes;

    q.type = toString$4(readUInt16BE(buf, offset));
    offset += 2;

    q.class = toString$1(readUInt16BE(buf, offset));
    offset += 2;

    const qu = !!(q.class & QU_MASK);
    if (qu) q.class &= NOT_QU_MASK;

    question.decode.bytes = offset - oldOffset;
    return q
  },
  encodingLength (q) {
    return name.encodingLength(q.name) + 4
  }
});
const RECURSION_DESIRED = 1 << 8;

const packet = {
  encode: function (result, buf, offset) {
    const allocing = !buf;

    if (allocing) buf = new Uint8Array(encodingLength(result));
    if (!offset) offset = 0;

    const oldOffset = offset;

    if (!result.questions) result.questions = [];
    if (!result.answers) result.answers = [];
    if (!result.authorities) result.authorities = [];
    if (!result.additionals) result.additionals = [];

    header.encode(result, buf, offset);
    offset += header.encode.bytes;

    offset = encodeList(result.questions, question, buf, offset);
    offset = encodeList(result.answers, answer, buf, offset);
    offset = encodeList(result.authorities, answer, buf, offset);
    offset = encodeList(result.additionals, answer, buf, offset);

    packet.encode.bytes = offset - oldOffset;

    // just a quick sanity check
    if (allocing && encode.bytes !== buf.length) {
      return buf.slice(0, encode.bytes)
    }

    return buf
  },
  decode: function (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;
    const result = header.decode(buf, offset);
    offset += header.decode.bytes;

    offset = decodeList(result.questions, question, buf, offset);
    offset = decodeList(result.answers, answer, buf, offset);
    offset = decodeList(result.authorities, answer, buf, offset);
    offset = decodeList(result.additionals, answer, buf, offset);

    packet.decode.bytes = offset - oldOffset;

    return result
  },
  encodingLength: function (result) {
    return header.encodingLength(result) +
      encodingLengthList(result.questions || [], question) +
      encodingLengthList(result.answers || [], answer) +
      encodingLengthList(result.authorities || [], answer) +
      encodingLengthList(result.additionals || [], answer)
  }
};
packet.encode.bytes = 0;
packet.decode.bytes = 0;

const encode = packet.encode;
const decode = packet.decode;
const encodingLength = packet.encodingLength;

function encodingLengthList (list, enc) {
  let len = 0;
  for (let i = 0; i < list.length; i++) len += enc.encodingLength(list[i]);
  return len
}

function encodeList (list, enc, buf, offset) {
  for (let i = 0; i < list.length; i++) {
    enc.encode(list[i], buf, offset);
    offset += enc.encode.bytes;
  }
  return offset
}

function decodeList (list, enc, buf, offset) {
  for (let i = 0; i < list.length; i++) {
    list[i] = enc.decode(buf, offset);
    offset += enc.decode.bytes;
  }
  return offset
}

const PREFERS_PADDING = 1;
const PREFERS_NO_PADDING = 2;

function make (name, charset, padding, paddingMode) {
  if (charset.length !== 64) {
    throw new Error(`Charset needs to be 64 characters long! (${charset.length})`)
  }
  const byCharCode = new Uint8Array(256);
  const byNum = new Uint8Array(64);
  for (let i = 0; i < 64; i += 1) {
    const code = charset.charCodeAt(i);
    if (code > 255) {
      throw new Error(`Character #${i} in charset [code=${code}, char=${charset.charAt(i)}] is too high! (max=255)`)
    }
    if (byCharCode[code] !== 0) {
      throw new Error(`Character [code=${code}, char=${charset.charAt(i)}] is more than once in the charset!`)
    }
    byCharCode[code] = i;
    byNum[i] = code;
  }
  const padCode = padding.charCodeAt(0);
  const codec = {
    name,
    encodingLength (str) {
      const strLen = str.length;
      const len = strLen * 0.75 | 0;
      if (str.charCodeAt(strLen - 1) === padCode) {
        if (str.charCodeAt(strLen - 2) === padCode) {
          return len - 2
        }
        return len - 1
      }
      return len
    },
    encode (str, buffer, offset) {
      if (buffer === null || buffer === undefined) {
        buffer = new Uint8Array(codec.encodingLength(str));
      }
      if (offset === null || offset === undefined) {
        offset = 0;
      }

      let strLen = str.length;
      if (str.charCodeAt(strLen - 1) === padCode) {
        if (str.charCodeAt(strLen - 2) === padCode) {
          strLen -= 2;
        } else {
          strLen -= 1;
        }
      }

      const padding = strLen % 4;
      const safeLen = strLen - padding;

      let off = offset;
      let i = 0;
      while (i < safeLen) {
        const code =
          (byCharCode[str.charCodeAt(i)] << 18) |
          (byCharCode[str.charCodeAt(i + 1)] << 12) |
          (byCharCode[str.charCodeAt(i + 2)] << 6) |
          byCharCode[str.charCodeAt(i + 3)];
        buffer[off++] = code >> 16;
        buffer[off++] = code >> 8;
        buffer[off++] = code;
        i += 4;
      }

      if (padding === 3) {
        const code =
          (byCharCode[str.charCodeAt(i)] << 10) |
          (byCharCode[str.charCodeAt(i + 1)] << 4) |
          (byCharCode[str.charCodeAt(i + 2)] >> 2);
        buffer[off++] = code >> 8;
        buffer[off++] = code;
      } else if (padding === 2) {
        buffer[off++] = (byCharCode[str.charCodeAt(i)] << 2) |
          (byCharCode[str.charCodeAt(i + 1)] >> 4);
      }

      codec.encode.bytes = off - offset;
      return buffer
    },
    decode (buffer, start, end) {
      if (start === null || start === undefined) {
        start = 0;
      }
      if (end === null || end === undefined) {
        end = buffer.length;
      }

      const length = end - start;
      const pad = length % 3;
      const safeEnd = start + length - pad;
      const codes = [];
      for (let off = start; off < safeEnd; off += 3) {
        const num = (buffer[off] << 16) | ((buffer[off + 1] << 8)) | buffer[off + 2];
        codes.push(
          byNum[num >> 18 & 0x3F],
          byNum[num >> 12 & 0x3F],
          byNum[num >> 6 & 0x3F],
          byNum[num & 0x3F]
        );
      }

      if (pad === 2) {
        const num = (buffer[end - 2] << 8) + buffer[end - 1];
        codes.push(
          byNum[num >> 10],
          byNum[(num >> 4) & 0x3F],
          byNum[(num << 2) & 0x3F]
        );
        if (paddingMode === PREFERS_PADDING) {
          codes.push(padCode);
        }
      } else if (pad === 1) {
        const num = buffer[end - 1];
        codes.push(
          byNum[num >> 2],
          byNum[(num << 4) & 0x3F]
        );
        if (paddingMode === PREFERS_PADDING) {
          codes.push(padCode, padCode);
        }
      }

      codec.decode.bytes = length;
      return String.fromCharCode.apply(String, codes)
    }
  };
  return codec
}

make('base64', 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/', '=', PREFERS_PADDING);
// https://datatracker.ietf.org/doc/html/rfc4648#section-5
const base64URL = make('base64-url', 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_', '=', PREFERS_NO_PADDING);

let AbortError = typeof global !== 'undefined' ? global.AbortError : typeof window !== 'undefined' ? window.AbortError : null;
if (!AbortError) {
  AbortError = class AbortError extends Error {
    constructor (message = 'Request aborted.') {
      super(message);
    }
  };
}
AbortError.prototype.name = 'AbortError';
AbortError.prototype.code = 'ABORT_ERR';

const URL$1 = (typeof globalThis !== 'undefined' && globalThis.URL) || require('url').URL;

class HTTPStatusError extends Error {
  constructor (uri, code, method) {
    super('status=' + code + ' while requesting ' + uri + ' [' + method + ']');
    this.uri = uri;
    this.status = code;
    this.method = method;
  }

  toJSON () {
    return {
      code: this.code,
      uri: this.uri,
      status: this.status,
      method: this.method,
      endpoint: this.endpoint
    }
  }
}
HTTPStatusError.prototype.name = 'HTTPStatusError';
HTTPStatusError.prototype.code = 'HTTP_STATUS';

class ResponseError extends Error {
  constructor (message, cause) {
    super(message);
    this.cause = cause;
  }

  toJSON () {
    return {
      message: this.message,
      endpoint: this.endpoint,
      code: this.code,
      cause: reduceError(this.cause)
    }
  }
}
ResponseError.prototype.name = 'ResponseError';
ResponseError.prototype.code = 'RESPONSE_ERR';

class TimeoutError extends Error {
  constructor (timeout) {
    super('Timeout (t=' + timeout + ').');
    this.timeout = timeout;
  }

  toJSON () {
    return {
      code: this.code,
      endpoint: this.endpoint,
      timeout: this.timeout
    }
  }
}
TimeoutError.prototype.name = 'TimeoutError';
TimeoutError.prototype.code = 'ETIMEOUT';

const v4Regex = /^((\d{1,3}\.){3,3}\d{1,3})(:(\d{2,5}))?$/;
const v6Regex = /^((::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?)(:(\d{2,5}))?$/i;

function reduceError (err) {
  if (typeof err === 'string') {
    return {
      message: err
    }
  }
  try {
    const json = JSON.stringify(err);
    if (json !== '{}') {
      return JSON.parse(json)
    }
  } catch (e) {}
  const error = {
    message: String(err.message || err)
  };
  if (err.code !== undefined) {
    error.code = String(err.code);
  }
  return error
}

const baseParts = /^(([a-z0-9]+:)\/\/)?([^/[\s:]+|\[[^\]]+\])?(:([^/\s]+))?(\/[^\s]*)?(.*)$/;
const httpFlags = /\[(post|get|((ipv4|ipv6|name)=([^\]]+)))\]/ig;
const updFlags = /\[(((pk|name)=([^\]]+)))\]/ig;

function parseEndpoint (endpoint) {
  const parts = baseParts.exec(endpoint);
  const protocol = parts[2] || 'https:';
  const host = parts[3];
  const port = parts[5];
  const path = parts[6];
  const rest = parts[7];
  if (protocol === 'https:' || protocol === 'http:') {
    const flags = parseFlags(rest, httpFlags);
    return {
      name: flags.name,
      protocol,
      ipv4: flags.ipv4,
      ipv6: flags.ipv6,
      host,
      port,
      path,
      method: flags.post ? 'POST' : 'GET'
    }
  }
  if (protocol === 'udp:' || protocol === 'udp4:' || protocol === 'udp6:') {
    const flags = parseFlags(rest, updFlags);
    const v6Parts = /^\[(.*)\]$/.exec(host);
    if (v6Parts && protocol === 'udp4:') {
      throw new Error(`Endpoint parsing error: Cannot use ipv6 host with udp4: (endpoint=${endpoint})`)
    }
    if (!v6Parts && protocol === 'udp6:') {
      throw new Error(`Endpoint parsing error: Incorrectly formatted host for udp6: (endpoint=${endpoint})`)
    }
    if (v6Parts) {
      return new UDP6Endpoint({ protocol: 'udp6:', ipv6: v6Parts[1], port, pk: flags.pk, name: flags.name })
    }
    return new UDP4Endpoint({ protocol: 'udp4:', ipv4: host, port, pk: flags.pk, name: flags.name })
  }
  throw new InvalidProtocolError(protocol, endpoint)
}

function parseFlags (rest, regex) {
  regex.lastIndex = 0;
  const result = {};
  while (true) {
    const match = regex.exec(rest);
    if (!match) break
    if (match[2]) {
      result[match[3].toLowerCase()] = match[4];
    } else {
      result[match[1].toLowerCase()] = true;
    }
  }
  return result
}

class InvalidProtocolError extends Error {
  constructor (protocol, endpoint) {
    super(`Invalid Endpoint: unsupported protocol "${protocol}" for endpoint: ${endpoint}, supported protocols: ${supportedProtocols.join(', ')}`);
    this.protocol = protocol;
    this.endpoint = endpoint;
  }

  toJSON () {
    return {
      code: this.code,
      endpoint: this.endpoint,
      timeout: this.timeout
    }
  }
}
InvalidProtocolError.prototype.name = 'InvalidProtocolError';
InvalidProtocolError.prototype.code = 'EPROTOCOL';

const supportedProtocols = ['http:', 'https:', 'udp4:', 'udp6:'];

class BaseEndpoint {
  constructor (opts, isHTTP) {
    this.name = opts.name || null;
    this.protocol = opts.protocol;
    const port = typeof opts.port === 'string' ? opts.port = parseInt(opts.port, 10) : opts.port;
    if (port === undefined || port === null) {
      this.port = isHTTP
        ? (this.protocol === 'https:' ? 443 : 80)
        : (opts.pk ? 443 : 53);
    } else if (typeof port !== 'number' && !isNaN(port)) {
      throw new Error(`Invalid Endpoint: port "${opts.port}" needs to be a number: ${JSON.stringify(opts)}`)
    } else {
      this.port = port;
    }
  }

  toJSON () {
    return this.toString()
  }
}

class UDPEndpoint extends BaseEndpoint {
  constructor (opts) {
    super(opts, false);
    this.pk = opts.pk || null;
  }

  toString () {
    const port = this.port !== (this.pk ? 443 : 53) ? `:${this.port}` : '';
    const pk = this.pk ? ` [pk=${this.pk}]` : '';
    const name = this.name ? ` [name=${this.name}]` : '';
    return `udp://${this.ipv4 || `[${this.ipv6}]`}${port}${pk}${name}`
  }
}

class UDP4Endpoint extends UDPEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'udp4:' }, opts));
    if (!opts.ipv4 || typeof opts.ipv4 !== 'string') {
      throw new Error(`Invalid Endpoint: .ipv4 "${opts.ipv4}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.ipv4 = opts.ipv4;
  }
}

class UDP6Endpoint extends UDPEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'udp6:' }, opts));
    if (!opts.ipv6 || typeof opts.ipv6 !== 'string') {
      throw new Error(`Invalid Endpoint: .ipv6 "${opts.ipv6}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.ipv6 = opts.ipv6;
  }
}

function safeHost (host) {
  return v6Regex.test(host) && !v4Regex.test(host) ? `[${host}]` : host
}

class HTTPEndpoint extends BaseEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'https:' }, opts), true);
    if (!opts.host) {
      if (opts.ipv4) {
        opts.host = opts.ipv4;
      }
      if (opts.ipv6) {
        opts.host = `[${opts.ipv6}]`;
      }
    }
    if (!opts.host || typeof opts.host !== 'string') {
      throw new Error(`Invalid Endpoint: host "${opts.path}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.host = opts.host;
    this.path = opts.path || '/dns-query';
    this.method = /^post$/i.test(opts.method) ? 'POST' : 'GET';
    this.ipv4 = opts.ipv4;
    this.ipv6 = opts.ipv6;
    if (!this.ipv6) {
      const v6Parts = v6Regex.exec(this.host);
      if (v6Parts) {
        this.ipv6 = v6Parts[1];
      }
    }
    if (!this.ipv4) {
      if (v4Regex.test(this.host)) {
        this.ipv4 = this.host;
      }
    }
    const url = `${this.protocol}//${safeHost(this.host)}:${this.port}${this.path}`;
    try {
      this.url = new URL$1(url);
    } catch (err) {
      throw new Error(err.message + ` [${url}]`)
    }
  }

  toString () {
    const protocol = this.protocol === 'https:' ? '' : 'http://';
    const port = this.port !== (this.protocol === 'https:' ? 443 : 80) ? `:${this.port}` : '';
    const method = this.method !== 'GET' ? ' [post]' : '';
    const path = this.path === '/dns-query' ? '' : this.path;
    const name = this.name ? ` [name=${this.name}]` : '';
    const ipv4 = this.ipv4 && this.ipv4 !== this.host ? ` [ipv4=${this.ipv4}]` : '';
    const ipv6 = this.ipv6 && this.ipv6 !== this.host ? ` [ipv6=${this.ipv6}]` : '';
    return `${protocol}${safeHost(this.host)}${port}${path}${method}${ipv4}${ipv6}${name}`
  }
}

function toEndpoint (input) {
  let opts;
  if (typeof input === 'string') {
    opts = parseEndpoint(input);
  } else {
    if (typeof input !== 'object' || input === null || Array.isArray(input)) {
      throw new Error(`Can not convert ${input} to an endpoint`)
    } else if (input instanceof BaseEndpoint) {
      return input
    }
    opts = input;
  }
  if (opts.protocol === null || opts.protocol === undefined) {
    opts.protocol = 'https:';
  }
  const protocol = opts.protocol;
  if (protocol === 'udp4:') {
    return new UDP4Endpoint(opts)
  }
  if (protocol === 'udp6:') {
    return new UDP6Endpoint(opts)
  }
  if (protocol === 'https:' || protocol === 'http:') {
    return new HTTPEndpoint(opts)
  }
  throw new InvalidProtocolError(protocol, JSON.stringify(opts))
}

/* global XMLHttpRequest, localStorage */
const contentType = 'application/dns-message';

function noop () { }

function queryDns () {
  throw new Error('Only "doh" endpoints are supported in the browser')
}

async function loadJSON (url, cache, timeout, abortSignal) {
  const cacheKey = cache ? cache.localStoragePrefix + cache.name : null;
  if (cacheKey) {
    try {
      const cached = JSON.parse(localStorage.getItem(cacheKey));
      if (cached && cached.time > cache.maxTime) {
        return cached
      }
    } catch (err) {}
  }
  const { data } = await requestRaw(url, 'GET', null, timeout, abortSignal);
  const result = {
    time: Date.now(),
    data: JSON.parse(decode$1(data))
  };
  if (cacheKey) {
    try {
      localStorage.setItem(cacheKey, JSON.stringify(result));
    } catch (err) {
      result.time = null;
    }
  }
  return result
}

function requestRaw (url, method, data, timeout, abortSignal) {
  return new Promise((resolve, reject) => {
    const target = new URL$1(url);
    if (method === 'GET' && data) {
      target.search = '?dns=' + base64URL.decode(data);
    }
    const uri = target.toString();
    const xhr = new XMLHttpRequest();
    xhr.open(method, uri, true);
    xhr.setRequestHeader('Accept', contentType);
    if (method === 'POST') {
      xhr.setRequestHeader('Content-Type', contentType);
    }
    xhr.responseType = 'arraybuffer';
    xhr.timeout = timeout;
    xhr.ontimeout = ontimeout;
    xhr.onreadystatechange = onreadystatechange;
    xhr.onerror = onerror;
    xhr.onload = onload;
    if (method === 'POST') {
      xhr.send(data);
    } else {
      xhr.send();
    }

    if (abortSignal) {
      abortSignal.addEventListener('abort', onabort);
    }

    function ontimeout () {
      finish(new TimeoutError(timeout));
      try {
        xhr.abort();
      } catch (e) { }
    }

    function onload () {
      if (xhr.status !== 200) {
        finish(new HTTPStatusError(uri, xhr.status, method));
      } else {
        let buf;
        if (typeof xhr.response === 'string') {
          buf = encode$1(xhr.response);
        } else if (xhr.response instanceof Uint8Array) {
          buf = xhr.response;
        } else if (Array.isArray(xhr.response) || xhr.response instanceof ArrayBuffer) {
          buf = new Uint8Array(xhr.response);
        } else {
          throw new Error('Unprocessable response ' + xhr.response)
        }
        finish(null, buf);
      }
    }

    function onreadystatechange () {
      if (xhr.readyState > 1 && xhr.status !== 200 && xhr.status !== 0) {
        finish(new HTTPStatusError(uri, xhr.status, method));
        try {
          xhr.abort();
        } catch (e) { }
      }
    }

    let finish = function (error, data) {
      finish = noop;
      if (abortSignal) {
        abortSignal.removeEventListener('abort', onabort);
      }
      if (error) {
        resolve({
          error,
          response: xhr
        });
      } else {
        resolve({
          data,
          response: xhr
        });
      }
    };

    function onerror () {
      finish(xhr.status === 200 ? new Error('Inexplicable XHR Error') : new HTTPStatusError(uri, xhr.status, method));
    }

    function onabort () {
      finish(new AbortError());
      try {
        xhr.abort();
      } catch (e) { }
    }
  })
}

function request (url, method, packet, timeout, abortSignal) {
  return requestRaw(url, method, packet, timeout, abortSignal)
}

function processResolvers$1 (resolvers) {
  return resolvers.filter(resolver => resolver.cors || resolver.endpoint.cors)
}

const resolvers = {
  data: [
    {
      name: 'adfree.usableprivacy.net',
      endpoint: {
        protocol: 'https:',
        host: 'adfree.usableprivacy.net'
      },
      description: 'Public updns DoH service with advertising, tracker and malware filters.\nHosted in Europe by @usableprivacy, details see: https://docs.usableprivacy.com',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      },
      filter: true
    },
    {
      name: 'adguard-dns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.adguard.com',
        ipv4: '94.140.15.15'
      },
      description: 'Remove ads and protect your computer from malware (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      },
      filter: true
    },
    {
      name: 'adguard-dns-family-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-family.adguard.com',
        ipv4: '94.140.15.16'
      },
      description: 'Adguard DNS with safesearch and adult content blocking (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      },
      filter: true
    },
    {
      name: 'adguard-dns-unfiltered-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-unfiltered.adguard.com',
        ipv4: '94.140.14.140'
      },
      description: 'AdGuard public DNS servers without filters (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      }
    },
    {
      name: 'ahadns-doh-chi',
      endpoint: {
        protocol: 'https:',
        host: 'doh.chi.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Chicago, USA. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=chi',
      country: 'United States',
      location: {
        lat: 41.8483,
        long: -87.6517
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-in',
      endpoint: {
        protocol: 'https:',
        host: 'doh.in.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Mumbai, India. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=in',
      country: 'India',
      location: {
        lat: 19.0748,
        long: 72.8856
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-la',
      endpoint: {
        protocol: 'https:',
        host: 'doh.la.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Los Angeles, USA. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=la',
      country: 'United States',
      location: {
        lat: 34.0549,
        long: -118.2578
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'doh.nl.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Amsterdam, Netherlands. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=nl',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-ny',
      endpoint: {
        protocol: 'https:',
        host: 'doh.ny.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in New York. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=ny',
      country: 'United States',
      location: {
        lat: 40.7308,
        long: -73.9975
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-pl',
      endpoint: {
        protocol: 'https:',
        host: 'doh.pl.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Poland. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=pl',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'alidns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.alidns.com',
        ipv4: '223.5.5.5',
        cors: true
      },
      description: 'A public DNS resolver that supports DoH/DoT in mainland China, provided by Alibaba-Cloud.\nWarning: GFW filtering rules are applied by that resolver.\nHomepage: https://alidns.com/',
      country: 'China',
      location: {
        lat: 34.7725,
        long: 113.7266
      },
      filter: true,
      log: true,
      cors: true
    },
    {
      name: 'ams-ads-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'dnsnl-noads.alekberg.net'
      },
      description: 'Resolver in Amsterdam. DoH protocol. Non-logging. Blocks ads, malware and trackers. DNSSEC enabled.',
      country: 'Romania',
      location: {
        lat: 45.9968,
        long: 24.997
      },
      filter: true
    },
    {
      name: 'ams-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'dnsnl.alekberg.net'
      },
      description: 'Resolver in Amsterdam. DoH protocol. Non-logging, non-filtering, DNSSEC.',
      country: 'Romania',
      location: {
        lat: 45.9968,
        long: 24.997
      }
    },
    {
      name: 'att',
      endpoint: {
        protocol: 'https:',
        host: 'dohtrial.att.net'
      },
      description: 'AT&T test DoH server.',
      log: true
    },
    {
      name: 'bcn-ads-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dnses-noads.alekberg.net'
      },
      description: 'Resolver in Spain. DoH protocol. Non-logging, remove ads and malware, DNSSEC.',
      country: 'Spain',
      location: {
        lat: 41.3891,
        long: 2.1611
      },
      filter: true
    },
    {
      name: 'bcn-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dnses.alekberg.net'
      },
      description: 'Resolver in Spain. DoH protocol. Non-logging, non-filtering, DNSSEC.',
      country: 'Spain',
      location: {
        lat: 41.3891,
        long: 2.1611
      }
    },
    {
      name: 'brahma-world',
      endpoint: {
        protocol: 'https:',
        host: 'dns.brahma.world'
      },
      description: 'DNS-over-HTTPS server. Non Logging, filters ads, trackers and malware. DNSSEC ready, QNAME Minimization, No EDNS Client-Subnet.\nHosted in Stockholm, Sweden. (https://dns.brahma.world)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'cisco-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.opendns.com',
        ipv4: '146.112.41.2'
      },
      description: 'Remove your DNS blind spot (DoH protocol)\nWarning: modifies your queries to include a copy of your network\naddress when forwarding them to a selection of companies and organizations.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true,
      log: true
    },
    {
      name: 'cloudflare',
      endpoint: {
        protocol: 'https:',
        host: 'dns.cloudflare.com',
        ipv4: '1.0.0.1',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) - aka 1.1.1.1 / 1.0.0.1',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      cors: true
    },
    {
      name: 'cloudflare-family',
      endpoint: {
        protocol: 'https:',
        host: 'family.cloudflare-dns.com',
        ipv4: '1.0.0.3',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) with malware protection and parental control - aka 1.1.1.3 / 1.0.0.3',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      filter: true,
      cors: true
    },
    {
      name: 'cloudflare-ipv6',
      endpoint: {
        protocol: 'https:',
        host: '1dot1dot1dot1.cloudflare-dns.com',
        cors: true
      },
      description: 'Cloudflare DNS over IPv6 (anycast)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'cloudflare-security',
      endpoint: {
        protocol: 'https:',
        host: 'security.cloudflare-dns.com',
        ipv4: '1.0.0.2',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) with malware blocking - aka 1.1.1.2 / 1.0.0.2',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      filter: true,
      cors: true
    },
    {
      name: 'controld-block-malware',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p1'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-block-malware-ad',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p2'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-block-malware-ad-social',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p3'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking and Social Networks domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-family-friendly',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/family'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking, Adult Content and Drugs domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-uncensored',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/uncensored'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS unblocks censored domains from various countries.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      }
    },
    {
      name: 'controld-unfiltered',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p0'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis is a Unfiltered DNS, no DNS record blocking or manipulation here, if you want to block Malware, Ads & Tracking or Social Network domains, use the other ControlD DNS configs.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      }
    },
    {
      name: 'dns.digitale-gesellschaft.ch',
      endpoint: {
        protocol: 'https:',
        host: 'dns.digitale-gesellschaft.ch'
      },
      description: 'Public DoH resolver operated by the Digital Society (https://www.digitale-gesellschaft.ch).\nHosted in Zurich, Switzerland.\nNon-logging, non-filtering, supports DNSSEC.',
      country: 'Switzerland',
      location: {
        lat: 47.1449,
        long: 8.1551
      }
    },
    {
      name: 'dns.ryan-palmer',
      endpoint: {
        protocol: 'https:',
        host: 'dns1.ryan-palmer.com'
      },
      description: 'Non-logging, non-filtering, DNSSEC DoH Server. Hosted in the UK.',
      country: 'United Kingdom',
      location: {
        lat: 51.5164,
        long: -0.093
      }
    },
    {
      name: 'dns.sb',
      endpoint: {
        protocol: 'https:',
        host: 'doh.sb',
        ipv4: '185.222.222.222',
        cors: true
      },
      description: 'DNSSEC-enabled DoH server by https://xtom.com/\nhttps://dns.sb/doh/',
      country: 'Unknown',
      location: {
        lat: 47,
        long: 8
      },
      cors: true
    },
    {
      name: 'dns.therifleman.name',
      endpoint: {
        protocol: 'https:',
        host: 'dns.therifleman.name'
      },
      description: 'DNS-over-HTTPS DNS forwarder from Mumbai, India. Blocks web and Android trackers and ads.\nIP addresses are not logged, but queries are logged for 24 hours for debugging.\nReport issues, send suggestions @ joker349 at protonmail.com.\nAlso supports DoT (for android) @ dns.therifleman.name and plain DNS @ 172.104.206.174',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'dnsforfamily-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-doh.dnsforfamily.com'
      },
      description: '(DoH Protocol) (Now supports DNSSEC). Block adult websites, gambling websites, malwares and advertisements.\nIt also enforces safe search in: Google, YouTube, Bing, DuckDuckGo and Yandex.\nSocial websites like Facebook and Instagram are not blocked. No DNS queries are logged.\nAs of 26-May-2022 5.9 million websites are blocked and new websites are added to blacklist daily.\nCompletely free, no ads or any commercial motive. Operating for 4 years now.\nProvided by: https://dnsforfamily.com',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true
    },
    {
      name: 'dnsforfamily-doh-no-safe-search',
      endpoint: {
        protocol: 'https:',
        host: 'dns-doh-no-safe-search.dnsforfamily.com'
      },
      description: '(DoH Protocol) (Now supports DNSSEC) Block adult websites, gambling websites, malwares and advertisements.\nUnlike other dnsforfamily servers, this one does not enforces safe search. So Google, YouTube, Bing, DuckDuckGo and Yandex are completely accessible without any restriction.\nSocial websites like Facebook and Instagram are not blocked. No DNS queries are logged.\nAs of 26-May-2022 5.9 million websites are blocked and new websites are added to blacklist daily.\nCompletely free, no ads or any commercial motive. Operating for 4 years now.\nWarning: This server is incompatible with anonymization.\nProvided by: https://dnsforfamily.com',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true
    },
    {
      name: 'dnsforge.de',
      endpoint: {
        protocol: 'https:',
        host: 'dnsforge.de',
        cors: true
      },
      description: 'Public DoH resolver running with Pihole for Adblocking (https://dnsforge.de).\nNon-logging, AD-filtering, supports DNSSEC. Hosted in Germany.',
      country: 'Germany',
      location: {
        lat: 52.2998,
        long: 9.447
      },
      filter: true,
      cors: true
    },
    {
      name: 'dnshome-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.dnshome.de'
      },
      description: 'https://www.dnshome.de/ public resolver in Germany'
    },
    {
      name: 'dnspod-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.pub',
        cors: true
      },
      description: 'A public DNS resolver in mainland China provided by DNSPod (Tencent Cloud).\nhttps://www.dnspod.cn/Products/Public.DNS?lang=en',
      filter: true,
      log: true,
      cors: true
    },
    {
      name: 'dnswarden-asia-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/adblock'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'dnswarden-asia-adultfilter-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/adultfilter'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'dnswarden-asia-uncensor-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/uncensored'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      }
    },
    {
      name: 'dnswarden-eu-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.eu.dnswarden.com'
      },
      description: 'Hosted in Germany. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Germany',
      location: {
        lat: 50.1103,
        long: 8.7147
      },
      filter: true
    },
    {
      name: 'dnswarden-us-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.us.dnswarden.com'
      },
      description: 'Hosted in USA (Dallas) . For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'United States',
      location: {
        lat: 32.7889,
        long: -96.8021
      },
      filter: true
    },
    {
      name: 'doh-ch-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-ch.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Switzerland. By https://blahdns.com/',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-adult',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/adult-filter/',
        cors: true
      },
      description: 'Blocks access to all adult, pornographic and explicit sites. It does\nnot block proxy or VPNs, nor mixed-content sites. Sites like Reddit\nare allowed. Google and Bing are set to the Safe Mode.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-family',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/family-filter/',
        cors: true
      },
      description: 'Blocks access to all adult, pornographic and explicit sites. It also\nblocks proxy and VPN domains that are used to bypass the filters.\nMixed content sites (like Reddit) are also blocked. Google, Bing and\nYoutube are set to the Safe Mode.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-security',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/security-filter/',
        cors: true
      },
      description: 'Block access to phishing, malware and malicious domains. It does not block adult content.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-crypto-sx',
      endpoint: {
        protocol: 'https:',
        host: 'doh.crypto.sx',
        cors: true
      },
      description: 'DNS-over-HTTPS server. Anycast, no logs, no censorship, DNSSEC.\nBackend hosted by Scaleway, globally cached via Cloudflare.\nMaintained by Frank Denis.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'doh-crypto-sx-ipv6',
      endpoint: {
        protocol: 'https:',
        host: 'doh-ipv6.crypto.sx',
        cors: true
      },
      description: 'DNS-over-HTTPS server accessible over IPv6. Anycast, no logs, no censorship, DNSSEC.\nBackend hosted by Scaleway, globally cached via Cloudflare.\nMaintained by Frank Denis.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'doh-de-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-de.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Germany. By https://blahdns.com/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-fi-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-fi.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Finland. By https://blahdns.com/',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-ibksturm',
      endpoint: {
        protocol: 'https:',
        host: 'ibksturm.synology.me'
      },
      description: 'DoH & DoT Server, No Logging, No Filters, DNSSEC\nRunning privately by ibksturm in Thurgau, Switzerland'
    },
    {
      name: 'doh-jp-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-jp.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Japan. By https://blahdns.com/',
      country: 'Japan',
      location: {
        lat: 35.6882,
        long: 139.7532
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh.ffmuc.net',
      endpoint: {
        protocol: 'https:',
        host: 'doh.ffmuc.net'
      },
      description: 'An open (non-logging, non-filtering, non-censoring) DoH resolver operated by Freifunk Munich with nodes in DE.\nhttps://ffmuc.net/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      }
    },
    {
      name: 'doh.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiarap.org'
      },
      description: 'Non-Logging DNS-over-HTTPS server, cached via Cloudflare.\nFilters out ads, trackers and malware, NO ECS, supports DNSSEC.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'google',
      endpoint: {
        protocol: 'https:',
        host: 'dns.google',
        ipv4: '8.8.8.8',
        cors: true
      },
      description: 'Google DNS (anycast)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      log: true,
      cors: true
    },
    {
      name: 'hdns',
      endpoint: {
        protocol: 'https:',
        host: 'query.hdns.io',
        cors: true
      },
      description: 'HDNS is a public DNS resolver that supports Handshake domains.\nhttps://www.hdns.io',
      country: 'United States',
      location: {
        lat: 37.7771,
        long: -122.406
      },
      cors: true
    },
    {
      name: 'he',
      endpoint: {
        protocol: 'https:',
        host: 'ordns.he.net'
      },
      description: 'Hurricane Electric DoH server (anycast)\nUnknown logging policy.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      log: true
    },
    {
      name: 'id-gmail-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiar.app'
      },
      description: 'Non-Logging DNS-over-HTTPS server located in Singapore.\nFilters out ads, trackers and malware, supports DNSSEC, provided by id-gmail.',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'iij',
      endpoint: {
        protocol: 'https:',
        host: 'public.dns.iij.jp'
      },
      description: 'DoH server operated by Internet Initiative Japan in Tokyo.\nhttps://www.iij.ad.jp/',
      country: 'Japan',
      location: {
        lat: 35.69,
        long: 139.69
      },
      log: true
    },
    {
      name: 'iqdns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'a.passcloud.xyz'
      },
      description: 'Non-logging DoH service runned by V2EX.com user johnsonwil.\nReturns "no such domain" for anti-Chinese government websites. Supports DNSSEC.\nFor more information: https://www.v2ex.com/t/785666',
      filter: true
    },
    {
      name: 'jp.tiar.app-doh',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiar.app'
      },
      description: 'Non-Logging, Non-Filtering DNS-over-HTTPS server in Japan.\nNo ECS, Support DNSSEC',
      country: 'Japan',
      location: {
        lat: 35.6882,
        long: 139.7532
      }
    },
    {
      name: 'jp.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiarap.org'
      },
      description: 'DNS-over-HTTPS Server. Non-Logging, Non-Filtering, No ECS, Support DNSSEC.\nCached via Cloudflare.'
    },
    {
      name: 'libredns',
      endpoint: {
        protocol: 'https:',
        host: 'doh.libredns.gr'
      },
      description: 'DoH server in Germany. No logging, but no DNS padding and no DNSSEC support.\nhttps://libredns.gr/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      }
    },
    {
      name: 'nextdns',
      endpoint: {
        protocol: 'https:',
        host: 'anycsast.dns.nextdns.io'
      },
      description: 'NextDNS is a cloud-based private DNS service that gives you full control\nover what is allowed and what is blocked on the Internet.\nDNSSEC, Anycast, Non-logging, NoFilters\nhttps://www.nextdns.io/',
      country: 'Netherlands',
      location: {
        lat: 52.3891,
        long: 4.6563
      }
    },
    {
      name: 'nextdns-ultralow',
      endpoint: {
        protocol: 'https:',
        host: 'dns.nextdns.io',
        path: '/dnscrypt-proxy'
      },
      description: 'NextDNS is a cloud-based private DNS service that gives you full control\nover what is allowed and what is blocked on the Internet.\nhttps://www.nextdns.io/\nTo select the server location, the "-ultralow" variant relies on bootstrap servers\ninstead of anycast.'
    },
    {
      name: 'njalla-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.njal.la',
        cors: true
      },
      description: 'Non-logging DoH server in Sweden operated by Njalla.\nhttps://dns.njal.la/',
      country: 'Sweden',
      location: {
        lat: 59.3247,
        long: 18.056
      },
      cors: true
    },
    {
      name: 'odoh-cloudflare',
      endpoint: {
        protocol: 'https:',
        host: 'odoh.cloudflare-dns.com',
        cors: true
      },
      description: 'Cloudflare ODoH server.\nhttps://cloudflare.com',
      cors: true
    },
    {
      name: 'odoh-crypto-sx',
      endpoint: {
        protocol: 'https:',
        host: 'odoh.crypto.sx',
        cors: true
      },
      description: 'ODoH target server. Anycast, no logs.\nBackend hosted by Scaleway. Maintained by Frank Denis.',
      cors: true
    },
    {
      name: 'odoh-id-gmail',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiar.app',
        path: '/odoh'
      },
      description: 'ODoH target server. Based in Singapore, no logs.\nFilter ads, trackers and malware.',
      filter: true
    },
    {
      name: 'odoh-jp.tiar.app',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiar.app',
        path: '/odoh'
      },
      description: 'ODoH target server. no logs.'
    },
    {
      name: 'odoh-jp.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiarap.org',
        path: '/odoh'
      },
      description: 'ODoH target server via Cloudflare, no logs.'
    },
    {
      name: 'odoh-resolver4.dns.openinternet.io',
      endpoint: {
        protocol: 'https:',
        host: 'resolver4.dns.openinternet.io'
      },
      description: "ODoH target server. no logs, no filter, DNSSEC.\nRunning on dedicated hardware colocated at Sonic.net in Santa Rosa, CA in the United States.\nUses Sonic's recusrive DNS servers as upstream resolvers (but is not affiliated with Sonic\nin any way). Provided by https://openinternet.io"
    },
    {
      name: 'odoh-tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiarap.org',
        path: '/odoh'
      },
      description: 'ODoH target server via Cloudflare, no logs.\nFilter ads, trackers and malware.',
      filter: true
    },
    {
      name: 'publicarray-au2-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh-2.seby.io',
        cors: true
      },
      description: 'DNSSEC • OpenNIC • Non-logging • Uncensored - hosted on ovh.com.au\nMaintained by publicarray - https://dns.seby.io',
      country: 'Australia',
      location: {
        lat: -33.8591,
        long: 151.2002
      },
      cors: true
    },
    {
      name: 'puredns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'puredns.org',
        ipv4: '146.190.6.13',
        cors: true
      },
      description: 'Public uncensored DNS resolver in Singapore - https://puredns.org\n** Only available in Indonesia and Singapore **',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'quad101',
      endpoint: {
        protocol: 'https:',
        host: 'dns.twnic.tw',
        cors: true
      },
      description: 'DNSSEC-aware public resolver by the Taiwan Network Information Center (TWNIC)\nhttps://101.101.101.101/index_en.html',
      cors: true
    },
    {
      name: 'quad9-doh-ip4-port443-filter-ecs-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns11.quad9.net',
        ipv4: '149.112.112.11'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter/ecs 9.9.9.11 - 149.112.112.11',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'quad9-doh-ip4-port443-filter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns.quad9.net',
        ipv4: '149.112.112.112'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter 9.9.9.9 - 149.112.112.9 - 149.112.112.112',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'quad9-doh-ip4-port443-nofilter-ecs-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns12.quad9.net',
        ipv4: '9.9.9.12'
      },
      description: 'Quad9 (anycast) no-dnssec/no-log/no-filter/ecs 9.9.9.12 - 149.112.112.12',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      }
    },
    {
      name: 'quad9-doh-ip4-port443-nofilter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns10.quad9.net',
        ipv4: '149.112.112.10'
      },
      description: 'Quad9 (anycast) no-dnssec/no-log/no-filter 9.9.9.10 - 149.112.112.10',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      }
    },
    {
      name: 'quad9-doh-ip6-port5053-filter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns9.quad9.net'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter 2620:fe::fe - 2620:fe::9 - 2620:fe::fe:9',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'safesurfer-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.safesurfer.io'
      },
      description: 'Family safety focused blocklist for over 2 million adult sites, as well as phishing and malware and more.\nFree to use, paid for customizing blocking for more categories+sites and viewing usage at my.safesurfer.io. Logs taken for viewing\nusage, data never sold - https://safesurfer.io',
      filter: true,
      log: true
    },
    {
      name: 'sth-ads-doh-se',
      endpoint: {
        protocol: 'https:',
        host: 'dnsse-noads.alekberg.net'
      },
      description: 'Resolver in Stockholm, Sweden. DoH server. Non-logging, remove ads and malware, DNSSEC.',
      country: 'Bulgaria',
      location: {
        lat: 42.696,
        long: 23.332
      },
      filter: true
    },
    {
      name: 'sth-doh-se',
      endpoint: {
        protocol: 'https:',
        host: 'dnsse.alekberg.net'
      },
      description: 'Resolver in Stockholm, Sweden. DoH server. Non-logging, non-filtering, DNSSEC.',
      country: 'Bulgaria',
      location: {
        lat: 42.696,
        long: 23.332
      }
    },
    {
      name: 'switch',
      endpoint: {
        protocol: 'https:',
        host: 'dns.switch.ch'
      },
      description: 'Public DoH service provided by SWITCH in Switzerland\nhttps://www.switch.ch\nProvides protection against malware, but does not block ads.',
      filter: true
    },
    {
      name: 'uncensoreddns-dk-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'unicast.uncensoreddns.org'
      },
      description: 'Also known as censurfridns.\nDoH, no logs, no filter, DNSSEC, unicast hosted in Denmark - https://blog.uncensoreddns.org',
      country: 'Denmark',
      location: {
        lat: 55.7123,
        long: 12.0564
      }
    },
    {
      name: 'uncensoreddns-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'anycast.uncensoreddns.org'
      },
      description: 'Also known as censurfridns.\nDoH, no logs, no filter, DNSSEC, anycast - https://blog.uncensoreddns.org',
      country: 'Denmark',
      location: {
        lat: 55.7123,
        long: 12.0564
      }
    },
    {
      name: 'v.dnscrypt.uk-doh-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'v.dnscrypt.uk'
      },
      description: 'DoH, no logs, uncensored, DNSSEC. Hosted in London UK on Digital Ocean\nhttps://www.dnscrypt.uk',
      country: 'United Kingdom',
      location: {
        lat: 51.4964,
        long: -0.1224
      }
    }
  ],
  time: 1654187067783
};

function processResolvers (res) {
  const time = (res.time === null || res.time === undefined) ? Date.now() : res.time;
  const resolvers = processResolvers$1(res.data.map(resolver => {
    resolver.endpoint = toEndpoint(Object.assign({ name: resolver.name }, resolver.endpoint));
    return resolver
  }));
  const endpoints = resolvers.map(resolver => resolver.endpoint);
  return {
    data: {
      resolvers,
      resolverByName: resolvers.reduce((byName, resolver) => {
        byName[resolver.name] = resolver;
        return byName
      }, {}),
      endpoints,
      endpointByName: endpoints.reduce((byName, endpoint) => {
        byName[endpoint.name] = endpoint;
        return byName
      }, {})
    },
    time
  }
}

const backup = processResolvers(resolvers);

function toMultiQuery (singleQuery) {
  const query = Object.assign({
    type: 'query'
  }, singleQuery);
  delete query.question;
  query.questions = [];
  if (singleQuery.question) {
    query.questions.push(singleQuery.question);
  }
  return query
}

function queryOne (endpoint, query, timeout, abortSignal) {
  if (abortSignal && abortSignal.aborted) {
    return Promise.reject(new AbortError())
  }
  if (endpoint.protocol === 'udp4:' || endpoint.protocol === 'udp6:') {
    return queryDns()
  }
  return queryDoh(endpoint, query, timeout, abortSignal)
}

function queryDoh (endpoint, query, timeout, abortSignal) {
  return request(
    endpoint.url,
    endpoint.method,
    encode(Object.assign({
      flags: RECURSION_DESIRED
    }, query)),
    timeout,
    abortSignal
  ).then(
    function (res) {
      const data = res.data;
      const response = res.response;
      let error = res.error;
      if (error === undefined) {
        if (data.length === 0) {
          error = new ResponseError('Empty.');
        } else {
          try {
            const decoded = decode(data);
            decoded.response = response;
            return decoded
          } catch (err) {
            error = new ResponseError('Invalid packet (cause=' + err.message + ')', err);
          }
        }
      }
      throw Object.assign(error, { response })
    }
  )
}

const UPDATE_URL = new URL$1('https://martinheidegger.github.io/dns-query/resolvers.json');

function isNameString (entry) {
  return /^@/.test(entry)
}

class Wellknown {
  constructor (opts) {
    this.opts = Object.assign({
      timeout: 5000,
      update: true,
      updateURL: UPDATE_URL,
      persist: false,
      localStoragePrefix: 'dnsquery_',
      maxAge: 300000 // 5 minutes
    }, opts);
    this._dataP = null;
  }

  _data (force, outdated) {
    if (!force && this._dataP !== null) {
      return this._dataP.then(res => {
        if (res.time < Date.now() - this.opts.maxAge) {
          return this._data(true, res)
        }
        return res
      })
    }
    this._dataP = (!this.opts.update
      ? Promise.resolve(backup)
      : loadJSON(
        this.opts.updateURL,
        this.opts.persist
          ? {
              name: 'resolvers.json',
              localStoragePrefix: this.opts.localStoragePrefix,
              maxTime: Date.now() - this.opts.maxAge
            }
          : null,
        this.opts.timeout
      )
        .then(res => processResolvers({
          data: res.data.resolvers,
          time: res.time
        }))
        .catch(() => outdated || backup)
    );
    return this._dataP
  }

  data () {
    return this._data(false).then(data => data.data)
  }

  endpoints (input) {
    if (input === null || input === undefined) {
      return this.data().then(data => data.endpoints)
    }
    if (input === 'doh') {
      input = filterDoh;
    }
    if (input === 'dns') {
      input = filterDns;
    }
    if (typeof input === 'function') {
      return this.data().then(data => data.endpoints.filter(input))
    }
    if (typeof input === 'string' || typeof input[Symbol.iterator] !== 'function') {
      return Promise.reject(new Error(`Endpoints (${input}) needs to be iterable (array).`))
    }
    input = Array.from(input).filter(Boolean);
    if (input.findIndex(isNameString) === -1) {
      try {
        return Promise.resolve(input.map(toEndpoint))
      } catch (err) {
        return Promise.reject(err)
      }
    }
    return this.data().then(data =>
      input.map(entry => {
        if (isNameString(entry)) {
          const found = data.endpointByName[entry.substring(1)];
          if (!found) {
            throw new Error(`Endpoint ${entry} is not known.`)
          }
          return found
        }
        return toEndpoint(entry)
      })
    )
  }
}

const wellknown = new Wellknown();

function isPromise (input) {
  if (input === null) {
    return false
  }
  if (typeof input !== 'object') {
    return false
  }
  return typeof input.then === 'function'
}

function toPromise (input) {
  return isPromise(input) ? input : Promise.resolve(input)
}

function query (q, opts) {
  opts = Object.assign({
    retries: 5,
    timeout: 30000 // 30 seconds
  }, opts);
  if (!q.question) return Promise.reject(new Error('To request data you need to specify a .question!'))
  return toPromise(opts.endpoints)
    .then(endpoints => {
      if (!Array.isArray(endpoints) || endpoints.length === 0) {
        throw new Error('No endpoints defined to lookup dns records.')
      }
      return queryN(endpoints.map(toEndpoint), toMultiQuery(q), opts)
    })
    .then(data => {
      data.question = data.questions[0];
      delete data.questions;
      return data
    })
}

function queryN (endpoints, q, opts) {
  const endpoint = endpoints.length === 1
    ? endpoints[0]
    : endpoints[Math.floor(Math.random() * endpoints.length) % endpoints.length];
  return queryOne(endpoint, q, opts.timeout, opts.signal)
    .then(
      data => {
        // Add the endpoint to give a chance to identify which endpoint returned the result
        data.endpoint = endpoint.toString();
        return data
      },
      err => {
        if (err.name === 'AbortError' || opts.retries === 0) {
          err.endpoint = endpoint.toString();
          throw err
        }
        if (opts.retries > 0) {
          opts.retries -= 1;
        }
        return queryN(endpoints, q, opts)
      }
    )
}

function filterDoh (endpoint) {
  return endpoint.protocol === 'https:' || endpoint.protocol === 'http:'
}

function filterDns (endpoint) {
  return endpoint.protocol === 'udp4:' || endpoint.protocol === 'udp6:'
}

const log$7 = new Logger$1("dns-over-https");
class DnsOverHttps {
    endpoints;
    retries;
    /**
     * Create new Dns-Over-Http DNS client.
     *
     * @param endpoints The endpoints for Dns-Over-Https queries;
     * Defaults to using dns-query's API..
     * @param retries Retries if a given endpoint fails.
     *
     * @throws {code: string} If DNS query fails.
     */
    static async create(endpoints, retries) {
        const _endpoints = endpoints ?? (await wellknown.endpoints("doh"));
        return new DnsOverHttps(_endpoints, retries);
    }
    constructor(endpoints, retries = 3) {
        this.endpoints = endpoints;
        this.retries = retries;
    }
    /**
     * Resolves a TXT record
     *
     * @param domain The domain name
     *
     * @throws if the query fails
     */
    async resolveTXT(domain) {
        let answers;
        try {
            const res = await query({
                question: { type: "TXT", name: domain }
            }, {
                endpoints: this.endpoints,
                retries: this.retries
            });
            answers = res.answers;
        }
        catch (error) {
            log$7.error("query failed: ", error);
            throw new Error("DNS query failed");
        }
        if (!answers)
            throw new Error(`Could not resolve ${domain}`);
        const data = answers.map((a) => a.data);
        const result = [];
        data.forEach((d) => {
            if (typeof d === "string") {
                result.push(d);
            }
            else if (Array.isArray(d)) {
                d.forEach((sd) => {
                    if (typeof sd === "string") {
                        result.push(sd);
                    }
                    else {
                        result.push(bytesToUtf8(sd));
                    }
                });
            }
            else {
                result.push(bytesToUtf8(d));
            }
        });
        return result;
    }
}

var base32$1 = {exports: {}};

/*
 * [hi-base32]{@link https://github.com/emn178/hi-base32}
 *
 * @version 0.5.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2018
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var root = typeof window === 'object' ? window : {};
	  var NODE_JS = !root.HI_BASE32_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  }
	  var COMMON_JS = !root.HI_BASE32_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var BASE32_ENCODE_CHAR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'.split('');
	  var BASE32_DECODE_CHAR = {
	    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8,
	    'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16,
	    'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24,
	    'Z': 25, '2': 26, '3': 27, '4': 28, '5': 29, '6': 30, '7': 31
	  };

	  var blocks = [0, 0, 0, 0, 0, 0, 0, 0];

	  var throwInvalidUtf8 = function (position, partial) {
	    if (partial.length > 10) {
	      partial = '...' + partial.substr(-10);
	    }
	    var err = new Error('Decoded data is not valid UTF-8.'
	      + ' Maybe try base32.decode.asBytes()?'
	      + ' Partial data after reading ' + position + ' bytes: ' + partial + ' <-');
	    err.position = position;
	    throw err;
	  };

	  var toUtf8String = function (bytes) {
	    var str = '', length = bytes.length, i = 0, followingChars = 0, b, c;
	    while (i < length) {
	      b = bytes[i++];
	      if (b <= 0x7F) {
	        str += String.fromCharCode(b);
	        continue;
	      } else if (b > 0xBF && b <= 0xDF) {
	        c = b & 0x1F;
	        followingChars = 1;
	      } else if (b <= 0xEF) {
	        c = b & 0x0F;
	        followingChars = 2;
	      } else if (b <= 0xF7) {
	        c = b & 0x07;
	        followingChars = 3;
	      } else {
	        throwInvalidUtf8(i, str);
	      }

	      for (var j = 0; j < followingChars; ++j) {
	        b = bytes[i++];
	        if (b < 0x80 || b > 0xBF) {
	          throwInvalidUtf8(i, str);
	        }
	        c <<= 6;
	        c += b & 0x3F;
	      }
	      if (c >= 0xD800 && c <= 0xDFFF) {
	        throwInvalidUtf8(i, str);
	      }
	      if (c > 0x10FFFF) {
	        throwInvalidUtf8(i, str);
	      }

	      if (c <= 0xFFFF) {
	        str += String.fromCharCode(c);
	      } else {
	        c -= 0x10000;
	        str += String.fromCharCode((c >> 10) + 0xD800);
	        str += String.fromCharCode((c & 0x3FF) + 0xDC00);
	      }
	    }
	    return str;
	  };

	  var decodeAsBytes = function (base32Str) {
	    if (base32Str === '') {
	      return [];
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    base32Str = base32Str.replace(/=/g, '');
	    var v1, v2, v3, v4, v5, v6, v7, v8, bytes = [], index = 0, length = base32Str.length;

	    // 4 char to 3 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	      bytes[index++] = (v7 << 5 | v8) & 255;
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	    }
	    return bytes;
	  };

	  var encodeAscii = function (str) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = str.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i++);
	      v5 = str.charCodeAt(i++);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encodeUtf8 = function (str) {
	    var v1, v2, v3, v4, v5, code, end = false, base32Str = '',
	      index = 0, i, start = 0, length = str.length;
	      if (str === '') {
	        return base32Str;
	      }
	    do {
	      blocks[0] = blocks[5];
	      blocks[1] = blocks[6];
	      blocks[2] = blocks[7];
	      for (i = start; index < length && i < 5; ++index) {
	        code = str.charCodeAt(index);
	        if (code < 0x80) {
	          blocks[i++] = code;
	        } else if (code < 0x800) {
	          blocks[i++] = 0xc0 | (code >> 6);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else if (code < 0xd800 || code >= 0xe000) {
	          blocks[i++] = 0xe0 | (code >> 12);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++index) & 0x3ff));
	          blocks[i++] = 0xf0 | (code >> 18);
	          blocks[i++] = 0x80 | ((code >> 12) & 0x3f);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        }
	      }
	      start = i - 5;
	      if (index === length) {
	        ++index;
	      }
	      if (index > length && i < 6) {
	        end = true;
	      }
	      v1 = blocks[0];
	      if (i > 4) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        v5 = blocks[4];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	          BASE32_ENCODE_CHAR[v5 & 31];
	      } else if (i === 1) {
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	          '======';
	      } else if (i === 2) {
	        v2 = blocks[1];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	          '====';
	      } else if (i === 3) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	          '===';
	      } else {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	          '=';
	      }
	    } while (!end);
	    return base32Str;
	  };

	  var encodeBytes = function (bytes) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = bytes.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i++];
	      v5 = bytes[i++];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = bytes[i++];
	      v2 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encode = function (input, asciiOnly) {
	    var notString = typeof(input) !== 'string';
	    if (notString && input.constructor === ArrayBuffer) {
	      input = new Uint8Array(input);
	    }
	    if (notString) {
	      return encodeBytes(input);
	    } else if (asciiOnly) {
	      return encodeAscii(input);
	    } else {
	      return encodeUtf8(input);
	    }
	  };

	  var decode = function (base32Str, asciiOnly) {
	    if (!asciiOnly) {
	      return toUtf8String(decodeAsBytes(base32Str));
	    }
	    if (base32Str === '') {
	      return '';
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    var v1, v2, v3, v4, v5, v6, v7, v8, str = '', length = base32Str.indexOf('=');
	    if (length === -1) {
	      length = base32Str.length;
	    }

	    // 8 char to 5 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255) +
	        String.fromCharCode((v7 << 5 | v8) & 255);
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255);
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255);
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255);
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255);
	    }
	    return str;
	  };

	  var exports = {
	    encode: encode,
	    decode: decode
	  };
	  decode.asBytes = decodeAsBytes;

	  if (COMMON_JS) {
	    module.exports = exports;
	  } else {
	    root.base32 = exports;
	  }
	})(); 
} (base32$1));

var base32Exports = base32$1.exports;
var base32 = /*@__PURE__*/getDefaultExportFromCjs(base32Exports);

class ENRTree {
    static RECORD_PREFIX = ENR.RECORD_PREFIX;
    static TREE_PREFIX = "enrtree:";
    static BRANCH_PREFIX = "enrtree-branch:";
    static ROOT_PREFIX = "enrtree-root:";
    /**
     * Extracts the branch subdomain referenced by a DNS tree root string after verifying
     * the root record signature with its base32 compressed public key.
     */
    static parseAndVerifyRoot(root, publicKey) {
        if (!root.startsWith(this.ROOT_PREFIX))
            throw new Error(`ENRTree root entry must start with '${this.ROOT_PREFIX}'`);
        const rootValues = ENRTree.parseRootValues(root);
        const decodedPublicKey = base32.decode.asBytes(publicKey);
        // The signature is a 65-byte secp256k1 over the keccak256 hash
        // of the record content, excluding the `sig=` part, encoded as URL-safe base64 string
        // (Trailing recovery bit must be trimmed to pass `ecdsaVerify` method)
        const signedComponent = root.split(" sig")[0];
        const signedComponentBuffer = utf8ToBytes$2(signedComponent);
        const signatureBuffer = fromString(rootValues.signature, "base64url").slice(0, 64);
        const isVerified = verifySignature(signatureBuffer, keccak256(signedComponentBuffer), new Uint8Array(decodedPublicKey));
        if (!isVerified)
            throw new Error("Unable to verify ENRTree root signature");
        return rootValues.eRoot;
    }
    static parseRootValues(txt) {
        const matches = txt.match(/^enrtree-root:v1 e=([^ ]+) l=([^ ]+) seq=(\d+) sig=([^ ]+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree root entry");
        matches.shift(); // The first entry is the full match
        const [eRoot, lRoot, seq, signature] = matches;
        if (!eRoot)
            throw new Error("Could not parse 'e' value from ENRTree root entry");
        if (!lRoot)
            throw new Error("Could not parse 'l' value from ENRTree root entry");
        if (!seq)
            throw new Error("Could not parse 'seq' value from ENRTree root entry");
        if (!signature)
            throw new Error("Could not parse 'sig' value from ENRTree root entry");
        return { eRoot, lRoot, seq: Number(seq), signature };
    }
    /**
     * Returns the public key and top level domain of an ENR tree entry.
     * The domain is the starting point for traversing a set of linked DNS TXT records
     * and the public key is used to verify the root entry record
     */
    static parseTree(tree) {
        if (!tree.startsWith(this.TREE_PREFIX))
            throw new Error(`ENRTree tree entry must start with '${this.TREE_PREFIX}'`);
        const matches = tree.match(/^enrtree:\/\/([^@]+)@(.+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree tree entry");
        matches.shift(); // The first entry is the full match
        const [publicKey, domain] = matches;
        if (!publicKey)
            throw new Error("Could not parse public key from ENRTree tree entry");
        if (!domain)
            throw new Error("Could not parse domain from ENRTree tree entry");
        return { publicKey, domain };
    }
    /**
     * Returns subdomains listed in an ENR branch entry. These in turn lead to
     * either further branch entries or ENR records.
     */
    static parseBranch(branch) {
        if (!branch.startsWith(this.BRANCH_PREFIX))
            throw new Error(`ENRTree branch entry must start with '${this.BRANCH_PREFIX}'`);
        return branch.split(this.BRANCH_PREFIX)[1].split(",");
    }
}

const log$6 = new Logger$1("discovery:fetch_nodes");
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0
    };
    let totalSearches = 0;
    const peers = [];
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && isNewPeer(peer, peers)) {
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    peers.push(peer);
                }
            }
            log$6.info(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
    return peers;
}
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function* yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0
    };
    let totalSearches = 0;
    const peerNodeIds = new Set();
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && peer.nodeId && !peerNodeIds.has(peer.nodeId)) {
            peerNodeIds.add(peer.nodeId);
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    yield peer;
                }
            }
            log$6.info(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
}
function isSatisfied(wanted, actual) {
    return (actual.relay >= wanted.relay &&
        actual.store >= wanted.store &&
        actual.filter >= wanted.filter &&
        actual.lightPush >= wanted.lightPush);
}
function isNewPeer(peer, peers) {
    if (!peer.nodeId)
        return false;
    for (const existingPeer of peers) {
        if (peer.nodeId === existingPeer.nodeId) {
            return false;
        }
    }
    return true;
}
function addCapabilities(node, total) {
    if (node.relay)
        total.relay += 1;
    if (node.store)
        total.store += 1;
    if (node.filter)
        total.filter += 1;
    if (node.lightPush)
        total.lightPush += 1;
}
/**
 * Checks if the proposed ENR [[node]] helps satisfy the [[wanted]] capabilities,
 * considering the [[actual]] capabilities of nodes retrieved so far..
 *
 * @throws If the function is called when the wanted capabilities are already fulfilled.
 */
function helpsSatisfyCapabilities(node, wanted, actual) {
    if (isSatisfied(wanted, actual)) {
        throw "Internal Error: Waku2 wanted capabilities are already fulfilled";
    }
    const missing = missingCapabilities(wanted, actual);
    return ((missing.relay && node.relay) ||
        (missing.store && node.store) ||
        (missing.filter && node.filter) ||
        (missing.lightPush && node.lightPush));
}
/**
 * Return a [[Waku2]] Object for which capabilities are set to true if they are
 * [[wanted]] yet missing from [[actual]].
 */
function missingCapabilities(wanted, actual) {
    return {
        relay: actual.relay < wanted.relay,
        store: actual.store < wanted.store,
        filter: actual.filter < wanted.filter,
        lightPush: actual.lightPush < wanted.lightPush
    };
}

const log$5 = new Logger$1("discovery:dns");
class DnsNodeDiscovery {
    dns;
    _DNSTreeCache;
    _errorTolerance = 10;
    static async dnsOverHttp(dnsClient) {
        if (!dnsClient) {
            dnsClient = await DnsOverHttps.create();
        }
        return new DnsNodeDiscovery(dnsClient);
    }
    /**
     * Returns a list of verified peers listed in an EIP-1459 DNS tree. Method may
     * return fewer peers than requested if @link wantedNodeCapabilityCount requires
     * larger quantity of peers than available or the number of errors/duplicate
     * peers encountered by randomized search exceeds the sum of the fields of
     * @link wantedNodeCapabilityCount plus the @link _errorTolerance factor.
     */
    async getPeers(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {}
        };
        const peers = await fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context));
        log$5.info("retrieved peers: ", peers.map((peer) => {
            return {
                id: peer.peerId?.toString(),
                multiaddrs: peer.multiaddrs?.map((ma) => ma.toString())
            };
        }));
        return peers;
    }
    constructor(dns) {
        this._DNSTreeCache = {};
        this.dns = dns;
    }
    /**
     * {@inheritDoc getPeers}
     */
    async *getNextPeer(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {}
        };
        for await (const peer of yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context))) {
            yield peer;
        }
    }
    /**
     * Runs a recursive, randomized descent of the DNS tree to retrieve a single
     * ENR record as an ENR. Returns null if parsing or DNS resolution fails.
     */
    async _search(subdomain, context) {
        try {
            const entry = await this._getTXTRecord(subdomain, context);
            context.visits[subdomain] = true;
            let next;
            let branches;
            const entryType = getEntryType(entry);
            try {
                switch (entryType) {
                    case ENRTree.ROOT_PREFIX:
                        next = ENRTree.parseAndVerifyRoot(entry, context.publicKey);
                        return await this._search(next, context);
                    case ENRTree.BRANCH_PREFIX:
                        branches = ENRTree.parseBranch(entry);
                        next = selectRandomPath(branches, context);
                        return await this._search(next, context);
                    case ENRTree.RECORD_PREFIX:
                        return EnrDecoder.fromString(entry);
                    default:
                        return null;
                }
            }
            catch (error) {
                log$5.error(`Failed to search DNS tree ${entryType} at subdomain ${subdomain}: ${error}`);
                return null;
            }
        }
        catch (error) {
            log$5.error(`Failed to retrieve TXT record at subdomain ${subdomain}: ${error}`);
            return null;
        }
    }
    /**
     * Retrieves the TXT record stored at a location from either
     * this DNS tree cache or via DNS query.
     *
     * @throws if the TXT Record contains non-UTF-8 values.
     */
    async _getTXTRecord(subdomain, context) {
        if (this._DNSTreeCache[subdomain]) {
            return this._DNSTreeCache[subdomain];
        }
        // Location is either the top level tree entry host or a subdomain of it.
        const location = subdomain !== context.domain
            ? `${subdomain}.${context.domain}`
            : context.domain;
        const response = await this.dns.resolveTXT(location);
        if (!response.length)
            throw new Error("Received empty result array while fetching TXT record");
        if (!response[0].length)
            throw new Error("Received empty TXT record");
        // Branch entries can be an array of strings of comma delimited subdomains, with
        // some subdomain strings split across the array elements
        const result = response.join("");
        this._DNSTreeCache[subdomain] = result;
        return result;
    }
}
function getEntryType(entry) {
    if (entry.startsWith(ENRTree.ROOT_PREFIX))
        return ENRTree.ROOT_PREFIX;
    if (entry.startsWith(ENRTree.BRANCH_PREFIX))
        return ENRTree.BRANCH_PREFIX;
    if (entry.startsWith(ENRTree.RECORD_PREFIX))
        return ENRTree.RECORD_PREFIX;
    return "";
}
/**
 * Returns a randomly selected subdomain string from the list provided by a branch
 * entry record.
 *
 * The client must track subdomains which are already resolved to avoid
 * going into an infinite loop b/c branch entries can contain
 * circular references. It’s in the client’s best interest to traverse the
 * tree in random order.
 */
function selectRandomPath(branches, context) {
    // Identify domains already visited in this traversal of the DNS tree.
    // Then filter against them to prevent cycles.
    const circularRefs = {};
    for (const [idx, subdomain] of branches.entries()) {
        if (context.visits[subdomain]) {
            circularRefs[idx] = true;
        }
    }
    // If all possible paths are circular...
    if (Object.keys(circularRefs).length === branches.length) {
        throw new Error("Unresolvable circular path detected");
    }
    // Randomly select a viable path
    let index;
    do {
        index = Math.floor(Math.random() * branches.length);
    } while (circularRefs[index]);
    return branches[index];
}

const log$4 = new Logger$1("peer-discovery-dns");
/**
 * Parse options and expose function to return bootstrap peer addresses.
 */
class PeerDiscoveryDns extends TypedEventEmitter {
    nextPeer;
    _started;
    _components;
    _options;
    constructor(components, options) {
        super();
        this._started = false;
        this._components = components;
        this._options = options;
        const { enrUrls } = options;
        log$4.info("Use following EIP-1459 ENR Tree URLs: ", enrUrls);
    }
    /**
     * Start discovery process
     */
    async start() {
        log$4.info("Starting peer discovery via dns");
        this._started = true;
        await this.findPeers();
    }
    async findPeers() {
        if (!this.nextPeer) {
            let { enrUrls } = this._options;
            if (!Array.isArray(enrUrls))
                enrUrls = [enrUrls];
            const { wantedNodeCapabilityCount } = this._options;
            const dns = await DnsNodeDiscovery.dnsOverHttp();
            this.nextPeer = dns.getNextPeer.bind(dns, enrUrls, wantedNodeCapabilityCount);
        }
        for await (const peerEnr of this.nextPeer()) {
            if (!this._started) {
                return;
            }
            const { peerInfo, shardInfo } = peerEnr;
            if (!peerInfo) {
                continue;
            }
            const tagsToUpdate = {
                [DEFAULT_BOOTSTRAP_TAG_NAME]: {
                    value: this._options.tagValue ?? DEFAULT_BOOTSTRAP_TAG_VALUE,
                    ttl: this._options.tagTTL ?? DEFAULT_BOOTSTRAP_TAG_TTL
                }
            };
            let isPeerChanged = false;
            const isPeerExists = await this._components.peerStore.has(peerInfo.id);
            if (isPeerExists) {
                const peer = await this._components.peerStore.get(peerInfo.id);
                const hasBootstrapTag = peer.tags.has(DEFAULT_BOOTSTRAP_TAG_NAME);
                if (!hasBootstrapTag) {
                    isPeerChanged = true;
                    await this._components.peerStore.merge(peerInfo.id, {
                        tags: tagsToUpdate
                    });
                }
            }
            else {
                isPeerChanged = true;
                await this._components.peerStore.save(peerInfo.id, {
                    tags: tagsToUpdate,
                    ...(shardInfo && {
                        metadata: {
                            shardInfo: encodeRelayShard(shardInfo)
                        }
                    })
                });
            }
            if (isPeerChanged) {
                this.dispatchEvent(new CustomEvent$1("peer", { detail: peerInfo }));
            }
        }
    }
    /**
     * Stop emitting events
     */
    stop() {
        this._started = false;
    }
    get [peerDiscoverySymbol]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return DNS_DISCOVERY_TAG;
    }
}
function wakuDnsDiscovery(enrUrls, wantedNodeCapabilityCount = DEFAULT_NODE_REQUIREMENTS) {
    return (components) => new PeerDiscoveryDns(components, { enrUrls, wantedNodeCapabilityCount });
}

/**
 * PeerExchangeRPC represents a message conforming to the Waku Peer Exchange protocol
 */
class PeerExchangeRPC {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(params) {
        const { numPeers } = params;
        return new PeerExchangeRPC({
            query: {
                numPeers: numPeers
            },
            response: undefined
        });
    }
    /**
     * Encode the current PeerExchangeRPC request to bytes
     * @returns Uint8Array
     */
    encode() {
        return PeerExchangeRPC$1.encode(this.proto);
    }
    /**
     * Decode the current PeerExchangeRPC request to bytes
     * @returns Uint8Array
     */
    static decode(bytes) {
        const res = PeerExchangeRPC$1.decode(bytes);
        return new PeerExchangeRPC(res);
    }
    get query() {
        return this.proto.query;
    }
    get response() {
        return this.proto.response;
    }
}

const PeerExchangeCodec = "/vac/waku/peer-exchange/2.0.0-alpha1";
const log$3 = new Logger$1("peer-exchange");
/**
 * Implementation of the Peer Exchange protocol (https://rfc.vac.dev/spec/34/)
 */
class WakuPeerExchange extends BaseProtocol {
    /**
     * @param components - libp2p components
     */
    constructor(components, pubsubTopics) {
        super(PeerExchangeCodec, components, log$3, pubsubTopics);
    }
    /**
     * Make a peer exchange query to a peer
     */
    async query(params) {
        const { numPeers, peerId } = params;
        const rpcQuery = PeerExchangeRPC.createRequest({
            numPeers: BigInt(numPeers)
        });
        const peer = await this.components.peerStore.get(peerId);
        if (!peer) {
            return {
                peerInfos: null,
                error: ProtocolError.NO_PEER_AVAILABLE
            };
        }
        let stream;
        try {
            stream = await this.getStream(peer);
        }
        catch (err) {
            log$3.error("Failed to get stream", err);
            return {
                peerInfos: null,
                error: ProtocolError.NO_STREAM_AVAILABLE
            };
        }
        const res = await pipe([rpcQuery.encode()], encode$5, stream, decode$4, async (source) => await all$1(source));
        try {
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const { response } = PeerExchangeRPC.decode(bytes);
            if (!response) {
                log$3.error("PeerExchangeRPC message did not contains a `response` field");
                return {
                    peerInfos: null,
                    error: ProtocolError.EMPTY_PAYLOAD
                };
            }
            const peerInfos = await Promise.all(response.peerInfos
                .map((peerInfo) => peerInfo.enr)
                .filter(isDefined)
                .map(async (enr) => {
                return { ENR: await EnrDecoder.fromRLP(enr) };
            }));
            return {
                peerInfos,
                error: null
            };
        }
        catch (err) {
            log$3.error("Failed to decode push reply", err);
            return {
                peerInfos: null,
                error: ProtocolError.DECODE_FAILED
            };
        }
    }
}

const log$2 = new Logger$1("peer-exchange-discovery");
const DEFAULT_PEER_EXCHANGE_REQUEST_NODES = 10;
const DEFAULT_PEER_EXCHANGE_QUERY_INTERVAL_MS = 10 * 1000;
const DEFAULT_MAX_RETRIES = 3;
const DEFAULT_PEER_EXCHANGE_TAG_NAME = Tags.PEER_EXCHANGE;
const DEFAULT_PEER_EXCHANGE_TAG_VALUE = 50;
const DEFAULT_PEER_EXCHANGE_TAG_TTL = 100_000_000;
class PeerExchangeDiscovery extends TypedEventEmitter {
    components;
    peerExchange;
    options;
    isStarted;
    queryingPeers = new Set();
    queryAttempts = new Map();
    handleDiscoveredPeer = (event) => {
        const { protocols, peerId } = event.detail;
        if (!protocols.includes(PeerExchangeCodec) ||
            this.queryingPeers.has(peerId.toString()))
            return;
        this.queryingPeers.add(peerId.toString());
        this.startRecurringQueries(peerId).catch((error) => log$2.error(`Error querying peer ${error}`));
    };
    constructor(components, pubsubTopics, options = {}) {
        super();
        this.components = components;
        this.peerExchange = new WakuPeerExchange(components, pubsubTopics);
        this.options = options;
        this.isStarted = false;
    }
    /**
     * Start emitting events
     */
    start() {
        if (this.isStarted) {
            return;
        }
        this.dispatchEvent(new CustomEvent$1("waku:peer-exchange:started", { detail: true }));
        log$2.info("Starting peer exchange node discovery, discovering peers");
        // might be better to use "peer:identify" or "peer:update"
        this.components.events.addEventListener("peer:identify", this.handleDiscoveredPeer);
    }
    /**
     * Remove event listener
     */
    stop() {
        if (!this.isStarted)
            return;
        log$2.info("Stopping peer exchange node discovery");
        this.isStarted = false;
        this.queryingPeers.clear();
        this.components.events.removeEventListener("peer:identify", this.handleDiscoveredPeer);
    }
    get [peerDiscoverySymbol]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return "@waku/peer-exchange";
    }
    startRecurringQueries = async (peerId) => {
        const peerIdStr = peerId.toString();
        const { queryInterval = DEFAULT_PEER_EXCHANGE_QUERY_INTERVAL_MS, maxRetries = DEFAULT_MAX_RETRIES } = this.options;
        log$2.info(`Querying peer: ${peerIdStr} (attempt ${this.queryAttempts.get(peerIdStr) ?? 1})`);
        await this.query(peerId);
        const currentAttempt = this.queryAttempts.get(peerIdStr) ?? 1;
        if (currentAttempt > maxRetries) {
            this.abortQueriesForPeer(peerIdStr);
            return;
        }
        setTimeout(() => {
            this.queryAttempts.set(peerIdStr, currentAttempt + 1);
            this.startRecurringQueries(peerId).catch((error) => {
                log$2.error(`Error in startRecurringQueries: ${error}`);
            });
        }, queryInterval * currentAttempt);
    };
    async query(peerId) {
        const { error, peerInfos } = await this.peerExchange.query({
            numPeers: DEFAULT_PEER_EXCHANGE_REQUEST_NODES,
            peerId
        });
        if (error) {
            log$2.error("Peer exchange query failed", error);
            return { error, peerInfos: null };
        }
        for (const _peerInfo of peerInfos) {
            const { ENR } = _peerInfo;
            if (!ENR) {
                log$2.warn("No ENR in peerInfo object, skipping");
                continue;
            }
            const { peerId, peerInfo, shardInfo } = ENR;
            if (!peerId || !peerInfo) {
                continue;
            }
            const hasPeer = await this.components.peerStore.has(peerId);
            if (hasPeer) {
                const { hasMultiaddrDiff, hasShardDiff } = await this.checkPeerInfoDiff(peerInfo, shardInfo);
                if (hasMultiaddrDiff || hasShardDiff) {
                    log$2.info(`Peer ${peerId.toString()} has updated multiaddrs or shardInfo, updating`);
                    if (hasMultiaddrDiff) {
                        log$2.info(`Peer ${peerId.toString()} has updated multiaddrs, updating`);
                        await this.components.peerStore.patch(peerId, {
                            multiaddrs: peerInfo.multiaddrs
                        });
                    }
                    if (hasShardDiff && shardInfo) {
                        log$2.info(`Peer ${peerId.toString()} has updated shardInfo, updating`);
                        await this.components.peerStore.merge(peerId, {
                            metadata: {
                                shardInfo: encodeRelayShard(shardInfo)
                            }
                        });
                        this.dispatchEvent(new CustomEvent$1("peer", {
                            detail: {
                                id: peerId,
                                multiaddrs: peerInfo.multiaddrs
                            }
                        }));
                    }
                    continue;
                }
            }
            // update the tags for the peer
            await this.components.peerStore.save(peerId, {
                tags: {
                    [DEFAULT_PEER_EXCHANGE_TAG_NAME]: {
                        value: this.options.tagValue ?? DEFAULT_PEER_EXCHANGE_TAG_VALUE,
                        ttl: this.options.tagTTL ?? DEFAULT_PEER_EXCHANGE_TAG_TTL
                    }
                },
                ...(shardInfo && {
                    metadata: {
                        shardInfo: encodeRelayShard(shardInfo)
                    }
                }),
                ...(peerInfo.multiaddrs && {
                    multiaddrs: peerInfo.multiaddrs
                })
            });
            log$2.info(`Discovered peer: ${peerId.toString()}`);
            this.dispatchEvent(new CustomEvent$1("peer", {
                detail: {
                    id: peerId,
                    multiaddrs: peerInfo.multiaddrs
                }
            }));
        }
        return { error: null, peerInfos };
    }
    abortQueriesForPeer(peerIdStr) {
        log$2.info(`Aborting queries for peer: ${peerIdStr}`);
        this.queryingPeers.delete(peerIdStr);
        this.queryAttempts.delete(peerIdStr);
    }
    async checkPeerInfoDiff(peerInfo, shardInfo) {
        const { id: peerId } = peerInfo;
        const peer = await this.components.peerStore.get(peerId);
        const existingMultiaddrs = peer.addresses.map((a) => a.multiaddr.toString());
        const newMultiaddrs = peerInfo.multiaddrs.map((ma) => ma.toString());
        const hasMultiaddrDiff = existingMultiaddrs.some((ma) => !newMultiaddrs.includes(ma));
        let hasShardDiff = false;
        const existingShardInfoBytes = peer.metadata.get("shardInfo");
        if (existingShardInfoBytes) {
            const existingShardInfo = decodeRelayShard(existingShardInfoBytes);
            if (existingShardInfo || shardInfo) {
                hasShardDiff =
                    existingShardInfo.clusterId !== shardInfo?.clusterId ||
                        existingShardInfo.shards.some((shard) => !shardInfo?.shards.includes(shard));
            }
        }
        return { hasMultiaddrDiff, hasShardDiff };
    }
}
function wakuPeerExchangeDiscovery(pubsubTopics) {
    return (components) => new PeerExchangeDiscovery(components, pubsubTopics);
}

const log$1 = new Logger$1("peer-exchange-discovery");
const DEFAULT_LOCAL_TAG_NAME = Tags.LOCAL;
const DEFAULT_LOCAL_TAG_VALUE = 50;
const DEFAULT_LOCAL_TAG_TTL = 100_000_000;
class LocalPeerCacheDiscovery extends TypedEventEmitter {
    components;
    options;
    isStarted;
    peers = [];
    constructor(components, options) {
        super();
        this.components = components;
        this.options = options;
        this.isStarted = false;
        this.peers = this.getPeersFromLocalStorage();
    }
    get [Symbol.toStringTag]() {
        return "@waku/local-peer-cache-discovery";
    }
    async start() {
        if (this.isStarted)
            return;
        log$1.info("Starting Local Storage Discovery");
        this.components.events.addEventListener("peer:identify", this.handleNewPeers);
        for (const { id: idStr, address } of this.peers) {
            const peerId = await createFromJSON({ id: idStr });
            if (await this.components.peerStore.has(peerId))
                continue;
            await this.components.peerStore.save(peerId, {
                multiaddrs: [multiaddr(address)],
                tags: {
                    [this.options?.tagName ?? DEFAULT_LOCAL_TAG_NAME]: {
                        value: this.options?.tagValue ?? DEFAULT_LOCAL_TAG_VALUE,
                        ttl: this.options?.tagTTL ?? DEFAULT_LOCAL_TAG_TTL
                    }
                }
            });
            this.dispatchEvent(new CustomEvent$1("peer", {
                detail: {
                    id: peerId,
                    multiaddrs: [multiaddr(address)]
                }
            }));
        }
        log$1.info(`Discovered ${this.peers.length} peers`);
        this.isStarted = true;
    }
    stop() {
        if (!this.isStarted)
            return;
        log$1.info("Stopping Local Storage Discovery");
        this.components.events.removeEventListener("peer:identify", this.handleNewPeers);
        this.isStarted = false;
        this.savePeersToLocalStorage();
    }
    handleNewPeers = (event) => {
        const { peerId, listenAddrs } = event.detail;
        const websocketMultiaddr = getWsMultiaddrFromMultiaddrs(listenAddrs);
        const localStoragePeers = this.getPeersFromLocalStorage();
        const existingPeerIndex = localStoragePeers.findIndex((_peer) => _peer.id === peerId.toString());
        if (existingPeerIndex >= 0) {
            localStoragePeers[existingPeerIndex].address =
                websocketMultiaddr.toString();
        }
        else {
            localStoragePeers.push({
                id: peerId.toString(),
                address: websocketMultiaddr.toString()
            });
        }
        this.peers = localStoragePeers;
        this.savePeersToLocalStorage();
    };
    getPeersFromLocalStorage() {
        try {
            const storedPeersData = localStorage.getItem("waku:peers");
            if (!storedPeersData)
                return [];
            const peers = JSON.parse(storedPeersData);
            return peers.filter(isValidStoredPeer);
        }
        catch (error) {
            log$1.error("Error parsing peers from local storage:", error);
            return [];
        }
    }
    savePeersToLocalStorage() {
        try {
            localStorage.setItem("waku:peers", JSON.stringify(this.peers));
        }
        catch (error) {
            log$1.error("Error saving peers to local storage:", error);
        }
    }
}
function isValidStoredPeer(peer) {
    return (peer &&
        typeof peer === "object" &&
        typeof peer.id === "string" &&
        typeof peer.address === "string");
}
function wakuLocalPeerCacheDiscovery() {
    return (components, options) => new LocalPeerCacheDiscovery(components, options);
}

function defaultPeerDiscoveries(pubsubTopics) {
    const dnsEnrTrees = [enrTree["SANDBOX"], enrTree["TEST"]];
    const discoveries = [
        wakuDnsDiscovery(dnsEnrTrees),
        wakuLocalPeerCacheDiscovery(),
        wakuPeerExchangeDiscovery(pubsubTopics)
    ];
    return discoveries;
}

const log = new Logger$1("sdk:create");
async function defaultLibp2p(pubsubTopics, options, userAgent) {
    if (!options?.hideWebSocketInfo && "production" !== "test") {
        /* eslint-disable no-console */
        console.info("%cIgnore WebSocket connection failures", "background: gray; color: white; font-size: x-large");
        console.info("%cWaku tries to discover peers and some of them are expected to fail", "background: gray; color: white; font-size: x-large");
        /* eslint-enable no-console */
    }
    const metadataService = pubsubTopics
        ? { metadata: wakuMetadata(pubsubTopics) }
        : {};
    const filter = options?.filterMultiaddrs === false || "production" === "test"
        ? all
        : wss;
    return createLibp2p({
        connectionManager: {
            minConnections: 1
        },
        transports: [webSockets({ filter: filter })],
        streamMuxers: [mplex()],
        connectionEncryption: [noise()],
        ...options,
        services: {
            identify: identify({
                agentVersion: userAgent ?? DefaultUserAgent
            }),
            ping: ping({
                maxInboundStreams: options?.pingMaxInboundStreams ?? DefaultPingMaxInboundStreams
            }),
            ...metadataService,
            ...options?.services
        }
    }); // TODO: make libp2p include it;
}
async function createLibp2pAndUpdateOptions(options) {
    const { networkConfig } = options;
    const pubsubTopics = derivePubsubTopicsFromNetworkConfig(networkConfig ?? DefaultNetworkConfig);
    log.info("Creating Waku node with pubsub topics", pubsubTopics);
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(...defaultPeerDiscoveries(pubsubTopics));
    }
    if (options?.bootstrapPeers) {
        peerDiscovery.push(bootstrap({ list: options.bootstrapPeers }));
    }
    libp2pOptions.peerDiscovery = peerDiscovery;
    const libp2p = await defaultLibp2p(pubsubTopics, libp2pOptions, options?.userAgent);
    return { libp2p, pubsubTopics };
}

/**
 * Create a Waku node that uses Waku Light Push, Filter and Store to send and
 * receive messages, enabling low resource consumption.
 * Uses Waku Filter V2 by default.
 */
async function createLightNode(options = {}) {
    const { libp2p, pubsubTopics } = await createLibp2pAndUpdateOptions(options);
    return new WakuNode(pubsubTopics, options, libp2p, {
        store: true,
        lightpush: true,
        filter: true
    });
}

export { DEFAULT_CLUSTER_ID, DNS_DISCOVERY_TAG, DecodedMessage, Decoder$1 as Decoder, DefaultNetworkConfig, DefaultPingKeepAliveValueSecs, DefaultPingMaxInboundStreams, DefaultRelayKeepAliveValueSecs, DefaultShardInfo, DefaultUserAgent, EConnectionStateEvents, EPeersByDiscoveryEvents, Encoder$1 as Encoder, HealthStatus, ProtocolError, Protocols, Tags, WakuNode, bytesToUtf8, createDecoder, createEncoder, createLibp2pAndUpdateOptions, createLightNode, defaultLibp2p, utf8ToBytes$2 as utf8ToBytes, index$5 as utils, waitForRemotePeer, index as waku, wakuFilter, wakuLightPush, wakuStore };

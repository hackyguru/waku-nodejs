import { concat, utf8ToBytes as utf8ToBytes$1 } from './bytes.js';

function isDefined(value) {
    return Boolean(value);
}

/**
 * Return pseudo random subset of the input.
 */
function getPseudoRandomSubset(values, wantedNumber) {
    if (values.length <= wantedNumber || values.length <= 1) {
        return values;
    }
    return shuffle(values).slice(0, wantedNumber);
}
function shuffle(arr) {
    if (arr.length <= 1) {
        return arr;
    }
    const randInt = () => {
        return Math.floor(Math.random() * Math.floor(arr.length));
    };
    for (let i = 0; i < arr.length; i++) {
        const j = randInt();
        const tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
    return arr;
}

function groupByContentTopic(values) {
    const groupedDecoders = new Map();
    values.forEach((value) => {
        let decs = groupedDecoders.get(value.contentTopic);
        if (!decs) {
            groupedDecoders.set(value.contentTopic, []);
            decs = groupedDecoders.get(value.contentTopic);
        }
        decs.push(value);
    });
    return groupedDecoders;
}

const FRAME_RATE = 60;
/**
 * Function that transforms IReceiver subscription to iterable stream of data.
 * @param receiver - object that allows to be subscribed to;
 * @param decoder - parameter to be passed to receiver for subscription;
 * @param options - options for receiver for subscription;
 * @param iteratorOptions - optional configuration for iterator;
 * @returns iterator and stop function to terminate it.
 */
async function toAsyncIterator(receiver, decoder, iteratorOptions) {
    const iteratorDelay = iteratorOptions?.iteratorDelay ?? FRAME_RATE;
    const messages = [];
    let unsubscribe;
    unsubscribe = await receiver.subscribeWithUnsubscribe(decoder, (message) => {
        messages.push(message);
    });
    const isWithTimeout = Number.isInteger(iteratorOptions?.timeoutMs);
    const timeoutMs = iteratorOptions?.timeoutMs ?? 0;
    const startTime = Date.now();
    async function* iterator() {
        while (true) {
            if (isWithTimeout && Date.now() - startTime >= timeoutMs) {
                return;
            }
            await wait(iteratorDelay);
            const message = messages.shift();
            if (!unsubscribe && messages.length === 0) {
                return message;
            }
            if (!message && unsubscribe) {
                continue;
            }
            yield message;
        }
    }
    return {
        iterator: iterator(),
        async stop() {
            if (unsubscribe) {
                await unsubscribe();
                unsubscribe = undefined;
            }
        }
    };
}
function wait(ms) {
    return new Promise((resolve) => {
        setTimeout(resolve, ms);
    });
}

const MB = 1024 ** 2;
const SIZE_CAP_IN_MB = 1;
/**
 * Return whether the size of the message is under the upper limit for the network.
 * This performs a protobuf encoding! If you have access to the fully encoded message,
 * use {@link isSizeUnderCapBuf} instead.
 * @param message
 * @param encoder
 */
async function isMessageSizeUnderCap(encoder, message) {
    const buf = await encoder.toWire(message);
    if (!buf)
        return false;
    return isWireSizeUnderCap(buf);
}
const isWireSizeUnderCap = (buf) => buf.length / MB <= SIZE_CAP_IN_MB;

// copied from utils
function isBytes(a) {
    return (a instanceof Uint8Array ||
        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));
}
function bytes(b, ...lengths) {
    if (!isBytes(b))
        throw new Error('Uint8Array expected');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error(`Uint8Array expected of length ${lengths}, not of length=${b.length}`);
}
function exists(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output(out, instance) {
    bytes(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}

/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.
// node.js versions earlier than v19 don't declare it in global scope.
// For node.js, package.json#exports field mapping rewrites import
// from `crypto` to `cryptoNode`, which imports native module.
// Makes the utils un-importable in browsers without a bundler.
// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.
// Cast array to view
const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// The rotate right (circular right shift) operation for uint32
const rotr = (word, shift) => (word << (32 - shift)) | (word >>> shift);
new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes(data) {
    if (typeof data === 'string')
        data = utf8ToBytes(data);
    bytes(data);
    return data;
}
// For runtime check if class implements interface
class Hash {
    // Safe version that clones internal state
    clone() {
        return this._cloneInto();
    }
}
function wrapConstructor(hashCons) {
    const hashC = (msg) => hashCons().update(toBytes(msg)).digest();
    const tmp = hashCons();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashCons();
    return hashC;
}

/**
 * Polyfill for Safari 14
 */
function setBigUint64(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
/**
 * Choice: a ? b : c
 */
const Chi = (a, b, c) => (a & b) ^ (~a & c);
/**
 * Majority function, true if any two inputs is true
 */
const Maj = (a, b, c) => (a & b) ^ (a & c) ^ (b & c);
/**
 * Merkle-Damgard hash construction base class.
 * Could be used to create MD5, RIPEMD, SHA1, SHA2.
 */
class HashMD extends Hash {
    constructor(blockLen, outputLen, padOffset, isLE) {
        super();
        this.blockLen = blockLen;
        this.outputLen = outputLen;
        this.padOffset = padOffset;
        this.isLE = isLE;
        this.finished = false;
        this.length = 0;
        this.pos = 0;
        this.destroyed = false;
        this.buffer = new Uint8Array(blockLen);
        this.view = createView(this.buffer);
    }
    update(data) {
        exists(this);
        const { view, buffer, blockLen } = this;
        data = toBytes(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input, cast it to view and process
            if (take === blockLen) {
                const dataView = createView(data);
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(dataView, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(view, 0);
                this.pos = 0;
            }
        }
        this.length += data.length;
        this.roundClean();
        return this;
    }
    digestInto(out) {
        exists(this);
        output(out, this);
        this.finished = true;
        // Padding
        // We can avoid allocation of buffer for padding completely if it
        // was previously not allocated here. But it won't change performance.
        const { buffer, view, blockLen, isLE } = this;
        let { pos } = this;
        // append the bit '1' to the message
        buffer[pos++] = 0b10000000;
        this.buffer.subarray(pos).fill(0);
        // we have less than padOffset left in buffer, so we cannot put length in
        // current block, need process it and pad again
        if (this.padOffset > blockLen - pos) {
            this.process(view, 0);
            pos = 0;
        }
        // Pad until full block byte with zeros
        for (let i = pos; i < blockLen; i++)
            buffer[i] = 0;
        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that
        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.
        // So we just write lowest 64 bits of that value.
        setBigUint64(view, blockLen - 8, BigInt(this.length * 8), isLE);
        this.process(view, 0);
        const oview = createView(out);
        const len = this.outputLen;
        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT
        if (len % 4)
            throw new Error('_sha2: outputLen should be aligned to 32bit');
        const outLen = len / 4;
        const state = this.get();
        if (outLen > state.length)
            throw new Error('_sha2: outputLen bigger than state');
        for (let i = 0; i < outLen; i++)
            oview.setUint32(4 * i, state[i], isLE);
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
    _cloneInto(to) {
        to || (to = new this.constructor());
        to.set(...this.get());
        const { blockLen, buffer, length, finished, destroyed, pos } = this;
        to.length = length;
        to.pos = pos;
        to.finished = finished;
        to.destroyed = destroyed;
        if (length % blockLen)
            to.buffer.set(buffer);
        return to;
    }
}

// SHA2-256 need to try 2^128 hashes to execute birthday attack.
// BTC network is doing 2^67 hashes/sec as per early 2023.
// Round constants:
// first 32 bits of the fractional parts of the cube roots of the first 64 primes 2..311)
// prettier-ignore
const SHA256_K = /* @__PURE__ */ new Uint32Array([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
]);
// Initial state:
// first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19
// prettier-ignore
const SHA256_IV = /* @__PURE__ */ new Uint32Array([
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
]);
// Temporary buffer, not used to store anything between runs
// Named this way because it matches specification.
const SHA256_W = /* @__PURE__ */ new Uint32Array(64);
class SHA256 extends HashMD {
    constructor() {
        super(64, 32, 8, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        this.A = SHA256_IV[0] | 0;
        this.B = SHA256_IV[1] | 0;
        this.C = SHA256_IV[2] | 0;
        this.D = SHA256_IV[3] | 0;
        this.E = SHA256_IV[4] | 0;
        this.F = SHA256_IV[5] | 0;
        this.G = SHA256_IV[6] | 0;
        this.H = SHA256_IV[7] | 0;
    }
    get() {
        const { A, B, C, D, E, F, G, H } = this;
        return [A, B, C, D, E, F, G, H];
    }
    // prettier-ignore
    set(A, B, C, D, E, F, G, H) {
        this.A = A | 0;
        this.B = B | 0;
        this.C = C | 0;
        this.D = D | 0;
        this.E = E | 0;
        this.F = F | 0;
        this.G = G | 0;
        this.H = H | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4)
            SHA256_W[i] = view.getUint32(offset, false);
        for (let i = 16; i < 64; i++) {
            const W15 = SHA256_W[i - 15];
            const W2 = SHA256_W[i - 2];
            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);
            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);
            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;
        }
        // Compression function main loop, 64 rounds
        let { A, B, C, D, E, F, G, H } = this;
        for (let i = 0; i < 64; i++) {
            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);
            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);
            const T2 = (sigma0 + Maj(A, B, C)) | 0;
            H = G;
            G = F;
            F = E;
            E = (D + T1) | 0;
            D = C;
            C = B;
            B = A;
            A = (T1 + T2) | 0;
        }
        // Add the compressed chunk to the current hash value
        A = (A + this.A) | 0;
        B = (B + this.B) | 0;
        C = (C + this.C) | 0;
        D = (D + this.D) | 0;
        E = (E + this.E) | 0;
        F = (F + this.F) | 0;
        G = (G + this.G) | 0;
        H = (H + this.H) | 0;
        this.set(A, B, C, D, E, F, G, H);
    }
    roundClean() {
        SHA256_W.fill(0);
    }
    destroy() {
        this.set(0, 0, 0, 0, 0, 0, 0, 0);
        this.buffer.fill(0);
    }
}
/**
 * SHA2-256 hash function
 * @param message - data that would be hashed
 */
const sha256 = /* @__PURE__ */ wrapConstructor(() => new SHA256());

var Protocols;
(function (Protocols) {
    Protocols["Relay"] = "relay";
    Protocols["Store"] = "store";
    Protocols["LightPush"] = "lightpush";
    Protocols["Filter"] = "filter";
})(Protocols || (Protocols = {}));
var ProtocolError;
(function (ProtocolError) {
    /** Could not determine the origin of the fault. Best to check connectivity and try again */
    ProtocolError["GENERIC_FAIL"] = "Generic error";
    /**
     * Failure to protobuf encode the message. This is not recoverable and needs
     * further investigation.
     */
    ProtocolError["ENCODE_FAILED"] = "Failed to encode";
    /**
     * Failure to protobuf decode the message. May be due to a remote peer issue,
     * ensuring that messages are sent via several peer enable mitigation of this error.
     */
    ProtocolError["DECODE_FAILED"] = "Failed to decode";
    /**
     * The message payload is empty, making the message invalid. Ensure that a non-empty
     * payload is set on the outgoing message.
     */
    ProtocolError["EMPTY_PAYLOAD"] = "Payload is empty";
    /**
     * The message size is above the maximum message size allowed on the Waku Network.
     * Compressing the message or using an alternative strategy for large messages is recommended.
     */
    ProtocolError["SIZE_TOO_BIG"] = "Size is too big";
    /**
     * The PubsubTopic passed to the send function is not configured on the Waku node.
     * Please ensure that the PubsubTopic is used when initializing the Waku node.
     */
    ProtocolError["TOPIC_NOT_CONFIGURED"] = "Topic not configured";
    /**
     * The pubsub topic configured on the decoder does not match the pubsub topic setup on the protocol.
     * Ensure that the pubsub topic used for decoder creation is the same as the one used for protocol.
     */
    ProtocolError["TOPIC_DECODER_MISMATCH"] = "Topic decoder mismatch";
    /**
     * The topics passed in the decoders do not match each other, or don't exist at all.
     * Ensure that all the pubsub topics used in the decoders are valid and match each other.
     */
    ProtocolError["INVALID_DECODER_TOPICS"] = "Invalid decoder topics";
    /**
     * Failure to find a peer with suitable protocols. This may due to a connection issue.
     * Mitigation can be: retrying after a given time period, display connectivity issue
     * to user or listening for `peer:connected:bootstrap` or `peer:connected:peer-exchange`
     * on the connection manager before retrying.
     */
    ProtocolError["NO_PEER_AVAILABLE"] = "No peer available";
    /**
     * Failure to find a stream to the peer. This may be because the connection with the peer is not still alive.
     * Mitigation can be: retrying after a given time period, or mitigation for `NO_PEER_AVAILABLE` can be used.
     */
    ProtocolError["NO_STREAM_AVAILABLE"] = "No stream available";
    /**
     * The remote peer did not behave as expected. Mitigation for `NO_PEER_AVAILABLE`
     * or `DECODE_FAILED` can be used.
     */
    ProtocolError["NO_RESPONSE"] = "No response received";
    /**
     * The remote peer rejected the message. Information provided by the remote peer
     * is logged. Review message validity, or mitigation for `NO_PEER_AVAILABLE`
     * or `DECODE_FAILED` can be used.
     */
    ProtocolError["REMOTE_PEER_REJECTED"] = "Remote peer rejected";
    /**
     * The protocol request timed out without a response. This may be due to a connection issue.
     * Mitigation can be: retrying after a given time period
     */
    ProtocolError["REQUEST_TIMEOUT"] = "Request timeout";
    /**
     * Missing credentials info message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L186
     */
    ProtocolError["RLN_IDENTITY_MISSING"] = "Identity credentials are not set";
    /**
     * Membership index missing info message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L188
     */
    ProtocolError["RLN_MEMBERSHIP_INDEX"] = "Membership index is not set";
    /**
     * Message limit is missing.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L190
     */
    ProtocolError["RLN_LIMIT_MISSING"] = "User message limit is not set";
    /**
     * General proof generation error message.
     * nwaku: https://github.com/waku-org/nwaku/blob/c3cb06ac6c03f0f382d3941ea53b330f6a8dd127/waku/waku_rln_relay/group_manager/group_manager_base.nim#L201C19-L201C42
     */
    ProtocolError["RLN_PROOF_GENERATION"] = "Proof generation failed";
})(ProtocolError || (ProtocolError = {}));

var Tags;
(function (Tags) {
    Tags["BOOTSTRAP"] = "bootstrap";
    Tags["PEER_EXCHANGE"] = "peer-exchange";
    Tags["LOCAL"] = "local-peer-cache";
})(Tags || (Tags = {}));
var EPeersByDiscoveryEvents;
(function (EPeersByDiscoveryEvents) {
    EPeersByDiscoveryEvents["PEER_DISCOVERY_BOOTSTRAP"] = "peer:discovery:bootstrap";
    EPeersByDiscoveryEvents["PEER_DISCOVERY_PEER_EXCHANGE"] = "peer:discovery:peer-exchange";
    EPeersByDiscoveryEvents["PEER_CONNECT_BOOTSTRAP"] = "peer:connected:bootstrap";
    EPeersByDiscoveryEvents["PEER_CONNECT_PEER_EXCHANGE"] = "peer:connected:peer-exchange";
})(EPeersByDiscoveryEvents || (EPeersByDiscoveryEvents = {}));
var EConnectionStateEvents;
(function (EConnectionStateEvents) {
    EConnectionStateEvents["CONNECTION_STATUS"] = "waku:connection";
})(EConnectionStateEvents || (EConnectionStateEvents = {}));

/**
 * The default cluster ID for The Waku Network
 */
const DEFAULT_CLUSTER_ID = 1;

var HealthStatus;
(function (HealthStatus) {
    HealthStatus["Unhealthy"] = "Unhealthy";
    HealthStatus["MinimallyHealthy"] = "MinimallyHealthy";
    HealthStatus["SufficientlyHealthy"] = "SufficientlyHealthy";
})(HealthStatus || (HealthStatus = {}));

function isStaticSharding(config) {
    return ("clusterId" in config && "shards" in config && !("contentTopics" in config));
}
function isAutoSharding(config) {
    return "contentTopics" in config;
}

function derivePubsubTopicsFromNetworkConfig(networkConfig) {
    if (isStaticSharding(networkConfig)) {
        if (networkConfig.shards.length === 0) {
            throw new Error("Invalid shards configuration: please provide at least one shard");
        }
        return shardInfoToPubsubTopics(networkConfig);
    }
    else if (isAutoSharding(networkConfig)) {
        if (networkConfig.contentTopics.length === 0) {
            throw new Error("Invalid content topics configuration: please provide at least one content topic");
        }
        return networkConfig.contentTopics.map((contentTopic) => contentTopicToPubsubTopic(contentTopic, networkConfig.clusterId));
    }
    else {
        throw new Error("Unknown shard config. Please use ShardInfo or ContentTopicInfo");
    }
}
const singleShardInfoToPubsubTopic = (shardInfo) => {
    if (shardInfo.shard === undefined)
        throw new Error("Invalid shard");
    return `/waku/2/rs/${shardInfo.clusterId ?? DEFAULT_CLUSTER_ID}/${shardInfo.shard}`;
};
const singleShardInfosToShardInfo = (singleShardInfos) => {
    if (singleShardInfos.length === 0)
        throw new Error("Invalid shard");
    const clusterIds = singleShardInfos.map((shardInfo) => shardInfo.clusterId);
    if (new Set(clusterIds).size !== 1) {
        throw new Error("Passed shard infos have different clusterIds");
    }
    const shards = singleShardInfos
        .map((shardInfo) => shardInfo.shard)
        .filter((shard) => shard !== undefined);
    return {
        clusterId: singleShardInfos[0].clusterId,
        shards
    };
};
const shardInfoToPubsubTopics = (shardInfo) => {
    if ("contentTopics" in shardInfo && shardInfo.contentTopics) {
        // Autosharding: explicitly defined content topics
        return Array.from(new Set(shardInfo.contentTopics.map((contentTopic) => contentTopicToPubsubTopic(contentTopic, shardInfo.clusterId))));
    }
    else if ("shards" in shardInfo) {
        // Static sharding
        if (shardInfo.shards === undefined)
            throw new Error("Invalid shard");
        return Array.from(new Set(shardInfo.shards.map((index) => `/waku/2/rs/${shardInfo.clusterId ?? DEFAULT_CLUSTER_ID}/${index}`)));
    }
    else if ("application" in shardInfo && "version" in shardInfo) {
        // Autosharding: single shard from application and version
        return [
            contentTopicToPubsubTopic(`/${shardInfo.application}/${shardInfo.version}/default/default`, shardInfo.clusterId)
        ];
    }
    else {
        throw new Error("Missing required configuration in shard parameters");
    }
};
const pubsubTopicToSingleShardInfo = (pubsubTopics) => {
    const parts = pubsubTopics.split("/");
    if (parts.length != 6 ||
        parts[1] !== "waku" ||
        parts[2] !== "2" ||
        parts[3] !== "rs")
        throw new Error("Invalid pubsub topic");
    const clusterId = parseInt(parts[4]);
    const shard = parseInt(parts[5]);
    if (isNaN(clusterId) || isNaN(shard))
        throw new Error("Invalid clusterId or shard");
    return {
        clusterId,
        shard
    };
};
const pubsubTopicsToShardInfo = (pubsubTopics) => {
    const shardInfoSet = new Set();
    const clusterIds = new Set();
    for (const topic of pubsubTopics) {
        const { clusterId, shard } = pubsubTopicToSingleShardInfo(topic);
        shardInfoSet.add(`${clusterId}:${shard}`);
        clusterIds.add(clusterId);
    }
    if (shardInfoSet.size === 0) {
        throw new Error("No valid pubsub topics provided");
    }
    if (clusterIds.size > 1) {
        throw new Error("Pubsub topics from multiple cluster IDs are not supported");
    }
    const clusterId = clusterIds.values().next().value;
    const shards = Array.from(shardInfoSet).map((info) => parseInt(info.split(":")[1]));
    return {
        clusterId,
        shards
    };
};
//TODO: move part of BaseProtocol instead of utils
// return `ProtocolError.TOPIC_NOT_CONFIGURED` instead of throwing
function ensurePubsubTopicIsConfigured(pubsubTopic, configuredTopics) {
    if (!configuredTopics.includes(pubsubTopic)) {
        throw new Error(`Pubsub topic ${pubsubTopic} has not been configured on this instance. Configured topics are: ${configuredTopics}. Please update your configuration by passing in the topic during Waku node instantiation.`);
    }
}
/**
 * Given a string, will throw an error if it is not formatted as a valid content topic for autosharding based on https://rfc.vac.dev/spec/51/
 * @param contentTopic String to validate
 * @returns Object with each content topic field as an attribute
 */
function ensureValidContentTopic(contentTopic) {
    const parts = contentTopic.split("/");
    if (parts.length < 5 || parts.length > 6) {
        throw Error("Content topic format is invalid");
    }
    // Validate generation field if present
    let generation = 0;
    if (parts.length == 6) {
        generation = parseInt(parts[1]);
        if (isNaN(generation)) {
            throw new Error("Invalid generation field in content topic");
        }
        if (generation > 0) {
            throw new Error("Generation greater than 0 is not supported");
        }
    }
    // Validate remaining fields
    const fields = parts.splice(-4);
    // Validate application field
    if (fields[0].length == 0) {
        throw new Error("Application field cannot be empty");
    }
    // Validate version field
    if (fields[1].length == 0) {
        throw new Error("Version field cannot be empty");
    }
    // Validate topic name field
    if (fields[2].length == 0) {
        throw new Error("Topic name field cannot be empty");
    }
    // Validate encoding field
    if (fields[3].length == 0) {
        throw new Error("Encoding field cannot be empty");
    }
    return {
        generation,
        application: fields[0],
        version: fields[1],
        topicName: fields[2],
        encoding: fields[3]
    };
}
/**
 * Given a string, determines which autoshard index to use for its pubsub topic.
 * Based on the algorithm described in the RFC: https://rfc.vac.dev/spec/51//#algorithm
 */
function contentTopicToShardIndex(contentTopic, networkShards = 8) {
    const { application, version } = ensureValidContentTopic(contentTopic);
    const digest = sha256(concat([utf8ToBytes$1(application), utf8ToBytes$1(version)]));
    const dataview = new DataView(digest.buffer.slice(-8));
    return Number(dataview.getBigUint64(0, false) % BigInt(networkShards));
}
function contentTopicToPubsubTopic(contentTopic, clusterId = DEFAULT_CLUSTER_ID, networkShards = 8) {
    if (!contentTopic) {
        throw Error("Content topic must be specified");
    }
    const shardIndex = contentTopicToShardIndex(contentTopic, networkShards);
    return `/waku/2/rs/${clusterId}/${shardIndex}`;
}
/**
 * Given an array of content topics, groups them together by their Pubsub topic as derived using the algorithm for autosharding.
 * If any of the content topics are not properly formatted, the function will throw an error.
 */
function contentTopicsByPubsubTopic(contentTopics, clusterId = DEFAULT_CLUSTER_ID, networkShards = 8) {
    const groupedContentTopics = new Map();
    for (const contentTopic of contentTopics) {
        const pubsubTopic = contentTopicToPubsubTopic(contentTopic, clusterId, networkShards);
        let topics = groupedContentTopics.get(pubsubTopic);
        if (!topics) {
            groupedContentTopics.set(pubsubTopic, []);
            topics = groupedContentTopics.get(pubsubTopic);
        }
        topics.push(contentTopic);
    }
    return groupedContentTopics;
}
/**
 * Used when creating encoders/decoders to determine which pubsub topic to use
 */
function determinePubsubTopic(contentTopic, 
// TODO: make it accept ShardInfo https://github.com/waku-org/js-waku/issues/2086
pubsubTopicShardInfo) {
    if (typeof pubsubTopicShardInfo == "string") {
        return pubsubTopicShardInfo;
    }
    return pubsubTopicShardInfo?.shard !== undefined
        ? singleShardInfoToPubsubTopic(pubsubTopicShardInfo)
        : contentTopicToPubsubTopic(contentTopic, pubsubTopicShardInfo?.clusterId ?? DEFAULT_CLUSTER_ID);
}
/**
 * Validates sharding configuration and sets defaults where possible.
 * @returns Validated sharding parameters, with any missing values set to defaults
 */
const ensureShardingConfigured = (networkConfig) => {
    const clusterId = networkConfig.clusterId ?? DEFAULT_CLUSTER_ID;
    const shards = "shards" in networkConfig ? networkConfig.shards : [];
    const contentTopics = "contentTopics" in networkConfig ? networkConfig.contentTopics : [];
    const isShardsConfigured = shards && shards.length > 0;
    const isContentTopicsConfigured = contentTopics && contentTopics.length > 0;
    if (isShardsConfigured) {
        return {
            shardInfo: { clusterId, shards },
            pubsubTopics: shardInfoToPubsubTopics({ clusterId, shards })
        };
    }
    if (isContentTopicsConfigured) {
        const pubsubTopics = Array.from(new Set(contentTopics.map((topic) => contentTopicToPubsubTopic(topic, clusterId))));
        const shards = Array.from(new Set(contentTopics.map((topic) => contentTopicToShardIndex(topic))));
        return {
            shardInfo: { clusterId, shards },
            pubsubTopics
        };
    }
    throw new Error("Missing minimum required configuration options for static sharding or autosharding.");
};

function pushOrInitMapSet(map, key, newValue) {
    let arr = map.get(key);
    if (typeof arr === "undefined") {
        map.set(key, new Set());
        arr = map.get(key);
    }
    arr.add(newValue);
}

const decodeRelayShard = (bytes) => {
    // explicitly converting to Uint8Array to avoid Buffer
    // https://github.com/libp2p/js-libp2p/issues/2146
    bytes = new Uint8Array(bytes);
    if (bytes.length < 3)
        throw new Error("Insufficient data");
    const view = new DataView(bytes.buffer);
    const clusterId = view.getUint16(0);
    const shards = [];
    if (bytes.length === 130) {
        // rsv format (Bit Vector)
        for (let i = 0; i < 1024; i++) {
            const byteIndex = Math.floor(i / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (i % 8);
            if (view.getUint8(byteIndex) & (1 << bitIndex)) {
                shards.push(i);
            }
        }
    }
    else {
        // rs format (Index List)
        const numIndices = view.getUint8(2);
        for (let i = 0, offset = 3; i < numIndices; i++, offset += 2) {
            if (offset + 1 >= bytes.length)
                throw new Error("Unexpected end of data");
            shards.push(view.getUint16(offset));
        }
    }
    return { clusterId, shards };
};
const encodeRelayShard = (shardInfo) => {
    const { clusterId, shards } = shardInfo;
    const totalLength = shards.length >= 64 ? 130 : 3 + 2 * shards.length;
    const buffer = new ArrayBuffer(totalLength);
    const view = new DataView(buffer);
    view.setUint16(0, clusterId);
    if (shards.length >= 64) {
        // rsv format (Bit Vector)
        for (const index of shards) {
            const byteIndex = Math.floor(index / 8) + 2; // Adjusted for the 2-byte cluster field
            const bitIndex = 7 - (index % 8);
            view.setUint8(byteIndex, view.getUint8(byteIndex) | (1 << bitIndex));
        }
    }
    else {
        // rs format (Index List)
        view.setUint8(2, shards.length);
        for (let i = 0, offset = 3; i < shards.length; i++, offset += 2) {
            view.setUint16(offset, shards[i]);
        }
    }
    return new Uint8Array(buffer);
};

async function delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
}

function removeItemFromArray(arr, value) {
    const index = arr.indexOf(value);
    if (index > -1) {
        arr.splice(index, 1);
    }
    return arr;
}
function getWsMultiaddrFromMultiaddrs(addresses) {
    const wsMultiaddr = addresses.find((addr) => addr.toString().includes("ws") || addr.toString().includes("wss"));
    if (!wsMultiaddr) {
        throw new Error("No ws multiaddr found in the given addresses");
    }
    return wsMultiaddr;
}

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

var browser = {exports: {}};

/**
 * Helpers.
 */

var ms;
var hasRequiredMs;

function requireMs () {
	if (hasRequiredMs) return ms;
	hasRequiredMs = 1;
	var s = 1000;
	var m = s * 60;
	var h = m * 60;
	var d = h * 24;
	var w = d * 7;
	var y = d * 365.25;

	/**
	 * Parse or format the given `val`.
	 *
	 * Options:
	 *
	 *  - `long` verbose formatting [false]
	 *
	 * @param {String|Number} val
	 * @param {Object} [options]
	 * @throws {Error} throw an error if val is not a non-empty string or a number
	 * @return {String|Number}
	 * @api public
	 */

	ms = function (val, options) {
	  options = options || {};
	  var type = typeof val;
	  if (type === 'string' && val.length > 0) {
	    return parse(val);
	  } else if (type === 'number' && isFinite(val)) {
	    return options.long ? fmtLong(val) : fmtShort(val);
	  }
	  throw new Error(
	    'val is not a non-empty string or a valid number. val=' +
	      JSON.stringify(val)
	  );
	};

	/**
	 * Parse the given `str` and return milliseconds.
	 *
	 * @param {String} str
	 * @return {Number}
	 * @api private
	 */

	function parse(str) {
	  str = String(str);
	  if (str.length > 100) {
	    return;
	  }
	  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
	    str
	  );
	  if (!match) {
	    return;
	  }
	  var n = parseFloat(match[1]);
	  var type = (match[2] || 'ms').toLowerCase();
	  switch (type) {
	    case 'years':
	    case 'year':
	    case 'yrs':
	    case 'yr':
	    case 'y':
	      return n * y;
	    case 'weeks':
	    case 'week':
	    case 'w':
	      return n * w;
	    case 'days':
	    case 'day':
	    case 'd':
	      return n * d;
	    case 'hours':
	    case 'hour':
	    case 'hrs':
	    case 'hr':
	    case 'h':
	      return n * h;
	    case 'minutes':
	    case 'minute':
	    case 'mins':
	    case 'min':
	    case 'm':
	      return n * m;
	    case 'seconds':
	    case 'second':
	    case 'secs':
	    case 'sec':
	    case 's':
	      return n * s;
	    case 'milliseconds':
	    case 'millisecond':
	    case 'msecs':
	    case 'msec':
	    case 'ms':
	      return n;
	    default:
	      return undefined;
	  }
	}

	/**
	 * Short format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtShort(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return Math.round(ms / d) + 'd';
	  }
	  if (msAbs >= h) {
	    return Math.round(ms / h) + 'h';
	  }
	  if (msAbs >= m) {
	    return Math.round(ms / m) + 'm';
	  }
	  if (msAbs >= s) {
	    return Math.round(ms / s) + 's';
	  }
	  return ms + 'ms';
	}

	/**
	 * Long format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtLong(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return plural(ms, msAbs, d, 'day');
	  }
	  if (msAbs >= h) {
	    return plural(ms, msAbs, h, 'hour');
	  }
	  if (msAbs >= m) {
	    return plural(ms, msAbs, m, 'minute');
	  }
	  if (msAbs >= s) {
	    return plural(ms, msAbs, s, 'second');
	  }
	  return ms + ' ms';
	}

	/**
	 * Pluralization helper.
	 */

	function plural(ms, msAbs, n, name) {
	  var isPlural = msAbs >= n * 1.5;
	  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
	}
	return ms;
}

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = requireMs();
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;
		let namespacesCache;
		let enabledCache;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => {
				if (enableOverride !== null) {
					return enableOverride;
				}
				if (namespacesCache !== createDebug.namespaces) {
					namespacesCache = createDebug.namespaces;
					enabledCache = createDebug.enabled(namespace);
				}

				return enabledCache;
			},
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);
		createDebug.namespaces = namespaces;

		createDebug.names = [];
		createDebug.skips = [];

		let i;
		const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
		const len = split.length;

		for (i = 0; i < len; i++) {
			if (!split[i]) {
				// ignore empty strings
				continue;
			}

			namespaces = split[i].replace(/\*/g, '.*?');

			if (namespaces[0] === '-') {
				createDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));
			} else {
				createDebug.names.push(new RegExp('^' + namespaces + '$'));
			}
		}
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names.map(toNamespace),
			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		if (name[name.length - 1] === '*') {
			return true;
		}

		let i;
		let len;

		for (i = 0, len = createDebug.skips.length; i < len; i++) {
			if (createDebug.skips[i].test(name)) {
				return false;
			}
		}

		for (i = 0, len = createDebug.names.length; i < len; i++) {
			if (createDebug.names[i].test(name)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Convert regexp to namespace
	*
	* @param {RegExp} regxep
	* @return {String} namespace
	* @api private
	*/
	function toNamespace(regexp) {
		return regexp.toString()
			.substring(2, regexp.toString().length - 2)
			.replace(/\.\*\?$/, '*');
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

var common = setup;

/* eslint-env browser */

(function (module, exports) {
	/**
	 * This is the web browser implementation of `debug()`.
	 */

	exports.formatArgs = formatArgs;
	exports.save = save;
	exports.load = load;
	exports.useColors = useColors;
	exports.storage = localstorage();
	exports.destroy = (() => {
		let warned = false;

		return () => {
			if (!warned) {
				warned = true;
				console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
			}
		};
	})();

	/**
	 * Colors.
	 */

	exports.colors = [
		'#0000CC',
		'#0000FF',
		'#0033CC',
		'#0033FF',
		'#0066CC',
		'#0066FF',
		'#0099CC',
		'#0099FF',
		'#00CC00',
		'#00CC33',
		'#00CC66',
		'#00CC99',
		'#00CCCC',
		'#00CCFF',
		'#3300CC',
		'#3300FF',
		'#3333CC',
		'#3333FF',
		'#3366CC',
		'#3366FF',
		'#3399CC',
		'#3399FF',
		'#33CC00',
		'#33CC33',
		'#33CC66',
		'#33CC99',
		'#33CCCC',
		'#33CCFF',
		'#6600CC',
		'#6600FF',
		'#6633CC',
		'#6633FF',
		'#66CC00',
		'#66CC33',
		'#9900CC',
		'#9900FF',
		'#9933CC',
		'#9933FF',
		'#99CC00',
		'#99CC33',
		'#CC0000',
		'#CC0033',
		'#CC0066',
		'#CC0099',
		'#CC00CC',
		'#CC00FF',
		'#CC3300',
		'#CC3333',
		'#CC3366',
		'#CC3399',
		'#CC33CC',
		'#CC33FF',
		'#CC6600',
		'#CC6633',
		'#CC9900',
		'#CC9933',
		'#CCCC00',
		'#CCCC33',
		'#FF0000',
		'#FF0033',
		'#FF0066',
		'#FF0099',
		'#FF00CC',
		'#FF00FF',
		'#FF3300',
		'#FF3333',
		'#FF3366',
		'#FF3399',
		'#FF33CC',
		'#FF33FF',
		'#FF6600',
		'#FF6633',
		'#FF9900',
		'#FF9933',
		'#FFCC00',
		'#FFCC33'
	];

	/**
	 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
	 * and the Firebug extension (any Firefox version) are known
	 * to support "%c" CSS customizations.
	 *
	 * TODO: add a `localStorage` variable to explicitly enable/disable colors
	 */

	// eslint-disable-next-line complexity
	function useColors() {
		// NB: In an Electron preload script, document will be defined but not fully
		// initialized. Since we know we're in Chrome, we'll just detect this case
		// explicitly
		if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
			return true;
		}

		// Internet Explorer and Edge do not support colors.
		if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {
			return false;
		}

		let m;

		// Is webkit? http://stackoverflow.com/a/16459606/376773
		// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
		return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||
			// Is firebug? http://stackoverflow.com/a/398120/376773
			(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
			// Is firefox >= v31?
			// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
			(typeof navigator !== 'undefined' && navigator.userAgent && (m = navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/)) && parseInt(m[1], 10) >= 31) ||
			// Double check webkit in userAgent just in case we are in a worker
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));
	}

	/**
	 * Colorize log arguments if enabled.
	 *
	 * @api public
	 */

	function formatArgs(args) {
		args[0] = (this.useColors ? '%c' : '') +
			this.namespace +
			(this.useColors ? ' %c' : ' ') +
			args[0] +
			(this.useColors ? '%c ' : ' ') +
			'+' + module.exports.humanize(this.diff);

		if (!this.useColors) {
			return;
		}

		const c = 'color: ' + this.color;
		args.splice(1, 0, c, 'color: inherit');

		// The final "%c" is somewhat tricky, because there could be other
		// arguments passed either before or after the %c, so we need to
		// figure out the correct index to insert the CSS into
		let index = 0;
		let lastC = 0;
		args[0].replace(/%[a-zA-Z%]/g, match => {
			if (match === '%%') {
				return;
			}
			index++;
			if (match === '%c') {
				// We only are interested in the *last* %c
				// (the user may have provided their own)
				lastC = index;
			}
		});

		args.splice(lastC, 0, c);
	}

	/**
	 * Invokes `console.debug()` when available.
	 * No-op when `console.debug` is not a "function".
	 * If `console.debug` is not available, falls back
	 * to `console.log`.
	 *
	 * @api public
	 */
	exports.log = console.debug || console.log || (() => {});

	/**
	 * Save `namespaces`.
	 *
	 * @param {String} namespaces
	 * @api private
	 */
	function save(namespaces) {
		try {
			if (namespaces) {
				exports.storage.setItem('debug', namespaces);
			} else {
				exports.storage.removeItem('debug');
			}
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	/**
	 * Load `namespaces`.
	 *
	 * @return {String} returns the previously persisted debug modes
	 * @api private
	 */
	function load() {
		let r;
		try {
			r = exports.storage.getItem('debug');
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}

		// If debug isn't set in LS, and we're in Electron, try to load $DEBUG
		if (!r && typeof process !== 'undefined' && 'env' in process) {
			r = process.env.DEBUG;
		}

		return r;
	}

	/**
	 * Localstorage attempts to return the localstorage.
	 *
	 * This is necessary because safari throws
	 * when a user disables cookies/localstorage
	 * and you attempt to access it.
	 *
	 * @return {LocalStorage}
	 * @api private
	 */

	function localstorage() {
		try {
			// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
			// The Browser also has localStorage in the global context.
			return localStorage;
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	module.exports = common(exports);

	const {formatters} = module.exports;

	/**
	 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
	 */

	formatters.j = function (v) {
		try {
			return JSON.stringify(v);
		} catch (error) {
			return '[UnexpectedJSONParseError]: ' + error.message;
		}
	}; 
} (browser, browser.exports));

var browserExports = browser.exports;
var debug = /*@__PURE__*/getDefaultExportFromCjs(browserExports);

const APP_NAME = "waku";
class Logger {
    _info;
    _warn;
    _error;
    static createDebugNamespace(level, prefix) {
        return prefix ? `${APP_NAME}:${level}:${prefix}` : `${APP_NAME}:${level}`;
    }
    constructor(prefix) {
        this._info = debug(Logger.createDebugNamespace("info", prefix));
        this._warn = debug(Logger.createDebugNamespace("warn", prefix));
        this._error = debug(Logger.createDebugNamespace("error", prefix));
    }
    get info() {
        return this._info;
    }
    get warn() {
        return this._warn;
    }
    get error() {
        return this._error;
    }
    log(level, ...args) {
        const logger = this[level];
        logger(...args);
    }
}

export { Logger, contentTopicToPubsubTopic, contentTopicToShardIndex, contentTopicsByPubsubTopic, decodeRelayShard, delay, derivePubsubTopicsFromNetworkConfig, determinePubsubTopic, encodeRelayShard, ensurePubsubTopicIsConfigured, ensureShardingConfigured, ensureValidContentTopic, getPseudoRandomSubset, getWsMultiaddrFromMultiaddrs, groupByContentTopic, isAutoSharding, isDefined, isMessageSizeUnderCap, isStaticSharding, isWireSizeUnderCap, pubsubTopicToSingleShardInfo, pubsubTopicsToShardInfo, pushOrInitMapSet, removeItemFromArray, shardInfoToPubsubTopics, singleShardInfoToPubsubTopic, singleShardInfosToShardInfo, toAsyncIterator };
